307 (array([22]),) False
   1040/500000: episode: 26, duration: 35.619s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 26.050 [1.000, 56.000], mean observation: -0.059 [-1.000, 1.000], loss: 23.370504, mean_absolute_error: 1.778437, mean_q: 8.055533
842 (array([22]),) False
   1080/500000: episode: 27, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 27.150 [6.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 9.051602, mean_absolute_error: 1.509034, mean_q: 6.971128
747 (array([22]),) False
   1120/500000: episode: 28, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 23.575 [1.000, 56.000], mean observation: -0.128 [-1.000, 1.000], loss: 3.116211, mean_absolute_error: 1.336189, mean_q: 5.245014
238 (array([22]),) False
   1160/500000: episode: 29, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 25.875 [0.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 1.465727, mean_absolute_error: 1.474954, mean_q: 4.572031
346 (array([12]),) False
   1200/500000: episode: 30, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 26.375 [3.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.833427, mean_absolute_error: 1.364319, mean_q: 3.792943
726 (array([12]),) False
   1240/500000: episode: 31, duration: 32.109s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 18.800 [2.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.518286, mean_absolute_error: 1.356652, mean_q: 3.416084
155 (array([22]),) False
   1280/500000: episode: 32, duration: 32.090s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.850 [0.000, 58.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.366752, mean_absolute_error: 1.343537, mean_q: 3.113736
832 (array([22]),) False
   1320/500000: episode: 33, duration: 32.165s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.075 [0.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.277667, mean_absolute_error: 1.292364, mean_q: 2.831109
501 (array([12]),) False
   1360/500000: episode: 34, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.350 [0.000, 51.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.215287, mean_absolute_error: 1.210194, mean_q: 2.548092
724 (array([58]),) False
   1400/500000: episode: 35, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.700 [2.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.173407, mean_absolute_error: 1.132454, mean_q: 2.362362
498 (array([12]),) False
   1440/500000: episode: 36, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 39.675 [0.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.151279, mean_absolute_error: 1.040090, mean_q: 2.183599
343 (array([22]),) False
   1480/500000: episode: 37, duration: 32.066s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.550 [3.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.135817, mean_absolute_error: 1.000883, mean_q: 2.076402
319 (array([33]),) False
   1520/500000: episode: 38, duration: 33.328s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 33.375 [4.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.122898, mean_absolute_error: 0.955176, mean_q: 1.982705
777 (array([48]),) False
   1560/500000: episode: 39, duration: 33.304s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 20.100 [2.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.109805, mean_absolute_error: 0.913093, mean_q: 1.906705
761 (array([3]),) False
   1600/500000: episode: 40, duration: 33.311s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.500 [0.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.110378, mean_absolute_error: 0.895331, mean_q: 1.871327
420 (array([22]),) False
   1640/500000: episode: 41, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 21.850 [2.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.103951, mean_absolute_error: 0.887559, mean_q: 1.826350
658 (array([48]),) False
   1680/500000: episode: 42, duration: 33.260s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.300 [8.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.100108, mean_absolute_error: 0.842393, mean_q: 1.768519
131 (array([22]),) False
   1720/500000: episode: 43, duration: 33.146s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 22.450 [3.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.095314, mean_absolute_error: 0.849834, mean_q: 1.784286
225 (array([48]),) False
   1760/500000: episode: 44, duration: 33.324s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.000 [1.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.094590, mean_absolute_error: 0.830113, mean_q: 1.744187
841 (array([21]),) False
   1800/500000: episode: 45, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.875 [5.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.091605, mean_absolute_error: 0.843516, mean_q: 1.730494
633 (array([22]),) False
   1840/500000: episode: 46, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 28.675 [4.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.090231, mean_absolute_error: 0.833096, mean_q: 1.712466
274 (array([12]),) False
   1880/500000: episode: 47, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 21.950 [0.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.082750, mean_absolute_error: 0.834951, mean_q: 1.727218
326 (array([48]),) False
   1920/500000: episode: 48, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 28.050 [3.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.086212, mean_absolute_error: 0.834875, mean_q: 1.722968
86 (array([22]),) False
   1960/500000: episode: 49, duration: 32.081s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.825 [0.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.084308, mean_absolute_error: 0.847643, mean_q: 1.728038
128 (array([22]),) False
   2000/500000: episode: 50, duration: 32.985s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.675 [1.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.082949, mean_absolute_error: 0.845352, mean_q: 1.726123
825 (array([22]),) False
   2040/500000: episode: 51, duration: 31.393s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.625 [2.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.081012, mean_absolute_error: 0.859923, mean_q: 1.753942
349 (array([48]),) False
   2080/500000: episode: 52, duration: 31.013s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.425 [6.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.082412, mean_absolute_error: 0.882379, mean_q: 1.759862
310 (array([12]),) False
   2120/500000: episode: 53, duration: 31.260s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 20.425 [0.000, 54.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.082936, mean_absolute_error: 0.891812, mean_q: 1.771729
627 (array([48]),) False
   2160/500000: episode: 54, duration: 31.101s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 44.000 [3.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.082209, mean_absolute_error: 0.898163, mean_q: 1.793318
216 (array([22]),) False
   2200/500000: episode: 55, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.775 [0.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.088967, mean_absolute_error: 0.927614, mean_q: 1.796599
482 (array([22]),) False
   2240/500000: episode: 56, duration: 32.113s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 24.250 [2.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.083311, mean_absolute_error: 0.925033, mean_q: 1.808924
384 (array([22]),) False
   2280/500000: episode: 57, duration: 30.381s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.050 [0.000, 59.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.083478, mean_absolute_error: 0.942731, mean_q: 1.824167
671 (array([57]),) False
   2320/500000: episode: 58, duration: 32.113s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.700 [2.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.083318, mean_absolute_error: 0.947578, mean_q: 1.827790
468 (array([22]),) False
   2360/500000: episode: 59, duration: 32.199s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.425 [4.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.080150, mean_absolute_error: 0.963369, mean_q: 1.838355
716 (array([48]),) False
   2400/500000: episode: 60, duration: 32.266s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 42.025 [6.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.079106, mean_absolute_error: 0.976824, mean_q: 1.854226
102 (array([22]),) False
   2440/500000: episode: 61, duration: 31.120s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 23.600 [0.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.080092, mean_absolute_error: 0.987692, mean_q: 1.869139
120 (array([44]),) False
   2480/500000: episode: 62, duration: 31.572s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.300 [0.000, 59.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.084596, mean_absolute_error: 1.002302, mean_q: 1.867214
604 (array([40]),) False
   2520/500000: episode: 63, duration: 31.912s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.750 [0.000, 54.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.079230, mean_absolute_error: 1.029540, mean_q: 1.898316
50 (array([22]),) False
   2560/500000: episode: 64, duration: 32.587s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 26.175 [5.000, 54.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.081619, mean_absolute_error: 1.038164, mean_q: 1.877669
116 (array([22]),) False
   2600/500000: episode: 65, duration: 30.397s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.500 [3.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.081851, mean_absolute_error: 1.040586, mean_q: 1.905792
162 (array([22]),) False
   2640/500000: episode: 66, duration: 31.811s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.550 [0.000, 60.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.082405, mean_absolute_error: 1.061519, mean_q: 1.923074
827 (array([14]),) False
   2680/500000: episode: 67, duration: 31.929s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 29.000 [0.000, 51.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.085894, mean_absolute_error: 1.059236, mean_q: 1.910991
561 (array([22]),) False
   2720/500000: episode: 68, duration: 31.104s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 27.800 [0.000, 57.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.080501, mean_absolute_error: 1.081359, mean_q: 1.939455
86 (array([22]),) False
   2760/500000: episode: 69, duration: 31.393s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.725 [4.000, 54.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.083413, mean_absolute_error: 1.092761, mean_q: 1.934644
448 (array([12]),) False
   2800/500000: episode: 70, duration: 32.345s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.400 [4.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.082603, mean_absolute_error: 1.097473, mean_q: 1.945752
590 (array([22]),) False
   2840/500000: episode: 71, duration: 31.379s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.075 [3.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.084289, mean_absolute_error: 1.117011, mean_q: 1.952277
251 (array([3]),) False
   2880/500000: episode: 72, duration: 32.080s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 19.775 [3.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.085340, mean_absolute_error: 1.124617, mean_q: 1.974608
608 (array([36]),) False
   2920/500000: episode: 73, duration: 31.462s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 26.225 [1.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.087064, mean_absolute_error: 1.134529, mean_q: 1.963676
291 (array([22]),) False
   2960/500000: episode: 74, duration: 31.731s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.100 [1.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.087024, mean_absolute_error: 1.145238, mean_q: 1.978001
471 (array([12]),) False
   3000/500000: episode: 75, duration: 30.758s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 25.700 [1.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.084198, mean_absolute_error: 1.144667, mean_q: 1.975655
603 (array([58]),) False
   3040/500000: episode: 76, duration: 31.613s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.775 [3.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.088749, mean_absolute_error: 1.157925, mean_q: 1.984074
360 (array([22]),) False
   3080/500000: episode: 77, duration: 32.395s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.425 [0.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.092528, mean_absolute_error: 1.164548, mean_q: 1.969043
832 (array([22]),) False
   3120/500000: episode: 78, duration: 31.480s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.100 [3.000, 50.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.085185, mean_absolute_error: 1.175486, mean_q: 2.007062
5 (array([37]),) False
   3160/500000: episode: 79, duration: 31.195s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.075 [1.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.086062, mean_absolute_error: 1.183388, mean_q: 2.001910
433 (array([22]),) False
   3200/500000: episode: 80, duration: 31.452s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.875 [6.000, 58.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.089435, mean_absolute_error: 1.210357, mean_q: 2.024937
251 (array([3]),) False
   3240/500000: episode: 81, duration: 32.407s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 18.950 [3.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.084527, mean_absolute_error: 1.222556, mean_q: 2.036152
462 (array([12]),) False
   3280/500000: episode: 82, duration: 31.127s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.025 [10.000, 56.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.087958, mean_absolute_error: 1.229534, mean_q: 2.038945
2 (array([12]),) False
   3320/500000: episode: 83, duration: 30.065s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.725 [0.000, 60.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.084706, mean_absolute_error: 1.234757, mean_q: 2.054913
770 (array([22]),) False
   3360/500000: episode: 84, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 28.800 [2.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.087010, mean_absolute_error: 1.235036, mean_q: 2.046195
802 (array([22]),) False
   3400/500000: episode: 85, duration: 30.854s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.925 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.090018, mean_absolute_error: 1.248364, mean_q: 2.035876
502 (array([22]),) False
   3440/500000: episode: 86, duration: 31.044s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.900 [9.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.087996, mean_absolute_error: 1.249892, mean_q: 2.037139
252 (array([22]),) False
   3480/500000: episode: 87, duration: 30.104s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 26.950 [0.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.091074, mean_absolute_error: 1.249686, mean_q: 2.027951
121 (array([22]),) False
   3520/500000: episode: 88, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 26.900 [0.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.092264, mean_absolute_error: 1.247378, mean_q: 2.028637
804 (array([3]),) False
   3560/500000: episode: 89, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 16.250 [1.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.087582, mean_absolute_error: 1.271610, mean_q: 2.067299
599 (array([48]),) False
   3600/500000: episode: 90, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 38.400 [3.000, 49.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.089975, mean_absolute_error: 1.282059, mean_q: 2.070436
428 (array([22]),) False
   3640/500000: episode: 91, duration: 30.284s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.025 [11.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.088859, mean_absolute_error: 1.288431, mean_q: 2.095936
747 (array([22]),) False
   3680/500000: episode: 92, duration: 30.976s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 28.275 [0.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.090734, mean_absolute_error: 1.289958, mean_q: 2.090413
328 (array([12]),) False
   3720/500000: episode: 93, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 29.800 [4.000, 49.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.087496, mean_absolute_error: 1.323268, mean_q: 2.127561
139 (array([48]),) False
   3760/500000: episode: 94, duration: 31.103s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 27.700 [7.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.089552, mean_absolute_error: 1.321082, mean_q: 2.122032
90 (array([22]),) False
   3800/500000: episode: 95, duration: 30.481s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 28.325 [1.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.085981, mean_absolute_error: 1.329612, mean_q: 2.146119
147 (array([44]),) False
   3840/500000: episode: 96, duration: 31.144s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 25.250 [1.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.086734, mean_absolute_error: 1.341237, mean_q: 2.133487
43 (array([12]),) False
   3880/500000: episode: 97, duration: 31.030s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 33.000 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.091198, mean_absolute_error: 1.349519, mean_q: 2.150753
744 (array([22]),) False
   3920/500000: episode: 98, duration: 31.794s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.900 [1.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.086422, mean_absolute_error: 1.360795, mean_q: 2.167553
296 (array([22]),) False
   3960/500000: episode: 99, duration: 30.423s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.900 [1.000, 57.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.094623, mean_absolute_error: 1.360819, mean_q: 2.154316
242 (array([22]),) False
   4000/500000: episode: 100, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 21.150 [0.000, 52.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.090518, mean_absolute_error: 1.383214, mean_q: 2.168283
490 (array([12]),) False
   4040/500000: episode: 101, duration: 31.111s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 19.725 [0.000, 54.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.098891, mean_absolute_error: 1.376869, mean_q: 2.158338
456 (array([22]),) False
   4080/500000: episode: 102, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 33.300 [1.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.093493, mean_absolute_error: 1.387889, mean_q: 2.153352
631 (array([22]),) False
   4120/500000: episode: 103, duration: 30.213s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.800 [0.000, 60.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.087755, mean_absolute_error: 1.405676, mean_q: 2.203722
743 (array([48]),) False
   4160/500000: episode: 104, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 29.375 [0.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.094301, mean_absolute_error: 1.415695, mean_q: 2.184218
445 (array([22]),) False
   4200/500000: episode: 105, duration: 30.897s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 28.000 [7.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.092766, mean_absolute_error: 1.433692, mean_q: 2.214360
335 (array([22]),) False
   4240/500000: episode: 106, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.150 [0.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.091279, mean_absolute_error: 1.449126, mean_q: 2.229363
127 (array([22]),) False
   4280/500000: episode: 107, duration: 30.317s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.925 [0.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.096640, mean_absolute_error: 1.458499, mean_q: 2.233701
319 (array([33]),) False
   4320/500000: episode: 108, duration: 31.041s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.350 [8.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.091226, mean_absolute_error: 1.478846, mean_q: 2.271374
496 (array([48]),) False
   4360/500000: episode: 109, duration: 31.035s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 39.125 [5.000, 53.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.092191, mean_absolute_error: 1.486601, mean_q: 2.288594
199 (array([22]),) False
   4400/500000: episode: 110, duration: 31.221s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.050 [0.000, 56.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.095363, mean_absolute_error: 1.494269, mean_q: 2.284317
747 (array([22]),) False
   4440/500000: episode: 111, duration: 30.192s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.250 [2.000, 56.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.094516, mean_absolute_error: 1.520943, mean_q: 2.321263
109 (array([48]),) False
   4480/500000: episode: 112, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 26.325 [1.000, 52.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.096841, mean_absolute_error: 1.527992, mean_q: 2.334768
514 (array([54]),) False
   4520/500000: episode: 113, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.925 [0.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.096522, mean_absolute_error: 1.533161, mean_q: 2.333650
321 (array([22]),) False
   4560/500000: episode: 114, duration: 31.022s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 20.075 [2.000, 47.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.099166, mean_absolute_error: 1.546406, mean_q: 2.335412
340 (array([12]),) False
   4600/500000: episode: 115, duration: 30.265s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.550 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.095009, mean_absolute_error: 1.542366, mean_q: 2.337372
828 (array([48]),) False
   4640/500000: episode: 116, duration: 31.075s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 27.575 [4.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.105723, mean_absolute_error: 1.564753, mean_q: 2.339828
667 (array([48]),) False
   4680/500000: episode: 117, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 42.575 [11.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.098380, mean_absolute_error: 1.572310, mean_q: 2.350454
307 (array([22]),) False
   4720/500000: episode: 118, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.875 [2.000, 58.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.096358, mean_absolute_error: 1.570751, mean_q: 2.360355
556 (array([48]),) False
   4760/500000: episode: 119, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 37.900 [4.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.095780, mean_absolute_error: 1.595902, mean_q: 2.392003
74 (array([22]),) False
   4800/500000: episode: 120, duration: 31.502s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.375 [0.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.102342, mean_absolute_error: 1.600040, mean_q: 2.387768
620 (array([44]),) False
   4840/500000: episode: 121, duration: 31.577s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 25.925 [3.000, 57.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.096094, mean_absolute_error: 1.608739, mean_q: 2.401634
21 (array([3]),) False
   4880/500000: episode: 122, duration: 31.600s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 28.325 [3.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.096301, mean_absolute_error: 1.609076, mean_q: 2.402283
720 (array([22]),) False
   4920/500000: episode: 123, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.875 [5.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.097373, mean_absolute_error: 1.624760, mean_q: 2.410424
169 (array([22]),) False
   4960/500000: episode: 124, duration: 31.470s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 25.475 [2.000, 57.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.098127, mean_absolute_error: 1.630397, mean_q: 2.420326
859 (array([22]),) False
   5000/500000: episode: 125, duration: 31.424s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.875 [7.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.096191, mean_absolute_error: 1.633240, mean_q: 2.426929
708 (array([40]),) False
   5040/500000: episode: 126, duration: 31.553s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.725 [0.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.095514, mean_absolute_error: 1.654620, mean_q: 2.451610
676 (array([40]),) False
   5080/500000: episode: 127, duration: 31.082s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 20.425 [0.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.096537, mean_absolute_error: 1.656487, mean_q: 2.465255
5 (array([37]),) False
   5120/500000: episode: 128, duration: 31.449s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.575 [0.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.106056, mean_absolute_error: 1.676485, mean_q: 2.471196
186 (array([22]),) False
   5160/500000: episode: 129, duration: 31.546s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.700 [0.000, 58.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.098634, mean_absolute_error: 1.675715, mean_q: 2.470834
328 (array([12]),) False
   5200/500000: episode: 130, duration: 31.173s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 21.650 [0.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.106243, mean_absolute_error: 1.685087, mean_q: 2.478832
382 (array([22]),) False
   5240/500000: episode: 131, duration: 30.103s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.525 [0.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.102313, mean_absolute_error: 1.695948, mean_q: 2.514506
381 (array([22]),) False
   5280/500000: episode: 132, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 28.525 [9.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.102441, mean_absolute_error: 1.700743, mean_q: 2.488784
122 (array([12]),) False
   5320/500000: episode: 133, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 24.800 [1.000, 56.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.099744, mean_absolute_error: 1.723832, mean_q: 2.512092
49 (array([22]),) False
   5360/500000: episode: 134, duration: 30.848s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.475 [1.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.101745, mean_absolute_error: 1.725518, mean_q: 2.535962
325 (array([22]),) False
   5400/500000: episode: 135, duration: 30.119s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.825 [0.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.103654, mean_absolute_error: 1.734121, mean_q: 2.551388
523 (array([22]),) False
   5440/500000: episode: 136, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.475 [6.000, 56.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.102631, mean_absolute_error: 1.762031, mean_q: 2.563644
531 (array([22]),) False
   5480/500000: episode: 137, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.625 [0.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.105928, mean_absolute_error: 1.750384, mean_q: 2.564460
792 (array([58]),) False
   5520/500000: episode: 138, duration: 30.843s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.325 [1.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.108741, mean_absolute_error: 1.764226, mean_q: 2.562127
489 (array([22]),) False
   5560/500000: episode: 139, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 30.775 [3.000, 55.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.108605, mean_absolute_error: 1.793504, mean_q: 2.588897
663 (array([22]),) False
   5600/500000: episode: 140, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 20.175 [3.000, 54.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.102233, mean_absolute_error: 1.803908, mean_q: 2.613056
276 (array([56]),) False
   5640/500000: episode: 141, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.775 [0.000, 58.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.097161, mean_absolute_error: 1.816769, mean_q: 2.640307
26 (array([22]),) False
   5680/500000: episode: 142, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.850 [0.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.103014, mean_absolute_error: 1.851375, mean_q: 2.648496
235 (array([14]),) False
   5720/500000: episode: 143, duration: 30.114s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 30.975 [0.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.115764, mean_absolute_error: 1.860248, mean_q: 2.665926
668 (array([22]),) False
   5760/500000: episode: 144, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 26.025 [4.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.109945, mean_absolute_error: 1.861849, mean_q: 2.686860
591 (array([22]),) False
   5800/500000: episode: 145, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 26.400 [1.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.106634, mean_absolute_error: 1.893055, mean_q: 2.693583
397 (array([22]),) False
   5840/500000: episode: 146, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.175 [2.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.117708, mean_absolute_error: 1.894493, mean_q: 2.708721
741 (array([22]),) False
   5880/500000: episode: 147, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.025 [3.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.113932, mean_absolute_error: 1.913292, mean_q: 2.716816
150 (array([22]),) False
   5920/500000: episode: 148, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.425 [0.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.105430, mean_absolute_error: 1.930546, mean_q: 2.738509
810 (array([12]),) False
   5960/500000: episode: 149, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.425 [6.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.113562, mean_absolute_error: 1.932223, mean_q: 2.755232
151 (array([22]),) False
   6000/500000: episode: 150, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.000 [3.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.115783, mean_absolute_error: 1.952953, mean_q: 2.754467
252 (array([22]),) False
   6040/500000: episode: 151, duration: 30.096s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 28.075 [8.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.112746, mean_absolute_error: 1.962657, mean_q: 2.775507
452 (array([22]),) False
   6080/500000: episode: 152, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 26.500 [1.000, 60.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.116898, mean_absolute_error: 1.975662, mean_q: 2.791773
513 (array([12]),) False
   6120/500000: episode: 153, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 29.800 [6.000, 59.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.108004, mean_absolute_error: 1.998436, mean_q: 2.814378
709 (array([41]),) False
   6160/500000: episode: 154, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.875 [0.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.117716, mean_absolute_error: 2.005307, mean_q: 2.796989
77 (array([22]),) False
   6200/500000: episode: 155, duration: 30.087s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.475 [1.000, 59.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.118971, mean_absolute_error: 2.006802, mean_q: 2.809026
533 (array([22]),) False
   6240/500000: episode: 156, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 28.300 [2.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.113391, mean_absolute_error: 2.051951, mean_q: 2.856398
852 (array([44]),) False
   6280/500000: episode: 157, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.175 [0.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.118776, mean_absolute_error: 2.047770, mean_q: 2.870989
534 (array([22]),) False
   6320/500000: episode: 158, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 27.975 [5.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.117020, mean_absolute_error: 2.060581, mean_q: 2.879817
716 (array([48]),) False
   6360/500000: episode: 159, duration: 30.114s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 38.900 [3.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.113083, mean_absolute_error: 2.086425, mean_q: 2.882761
570 (array([47]),) False
   6400/500000: episode: 160, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.450 [3.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.115280, mean_absolute_error: 2.087069, mean_q: 2.900826
804 (array([3]),) False
   6440/500000: episode: 161, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 15.400 [3.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.124904, mean_absolute_error: 2.096726, mean_q: 2.907766
464 (array([22]),) False
   6480/500000: episode: 162, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.875 [2.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.111020, mean_absolute_error: 2.112288, mean_q: 2.933054
493 (array([22]),) False
   6520/500000: episode: 163, duration: 30.113s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 29.000 [3.000, 60.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.118932, mean_absolute_error: 2.120187, mean_q: 2.932691
613 (array([22]),) False
   6560/500000: episode: 164, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.675 [0.000, 51.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.109088, mean_absolute_error: 2.152683, mean_q: 2.954130
105 (array([22]),) False
   6600/500000: episode: 165, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 28.050 [22.000, 57.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.123308, mean_absolute_error: 2.161774, mean_q: 2.967650
673 (array([3]),) False
   6640/500000: episode: 166, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 14.475 [1.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.118793, mean_absolute_error: 2.177359, mean_q: 3.002275
809 (array([48]),) False
   6680/500000: episode: 167, duration: 30.083s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 33.125 [0.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.113846, mean_absolute_error: 2.201344, mean_q: 3.028692
414 (array([48]),) False
   6720/500000: episode: 168, duration: 31.068s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.400 [0.000, 56.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.128584, mean_absolute_error: 2.201828, mean_q: 3.030304
132 (array([22]),) False
   6760/500000: episode: 169, duration: 31.233s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.350 [2.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.126811, mean_absolute_error: 2.237534, mean_q: 3.046433
125 (array([58]),) False
   6800/500000: episode: 170, duration: 31.662s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 41.075 [2.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.130291, mean_absolute_error: 2.245290, mean_q: 3.075165
158 (array([22]),) False
   6840/500000: episode: 171, duration: 31.110s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.000 [3.000, 60.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.138486, mean_absolute_error: 2.252409, mean_q: 3.067805
632 (array([22]),) False
   6880/500000: episode: 172, duration: 31.582s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.475 [5.000, 58.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.123339, mean_absolute_error: 2.287680, mean_q: 3.125543
641 (array([22]),) False
   6920/500000: episode: 173, duration: 31.563s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.550 [4.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.127691, mean_absolute_error: 2.307117, mean_q: 3.125366
23 (array([48]),) False
   6960/500000: episode: 174, duration: 31.640s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 25.275 [6.000, 55.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.141157, mean_absolute_error: 2.301523, mean_q: 3.120298
35 (array([48]),) False
   7000/500000: episode: 175, duration: 31.100s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.475 [1.000, 59.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.120223, mean_absolute_error: 2.324036, mean_q: 3.154057
825 (array([22]),) False
   7040/500000: episode: 176, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 26.925 [4.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.128172, mean_absolute_error: 2.338134, mean_q: 3.172031
114 (array([22]),) False
   7080/500000: episode: 177, duration: 31.459s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.925 [1.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.137188, mean_absolute_error: 2.357065, mean_q: 3.185926
559 (array([59]),) False
   7120/500000: episode: 178, duration: 31.512s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.350 [1.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.141261, mean_absolute_error: 2.361144, mean_q: 3.197679
705 (array([22]),) False
   7160/500000: episode: 179, duration: 31.097s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.500 [1.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.124540, mean_absolute_error: 2.395284, mean_q: 3.229748
666 (array([22]),) False
   7200/500000: episode: 180, duration: 32.671s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.300 [11.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.141167, mean_absolute_error: 2.391040, mean_q: 3.211243
2 (array([12]),) False
   7240/500000: episode: 181, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.875 [2.000, 56.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.135020, mean_absolute_error: 2.411403, mean_q: 3.263655
309 (array([22]),) False
   7280/500000: episode: 182, duration: 33.371s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 30.675 [14.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.134437, mean_absolute_error: 2.416638, mean_q: 3.271047
27 (array([22]),) False
   7320/500000: episode: 183, duration: 31.313s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.650 [2.000, 59.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.136771, mean_absolute_error: 2.444028, mean_q: 3.287914
729 (array([22]),) False
   7360/500000: episode: 184, duration: 31.588s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 26.375 [1.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.143094, mean_absolute_error: 2.448008, mean_q: 3.294268
492 (array([22]),) False
   7400/500000: episode: 185, duration: 31.554s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.725 [0.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.137762, mean_absolute_error: 2.484482, mean_q: 3.322042
675 (array([22]),) False
   7440/500000: episode: 186, duration: 31.620s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.500 [1.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.150776, mean_absolute_error: 2.482759, mean_q: 3.321386
665 (array([12]),) False
   7480/500000: episode: 187, duration: 31.208s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.950 [1.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.143196, mean_absolute_error: 2.500722, mean_q: 3.340228
747 (array([22]),) False
   7520/500000: episode: 188, duration: 31.637s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.050 [8.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.147454, mean_absolute_error: 2.500846, mean_q: 3.347442
127 (array([22]),) False
   7560/500000: episode: 189, duration: 31.470s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.400 [5.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.130041, mean_absolute_error: 2.538512, mean_q: 3.375468
641 (array([22]),) False
   7600/500000: episode: 190, duration: 32.935s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.400 [1.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.148362, mean_absolute_error: 2.510823, mean_q: 3.363435
274 (array([12]),) False
   7640/500000: episode: 191, duration: 32.361s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 25.500 [5.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.148574, mean_absolute_error: 2.554061, mean_q: 3.385514
529 (array([3]),) False
   7680/500000: episode: 192, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 17.650 [3.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.153572, mean_absolute_error: 2.543913, mean_q: 3.400927
321 (array([22]),) False
   7720/500000: episode: 193, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.725 [5.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.155355, mean_absolute_error: 2.564784, mean_q: 3.398474
121 (array([22]),) False
   7760/500000: episode: 194, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 28.175 [9.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.149396, mean_absolute_error: 2.573681, mean_q: 3.435437
260 (array([22]),) False
   7800/500000: episode: 195, duration: 32.393s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 21.825 [3.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.157946, mean_absolute_error: 2.588256, mean_q: 3.452727
465 (array([48]),) False
   7840/500000: episode: 196, duration: 33.269s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.325 [8.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.144056, mean_absolute_error: 2.589210, mean_q: 3.431938
728 (array([12]),) False
   7880/500000: episode: 197, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 37.025 [8.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.151040, mean_absolute_error: 2.601169, mean_q: 3.451402
172 (array([12]),) False
   7920/500000: episode: 198, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.250 [7.000, 58.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.155608, mean_absolute_error: 2.609503, mean_q: 3.412831
298 (array([22]),) False
   7960/500000: episode: 199, duration: 32.324s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.975 [0.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.138495, mean_absolute_error: 2.608481, mean_q: 3.468222
78 (array([55]),) False
   8000/500000: episode: 200, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 22.850 [1.000, 47.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.152782, mean_absolute_error: 2.601948, mean_q: 3.441854
363 (array([36]),) False
   8040/500000: episode: 201, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 28.975 [4.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.138696, mean_absolute_error: 2.633441, mean_q: 3.458608
528 (array([12]),) False
   8080/500000: episode: 202, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 26.175 [0.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.142220, mean_absolute_error: 2.613761, mean_q: 3.461925
22 (array([37]),) False
   8120/500000: episode: 203, duration: 31.204s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 41.175 [11.000, 55.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.151991, mean_absolute_error: 2.625966, mean_q: 3.441559
812 (array([22]),) False
   8160/500000: episode: 204, duration: 31.572s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 25.175 [5.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.161063, mean_absolute_error: 2.639038, mean_q: 3.473843
815 (array([22]),) False
   8200/500000: episode: 205, duration: 31.459s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.350 [1.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.166583, mean_absolute_error: 2.641330, mean_q: 3.458878
411 (array([22]),) False
   8240/500000: episode: 206, duration: 31.614s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.325 [0.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.151112, mean_absolute_error: 2.663432, mean_q: 3.501850
127 (array([22]),) False
   8280/500000: episode: 207, duration: 31.177s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 26.025 [4.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.147545, mean_absolute_error: 2.697181, mean_q: 3.511723
233 (array([54]),) False
   8320/500000: episode: 208, duration: 31.560s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 27.575 [2.000, 57.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.152915, mean_absolute_error: 2.699114, mean_q: 3.532173
413 (array([22]),) False
   8360/500000: episode: 209, duration: 31.577s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 25.875 [0.000, 53.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.153383, mean_absolute_error: 2.715754, mean_q: 3.546593
480 (array([22]),) False
   8400/500000: episode: 210, duration: 31.595s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 28.300 [0.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.146199, mean_absolute_error: 2.727837, mean_q: 3.548535
409 (array([22]),) False
   8440/500000: episode: 211, duration: 31.107s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.150 [10.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.151249, mean_absolute_error: 2.739973, mean_q: 3.562756
376 (array([22]),) False
   8480/500000: episode: 212, duration: 31.527s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 31.725 [2.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.143308, mean_absolute_error: 2.745346, mean_q: 3.582972
773 (array([22]),) False
   8520/500000: episode: 213, duration: 31.572s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.225 [0.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.158252, mean_absolute_error: 2.762735, mean_q: 3.574363
402 (array([22]),) False
   8560/500000: episode: 214, duration: 32.737s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 27.350 [4.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.153226, mean_absolute_error: 2.757012, mean_q: 3.574965
396 (array([48]),) False
   8600/500000: episode: 215, duration: 31.146s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 37.800 [0.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.152753, mean_absolute_error: 2.746190, mean_q: 3.604073
240 (array([22]),) False
   8640/500000: episode: 216, duration: 31.503s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 29.275 [2.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.166383, mean_absolute_error: 2.771436, mean_q: 3.597291
774 (array([57]),) False
   8680/500000: episode: 217, duration: 31.492s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.250 [7.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.153759, mean_absolute_error: 2.777591, mean_q: 3.618001
552 (array([22]),) False
   8720/500000: episode: 218, duration: 31.571s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.350 [2.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.161610, mean_absolute_error: 2.779938, mean_q: 3.603129
424 (array([22]),) False
   8760/500000: episode: 219, duration: 31.060s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.075 [2.000, 58.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.147014, mean_absolute_error: 2.801063, mean_q: 3.627279
673 (array([3]),) False
   8800/500000: episode: 220, duration: 31.542s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 14.025 [3.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.164193, mean_absolute_error: 2.808222, mean_q: 3.638876
238 (array([22]),) False
   8840/500000: episode: 221, duration: 31.548s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 26.000 [1.000, 54.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.159022, mean_absolute_error: 2.827362, mean_q: 3.667549
319 (array([33]),) False
   8880/500000: episode: 222, duration: 31.510s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 23.500 [0.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.164678, mean_absolute_error: 2.808999, mean_q: 3.664681
192 (array([22]),) False
   8920/500000: episode: 223, duration: 31.113s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 26.350 [1.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.164433, mean_absolute_error: 2.848109, mean_q: 3.678443
575 (array([44]),) False
   8960/500000: episode: 224, duration: 31.504s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 28.975 [6.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.160355, mean_absolute_error: 2.855301, mean_q: 3.679673
490 (array([12]),) False
   9000/500000: episode: 225, duration: 31.870s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 18.375 [2.000, 54.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.167413, mean_absolute_error: 2.854256, mean_q: 3.684203
804 (array([3]),) False
   9040/500000: episode: 226, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 10.950 [3.000, 51.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.162701, mean_absolute_error: 2.859568, mean_q: 3.704156
18 (array([22]),) False
   9080/500000: episode: 227, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.750 [2.000, 54.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.174629, mean_absolute_error: 2.867145, mean_q: 3.693121
289 (array([21]),) False
   9120/500000: episode: 228, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 27.750 [4.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.167131, mean_absolute_error: 2.877596, mean_q: 3.707595
220 (array([22]),) False
   9160/500000: episode: 229, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 25.350 [0.000, 59.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.174123, mean_absolute_error: 2.891491, mean_q: 3.712781
741 (array([22]),) False
   9200/500000: episode: 230, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 29.350 [3.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.172217, mean_absolute_error: 2.905790, mean_q: 3.750230
24 (array([22]),) False
   9240/500000: episode: 231, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.550 [3.000, 59.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.173002, mean_absolute_error: 2.913790, mean_q: 3.776498
568 (array([22]),) False
   9280/500000: episode: 232, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.625 [6.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.178745, mean_absolute_error: 2.957437, mean_q: 3.792049
342 (array([12]),) False
   9320/500000: episode: 233, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.275 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.180877, mean_absolute_error: 2.964260, mean_q: 3.799532
745 (array([22]),) False
   9360/500000: episode: 234, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 28.475 [4.000, 56.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.181893, mean_absolute_error: 2.953369, mean_q: 3.823135
580 (array([22]),) False
   9400/500000: episode: 235, duration: 32.302s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.500 [1.000, 56.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.159652, mean_absolute_error: 2.997366, mean_q: 3.842099
150 (array([22]),) False
   9440/500000: episode: 236, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.100 [1.000, 47.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.178416, mean_absolute_error: 2.981860, mean_q: 3.837601
99 (array([22]),) False
   9480/500000: episode: 237, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.575 [0.000, 58.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.158032, mean_absolute_error: 3.014538, mean_q: 3.852349
765 (array([48]),) False
   9520/500000: episode: 238, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 28.350 [5.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.171009, mean_absolute_error: 3.008424, mean_q: 3.852001
592 (array([22]),) False
   9560/500000: episode: 239, duration: 32.258s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.650 [0.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.177279, mean_absolute_error: 2.989842, mean_q: 3.876771
538 (array([12]),) False
   9600/500000: episode: 240, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.775 [3.000, 44.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.170292, mean_absolute_error: 3.029462, mean_q: 3.879327
419 (array([40]),) False
   9640/500000: episode: 241, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.475 [8.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.160839, mean_absolute_error: 3.043305, mean_q: 3.880721
789 (array([22]),) False
   9680/500000: episode: 242, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.725 [0.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.174010, mean_absolute_error: 3.045600, mean_q: 3.883691
439 (array([12]),) False
   9720/500000: episode: 243, duration: 32.366s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.500 [0.000, 49.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.181469, mean_absolute_error: 3.025044, mean_q: 3.876514
548 (array([22]),) False
   9760/500000: episode: 244, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.050 [2.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.172674, mean_absolute_error: 3.051183, mean_q: 3.887933
607 (array([12]),) False
   9800/500000: episode: 245, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 27.350 [8.000, 53.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.193320, mean_absolute_error: 3.043633, mean_q: 3.860671
408 (array([12]),) False
   9840/500000: episode: 246, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.175 [4.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.151873, mean_absolute_error: 3.035481, mean_q: 3.893037
466 (array([22]),) False
   9880/500000: episode: 247, duration: 32.303s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 29.275 [14.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.164498, mean_absolute_error: 3.046978, mean_q: 3.893142
120 (array([44]),) False
   9920/500000: episode: 248, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 30.625 [0.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.181819, mean_absolute_error: 3.034892, mean_q: 3.871398
467 (array([48]),) False
   9960/500000: episode: 249, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.075 [2.000, 60.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.182220, mean_absolute_error: 3.052406, mean_q: 3.883947
500 (array([22]),) False
  10000/500000: episode: 250, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.350 [0.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.184381, mean_absolute_error: 3.072150, mean_q: 3.912175
706 (array([22]),) False
  10040/500000: episode: 251, duration: 32.332s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.975 [2.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.169172, mean_absolute_error: 3.075444, mean_q: 3.923839
396 (array([48]),) False
  10080/500000: episode: 252, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 41.425 [4.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.184298, mean_absolute_error: 3.091159, mean_q: 3.931900
104 (array([22]),) False
  10120/500000: episode: 253, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.950 [2.000, 50.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.177743, mean_absolute_error: 3.086042, mean_q: 3.934339
545 (array([22]),) False
  10160/500000: episode: 254, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.700 [5.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.177777, mean_absolute_error: 3.114020, mean_q: 3.945300
702 (array([22]),) False
  10200/500000: episode: 255, duration: 32.269s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.500 [0.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.178347, mean_absolute_error: 3.104644, mean_q: 3.940639
34 (array([22]),) False
  10240/500000: episode: 256, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.500 [0.000, 57.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.156895, mean_absolute_error: 3.120337, mean_q: 3.970611
271 (array([18]),) False
  10280/500000: episode: 257, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 25.025 [2.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.182483, mean_absolute_error: 3.108804, mean_q: 3.980422
567 (array([22]),) False
  10320/500000: episode: 258, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.475 [1.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.173443, mean_absolute_error: 3.140942, mean_q: 3.987237
439 (array([12]),) False
  10360/500000: episode: 259, duration: 32.337s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.150 [1.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.177197, mean_absolute_error: 3.147730, mean_q: 3.995170
93 (array([22]),) False
  10400/500000: episode: 260, duration: 32.406s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.825 [0.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.181221, mean_absolute_error: 3.142738, mean_q: 3.972167
746 (array([37]),) False
  10440/500000: episode: 261, duration: 31.556s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 38.675 [3.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.177868, mean_absolute_error: 3.166973, mean_q: 3.998596
110 (array([22]),) False
  10480/500000: episode: 262, duration: 31.486s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 25.150 [2.000, 48.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.182715, mean_absolute_error: 3.154384, mean_q: 3.985959
815 (array([22]),) False
  10520/500000: episode: 263, duration: 31.078s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.075 [11.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.195372, mean_absolute_error: 3.137581, mean_q: 4.007097
751 (array([22]),) False
  10560/500000: episode: 264, duration: 31.446s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 23.725 [2.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.169893, mean_absolute_error: 3.175612, mean_q: 4.017396
273 (array([22]),) False
  10600/500000: episode: 265, duration: 31.500s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.975 [1.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.177568, mean_absolute_error: 3.142739, mean_q: 4.008338
375 (array([22]),) False
  10640/500000: episode: 266, duration: 31.538s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.825 [0.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.179681, mean_absolute_error: 3.175931, mean_q: 4.015638
819 (array([48]),) False
  10680/500000: episode: 267, duration: 31.103s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.875 [8.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.172223, mean_absolute_error: 3.183800, mean_q: 4.038545
775 (array([58]),) False
  10720/500000: episode: 268, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 33.450 [0.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.195765, mean_absolute_error: 3.185895, mean_q: 4.026615
481 (array([22]),) False
  10760/500000: episode: 269, duration: 31.552s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.950 [4.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.183362, mean_absolute_error: 3.189891, mean_q: 4.019226
859 (array([22]),) False
  10800/500000: episode: 270, duration: 31.623s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.525 [1.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.157412, mean_absolute_error: 3.184324, mean_q: 4.041719
146 (array([12]),) False
  10840/500000: episode: 271, duration: 31.364s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 30.125 [0.000, 59.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.178929, mean_absolute_error: 3.183910, mean_q: 4.038199
63 (array([18]),) False
  10880/500000: episode: 272, duration: 32.644s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.925 [1.000, 51.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.188543, mean_absolute_error: 3.166878, mean_q: 4.027949
820 (array([48]),) False
  10920/500000: episode: 273, duration: 32.108s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.850 [4.000, 54.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.175519, mean_absolute_error: 3.208929, mean_q: 4.038036
561 (array([22]),) False
  10960/500000: episode: 274, duration: 31.924s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.900 [3.000, 55.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.193418, mean_absolute_error: 3.186515, mean_q: 4.022172
654 (array([22]),) False
  11000/500000: episode: 275, duration: 31.446s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.550 [1.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.172102, mean_absolute_error: 3.200232, mean_q: 4.045822
538 (array([12]),) False
  11040/500000: episode: 276, duration: 32.428s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 28.825 [6.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.184284, mean_absolute_error: 3.189126, mean_q: 4.032526
524 (array([22]),) False
  11080/500000: episode: 277, duration: 32.852s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.675 [1.000, 52.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.170708, mean_absolute_error: 3.211968, mean_q: 4.039477
723 (array([48]),) False
  11120/500000: episode: 278, duration: 32.685s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.500 [5.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.185510, mean_absolute_error: 3.202855, mean_q: 4.058137
34 (array([22]),) False
  11160/500000: episode: 279, duration: 32.091s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.275 [0.000, 60.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.186176, mean_absolute_error: 3.210794, mean_q: 4.055554
452 (array([22]),) False
  11200/500000: episode: 280, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 20.250 [2.000, 53.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.184269, mean_absolute_error: 3.210938, mean_q: 4.053805
673 (array([3]),) False
  11240/500000: episode: 281, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 17.300 [0.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.182114, mean_absolute_error: 3.217885, mean_q: 4.073920
730 (array([54]),) False
  11280/500000: episode: 282, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 43.175 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.198443, mean_absolute_error: 3.220062, mean_q: 4.062043
273 (array([22]),) False
  11320/500000: episode: 283, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 24.575 [0.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.182225, mean_absolute_error: 3.211092, mean_q: 4.070777
381 (array([22]),) False
  11360/500000: episode: 284, duration: 32.934s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.175 [6.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.202516, mean_absolute_error: 3.208115, mean_q: 4.062587
548 (array([22]),) False
  11400/500000: episode: 285, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 22.750 [2.000, 47.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.206486, mean_absolute_error: 3.212271, mean_q: 4.069190
519 (array([58]),) False
  11440/500000: episode: 286, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 44.025 [1.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.182562, mean_absolute_error: 3.225018, mean_q: 4.071614
750 (array([22]),) False
  11480/500000: episode: 287, duration: 32.145s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.750 [15.000, 43.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.198036, mean_absolute_error: 3.196824, mean_q: 4.034142
691 (array([22]),) False
  11520/500000: episode: 288, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.300 [4.000, 50.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.188084, mean_absolute_error: 3.221043, mean_q: 4.074419
105 (array([22]),) False
  11560/500000: episode: 289, duration: 32.897s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 25.950 [1.000, 54.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.185035, mean_absolute_error: 3.193563, mean_q: 4.053125
115 (array([22]),) False
  11600/500000: episode: 290, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.800 [1.000, 50.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.182943, mean_absolute_error: 3.198426, mean_q: 4.050889
322 (array([12]),) False
  11640/500000: episode: 291, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.525 [8.000, 53.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.190092, mean_absolute_error: 3.194301, mean_q: 4.034158
799 (array([36]),) False
  11680/500000: episode: 292, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 18.400 [0.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.180166, mean_absolute_error: 3.185114, mean_q: 4.026570
22 (array([37]),) False
  11720/500000: episode: 293, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.250 [1.000, 60.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.168474, mean_absolute_error: 3.194300, mean_q: 4.016408
708 (array([40]),) False
  11760/500000: episode: 294, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.750 [2.000, 53.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.185213, mean_absolute_error: 3.190737, mean_q: 4.043359
759 (array([48]),) False
  11800/500000: episode: 295, duration: 32.123s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.400 [0.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.188152, mean_absolute_error: 3.194877, mean_q: 4.029248
671 (array([57]),) False
  11840/500000: episode: 296, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.025 [0.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.184767, mean_absolute_error: 3.187689, mean_q: 4.013082
288 (array([33]),) False
  11880/500000: episode: 297, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.800 [2.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.186390, mean_absolute_error: 3.175838, mean_q: 4.002652
401 (array([12]),) False
  11920/500000: episode: 298, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 25.950 [7.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.165597, mean_absolute_error: 3.217227, mean_q: 4.031579
73 (array([22]),) False
  11960/500000: episode: 299, duration: 32.119s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.800 [1.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.193420, mean_absolute_error: 3.174614, mean_q: 3.989727
483 (array([48]),) False
  12000/500000: episode: 300, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 30.050 [7.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.188319, mean_absolute_error: 3.184874, mean_q: 4.010536
333 (array([12]),) False
  12040/500000: episode: 301, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 19.125 [3.000, 55.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.177559, mean_absolute_error: 3.187313, mean_q: 4.033122
12 (array([22]),) False
  12080/500000: episode: 302, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.650 [0.000, 59.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.192990, mean_absolute_error: 3.157182, mean_q: 4.015732
448 (array([12]),) False
  12120/500000: episode: 303, duration: 32.393s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 27.575 [9.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.184705, mean_absolute_error: 3.163729, mean_q: 4.004532
461 (array([22]),) False
  12160/500000: episode: 304, duration: 33.329s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.675 [3.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.184350, mean_absolute_error: 3.166904, mean_q: 3.999557
372 (array([22]),) False
  12200/500000: episode: 305, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.950 [4.000, 58.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.157109, mean_absolute_error: 3.176664, mean_q: 4.023166
324 (array([12]),) False
  12240/500000: episode: 306, duration: 32.972s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 27.850 [8.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.179959, mean_absolute_error: 3.195777, mean_q: 4.015861
100 (array([22]),) False
  12280/500000: episode: 307, duration: 32.082s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 27.250 [11.000, 58.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.188605, mean_absolute_error: 3.190699, mean_q: 4.017531
268 (array([22]),) False
  12320/500000: episode: 308, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 28.050 [2.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.191845, mean_absolute_error: 3.185284, mean_q: 4.018847
221 (array([22]),) False
  12360/500000: episode: 309, duration: 32.942s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.075 [2.000, 60.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.169172, mean_absolute_error: 3.201424, mean_q: 4.044604
89 (array([58]),) False
  12400/500000: episode: 310, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 49.050 [4.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.187725, mean_absolute_error: 3.185838, mean_q: 4.027596
337 (array([22]),) False
  12440/500000: episode: 311, duration: 32.035s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 26.950 [0.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.179578, mean_absolute_error: 3.198627, mean_q: 4.036913
201 (array([22]),) False
  12480/500000: episode: 312, duration: 32.958s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.950 [2.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.187888, mean_absolute_error: 3.152619, mean_q: 3.990763
613 (array([22]),) False
  12520/500000: episode: 313, duration: 32.972s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.000 [2.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.180596, mean_absolute_error: 3.185899, mean_q: 4.011856
773 (array([22]),) False
  12560/500000: episode: 314, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.475 [1.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.178941, mean_absolute_error: 3.188118, mean_q: 4.019087
370 (array([58]),) False
  12600/500000: episode: 315, duration: 32.112s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 32.250 [1.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.185014, mean_absolute_error: 3.146707, mean_q: 3.992576
229 (array([48]),) False
  12640/500000: episode: 316, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.350 [0.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.162135, mean_absolute_error: 3.184712, mean_q: 4.044724
72 (array([12]),) False
  12680/500000: episode: 317, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.800 [7.000, 60.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.206644, mean_absolute_error: 3.168894, mean_q: 4.007302
411 (array([22]),) False
  12720/500000: episode: 318, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.125 [2.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.174748, mean_absolute_error: 3.191328, mean_q: 4.007738
793 (array([12]),) False
  12760/500000: episode: 319, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.850 [1.000, 57.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.156167, mean_absolute_error: 3.200346, mean_q: 4.025824
344 (array([22]),) False
  12800/500000: episode: 320, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 28.600 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.175341, mean_absolute_error: 3.166999, mean_q: 4.008567
320 (array([22]),) False
  12840/500000: episode: 321, duration: 32.957s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.725 [6.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.186769, mean_absolute_error: 3.167421, mean_q: 4.008872
820 (array([48]),) False
  12880/500000: episode: 322, duration: 32.983s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.600 [1.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.174271, mean_absolute_error: 3.189827, mean_q: 3.994240
12 (array([22]),) False
  12920/500000: episode: 323, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.525 [8.000, 54.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.172532, mean_absolute_error: 3.165856, mean_q: 3.973049
265 (array([22]),) False
  12960/500000: episode: 324, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.100 [2.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.171383, mean_absolute_error: 3.157340, mean_q: 3.983601
714 (array([22]),) False
  13000/500000: episode: 325, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 33.600 [5.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.176099, mean_absolute_error: 3.147209, mean_q: 3.982812
541 (array([57]),) False
  13040/500000: episode: 326, duration: 32.924s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 44.375 [0.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.192460, mean_absolute_error: 3.149270, mean_q: 3.965246
844 (array([48]),) False
  13080/500000: episode: 327, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 29.075 [0.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.174391, mean_absolute_error: 3.165736, mean_q: 3.993387
492 (array([22]),) False
  13120/500000: episode: 328, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.825 [0.000, 55.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.168710, mean_absolute_error: 3.177683, mean_q: 3.978485
811 (array([33]),) False
  13160/500000: episode: 329, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.675 [8.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.168059, mean_absolute_error: 3.177355, mean_q: 3.985669
422 (array([48]),) False
  13200/500000: episode: 330, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 25.150 [2.000, 56.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.182495, mean_absolute_error: 3.180703, mean_q: 4.000713
656 (array([48]),) False
  13240/500000: episode: 331, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 42.175 [0.000, 54.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.172094, mean_absolute_error: 3.174787, mean_q: 3.991490
205 (array([22]),) False
  13280/500000: episode: 332, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.375 [6.000, 55.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.165218, mean_absolute_error: 3.174806, mean_q: 3.995195
758 (array([38]),) False
  13320/500000: episode: 333, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.425 [4.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.174446, mean_absolute_error: 3.166148, mean_q: 3.985340
158 (array([22]),) False
  13360/500000: episode: 334, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.825 [7.000, 60.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.185660, mean_absolute_error: 3.172235, mean_q: 3.972714
218 (array([22]),) False
  13400/500000: episode: 335, duration: 32.163s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.050 [6.000, 56.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.186154, mean_absolute_error: 3.147540, mean_q: 3.972682
409 (array([22]),) False
  13440/500000: episode: 336, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.775 [6.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.184400, mean_absolute_error: 3.158368, mean_q: 3.964180
478 (array([22]),) False
  13480/500000: episode: 337, duration: 32.926s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.975 [1.000, 45.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.175900, mean_absolute_error: 3.122662, mean_q: 3.965792
653 (array([48]),) False
  13520/500000: episode: 338, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 41.300 [7.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.183193, mean_absolute_error: 3.135342, mean_q: 3.950511
722 (array([22]),) False
  13560/500000: episode: 339, duration: 32.195s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.775 [0.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.168267, mean_absolute_error: 3.142737, mean_q: 3.968202
799 (array([36]),) False
  13600/500000: episode: 340, duration: 32.973s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.800 [3.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.169296, mean_absolute_error: 3.117435, mean_q: 3.948303
17 (array([22]),) False
  13640/500000: episode: 341, duration: 33.038s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.900 [0.000, 42.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.170522, mean_absolute_error: 3.116963, mean_q: 3.925422
629 (array([22]),) False
  13680/500000: episode: 342, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 42.050 [10.000, 59.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.169567, mean_absolute_error: 3.117002, mean_q: 3.938189
633 (array([22]),) False
  13720/500000: episode: 343, duration: 32.175s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.575 [1.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.158008, mean_absolute_error: 3.109381, mean_q: 3.961803
131 (array([22]),) False
  13760/500000: episode: 344, duration: 32.907s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 33.800 [1.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.168798, mean_absolute_error: 3.123215, mean_q: 3.939475
715 (array([22]),) False
  13800/500000: episode: 345, duration: 32.991s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.500 [1.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.176276, mean_absolute_error: 3.104075, mean_q: 3.932137
262 (array([22]),) False
  13840/500000: episode: 346, duration: 32.927s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 21.800 [3.000, 52.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.174394, mean_absolute_error: 3.100583, mean_q: 3.926983
532 (array([25]),) False
  13880/500000: episode: 347, duration: 32.065s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.400 [1.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.174231, mean_absolute_error: 3.103614, mean_q: 3.909303
30 (array([22]),) False
  13920/500000: episode: 348, duration: 32.972s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.375 [4.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.169559, mean_absolute_error: 3.106889, mean_q: 3.921773
482 (array([22]),) False
  13960/500000: episode: 349, duration: 32.863s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 25.975 [6.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.169156, mean_absolute_error: 3.104041, mean_q: 3.919933
518 (array([22]),) False
  14000/500000: episode: 350, duration: 32.969s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.100 [3.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.177198, mean_absolute_error: 3.110271, mean_q: 3.922389
414 (array([48]),) False
  14040/500000: episode: 351, duration: 32.116s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 34.600 [0.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.184438, mean_absolute_error: 3.105793, mean_q: 3.898968
71 (array([58]),) False
  14080/500000: episode: 352, duration: 32.963s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 45.225 [6.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.153270, mean_absolute_error: 3.113604, mean_q: 3.925774
54 (array([8]),) False
  14120/500000: episode: 353, duration: 32.876s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.000 [2.000, 60.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.171882, mean_absolute_error: 3.092599, mean_q: 3.904401
151 (array([22]),) False
  14160/500000: episode: 354, duration: 32.952s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.725 [2.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.178710, mean_absolute_error: 3.083111, mean_q: 3.896240
392 (array([40]),) False
  14200/500000: episode: 355, duration: 32.100s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.575 [6.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.167438, mean_absolute_error: 3.090909, mean_q: 3.912581
668 (array([22]),) False
  14240/500000: episode: 356, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 27.700 [6.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.172872, mean_absolute_error: 3.102784, mean_q: 3.913144
730 (array([54]),) False
  14280/500000: episode: 357, duration: 32.858s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 37.575 [3.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.162771, mean_absolute_error: 3.104763, mean_q: 3.934057
26 (array([22]),) False
  14320/500000: episode: 358, duration: 32.869s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.675 [9.000, 57.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.155461, mean_absolute_error: 3.106318, mean_q: 3.914584
89 (array([58]),) False
  14360/500000: episode: 359, duration: 31.932s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 42.500 [0.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.163034, mean_absolute_error: 3.091851, mean_q: 3.927887
497 (array([33]),) False
  14400/500000: episode: 360, duration: 32.957s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.300 [1.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.169246, mean_absolute_error: 3.105715, mean_q: 3.920299
786 (array([22]),) False
  14440/500000: episode: 361, duration: 32.939s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.275 [13.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.181818, mean_absolute_error: 3.081453, mean_q: 3.908057
613 (array([22]),) False
  14480/500000: episode: 362, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.675 [4.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.189022, mean_absolute_error: 3.097912, mean_q: 3.917156
373 (array([22]),) False
  14520/500000: episode: 363, duration: 32.163s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.750 [1.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.176688, mean_absolute_error: 3.094836, mean_q: 3.913494
834 (array([44]),) False
  14560/500000: episode: 364, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 27.700 [1.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.164036, mean_absolute_error: 3.091284, mean_q: 3.905725
416 (array([22]),) False
  14600/500000: episode: 365, duration: 32.935s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.825 [0.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.166940, mean_absolute_error: 3.079115, mean_q: 3.899841
115 (array([22]),) False
  14640/500000: episode: 366, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 26.425 [1.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.156944, mean_absolute_error: 3.072527, mean_q: 3.887897
751 (array([22]),) False
  14680/500000: episode: 367, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.175 [1.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.168065, mean_absolute_error: 3.078804, mean_q: 3.894339
639 (array([22]),) False
  14720/500000: episode: 368, duration: 32.941s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 27.550 [0.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.166922, mean_absolute_error: 3.054518, mean_q: 3.879794
288 (array([33]),) False
  14760/500000: episode: 369, duration: 33.524s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.725 [0.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.157376, mean_absolute_error: 3.060345, mean_q: 3.899014
108 (array([48]),) False
  14800/500000: episode: 370, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 28.400 [6.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.167555, mean_absolute_error: 3.083783, mean_q: 3.884011
834 (array([44]),) False
  14840/500000: episode: 371, duration: 32.048s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 22.950 [0.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.165229, mean_absolute_error: 3.084674, mean_q: 3.891706
525 (array([22]),) False
  14880/500000: episode: 372, duration: 32.907s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.175 [1.000, 54.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.173052, mean_absolute_error: 3.080369, mean_q: 3.890249
654 (array([22]),) False
  14920/500000: episode: 373, duration: 32.843s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.750 [4.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.159843, mean_absolute_error: 3.080690, mean_q: 3.903757
845 (array([22]),) False
  14960/500000: episode: 374, duration: 32.865s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.050 [1.000, 55.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.178696, mean_absolute_error: 3.061714, mean_q: 3.875102
678 (array([22]),) False
  15000/500000: episode: 375, duration: 32.135s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.325 [0.000, 59.000], mean observation: -0.107 [-1.000, 1.000], loss: 0.179612, mean_absolute_error: 3.093666, mean_q: 3.892750
490 (array([12]),) False
  15040/500000: episode: 376, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.400 [8.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.166277, mean_absolute_error: 3.082741, mean_q: 3.899604
292 (array([22]),) False
  15080/500000: episode: 377, duration: 32.908s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.925 [6.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.175724, mean_absolute_error: 3.051469, mean_q: 3.890271
276 (array([56]),) False
  15120/500000: episode: 378, duration: 32.989s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.475 [4.000, 59.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.173126, mean_absolute_error: 3.084107, mean_q: 3.883027
477 (array([22]),) False
  15160/500000: episode: 379, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.050 [2.000, 55.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.173342, mean_absolute_error: 3.087822, mean_q: 3.913834
341 (array([22]),) False
  15200/500000: episode: 380, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 25.300 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.171782, mean_absolute_error: 3.070714, mean_q: 3.890368
517 (array([22]),) False
  15240/500000: episode: 381, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.450 [6.000, 50.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.159210, mean_absolute_error: 3.097621, mean_q: 3.934630
250 (array([22]),) False
  15280/500000: episode: 382, duration: 32.969s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 29.975 [1.000, 58.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.183255, mean_absolute_error: 3.102378, mean_q: 3.915139
679 (array([44]),) False
  15320/500000: episode: 383, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 22.400 [3.000, 60.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.173787, mean_absolute_error: 3.100231, mean_q: 3.920673
496 (array([48]),) False
  15360/500000: episode: 384, duration: 32.953s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 38.875 [0.000, 56.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.166486, mean_absolute_error: 3.072580, mean_q: 3.891915
180 (array([48]),) False
  15400/500000: episode: 385, duration: 32.838s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 39.050 [3.000, 53.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.163047, mean_absolute_error: 3.087915, mean_q: 3.908424
452 (array([22]),) False
  15440/500000: episode: 386, duration: 32.948s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 26.150 [2.000, 59.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.175387, mean_absolute_error: 3.089059, mean_q: 3.901002
459 (array([22]),) False
  15480/500000: episode: 387, duration: 32.089s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.425 [1.000, 56.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.160631, mean_absolute_error: 3.095100, mean_q: 3.898624
771 (array([12]),) False
  15520/500000: episode: 388, duration: 32.931s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 19.150 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.177117, mean_absolute_error: 3.087855, mean_q: 3.911675
787 (array([3]),) False
  15560/500000: episode: 389, duration: 32.897s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.150 [8.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.166350, mean_absolute_error: 3.103939, mean_q: 3.943935
82 (array([22]),) False
  15600/500000: episode: 390, duration: 33.008s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.875 [1.000, 59.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.177812, mean_absolute_error: 3.120455, mean_q: 3.937590
255 (array([12]),) False
  15640/500000: episode: 391, duration: 32.130s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 24.000 [0.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.161746, mean_absolute_error: 3.114261, mean_q: 3.938205
651 (array([22]),) False
  15680/500000: episode: 392, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.775 [3.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.160356, mean_absolute_error: 3.115843, mean_q: 3.939273
469 (array([22]),) False
  15720/500000: episode: 393, duration: 32.958s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.375 [1.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.165215, mean_absolute_error: 3.110451, mean_q: 3.918602
793 (array([12]),) False
  15760/500000: episode: 394, duration: 32.957s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 23.050 [0.000, 56.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.173393, mean_absolute_error: 3.130399, mean_q: 3.943083
613 (array([22]),) False
  15800/500000: episode: 395, duration: 32.141s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.050 [1.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.159526, mean_absolute_error: 3.124247, mean_q: 3.955297
504 (array([48]),) False
  15840/500000: episode: 396, duration: 32.617s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 40.650 [2.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.174699, mean_absolute_error: 3.128079, mean_q: 3.940176
513 (array([12]),) False
  15880/500000: episode: 397, duration: 31.481s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 41.875 [1.000, 58.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.171476, mean_absolute_error: 3.130626, mean_q: 3.932684
387 (array([22]),) False
  15920/500000: episode: 398, duration: 31.608s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.525 [8.000, 54.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.166229, mean_absolute_error: 3.130083, mean_q: 3.938439
429 (array([22]),) False
  15960/500000: episode: 399, duration: 31.143s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.200 [7.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.169398, mean_absolute_error: 3.137836, mean_q: 3.943741
24 (array([22]),) False
  16000/500000: episode: 400, duration: 31.471s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.500 [4.000, 58.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.160960, mean_absolute_error: 3.129698, mean_q: 3.947578
23 (array([48]),) False
  16040/500000: episode: 401, duration: 31.749s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 28.400 [0.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.175974, mean_absolute_error: 3.131408, mean_q: 3.945461
456 (array([22]),) False
  16080/500000: episode: 402, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.275 [5.000, 57.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.165706, mean_absolute_error: 3.095876, mean_q: 3.945939
784 (array([22]),) False
  16120/500000: episode: 403, duration: 32.708s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.850 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.174638, mean_absolute_error: 3.093156, mean_q: 3.907729
38 (array([22]),) False
  16160/500000: episode: 404, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.225 [2.000, 47.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.176242, mean_absolute_error: 3.101952, mean_q: 3.913965
707 (array([48]),) False
  16200/500000: episode: 405, duration: 31.264s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 38.950 [0.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.175886, mean_absolute_error: 3.095685, mean_q: 3.892309
49 (array([22]),) False
  16240/500000: episode: 406, duration: 32.826s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.725 [4.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.160432, mean_absolute_error: 3.107719, mean_q: 3.921983
191 (array([38]),) False
  16280/500000: episode: 407, duration: 30.792s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 25.600 [11.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.171746, mean_absolute_error: 3.110907, mean_q: 3.940082
603 (array([58]),) False
  16320/500000: episode: 408, duration: 32.030s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 33.850 [0.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.180738, mean_absolute_error: 3.087572, mean_q: 3.899793
518 (array([22]),) False
  16360/500000: episode: 409, duration: 31.897s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.225 [0.000, 57.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.172461, mean_absolute_error: 3.076873, mean_q: 3.908299
202 (array([22]),) False
  16400/500000: episode: 410, duration: 32.171s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.750 [2.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.159246, mean_absolute_error: 3.094459, mean_q: 3.923850
624 (array([48]),) False
  16440/500000: episode: 411, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.500 [5.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.162938, mean_absolute_error: 3.089485, mean_q: 3.916613
576 (array([58]),) False
  16480/500000: episode: 412, duration: 31.289s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 44.300 [1.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.167913, mean_absolute_error: 3.105842, mean_q: 3.917370
773 (array([22]),) False
  16520/500000: episode: 413, duration: 31.050s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.350 [3.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.163136, mean_absolute_error: 3.101422, mean_q: 3.927969
426 (array([22]),) False
  16560/500000: episode: 414, duration: 31.365s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.850 [2.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.160943, mean_absolute_error: 3.109723, mean_q: 3.927149
496 (array([48]),) False
  16600/500000: episode: 415, duration: 30.356s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 40.675 [1.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.178101, mean_absolute_error: 3.100332, mean_q: 3.921401
655 (array([22]),) False
  16640/500000: episode: 416, duration: 31.246s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.900 [0.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.167390, mean_absolute_error: 3.129758, mean_q: 3.930558
4 (array([22]),) False
  16680/500000: episode: 417, duration: 31.230s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 27.475 [1.000, 60.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.161750, mean_absolute_error: 3.115517, mean_q: 3.927755
240 (array([22]),) False
  16720/500000: episode: 418, duration: 31.999s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.050 [2.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.161571, mean_absolute_error: 3.121934, mean_q: 3.960321
17 (array([22]),) False
  16760/500000: episode: 419, duration: 30.400s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.900 [0.000, 60.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.162355, mean_absolute_error: 3.124403, mean_q: 3.952850
336 (array([12]),) False
  16800/500000: episode: 420, duration: 31.331s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 28.575 [12.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.164352, mean_absolute_error: 3.118546, mean_q: 3.935171
111 (array([22]),) False
  16840/500000: episode: 421, duration: 31.158s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 24.075 [0.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.186105, mean_absolute_error: 3.137457, mean_q: 3.933034
173 (array([3]),) False
  16880/500000: episode: 422, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 14.575 [2.000, 55.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.153431, mean_absolute_error: 3.150841, mean_q: 3.952119
537 (array([22]),) False
  16920/500000: episode: 423, duration: 30.110s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.750 [1.000, 52.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.168211, mean_absolute_error: 3.145848, mean_q: 3.954144
94 (array([44]),) False
  16960/500000: episode: 424, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 36.300 [4.000, 60.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.168988, mean_absolute_error: 3.134895, mean_q: 3.966086
717 (array([22]),) False
  17000/500000: episode: 425, duration: 31.126s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.650 [2.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.180706, mean_absolute_error: 3.127358, mean_q: 3.948966
796 (array([38]),) False
  17040/500000: episode: 426, duration: 31.175s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.850 [2.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.162753, mean_absolute_error: 3.155696, mean_q: 3.965583
55 (array([22]),) False
  17080/500000: episode: 427, duration: 30.403s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.600 [8.000, 52.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.167882, mean_absolute_error: 3.141597, mean_q: 3.956594
451 (array([38]),) False
  17120/500000: episode: 428, duration: 31.270s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.750 [4.000, 54.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.178553, mean_absolute_error: 3.123535, mean_q: 3.938840
179 (array([18]),) False
  17160/500000: episode: 429, duration: 31.114s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.375 [0.000, 54.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.173131, mean_absolute_error: 3.125810, mean_q: 3.954556
143 (array([12]),) False
  17200/500000: episode: 430, duration: 32.043s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 18.925 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.166555, mean_absolute_error: 3.105356, mean_q: 3.943219
659 (array([40]),) False
  17240/500000: episode: 431, duration: 31.109s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.400 [3.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.158331, mean_absolute_error: 3.117267, mean_q: 3.949743
184 (array([12]),) False
  17280/500000: episode: 432, duration: 31.756s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 26.550 [10.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.181588, mean_absolute_error: 3.108352, mean_q: 3.895248
853 (array([22]),) False
  17320/500000: episode: 433, duration: 31.471s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 29.100 [18.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.166549, mean_absolute_error: 3.104173, mean_q: 3.918772
813 (array([22]),) False
  17360/500000: episode: 434, duration: 32.042s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 25.625 [2.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.170879, mean_absolute_error: 3.109773, mean_q: 3.931852
265 (array([22]),) False
  17400/500000: episode: 435, duration: 30.530s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 24.450 [0.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.165920, mean_absolute_error: 3.081264, mean_q: 3.902289
37 (array([48]),) False
  17440/500000: episode: 436, duration: 31.065s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 41.900 [2.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.164647, mean_absolute_error: 3.067204, mean_q: 3.872644
842 (array([22]),) False
  17480/500000: episode: 437, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.975 [3.000, 56.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.158811, mean_absolute_error: 3.100272, mean_q: 3.907504
486 (array([22]),) False
  17520/500000: episode: 438, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 25.800 [1.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.181517, mean_absolute_error: 3.076180, mean_q: 3.875383
218 (array([22]),) False
  17560/500000: episode: 439, duration: 31.501s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.900 [0.000, 60.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.170651, mean_absolute_error: 3.072759, mean_q: 3.883033
564 (array([22]),) False
  17600/500000: episode: 440, duration: 31.926s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.750 [4.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.170663, mean_absolute_error: 3.060013, mean_q: 3.881966
113 (array([22]),) False
  17640/500000: episode: 441, duration: 31.973s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.600 [6.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.173707, mean_absolute_error: 3.058548, mean_q: 3.868753
105 (array([22]),) False
  17680/500000: episode: 442, duration: 32.390s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.450 [5.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.179373, mean_absolute_error: 3.061409, mean_q: 3.867534
616 (array([22]),) False
  17720/500000: episode: 443, duration: 31.871s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.700 [6.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.175839, mean_absolute_error: 3.077887, mean_q: 3.894970
190 (array([3]),) False
  17760/500000: episode: 444, duration: 33.452s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 11.625 [0.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.165759, mean_absolute_error: 3.072813, mean_q: 3.884696
699 (array([22]),) False
  17800/500000: episode: 445, duration: 33.432s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.050 [3.000, 53.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.162301, mean_absolute_error: 3.062833, mean_q: 3.885459
732 (array([12]),) False
  17840/500000: episode: 446, duration: 32.553s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 23.050 [11.000, 47.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.166366, mean_absolute_error: 3.074896, mean_q: 3.883190
758 (array([38]),) False
  17880/500000: episode: 447, duration: 31.441s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.025 [1.000, 47.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.165233, mean_absolute_error: 3.053775, mean_q: 3.871602
66 (array([22]),) False
  17920/500000: episode: 448, duration: 33.728s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.250 [5.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.170618, mean_absolute_error: 3.043010, mean_q: 3.861382
735 (array([22]),) False
  17960/500000: episode: 449, duration: 33.743s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.375 [10.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.181788, mean_absolute_error: 3.022070, mean_q: 3.849845
22 (array([37]),) False
  18000/500000: episode: 450, duration: 33.615s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 26.500 [4.000, 60.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.152366, mean_absolute_error: 3.066946, mean_q: 3.871444
225 (array([48]),) False
  18040/500000: episode: 451, duration: 32.451s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 25.825 [4.000, 50.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.163452, mean_absolute_error: 3.040820, mean_q: 3.866023
568 (array([22]),) False
  18080/500000: episode: 452, duration: 33.325s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.275 [2.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.161708, mean_absolute_error: 3.081653, mean_q: 3.897994
414 (array([48]),) False
  18120/500000: episode: 453, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 40.425 [3.000, 50.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.174483, mean_absolute_error: 3.060653, mean_q: 3.874218
312 (array([12]),) False
  18160/500000: episode: 454, duration: 33.363s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 19.025 [0.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.167859, mean_absolute_error: 3.067630, mean_q: 3.867415
383 (array([22]),) False
  18200/500000: episode: 455, duration: 32.496s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.025 [1.000, 50.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.184592, mean_absolute_error: 3.056748, mean_q: 3.839901
97 (array([22]),) False
  18240/500000: episode: 456, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 21.925 [0.000, 55.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.159342, mean_absolute_error: 3.070091, mean_q: 3.861846
834 (array([44]),) False
  18280/500000: episode: 457, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.025 [8.000, 55.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.146182, mean_absolute_error: 3.087364, mean_q: 3.921948
37 (array([48]),) False
  18320/500000: episode: 458, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 43.325 [2.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.166261, mean_absolute_error: 3.084080, mean_q: 3.908285
55 (array([22]),) False
  18360/500000: episode: 459, duration: 32.407s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.500 [1.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.161050, mean_absolute_error: 3.101880, mean_q: 3.928149
662 (array([12]),) False
  18400/500000: episode: 460, duration: 33.436s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.600 [3.000, 59.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.171139, mean_absolute_error: 3.110556, mean_q: 3.927978
212 (array([36]),) False
  18440/500000: episode: 461, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.975 [2.000, 59.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.172707, mean_absolute_error: 3.091288, mean_q: 3.906625
814 (array([22]),) False
  18480/500000: episode: 462, duration: 33.356s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.475 [3.000, 53.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.167154, mean_absolute_error: 3.078406, mean_q: 3.922181
532 (array([25]),) False
  18520/500000: episode: 463, duration: 32.382s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.925 [6.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.168917, mean_absolute_error: 3.070281, mean_q: 3.880000
271 (array([18]),) False
  18560/500000: episode: 464, duration: 33.244s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.700 [3.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.154010, mean_absolute_error: 3.096462, mean_q: 3.907155
380 (array([22]),) False
  18600/500000: episode: 465, duration: 33.343s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 28.200 [2.000, 60.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.173266, mean_absolute_error: 3.059115, mean_q: 3.867413
349 (array([48]),) False
  18640/500000: episode: 466, duration: 33.337s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.775 [5.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.156317, mean_absolute_error: 3.075684, mean_q: 3.873610
847 (array([21]),) False
  18680/500000: episode: 467, duration: 32.493s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.725 [5.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.146029, mean_absolute_error: 3.047153, mean_q: 3.857884
256 (array([22]),) False
  18720/500000: episode: 468, duration: 33.354s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.050 [1.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.159828, mean_absolute_error: 3.043211, mean_q: 3.856426
250 (array([22]),) False
  18760/500000: episode: 469, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.275 [2.000, 58.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.180193, mean_absolute_error: 3.021133, mean_q: 3.805507
15 (array([22]),) False
  18800/500000: episode: 470, duration: 33.286s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.375 [1.000, 59.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.151956, mean_absolute_error: 3.035915, mean_q: 3.853193
604 (array([40]),) False
  18840/500000: episode: 471, duration: 32.502s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 39.175 [3.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.156526, mean_absolute_error: 3.026167, mean_q: 3.855632
641 (array([22]),) False
  18880/500000: episode: 472, duration: 33.293s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 27.100 [5.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.161043, mean_absolute_error: 3.042346, mean_q: 3.851689
406 (array([48]),) False
  18920/500000: episode: 473, duration: 33.303s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 31.450 [1.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.154443, mean_absolute_error: 3.041518, mean_q: 3.845201
787 (array([3]),) False
  18960/500000: episode: 474, duration: 33.380s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 25.125 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.157010, mean_absolute_error: 3.035791, mean_q: 3.844043
741 (array([22]),) False
  19000/500000: episode: 475, duration: 32.455s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 26.650 [3.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.147939, mean_absolute_error: 3.048574, mean_q: 3.864233
414 (array([48]),) False
  19040/500000: episode: 476, duration: 33.303s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 41.450 [6.000, 56.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.153291, mean_absolute_error: 3.033449, mean_q: 3.848512
516 (array([48]),) False
  19080/500000: episode: 477, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 34.450 [0.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.165776, mean_absolute_error: 3.035220, mean_q: 3.855696
679 (array([44]),) False
  19120/500000: episode: 478, duration: 33.397s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 26.325 [1.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.169254, mean_absolute_error: 3.032066, mean_q: 3.832229
492 (array([22]),) False
  19160/500000: episode: 479, duration: 32.494s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 20.875 [6.000, 39.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.158616, mean_absolute_error: 3.046843, mean_q: 3.857473
251 (array([3]),) False
  19200/500000: episode: 480, duration: 33.259s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 16.675 [2.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.159380, mean_absolute_error: 3.025386, mean_q: 3.828902
87 (array([3]),) False
  19240/500000: episode: 481, duration: 33.276s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 10.125 [1.000, 52.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.144974, mean_absolute_error: 3.014619, mean_q: 3.844633
654 (array([22]),) False
  19280/500000: episode: 482, duration: 33.394s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.625 [5.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.166885, mean_absolute_error: 3.031478, mean_q: 3.836693
99 (array([22]),) False
  19320/500000: episode: 483, duration: 32.456s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.750 [3.000, 59.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.151832, mean_absolute_error: 3.032897, mean_q: 3.848045
190 (array([3]),) False
  19360/500000: episode: 484, duration: 33.362s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 16.050 [3.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.158616, mean_absolute_error: 3.018988, mean_q: 3.827489
375 (array([22]),) False
  19400/500000: episode: 485, duration: 33.259s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.775 [2.000, 51.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.154140, mean_absolute_error: 3.024235, mean_q: 3.830410
9 (array([14]),) False
  19440/500000: episode: 486, duration: 33.356s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 39.975 [6.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.158318, mean_absolute_error: 2.984629, mean_q: 3.791536
27 (array([22]),) False
  19480/500000: episode: 487, duration: 32.502s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.750 [2.000, 56.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.166488, mean_absolute_error: 2.977799, mean_q: 3.792276
439 (array([12]),) False
  19520/500000: episode: 488, duration: 33.325s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 20.025 [0.000, 56.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.160041, mean_absolute_error: 2.985444, mean_q: 3.785271
636 (array([12]),) False
  19560/500000: episode: 489, duration: 33.386s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 37.750 [1.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.162454, mean_absolute_error: 2.970043, mean_q: 3.791531
459 (array([22]),) False
  19600/500000: episode: 490, duration: 33.385s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.925 [3.000, 57.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.156792, mean_absolute_error: 3.010108, mean_q: 3.813848
245 (array([22]),) False
  19640/500000: episode: 491, duration: 32.487s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.525 [1.000, 56.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.164146, mean_absolute_error: 2.979223, mean_q: 3.793136
351 (array([22]),) False
  19680/500000: episode: 492, duration: 33.293s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.350 [0.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.149612, mean_absolute_error: 2.997847, mean_q: 3.807611
318 (array([48]),) False
  19720/500000: episode: 493, duration: 33.294s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 33.950 [1.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.169151, mean_absolute_error: 2.980695, mean_q: 3.785820
50 (array([22]),) False
  19760/500000: episode: 494, duration: 33.461s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.025 [3.000, 57.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.150627, mean_absolute_error: 2.995797, mean_q: 3.819646
95 (array([22]),) False
  19800/500000: episode: 495, duration: 32.463s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.200 [1.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.182077, mean_absolute_error: 2.990611, mean_q: 3.798394
589 (array([22]),) False
  19840/500000: episode: 496, duration: 33.341s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.675 [9.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.160267, mean_absolute_error: 2.991456, mean_q: 3.793724
135 (array([22]),) False
  19880/500000: episode: 497, duration: 32.759s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.775 [9.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.150921, mean_absolute_error: 3.001380, mean_q: 3.794656
716 (array([48]),) False
  19920/500000: episode: 498, duration: 31.148s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 40.400 [11.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.160045, mean_absolute_error: 2.981242, mean_q: 3.800723
653 (array([48]),) False
  19960/500000: episode: 499, duration: 30.182s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 43.050 [9.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.165318, mean_absolute_error: 2.972949, mean_q: 3.788634
418 (array([22]),) False
  20000/500000: episode: 500, duration: 31.183s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 30.475 [2.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.153642, mean_absolute_error: 2.988005, mean_q: 3.770206
371 (array([14]),) False
  20040/500000: episode: 501, duration: 31.072s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 24.525 [0.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.171213, mean_absolute_error: 2.964359, mean_q: 3.761972
453 (array([22]),) False
  20080/500000: episode: 502, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 29.600 [4.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.156005, mean_absolute_error: 2.970036, mean_q: 3.770056
302 (array([22]),) False
  20120/500000: episode: 503, duration: 30.285s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.000 [0.000, 52.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.154943, mean_absolute_error: 2.968364, mean_q: 3.759767
544 (array([22]),) False
  20160/500000: episode: 504, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 27.025 [4.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.160817, mean_absolute_error: 2.963938, mean_q: 3.763833
184 (array([12]),) False
  20200/500000: episode: 505, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 25.200 [1.000, 52.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.146531, mean_absolute_error: 2.957101, mean_q: 3.757751
273 (array([22]),) False
  20240/500000: episode: 506, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.700 [2.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.152144, mean_absolute_error: 2.959612, mean_q: 3.758806
378 (array([22]),) False
  20280/500000: episode: 507, duration: 30.112s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.650 [0.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.143820, mean_absolute_error: 2.979259, mean_q: 3.803805
860 (array([12]),) False
  20320/500000: episode: 508, duration: 30.830s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 22.750 [8.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.155586, mean_absolute_error: 2.963316, mean_q: 3.793975
385 (array([30]),) False
  20360/500000: episode: 509, duration: 30.849s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.850 [3.000, 57.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.158402, mean_absolute_error: 2.982536, mean_q: 3.794291
608 (array([36]),) False
  20400/500000: episode: 510, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 22.500 [3.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.153789, mean_absolute_error: 2.977134, mean_q: 3.791070
226 (array([22]),) False
  20440/500000: episode: 511, duration: 30.070s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.175 [2.000, 56.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.159293, mean_absolute_error: 2.970047, mean_q: 3.782911
29 (array([22]),) False
  20480/500000: episode: 512, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.425 [0.000, 57.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.161976, mean_absolute_error: 2.958797, mean_q: 3.765416
714 (array([22]),) False
  20520/500000: episode: 513, duration: 30.844s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 24.225 [1.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.174326, mean_absolute_error: 2.935469, mean_q: 3.730142
686 (array([48]),) False
  20560/500000: episode: 514, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 43.050 [6.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.157318, mean_absolute_error: 2.937543, mean_q: 3.757214
498 (array([12]),) False
  20600/500000: episode: 515, duration: 30.199s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 26.350 [2.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.141175, mean_absolute_error: 2.956601, mean_q: 3.755399
503 (array([3]),) False
  20640/500000: episode: 516, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 16.675 [2.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.158864, mean_absolute_error: 2.948576, mean_q: 3.732618
761 (array([3]),) False
  20680/500000: episode: 517, duration: 30.962s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 12.100 [3.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.144370, mean_absolute_error: 2.939373, mean_q: 3.759085
477 (array([22]),) False
  20720/500000: episode: 518, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.950 [5.000, 55.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.154000, mean_absolute_error: 2.939119, mean_q: 3.757349
362 (array([22]),) False
  20760/500000: episode: 519, duration: 30.081s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.825 [4.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.163074, mean_absolute_error: 2.924858, mean_q: 3.749571
452 (array([22]),) False
  20800/500000: episode: 520, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.700 [2.000, 57.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.156672, mean_absolute_error: 2.931543, mean_q: 3.742023
213 (array([22]),) False
  20840/500000: episode: 521, duration: 30.830s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.925 [0.000, 60.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.160102, mean_absolute_error: 2.940520, mean_q: 3.764346
597 (array([22]),) False
  20880/500000: episode: 522, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 29.925 [15.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.135791, mean_absolute_error: 2.949282, mean_q: 3.766885
385 (array([30]),) False
  20920/500000: episode: 523, duration: 30.055s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.700 [3.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.155467, mean_absolute_error: 2.936890, mean_q: 3.745512
659 (array([40]),) False
  20960/500000: episode: 524, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.650 [1.000, 52.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.147708, mean_absolute_error: 2.925730, mean_q: 3.743024
27 (array([22]),) False
  21000/500000: episode: 525, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 27.425 [6.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.160090, mean_absolute_error: 2.922584, mean_q: 3.728410
409 (array([22]),) False
  21040/500000: episode: 526, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.800 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.164545, mean_absolute_error: 2.930275, mean_q: 3.742602
521 (array([22]),) False
  21080/500000: episode: 527, duration: 30.027s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.875 [0.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.148528, mean_absolute_error: 2.948974, mean_q: 3.757859
241 (array([22]),) False
  21120/500000: episode: 528, duration: 30.879s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.650 [1.000, 56.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.148063, mean_absolute_error: 2.927348, mean_q: 3.761407
514 (array([54]),) False
  21160/500000: episode: 529, duration: 31.295s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.400 [0.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.152509, mean_absolute_error: 2.935337, mean_q: 3.747351
263 (array([8]),) False
  21200/500000: episode: 530, duration: 31.337s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.625 [0.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.153729, mean_absolute_error: 2.930789, mean_q: 3.749448
807 (array([22]),) False
  21240/500000: episode: 531, duration: 30.478s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.975 [1.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.166731, mean_absolute_error: 2.918672, mean_q: 3.738521
544 (array([22]),) False
  21280/500000: episode: 532, duration: 31.186s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.350 [3.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.143999, mean_absolute_error: 2.946240, mean_q: 3.772822
771 (array([12]),) False
  21320/500000: episode: 533, duration: 31.019s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 17.325 [2.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.152160, mean_absolute_error: 2.950053, mean_q: 3.762571
499 (array([8]),) False
  21360/500000: episode: 534, duration: 31.111s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 38.850 [1.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.150410, mean_absolute_error: 2.961424, mean_q: 3.799736
105 (array([22]),) False
  21400/500000: episode: 535, duration: 30.053s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 20.525 [4.000, 56.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.157960, mean_absolute_error: 2.963404, mean_q: 3.769523
742 (array([33]),) False
  21440/500000: episode: 536, duration: 31.362s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.425 [3.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.150868, mean_absolute_error: 2.973800, mean_q: 3.790074
736 (array([22]),) False
  21480/500000: episode: 537, duration: 31.570s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 26.225 [4.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.138524, mean_absolute_error: 2.987614, mean_q: 3.787240
403 (array([12]),) False
  21520/500000: episode: 538, duration: 31.530s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 30.575 [2.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.146542, mean_absolute_error: 2.981794, mean_q: 3.805026
191 (array([38]),) False
  21560/500000: episode: 539, duration: 31.158s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 22.500 [1.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.153977, mean_absolute_error: 2.973277, mean_q: 3.792953
271 (array([18]),) False
  21600/500000: episode: 540, duration: 31.481s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 24.375 [2.000, 52.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.160906, mean_absolute_error: 2.984428, mean_q: 3.801940
551 (array([22]),) False
  21640/500000: episode: 541, duration: 31.520s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.700 [0.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.150563, mean_absolute_error: 2.987730, mean_q: 3.801225
525 (array([22]),) False
  21680/500000: episode: 542, duration: 31.583s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 29.250 [6.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.147293, mean_absolute_error: 2.994794, mean_q: 3.809101
740 (array([58]),) False
  21720/500000: episode: 543, duration: 31.113s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 46.950 [5.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.147238, mean_absolute_error: 2.984079, mean_q: 3.790149
391 (array([22]),) False
  21760/500000: episode: 544, duration: 31.514s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.575 [6.000, 55.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.148462, mean_absolute_error: 2.996600, mean_q: 3.797896
446 (array([22]),) False
  21800/500000: episode: 545, duration: 31.586s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.850 [1.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.157750, mean_absolute_error: 3.015350, mean_q: 3.820575
355 (array([22]),) False
  21840/500000: episode: 546, duration: 32.446s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.750 [2.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.139127, mean_absolute_error: 3.005224, mean_q: 3.822366
673 (array([3]),) False
  21880/500000: episode: 547, duration: 32.486s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 12.575 [2.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.159434, mean_absolute_error: 3.000519, mean_q: 3.846334
508 (array([22]),) False
  21920/500000: episode: 548, duration: 33.300s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 26.950 [2.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.160120, mean_absolute_error: 2.991055, mean_q: 3.817892
147 (array([44]),) False
  21960/500000: episode: 549, duration: 32.742s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 30.575 [6.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.161875, mean_absolute_error: 2.995969, mean_q: 3.828096
578 (array([22]),) False
  22000/500000: episode: 550, duration: 31.473s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.725 [1.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.152670, mean_absolute_error: 2.987566, mean_q: 3.792060
496 (array([48]),) False
  22040/500000: episode: 551, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 42.075 [4.000, 57.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.160951, mean_absolute_error: 3.000281, mean_q: 3.801813
265 (array([22]),) False
  22080/500000: episode: 552, duration: 31.465s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.375 [0.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.155632, mean_absolute_error: 2.993720, mean_q: 3.800164
95 (array([22]),) False
  22120/500000: episode: 553, duration: 31.526s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.450 [1.000, 57.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.161484, mean_absolute_error: 2.981046, mean_q: 3.780953
238 (array([22]),) False
  22160/500000: episode: 554, duration: 31.506s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 23.250 [0.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.162516, mean_absolute_error: 2.999082, mean_q: 3.795929
264 (array([12]),) False
  22200/500000: episode: 555, duration: 31.104s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 28.525 [6.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.153226, mean_absolute_error: 2.963580, mean_q: 3.778408
315 (array([12]),) False
  22240/500000: episode: 556, duration: 31.557s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.925 [3.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.170376, mean_absolute_error: 2.955450, mean_q: 3.752677
347 (array([22]),) False
  22280/500000: episode: 557, duration: 31.548s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.675 [3.000, 57.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.147932, mean_absolute_error: 2.976136, mean_q: 3.772238
414 (array([48]),) False
  22320/500000: episode: 558, duration: 31.495s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 39.925 [3.000, 52.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.160990, mean_absolute_error: 2.954569, mean_q: 3.771744
280 (array([48]),) False
  22360/500000: episode: 559, duration: 31.482s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 23.700 [0.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.142652, mean_absolute_error: 2.979456, mean_q: 3.809104
141 (array([44]),) False
  22400/500000: episode: 560, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 39.775 [0.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.157082, mean_absolute_error: 2.949647, mean_q: 3.764252
133 (array([22]),) False
  22440/500000: episode: 561, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.450 [5.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.158012, mean_absolute_error: 2.956351, mean_q: 3.756736
743 (array([48]),) False
  22480/500000: episode: 562, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 37.650 [0.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.156022, mean_absolute_error: 2.936749, mean_q: 3.733422
661 (array([48]),) False
  22520/500000: episode: 563, duration: 32.473s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 28.900 [0.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.153438, mean_absolute_error: 2.938161, mean_q: 3.724139
626 (array([22]),) False
  22560/500000: episode: 564, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.900 [2.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.134842, mean_absolute_error: 2.953395, mean_q: 3.768602
799 (array([36]),) False
  22600/500000: episode: 565, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 33.750 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.155187, mean_absolute_error: 2.920774, mean_q: 3.738745
722 (array([22]),) False
  22640/500000: episode: 566, duration: 33.378s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.400 [0.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.157035, mean_absolute_error: 2.951263, mean_q: 3.763030
727 (array([12]),) False
  22680/500000: episode: 567, duration: 32.306s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.425 [0.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.156017, mean_absolute_error: 2.961436, mean_q: 3.781966
236 (array([22]),) False
  22720/500000: episode: 568, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.100 [7.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.145254, mean_absolute_error: 2.958162, mean_q: 3.769840
542 (array([44]),) False
  22760/500000: episode: 569, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.475 [2.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.167476, mean_absolute_error: 2.942956, mean_q: 3.742299
628 (array([22]),) False
  22800/500000: episode: 570, duration: 33.253s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.600 [0.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.158987, mean_absolute_error: 2.923101, mean_q: 3.741074
41 (array([12]),) False
  22840/500000: episode: 571, duration: 32.341s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.925 [1.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.150100, mean_absolute_error: 2.946469, mean_q: 3.754188
734 (array([48]),) False
  22880/500000: episode: 572, duration: 33.259s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 23.975 [3.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.158166, mean_absolute_error: 2.944840, mean_q: 3.753871
131 (array([22]),) False
  22920/500000: episode: 573, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 21.925 [2.000, 53.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.149418, mean_absolute_error: 2.930209, mean_q: 3.743006
700 (array([44]),) False
  22960/500000: episode: 574, duration: 33.302s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.425 [0.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.147030, mean_absolute_error: 2.942486, mean_q: 3.753483
755 (array([22]),) False
  23000/500000: episode: 575, duration: 32.337s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.750 [0.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.151259, mean_absolute_error: 2.931574, mean_q: 3.738617
81 (array([22]),) False
  23040/500000: episode: 576, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.375 [2.000, 60.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.144245, mean_absolute_error: 2.928019, mean_q: 3.743567
505 (array([22]),) False
  23080/500000: episode: 577, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.075 [0.000, 50.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.151994, mean_absolute_error: 2.936267, mean_q: 3.759498
458 (array([22]),) False
  23120/500000: episode: 578, duration: 33.321s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 27.050 [6.000, 56.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.156947, mean_absolute_error: 2.947289, mean_q: 3.755452
231 (array([22]),) False
  23160/500000: episode: 579, duration: 32.367s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.600 [1.000, 59.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.148466, mean_absolute_error: 2.948075, mean_q: 3.769356
467 (array([48]),) False
  23200/500000: episode: 580, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 35.975 [1.000, 58.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.143862, mean_absolute_error: 2.925996, mean_q: 3.735871
794 (array([22]),) False
  23240/500000: episode: 581, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 49.450 [1.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.143278, mean_absolute_error: 2.940421, mean_q: 3.750684
138 (array([3]),) False
  23280/500000: episode: 582, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 12.200 [1.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.140167, mean_absolute_error: 2.939249, mean_q: 3.767593
170 (array([44]),) False
  23320/500000: episode: 583, duration: 32.419s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 27.175 [3.000, 58.000], mean observation: -0.171 [-1.000, 1.000], loss: 0.146100, mean_absolute_error: 2.950078, mean_q: 3.755189
142 (array([12]),) False
  23360/500000: episode: 584, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 19.825 [2.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.149285, mean_absolute_error: 2.957460, mean_q: 3.769088
725 (array([36]),) False
  23400/500000: episode: 585, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.925 [3.000, 52.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.154641, mean_absolute_error: 2.966412, mean_q: 3.773129
530 (array([22]),) False
  23440/500000: episode: 586, duration: 33.337s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.800 [3.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.152608, mean_absolute_error: 2.955058, mean_q: 3.750206
563 (array([22]),) False
  23480/500000: episode: 587, duration: 32.400s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.075 [5.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.149397, mean_absolute_error: 2.956998, mean_q: 3.758961
461 (array([22]),) False
  23520/500000: episode: 588, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.225 [5.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.150819, mean_absolute_error: 2.946857, mean_q: 3.758347
399 (array([22]),) False
  23560/500000: episode: 589, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 32.750 [1.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.151726, mean_absolute_error: 2.947051, mean_q: 3.753531
834 (array([44]),) False
  23600/500000: episode: 590, duration: 33.272s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 38.300 [1.000, 49.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.151542, mean_absolute_error: 2.942313, mean_q: 3.764825
190 (array([3]),) False
  23640/500000: episode: 591, duration: 32.421s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 18.325 [1.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.159596, mean_absolute_error: 2.959031, mean_q: 3.778400
86 (array([22]),) False
  23680/500000: episode: 592, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.000 [3.000, 57.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.154739, mean_absolute_error: 2.950451, mean_q: 3.774853
13 (array([48]),) False
  23720/500000: episode: 593, duration: 33.309s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 37.350 [15.000, 57.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.148124, mean_absolute_error: 2.964968, mean_q: 3.792581
15 (array([22]),) False
  23760/500000: episode: 594, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.325 [3.000, 56.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.155380, mean_absolute_error: 2.969060, mean_q: 3.771344
5 (array([37]),) False
  23800/500000: episode: 595, duration: 32.335s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 48.150 [11.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.156113, mean_absolute_error: 2.966504, mean_q: 3.788978
295 (array([22]),) False
  23840/500000: episode: 596, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.425 [5.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.149707, mean_absolute_error: 2.995976, mean_q: 3.814034
64 (array([12]),) False
  23880/500000: episode: 597, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.050 [1.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.157079, mean_absolute_error: 2.996181, mean_q: 3.819920
58 (array([48]),) False
  23920/500000: episode: 598, duration: 33.312s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 40.025 [3.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.154187, mean_absolute_error: 3.008347, mean_q: 3.807695
496 (array([48]),) False
  23960/500000: episode: 599, duration: 32.292s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 42.325 [1.000, 58.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.140439, mean_absolute_error: 3.004044, mean_q: 3.824748
466 (array([22]),) False
  24000/500000: episode: 600, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.975 [6.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.142728, mean_absolute_error: 3.009269, mean_q: 3.832422
69 (array([12]),) False
  24040/500000: episode: 601, duration: 33.298s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.375 [3.000, 59.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.150856, mean_absolute_error: 3.002934, mean_q: 3.822791
41 (array([12]),) False
  24080/500000: episode: 602, duration: 33.309s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.475 [0.000, 51.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.155769, mean_absolute_error: 3.007136, mean_q: 3.821043
793 (array([12]),) False
  24120/500000: episode: 603, duration: 32.424s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 22.325 [3.000, 59.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.163956, mean_absolute_error: 3.017503, mean_q: 3.829785
572 (array([58]),) False
  24160/500000: episode: 604, duration: 33.246s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 50.050 [8.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.164002, mean_absolute_error: 3.017218, mean_q: 3.830362
299 (array([12]),) False
  24200/500000: episode: 605, duration: 33.306s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 25.125 [0.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.171051, mean_absolute_error: 3.016299, mean_q: 3.812632
575 (array([44]),) False
  24240/500000: episode: 606, duration: 33.297s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 31.425 [3.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.161059, mean_absolute_error: 2.999074, mean_q: 3.818820
724 (array([58]),) False
  24280/500000: episode: 607, duration: 32.504s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 37.975 [3.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.153817, mean_absolute_error: 2.992469, mean_q: 3.814936
393 (array([22]),) False
  24320/500000: episode: 608, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.550 [2.000, 57.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.158981, mean_absolute_error: 3.004584, mean_q: 3.808288
192 (array([22]),) False
  24360/500000: episode: 609, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 26.850 [0.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.152251, mean_absolute_error: 3.015051, mean_q: 3.833273
422 (array([48]),) False
  24400/500000: episode: 610, duration: 33.280s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 38.700 [1.000, 59.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.165624, mean_absolute_error: 3.027202, mean_q: 3.826342
56 (array([12]),) False
  24440/500000: episode: 611, duration: 32.439s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.900 [4.000, 45.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.151906, mean_absolute_error: 3.020022, mean_q: 3.833089
181 (array([22]),) False
  24480/500000: episode: 612, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 29.925 [0.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.158006, mean_absolute_error: 3.005222, mean_q: 3.819694
766 (array([12]),) False
  24520/500000: episode: 613, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 40.400 [1.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.153670, mean_absolute_error: 3.009622, mean_q: 3.808648
369 (array([48]),) False
  24560/500000: episode: 614, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 40.050 [3.000, 52.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.139569, mean_absolute_error: 3.001311, mean_q: 3.807289
229 (array([48]),) False
  24600/500000: episode: 615, duration: 32.342s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 27.625 [0.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.157005, mean_absolute_error: 3.012052, mean_q: 3.831882
860 (array([12]),) False
  24640/500000: episode: 616, duration: 33.251s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.450 [1.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.153544, mean_absolute_error: 2.994257, mean_q: 3.811818
779 (array([12]),) False
  24680/500000: episode: 617, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 16.950 [0.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.140553, mean_absolute_error: 3.018087, mean_q: 3.849423
178 (array([38]),) False
  24720/500000: episode: 618, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.150 [2.000, 59.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.154489, mean_absolute_error: 3.018713, mean_q: 3.831743
220 (array([22]),) False
  24760/500000: episode: 619, duration: 32.355s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.675 [2.000, 59.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.146228, mean_absolute_error: 3.016469, mean_q: 3.815913
365 (array([22]),) False
  24800/500000: episode: 620, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.200 [1.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.161138, mean_absolute_error: 3.043063, mean_q: 3.856750
365 (array([22]),) False
  24840/500000: episode: 621, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.250 [10.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.167160, mean_absolute_error: 3.021549, mean_q: 3.840929
553 (array([22]),) False
  24880/500000: episode: 622, duration: 33.290s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.950 [12.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.165237, mean_absolute_error: 3.027922, mean_q: 3.834951
51 (array([22]),) False
  24920/500000: episode: 623, duration: 32.366s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.575 [7.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.148752, mean_absolute_error: 3.019852, mean_q: 3.831859
123 (array([22]),) False
  24960/500000: episode: 624, duration: 33.242s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 20.725 [10.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.157450, mean_absolute_error: 3.007016, mean_q: 3.834075
227 (array([22]),) False
  25000/500000: episode: 625, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.550 [4.000, 58.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.168488, mean_absolute_error: 3.024007, mean_q: 3.828616
257 (array([22]),) False
  25040/500000: episode: 626, duration: 33.267s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 39.050 [3.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.161045, mean_absolute_error: 3.029689, mean_q: 3.878800
130 (array([22]),) False
  25080/500000: episode: 627, duration: 32.357s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.050 [9.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.154338, mean_absolute_error: 3.025983, mean_q: 3.860267
631 (array([22]),) False
  25120/500000: episode: 628, duration: 33.304s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.350 [4.000, 58.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.155274, mean_absolute_error: 3.038033, mean_q: 3.837081
757 (array([48]),) False
  25160/500000: episode: 629, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 37.600 [3.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.143905, mean_absolute_error: 3.050627, mean_q: 3.871330
594 (array([48]),) False
  25200/500000: episode: 630, duration: 33.243s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 25.200 [0.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.154294, mean_absolute_error: 3.036982, mean_q: 3.859383
838 (array([21]),) False
  25240/500000: episode: 631, duration: 32.448s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.700 [4.000, 56.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.153387, mean_absolute_error: 3.038626, mean_q: 3.855371
264 (array([12]),) False
  25280/500000: episode: 632, duration: 33.263s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 19.325 [2.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.164662, mean_absolute_error: 3.020666, mean_q: 3.849204
545 (array([22]),) False
  25320/500000: episode: 633, duration: 33.248s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.300 [6.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.165121, mean_absolute_error: 3.032501, mean_q: 3.841257
599 (array([48]),) False
  25360/500000: episode: 634, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 40.050 [8.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.160059, mean_absolute_error: 3.006398, mean_q: 3.823288
355 (array([22]),) False
  25400/500000: episode: 635, duration: 32.340s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.500 [9.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.149573, mean_absolute_error: 3.035762, mean_q: 3.842514
31 (array([48]),) False
  25440/500000: episode: 636, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.125 [3.000, 59.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.153228, mean_absolute_error: 3.035887, mean_q: 3.843585
255 (array([12]),) False
  25480/500000: episode: 637, duration: 33.257s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 25.075 [0.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.159581, mean_absolute_error: 3.026779, mean_q: 3.843797
104 (array([22]),) False
  25520/500000: episode: 638, duration: 33.315s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.725 [2.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.146336, mean_absolute_error: 3.042174, mean_q: 3.862569
145 (array([19]),) False
  25560/500000: episode: 639, duration: 32.366s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.300 [9.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.159455, mean_absolute_error: 3.040151, mean_q: 3.850885
486 (array([22]),) False
  25600/500000: episode: 640, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 21.625 [1.000, 55.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.165357, mean_absolute_error: 3.043548, mean_q: 3.868881
817 (array([12]),) False
  25640/500000: episode: 641, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 26.475 [9.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.160452, mean_absolute_error: 3.041790, mean_q: 3.854812
182 (array([54]),) False
  25680/500000: episode: 642, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 46.700 [0.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.162877, mean_absolute_error: 3.026594, mean_q: 3.837549
158 (array([22]),) False
  25720/500000: episode: 643, duration: 32.409s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 29.250 [7.000, 60.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.166015, mean_absolute_error: 3.031195, mean_q: 3.836797
703 (array([3]),) False
  25760/500000: episode: 644, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 28.750 [2.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.142797, mean_absolute_error: 3.034330, mean_q: 3.842644
129 (array([22]),) False
  25800/500000: episode: 645, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 20.875 [5.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.150069, mean_absolute_error: 3.027954, mean_q: 3.857760
63 (array([18]),) False
  25840/500000: episode: 646, duration: 33.355s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 20.825 [9.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.150786, mean_absolute_error: 3.012032, mean_q: 3.835179
696 (array([36]),) False
  25880/500000: episode: 647, duration: 32.436s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.525 [4.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.156696, mean_absolute_error: 3.023191, mean_q: 3.825694
828 (array([48]),) False
  25920/500000: episode: 648, duration: 33.250s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 41.200 [7.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.169081, mean_absolute_error: 3.009261, mean_q: 3.817492
376 (array([22]),) False
  25960/500000: episode: 649, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 41.750 [0.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.149378, mean_absolute_error: 3.028253, mean_q: 3.839038
370 (array([58]),) False
  26000/500000: episode: 650, duration: 33.278s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 38.375 [0.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.154386, mean_absolute_error: 3.033808, mean_q: 3.862809
230 (array([22]),) False
  26040/500000: episode: 651, duration: 32.387s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 26.900 [12.000, 60.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.147912, mean_absolute_error: 3.031871, mean_q: 3.845277
148 (array([22]),) False
  26080/500000: episode: 652, duration: 33.256s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.475 [6.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.159786, mean_absolute_error: 3.007733, mean_q: 3.822929
785 (array([22]),) False
  26120/500000: episode: 653, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.900 [1.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.164561, mean_absolute_error: 3.036251, mean_q: 3.853097
674 (array([48]),) False
  26160/500000: episode: 654, duration: 33.270s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 29.650 [5.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.154025, mean_absolute_error: 3.047972, mean_q: 3.840109
8 (array([22]),) False
  26200/500000: episode: 655, duration: 32.394s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 33.075 [0.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.169747, mean_absolute_error: 3.022304, mean_q: 3.823325
731 (array([21]),) False
  26240/500000: episode: 656, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 37.900 [7.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.147818, mean_absolute_error: 3.016413, mean_q: 3.839411
190 (array([3]),) False
  26280/500000: episode: 657, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 12.625 [1.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.162235, mean_absolute_error: 3.016369, mean_q: 3.811805
218 (array([22]),) False
  26320/500000: episode: 658, duration: 33.304s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.425 [5.000, 60.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.145710, mean_absolute_error: 3.046842, mean_q: 3.843488
479 (array([22]),) False
  26360/500000: episode: 659, duration: 32.475s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.325 [0.000, 54.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.163331, mean_absolute_error: 3.012587, mean_q: 3.825890
423 (array([22]),) False
  26400/500000: episode: 660, duration: 33.291s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 21.675 [0.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.147604, mean_absolute_error: 3.047511, mean_q: 3.853348
679 (array([44]),) False
  26440/500000: episode: 661, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.325 [1.000, 53.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.147768, mean_absolute_error: 3.051113, mean_q: 3.873811
458 (array([22]),) False
  26480/500000: episode: 662, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.550 [0.000, 53.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.176829, mean_absolute_error: 3.023256, mean_q: 3.851759
82 (array([22]),) False
  26520/500000: episode: 663, duration: 32.373s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.750 [4.000, 60.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.167185, mean_absolute_error: 3.023894, mean_q: 3.858679
160 (array([12]),) False
  26560/500000: episode: 664, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.000 [5.000, 53.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.164658, mean_absolute_error: 3.019681, mean_q: 3.838088
776 (array([22]),) False
  26600/500000: episode: 665, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.375 [4.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.158169, mean_absolute_error: 3.017915, mean_q: 3.836588
820 (array([48]),) False
  26640/500000: episode: 666, duration: 33.391s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.075 [2.000, 51.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.157311, mean_absolute_error: 3.005127, mean_q: 3.805813
286 (array([22]),) False
  26680/500000: episode: 667, duration: 32.499s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 21.275 [1.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.160821, mean_absolute_error: 2.984370, mean_q: 3.798628
539 (array([22]),) False
  26720/500000: episode: 668, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.050 [13.000, 52.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.149524, mean_absolute_error: 3.002594, mean_q: 3.824898
750 (array([22]),) False
  26760/500000: episode: 669, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.925 [3.000, 54.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.146956, mean_absolute_error: 3.010211, mean_q: 3.823966
145 (array([19]),) False
  26800/500000: episode: 670, duration: 33.243s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.300 [3.000, 56.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.159036, mean_absolute_error: 3.008750, mean_q: 3.807378
438 (array([22]),) False
  26840/500000: episode: 671, duration: 32.377s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.725 [1.000, 48.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.157216, mean_absolute_error: 3.016428, mean_q: 3.820441
88 (array([22]),) False
  26880/500000: episode: 672, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.800 [0.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.150400, mean_absolute_error: 3.027627, mean_q: 3.833599
238 (array([22]),) False
  26920/500000: episode: 673, duration: 32.292s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.950 [8.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.152228, mean_absolute_error: 3.042571, mean_q: 3.854512
790 (array([48]),) False
  26960/500000: episode: 674, duration: 31.530s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 29.525 [3.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.160875, mean_absolute_error: 3.024284, mean_q: 3.832810
163 (array([44]),) False
  27000/500000: episode: 675, duration: 31.114s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.775 [0.000, 56.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.158010, mean_absolute_error: 3.058317, mean_q: 3.893035
41 (array([12]),) False
  27040/500000: episode: 676, duration: 31.533s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 26.625 [2.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.171276, mean_absolute_error: 3.048414, mean_q: 3.857152
293 (array([22]),) False
  27080/500000: episode: 677, duration: 31.472s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.200 [0.000, 54.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.164990, mean_absolute_error: 3.037579, mean_q: 3.848302
51 (array([22]),) False
  27120/500000: episode: 678, duration: 31.575s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 25.475 [5.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.156453, mean_absolute_error: 3.021914, mean_q: 3.856126
321 (array([22]),) False
  27160/500000: episode: 679, duration: 31.133s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.800 [7.000, 49.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.163920, mean_absolute_error: 3.017392, mean_q: 3.821926
708 (array([40]),) False
  27200/500000: episode: 680, duration: 31.549s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.150 [4.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.151902, mean_absolute_error: 3.023483, mean_q: 3.842506
58 (array([48]),) False
  27240/500000: episode: 681, duration: 31.469s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 39.525 [0.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.159582, mean_absolute_error: 3.015858, mean_q: 3.834129
488 (array([22]),) False
  27280/500000: episode: 682, duration: 31.583s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 22.650 [3.000, 55.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.151327, mean_absolute_error: 3.015064, mean_q: 3.847918
561 (array([22]),) False
  27320/500000: episode: 683, duration: 31.437s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.375 [3.000, 52.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.159858, mean_absolute_error: 3.003721, mean_q: 3.822640
622 (array([36]),) False
  27360/500000: episode: 684, duration: 32.960s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 36.100 [7.000, 57.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.165959, mean_absolute_error: 3.011298, mean_q: 3.833263
154 (array([44]),) False
  27400/500000: episode: 685, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 26.375 [9.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.166821, mean_absolute_error: 3.000656, mean_q: 3.836623
786 (array([22]),) False
  27440/500000: episode: 686, duration: 32.450s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.700 [1.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.164675, mean_absolute_error: 2.992030, mean_q: 3.809437
837 (array([48]),) False
  27480/500000: episode: 687, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 38.950 [0.000, 60.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.158577, mean_absolute_error: 3.037925, mean_q: 3.853856
62 (array([22]),) False
  27520/500000: episode: 688, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 26.525 [1.000, 60.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.157339, mean_absolute_error: 3.015169, mean_q: 3.827825
183 (array([22]),) False
  27560/500000: episode: 689, duration: 33.291s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.975 [0.000, 55.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.147208, mean_absolute_error: 3.057073, mean_q: 3.862074
751 (array([22]),) False
  27600/500000: episode: 690, duration: 32.438s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 28.750 [4.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.162472, mean_absolute_error: 3.029089, mean_q: 3.844336
607 (array([12]),) False
  27640/500000: episode: 691, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 31.275 [5.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.152215, mean_absolute_error: 3.045166, mean_q: 3.852693
506 (array([8]),) False
  27680/500000: episode: 692, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.375 [2.000, 55.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.166788, mean_absolute_error: 3.046389, mean_q: 3.860423
53 (array([22]),) False
  27720/500000: episode: 693, duration: 33.259s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.475 [1.000, 59.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.157165, mean_absolute_error: 3.058428, mean_q: 3.857199
669 (array([15]),) False
  27760/500000: episode: 694, duration: 32.432s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.275 [4.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.150745, mean_absolute_error: 3.056466, mean_q: 3.869011
263 (array([8]),) False
  27800/500000: episode: 695, duration: 33.214s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.975 [3.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.164638, mean_absolute_error: 3.028411, mean_q: 3.838144
598 (array([22]),) False
  27840/500000: episode: 696, duration: 33.260s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.250 [0.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.166569, mean_absolute_error: 3.049143, mean_q: 3.850422
413 (array([22]),) False
  27880/500000: episode: 697, duration: 33.314s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 27.225 [0.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.158662, mean_absolute_error: 3.028751, mean_q: 3.843841
305 (array([12]),) False
  27920/500000: episode: 698, duration: 32.411s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.400 [4.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.153464, mean_absolute_error: 3.009059, mean_q: 3.801819
141 (array([44]),) False
  27960/500000: episode: 699, duration: 33.325s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.700 [1.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.151247, mean_absolute_error: 3.042494, mean_q: 3.855415
104 (array([22]),) False
  28000/500000: episode: 700, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.425 [10.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.158695, mean_absolute_error: 2.979326, mean_q: 3.788676
91 (array([48]),) False
  28040/500000: episode: 701, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 42.000 [2.000, 58.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.155065, mean_absolute_error: 2.984181, mean_q: 3.792667
345 (array([22]),) False
  28080/500000: episode: 702, duration: 32.393s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.025 [9.000, 55.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.151899, mean_absolute_error: 2.975789, mean_q: 3.767085
534 (array([22]),) False
  28120/500000: episode: 703, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.975 [1.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.146899, mean_absolute_error: 2.991130, mean_q: 3.801949
629 (array([22]),) False
  28160/500000: episode: 704, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 41.850 [4.000, 56.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.145424, mean_absolute_error: 2.982441, mean_q: 3.798413
547 (array([21]),) False
  28200/500000: episode: 705, duration: 33.336s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.650 [1.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.147513, mean_absolute_error: 3.001368, mean_q: 3.811093
733 (array([22]),) False
  28240/500000: episode: 706, duration: 32.430s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.825 [2.000, 55.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.151654, mean_absolute_error: 2.990318, mean_q: 3.798549
134 (array([58]),) False
  28280/500000: episode: 707, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 42.125 [0.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.176203, mean_absolute_error: 2.978539, mean_q: 3.797372
343 (array([22]),) False
  28320/500000: episode: 708, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.900 [1.000, 46.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.163674, mean_absolute_error: 2.978083, mean_q: 3.785350
830 (array([22]),) False
  28360/500000: episode: 709, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.775 [1.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.154276, mean_absolute_error: 2.951526, mean_q: 3.762688
320 (array([22]),) False
  28400/500000: episode: 710, duration: 32.351s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 19.850 [0.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.151626, mean_absolute_error: 2.950289, mean_q: 3.759986
248 (array([12]),) False
  28440/500000: episode: 711, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 27.375 [4.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.147240, mean_absolute_error: 2.961470, mean_q: 3.780350
232 (array([22]),) False
  28480/500000: episode: 712, duration: 33.282s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 21.850 [0.000, 58.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.166407, mean_absolute_error: 2.958328, mean_q: 3.763261
287 (array([48]),) False
  28520/500000: episode: 713, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 21.525 [1.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.130732, mean_absolute_error: 2.971095, mean_q: 3.768800
672 (array([44]),) False
  28560/500000: episode: 714, duration: 32.412s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 41.950 [0.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.149658, mean_absolute_error: 2.957785, mean_q: 3.769538
811 (array([33]),) False
  28600/500000: episode: 715, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 26.025 [6.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.150881, mean_absolute_error: 2.950400, mean_q: 3.743021
731 (array([21]),) False
  28640/500000: episode: 716, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 36.125 [3.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.138811, mean_absolute_error: 2.930241, mean_q: 3.724042
354 (array([12]),) False
  28680/500000: episode: 717, duration: 33.322s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.725 [2.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.139831, mean_absolute_error: 2.946460, mean_q: 3.748006
677 (array([48]),) False
  28720/500000: episode: 718, duration: 32.338s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 31.825 [0.000, 57.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.158483, mean_absolute_error: 2.913220, mean_q: 3.701960
394 (array([22]),) False
  28760/500000: episode: 719, duration: 33.290s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.075 [6.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.155938, mean_absolute_error: 2.915919, mean_q: 3.715806
620 (array([44]),) False
  28800/500000: episode: 720, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 34.550 [3.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.145164, mean_absolute_error: 2.906200, mean_q: 3.695163
360 (array([22]),) False
  28840/500000: episode: 721, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 25.625 [1.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.146893, mean_absolute_error: 2.912831, mean_q: 3.731860
857 (array([22]),) False
  28880/500000: episode: 722, duration: 32.380s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.475 [0.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.137975, mean_absolute_error: 2.924268, mean_q: 3.743082
319 (array([33]),) False
  28920/500000: episode: 723, duration: 33.293s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.375 [3.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.148393, mean_absolute_error: 2.908733, mean_q: 3.709920
819 (array([48]),) False
  28960/500000: episode: 724, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 32.400 [0.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.149518, mean_absolute_error: 2.953813, mean_q: 3.760589
19 (array([12]),) False
  29000/500000: episode: 725, duration: 33.294s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.775 [2.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.163461, mean_absolute_error: 2.912218, mean_q: 3.711111
327 (array([22]),) False
  29040/500000: episode: 726, duration: 32.427s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.300 [1.000, 50.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.169399, mean_absolute_error: 2.912566, mean_q: 3.702525
73 (array([22]),) False
  29080/500000: episode: 727, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.450 [0.000, 55.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.147886, mean_absolute_error: 2.930401, mean_q: 3.741139
816 (array([4]),) False
  29120/500000: episode: 728, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 36.750 [0.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.154956, mean_absolute_error: 2.891944, mean_q: 3.712417
55 (array([22]),) False
  29160/500000: episode: 729, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.700 [11.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.154826, mean_absolute_error: 2.885132, mean_q: 3.695818
150 (array([22]),) False
  29200/500000: episode: 730, duration: 32.505s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.100 [11.000, 60.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.144932, mean_absolute_error: 2.894806, mean_q: 3.701560
428 (array([22]),) False
  29240/500000: episode: 731, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.325 [1.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.138118, mean_absolute_error: 2.890645, mean_q: 3.689368
643 (array([44]),) False
  29280/500000: episode: 732, duration: 33.248s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 30.750 [13.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.142215, mean_absolute_error: 2.882088, mean_q: 3.708773
830 (array([22]),) False
  29320/500000: episode: 733, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.525 [5.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.135853, mean_absolute_error: 2.908659, mean_q: 3.718498
134 (array([58]),) False
  29360/500000: episode: 734, duration: 32.424s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 48.000 [4.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.151164, mean_absolute_error: 2.899830, mean_q: 3.718102
222 (array([22]),) False
  29400/500000: episode: 735, duration: 33.304s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.425 [4.000, 54.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.152095, mean_absolute_error: 2.908507, mean_q: 3.716280
550 (array([12]),) False
  29440/500000: episode: 736, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 29.075 [2.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.147237, mean_absolute_error: 2.900811, mean_q: 3.709533
313 (array([22]),) False
  29480/500000: episode: 737, duration: 33.294s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.175 [8.000, 53.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.144523, mean_absolute_error: 2.902601, mean_q: 3.690585
254 (array([22]),) False
  29520/500000: episode: 738, duration: 32.421s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.250 [3.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.151047, mean_absolute_error: 2.895622, mean_q: 3.716330
392 (array([40]),) False
  29560/500000: episode: 739, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 25.600 [5.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.134797, mean_absolute_error: 2.894297, mean_q: 3.720206
635 (array([22]),) False
  29600/500000: episode: 740, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.875 [2.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.147263, mean_absolute_error: 2.889628, mean_q: 3.701883
56 (array([12]),) False
  29640/500000: episode: 741, duration: 33.286s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.450 [1.000, 57.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.157812, mean_absolute_error: 2.891471, mean_q: 3.708592
683 (array([22]),) False
  29680/500000: episode: 742, duration: 32.414s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.600 [0.000, 56.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.155365, mean_absolute_error: 2.915469, mean_q: 3.729219
763 (array([48]),) False
  29720/500000: episode: 743, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 42.575 [8.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.139621, mean_absolute_error: 2.896204, mean_q: 3.686179
262 (array([22]),) False
  29760/500000: episode: 744, duration: 33.368s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 30.100 [4.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.148094, mean_absolute_error: 2.880091, mean_q: 3.662299
856 (array([48]),) False
  29800/500000: episode: 745, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 43.925 [9.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.138783, mean_absolute_error: 2.902960, mean_q: 3.690631
235 (array([14]),) False
  29840/500000: episode: 746, duration: 32.396s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.075 [9.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.155546, mean_absolute_error: 2.895417, mean_q: 3.703627
506 (array([8]),) False
  29880/500000: episode: 747, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 28.125 [2.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.147561, mean_absolute_error: 2.897922, mean_q: 3.694137
530 (array([22]),) False
  29920/500000: episode: 748, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.425 [3.000, 55.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.156202, mean_absolute_error: 2.893502, mean_q: 3.696786
704 (array([22]),) False
  29960/500000: episode: 749, duration: 33.267s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.250 [0.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.156689, mean_absolute_error: 2.915229, mean_q: 3.714139
603 (array([58]),) False
  30000/500000: episode: 750, duration: 32.310s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 44.225 [1.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.143123, mean_absolute_error: 2.886270, mean_q: 3.694312
546 (array([22]),) False
  30040/500000: episode: 751, duration: 33.320s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.700 [12.000, 52.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.162594, mean_absolute_error: 2.875793, mean_q: 3.681488
700 (array([44]),) False
  30080/500000: episode: 752, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 45.675 [1.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.148526, mean_absolute_error: 2.878194, mean_q: 3.689920
327 (array([22]),) False
  30120/500000: episode: 753, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.675 [3.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.150453, mean_absolute_error: 2.864658, mean_q: 3.678491
768 (array([22]),) False
  30160/500000: episode: 754, duration: 32.430s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 22.075 [1.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.150751, mean_absolute_error: 2.867065, mean_q: 3.670641
670 (array([22]),) False
  30200/500000: episode: 755, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 24.475 [1.000, 57.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.148135, mean_absolute_error: 2.831359, mean_q: 3.646572
862 (array([14]),) False
  30240/500000: episode: 756, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 39.750 [0.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.129782, mean_absolute_error: 2.868810, mean_q: 3.688443
427 (array([22]),) False
  30280/500000: episode: 757, duration: 33.302s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 24.800 [5.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.138369, mean_absolute_error: 2.849692, mean_q: 3.644304
51 (array([22]),) False
  30320/500000: episode: 758, duration: 32.325s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.825 [4.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.153098, mean_absolute_error: 2.843847, mean_q: 3.647638
727 (array([12]),) False
  30360/500000: episode: 759, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 19.700 [1.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.145327, mean_absolute_error: 2.839746, mean_q: 3.637315
298 (array([22]),) False
  30400/500000: episode: 760, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.025 [1.000, 52.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.146849, mean_absolute_error: 2.818951, mean_q: 3.633315
799 (array([36]),) False
  30440/500000: episode: 761, duration: 33.283s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 29.600 [3.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.151635, mean_absolute_error: 2.815414, mean_q: 3.616333
509 (array([22]),) False
  30480/500000: episode: 762, duration: 32.345s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.800 [4.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.141314, mean_absolute_error: 2.818326, mean_q: 3.626926
733 (array([22]),) False
  30520/500000: episode: 763, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.250 [0.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.145012, mean_absolute_error: 2.802744, mean_q: 3.609294
654 (array([22]),) False
  30560/500000: episode: 764, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.050 [1.000, 48.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.147189, mean_absolute_error: 2.802999, mean_q: 3.612917
16 (array([22]),) False
  30600/500000: episode: 765, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.975 [2.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.139036, mean_absolute_error: 2.798361, mean_q: 3.597319
733 (array([22]),) False
  30640/500000: episode: 766, duration: 32.405s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 27.125 [3.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.140574, mean_absolute_error: 2.807296, mean_q: 3.613210
368 (array([22]),) False
  30680/500000: episode: 767, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.150 [2.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.134884, mean_absolute_error: 2.787864, mean_q: 3.593001
703 (array([3]),) False
  30720/500000: episode: 768, duration: 33.348s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 21.525 [0.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.135943, mean_absolute_error: 2.805157, mean_q: 3.609094
173 (array([3]),) False
  30760/500000: episode: 769, duration: 33.336s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 10.500 [3.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.135066, mean_absolute_error: 2.798449, mean_q: 3.609339
509 (array([22]),) False
  30800/500000: episode: 770, duration: 31.726s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.175 [3.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.143655, mean_absolute_error: 2.806345, mean_q: 3.610611
379 (array([22]),) False
  30840/500000: episode: 771, duration: 31.572s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.525 [12.000, 56.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.142825, mean_absolute_error: 2.809680, mean_q: 3.609891
76 (array([38]),) False
  30880/500000: episode: 772, duration: 31.583s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.400 [9.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.152355, mean_absolute_error: 2.786714, mean_q: 3.573950
154 (array([44]),) False
  30920/500000: episode: 773, duration: 31.653s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 34.275 [3.000, 57.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.142720, mean_absolute_error: 2.813894, mean_q: 3.609726
804 (array([3]),) False
  30960/500000: episode: 774, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 15.300 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.159036, mean_absolute_error: 2.770504, mean_q: 3.559605
576 (array([58]),) False
  31000/500000: episode: 775, duration: 31.522s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 44.575 [2.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.154346, mean_absolute_error: 2.770687, mean_q: 3.556248
322 (array([12]),) False
  31040/500000: episode: 776, duration: 31.515s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 32.200 [1.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.140897, mean_absolute_error: 2.788024, mean_q: 3.589870
432 (array([22]),) False
  31080/500000: episode: 777, duration: 31.583s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.325 [3.000, 57.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.140449, mean_absolute_error: 2.765110, mean_q: 3.573159
542 (array([44]),) False
  31120/500000: episode: 778, duration: 31.147s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.650 [4.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.145514, mean_absolute_error: 2.755018, mean_q: 3.550047
195 (array([22]),) False
  31160/500000: episode: 779, duration: 31.452s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 36.175 [5.000, 54.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.149387, mean_absolute_error: 2.767698, mean_q: 3.568693
35 (array([48]),) False
  31200/500000: episode: 780, duration: 31.549s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 44.750 [6.000, 58.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.142861, mean_absolute_error: 2.760788, mean_q: 3.552734
593 (array([37]),) False
  31240/500000: episode: 781, duration: 31.505s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 34.050 [1.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.139186, mean_absolute_error: 2.767151, mean_q: 3.562378
172 (array([12]),) False
  31280/500000: episode: 782, duration: 31.092s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 18.275 [0.000, 56.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.140464, mean_absolute_error: 2.754395, mean_q: 3.544733
651 (array([22]),) False
  31320/500000: episode: 783, duration: 31.538s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.425 [1.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.127798, mean_absolute_error: 2.766671, mean_q: 3.558923
343 (array([22]),) False
  31360/500000: episode: 784, duration: 31.608s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.125 [11.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.132650, mean_absolute_error: 2.761861, mean_q: 3.567243
584 (array([36]),) False
  31400/500000: episode: 785, duration: 31.504s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 11.850 [3.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.142278, mean_absolute_error: 2.793208, mean_q: 3.597177
676 (array([40]),) False
  31440/500000: episode: 786, duration: 31.558s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.650 [3.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.145150, mean_absolute_error: 2.751427, mean_q: 3.545853
518 (array([22]),) False
  31480/500000: episode: 787, duration: 33.317s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.575 [4.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.145837, mean_absolute_error: 2.743628, mean_q: 3.529542
832 (array([22]),) False
  31520/500000: episode: 788, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.900 [11.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.123785, mean_absolute_error: 2.752893, mean_q: 3.549226
168 (array([22]),) False
  31560/500000: episode: 789, duration: 33.274s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 16.925 [3.000, 53.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.143659, mean_absolute_error: 2.746108, mean_q: 3.554585
579 (array([58]),) False
  31600/500000: episode: 790, duration: 32.374s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 20.825 [3.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.127065, mean_absolute_error: 2.759904, mean_q: 3.562074
459 (array([22]),) False
  31640/500000: episode: 791, duration: 33.256s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.650 [0.000, 54.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.143180, mean_absolute_error: 2.743394, mean_q: 3.541768
14 (array([48]),) False
  31680/500000: episode: 792, duration: 33.202s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 32.675 [1.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.139900, mean_absolute_error: 2.745128, mean_q: 3.533877
667 (array([48]),) False
  31720/500000: episode: 793, duration: 33.289s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 40.400 [0.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.143044, mean_absolute_error: 2.751197, mean_q: 3.538666
328 (array([12]),) False
  31760/500000: episode: 794, duration: 32.387s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 17.775 [1.000, 51.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.135627, mean_absolute_error: 2.741035, mean_q: 3.537866
189 (array([12]),) False
  31800/500000: episode: 795, duration: 33.245s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 19.600 [10.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.144899, mean_absolute_error: 2.756970, mean_q: 3.564555
734 (array([48]),) False
  31840/500000: episode: 796, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 30.475 [12.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.125133, mean_absolute_error: 2.797726, mean_q: 3.604161
708 (array([40]),) False
  31880/500000: episode: 797, duration: 33.389s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.125 [4.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.141201, mean_absolute_error: 2.769716, mean_q: 3.567050
704 (array([22]),) False
  31920/500000: episode: 798, duration: 32.436s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.800 [0.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.135274, mean_absolute_error: 2.773217, mean_q: 3.571563
751 (array([22]),) False
  31960/500000: episode: 799, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 33.500 [2.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.149100, mean_absolute_error: 2.769742, mean_q: 3.581131
96 (array([22]),) False
  32000/500000: episode: 800, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.675 [10.000, 60.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.129096, mean_absolute_error: 2.767414, mean_q: 3.559401
315 (array([12]),) False
  32040/500000: episode: 801, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.750 [12.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.137837, mean_absolute_error: 2.752663, mean_q: 3.578639
432 (array([22]),) False
  32080/500000: episode: 802, duration: 32.338s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.675 [0.000, 53.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.150174, mean_absolute_error: 2.755897, mean_q: 3.576349
241 (array([22]),) False
  32120/500000: episode: 803, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.500 [1.000, 52.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.144624, mean_absolute_error: 2.763838, mean_q: 3.566844
632 (array([22]),) False
  32160/500000: episode: 804, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.575 [8.000, 60.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.147651, mean_absolute_error: 2.785806, mean_q: 3.584279
569 (array([22]),) False
  32200/500000: episode: 805, duration: 33.349s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 29.075 [4.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.146074, mean_absolute_error: 2.789729, mean_q: 3.595850
656 (array([48]),) False
  32240/500000: episode: 806, duration: 32.466s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 40.250 [2.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.146411, mean_absolute_error: 2.784999, mean_q: 3.579509
695 (array([22]),) False
  32280/500000: episode: 807, duration: 33.265s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.800 [8.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.141613, mean_absolute_error: 2.807473, mean_q: 3.614395
564 (array([22]),) False
  32320/500000: episode: 808, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.825 [0.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.143358, mean_absolute_error: 2.786920, mean_q: 3.591567
598 (array([22]),) False
  32360/500000: episode: 809, duration: 33.354s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 30.175 [20.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.139384, mean_absolute_error: 2.787878, mean_q: 3.605300
151 (array([22]),) False
  32400/500000: episode: 810, duration: 32.327s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.850 [1.000, 48.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.143032, mean_absolute_error: 2.796314, mean_q: 3.606985
302 (array([22]),) False
  32440/500000: episode: 811, duration: 33.261s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.850 [7.000, 47.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.145968, mean_absolute_error: 2.802952, mean_q: 3.613572
162 (array([22]),) False
  32480/500000: episode: 812, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.700 [3.000, 56.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.134879, mean_absolute_error: 2.784948, mean_q: 3.593055
624 (array([48]),) False
  32520/500000: episode: 813, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 27.750 [4.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.144266, mean_absolute_error: 2.766342, mean_q: 3.587403
134 (array([58]),) False
  32560/500000: episode: 814, duration: 32.387s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 47.825 [8.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.145859, mean_absolute_error: 2.762425, mean_q: 3.574335
26 (array([22]),) False
  32600/500000: episode: 815, duration: 33.299s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.875 [4.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.146589, mean_absolute_error: 2.741212, mean_q: 3.556901
176 (array([3]),) False
  32640/500000: episode: 816, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 44.350 [3.000, 58.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.154575, mean_absolute_error: 2.770366, mean_q: 3.577502
821 (array([22]),) False
  32680/500000: episode: 817, duration: 33.381s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.625 [1.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.151654, mean_absolute_error: 2.747913, mean_q: 3.554361
595 (array([22]),) False
  32720/500000: episode: 818, duration: 32.419s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.850 [3.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.148553, mean_absolute_error: 2.770554, mean_q: 3.560586
783 (array([22]),) False
  32760/500000: episode: 819, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.800 [12.000, 52.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.150373, mean_absolute_error: 2.745239, mean_q: 3.529053
600 (array([48]),) False
  32800/500000: episode: 820, duration: 33.285s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 41.475 [2.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.131670, mean_absolute_error: 2.766117, mean_q: 3.565677
726 (array([12]),) False
  32840/500000: episode: 821, duration: 33.321s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 21.825 [3.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.155564, mean_absolute_error: 2.707966, mean_q: 3.511465
453 (array([22]),) False
  32880/500000: episode: 822, duration: 32.351s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 21.725 [5.000, 49.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.123906, mean_absolute_error: 2.742581, mean_q: 3.560041
210 (array([58]),) False
  32920/500000: episode: 823, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.700 [3.000, 59.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.134367, mean_absolute_error: 2.725999, mean_q: 3.535537
11 (array([22]),) False
  32960/500000: episode: 824, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.325 [14.000, 57.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.126837, mean_absolute_error: 2.744416, mean_q: 3.549153
374 (array([22]),) False
  33000/500000: episode: 825, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.725 [10.000, 60.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.130438, mean_absolute_error: 2.750470, mean_q: 3.548758
320 (array([22]),) False
  33040/500000: episode: 826, duration: 32.407s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.700 [0.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.148528, mean_absolute_error: 2.738838, mean_q: 3.532819
180 (array([48]),) False
  33080/500000: episode: 827, duration: 33.268s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 43.600 [2.000, 57.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.141848, mean_absolute_error: 2.726938, mean_q: 3.519125
702 (array([22]),) False
  33120/500000: episode: 828, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.425 [3.000, 52.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.141079, mean_absolute_error: 2.735811, mean_q: 3.536664
674 (array([48]),) False
  33160/500000: episode: 829, duration: 33.308s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.325 [11.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.146294, mean_absolute_error: 2.715377, mean_q: 3.502780
380 (array([22]),) False
  33200/500000: episode: 830, duration: 32.436s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.575 [0.000, 60.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.126573, mean_absolute_error: 2.720440, mean_q: 3.531078
73 (array([22]),) False
  33240/500000: episode: 831, duration: 33.253s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.225 [12.000, 55.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.138169, mean_absolute_error: 2.729640, mean_q: 3.524956
44 (array([22]),) False
  33280/500000: episode: 832, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 22.325 [2.000, 56.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.143861, mean_absolute_error: 2.725653, mean_q: 3.516547
719 (array([22]),) False
  33320/500000: episode: 833, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 35.825 [2.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.139860, mean_absolute_error: 2.730415, mean_q: 3.526875
179 (array([18]),) False
  33360/500000: episode: 834, duration: 32.391s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 18.925 [3.000, 55.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.156860, mean_absolute_error: 2.729488, mean_q: 3.541727
260 (array([22]),) False
  33400/500000: episode: 835, duration: 33.253s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.700 [2.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.150267, mean_absolute_error: 2.729522, mean_q: 3.535241
186 (array([22]),) False
  33440/500000: episode: 836, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.400 [1.000, 59.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.150926, mean_absolute_error: 2.705551, mean_q: 3.504475
66 (array([22]),) False
  33480/500000: episode: 837, duration: 33.251s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.350 [2.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.131385, mean_absolute_error: 2.737825, mean_q: 3.545652
767 (array([48]),) False
  33520/500000: episode: 838, duration: 32.420s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 41.350 [5.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.141359, mean_absolute_error: 2.741859, mean_q: 3.544987
681 (array([12]),) False
  33560/500000: episode: 839, duration: 33.254s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.025 [0.000, 58.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.142954, mean_absolute_error: 2.747363, mean_q: 3.553473
640 (array([22]),) False
  33600/500000: episode: 840, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.425 [9.000, 55.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.140850, mean_absolute_error: 2.740808, mean_q: 3.558372
63 (array([18]),) False
  33640/500000: episode: 841, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 18.175 [0.000, 49.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.140907, mean_absolute_error: 2.726723, mean_q: 3.528942
607 (array([12]),) False
  33680/500000: episode: 842, duration: 32.371s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.325 [2.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.141333, mean_absolute_error: 2.781590, mean_q: 3.589272
735 (array([22]),) False
  33720/500000: episode: 843, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.225 [2.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.140521, mean_absolute_error: 2.755603, mean_q: 3.575078
711 (array([22]),) False
  33760/500000: episode: 844, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.600 [3.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.147530, mean_absolute_error: 2.783001, mean_q: 3.594592
394 (array([22]),) False
  33800/500000: episode: 845, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.675 [4.000, 53.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.141118, mean_absolute_error: 2.765137, mean_q: 3.573826
133 (array([22]),) False
  33840/500000: episode: 846, duration: 32.374s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.700 [0.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.147759, mean_absolute_error: 2.780669, mean_q: 3.585702
630 (array([22]),) False
  33880/500000: episode: 847, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 28.600 [0.000, 57.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.143684, mean_absolute_error: 2.778845, mean_q: 3.578137
178 (array([38]),) False
  33920/500000: episode: 848, duration: 33.263s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.700 [7.000, 55.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.144774, mean_absolute_error: 2.807978, mean_q: 3.599673
95 (array([22]),) False
  33960/500000: episode: 849, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.950 [3.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.141157, mean_absolute_error: 2.820629, mean_q: 3.619692
51 (array([22]),) False
  34000/500000: episode: 850, duration: 32.324s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.275 [0.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.152964, mean_absolute_error: 2.798650, mean_q: 3.599240
92 (array([22]),) False
  34040/500000: episode: 851, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.975 [3.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.146512, mean_absolute_error: 2.820539, mean_q: 3.644027
683 (array([22]),) False
  34080/500000: episode: 852, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.425 [3.000, 53.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.140311, mean_absolute_error: 2.808941, mean_q: 3.631093
681 (array([12]),) False
  34120/500000: episode: 853, duration: 32.198s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.150 [0.000, 57.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.152301, mean_absolute_error: 2.827403, mean_q: 3.635241
661 (array([48]),) False
  34160/500000: episode: 854, duration: 31.682s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.800 [2.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.148532, mean_absolute_error: 2.825479, mean_q: 3.635431
651 (array([22]),) False
  34200/500000: episode: 855, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.275 [1.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.145134, mean_absolute_error: 2.809116, mean_q: 3.631388
528 (array([12]),) False
  34240/500000: episode: 856, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 23.200 [6.000, 51.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.144384, mean_absolute_error: 2.811413, mean_q: 3.632367
178 (array([38]),) False
  34280/500000: episode: 857, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 25.450 [10.000, 57.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.141138, mean_absolute_error: 2.828549, mean_q: 3.638335
854 (array([12]),) False
  34320/500000: episode: 858, duration: 32.422s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 21.925 [12.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.139464, mean_absolute_error: 2.843373, mean_q: 3.660822
745 (array([22]),) False
  34360/500000: episode: 859, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 28.000 [8.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.155948, mean_absolute_error: 2.827329, mean_q: 3.633939
544 (array([22]),) False
  34400/500000: episode: 860, duration: 33.204s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.000 [10.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.142931, mean_absolute_error: 2.814772, mean_q: 3.628371
583 (array([22]),) False
  34440/500000: episode: 861, duration: 33.303s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 23.525 [3.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.139475, mean_absolute_error: 2.828489, mean_q: 3.630200
742 (array([33]),) False
  34480/500000: episode: 862, duration: 32.430s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 31.200 [2.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.143750, mean_absolute_error: 2.825064, mean_q: 3.644975
103 (array([22]),) False
  34520/500000: episode: 863, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 31.175 [1.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.139206, mean_absolute_error: 2.821645, mean_q: 3.631283
691 (array([22]),) False
  34560/500000: episode: 864, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.525 [4.000, 54.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.146225, mean_absolute_error: 2.836620, mean_q: 3.655963
788 (array([3]),) False
  34600/500000: episode: 865, duration: 33.341s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 43.800 [2.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.146467, mean_absolute_error: 2.842553, mean_q: 3.649012
352 (array([22]),) False
  34640/500000: episode: 866, duration: 32.389s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.400 [4.000, 53.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.136599, mean_absolute_error: 2.851596, mean_q: 3.648107
41 (array([12]),) False
  34680/500000: episode: 867, duration: 32.995s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 29.200 [0.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.131577, mean_absolute_error: 2.826762, mean_q: 3.636911
405 (array([22]),) False
  34720/500000: episode: 868, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.825 [3.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.134771, mean_absolute_error: 2.802323, mean_q: 3.615419
365 (array([22]),) False
  34760/500000: episode: 869, duration: 33.242s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.450 [0.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.143939, mean_absolute_error: 2.823301, mean_q: 3.621314
87 (array([3]),) False
  34800/500000: episode: 870, duration: 32.293s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 9.325 [1.000, 54.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.136716, mean_absolute_error: 2.818785, mean_q: 3.635398
428 (array([22]),) False
  34840/500000: episode: 871, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.300 [2.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.149482, mean_absolute_error: 2.818183, mean_q: 3.609993
387 (array([22]),) False
  34880/500000: episode: 872, duration: 32.742s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.650 [0.000, 60.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.140029, mean_absolute_error: 2.794533, mean_q: 3.596638
87 (array([3]),) False
  34920/500000: episode: 873, duration: 32.876s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 14.525 [3.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.145506, mean_absolute_error: 2.825603, mean_q: 3.624971
52 (array([22]),) False
  34960/500000: episode: 874, duration: 31.663s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.375 [0.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.140857, mean_absolute_error: 2.790056, mean_q: 3.582577
294 (array([22]),) False
  35000/500000: episode: 875, duration: 32.029s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.075 [8.000, 38.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.140106, mean_absolute_error: 2.762394, mean_q: 3.556777
341 (array([22]),) False
  35040/500000: episode: 876, duration: 32.059s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.250 [3.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.140880, mean_absolute_error: 2.776009, mean_q: 3.579005
479 (array([22]),) False
  35080/500000: episode: 877, duration: 32.884s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.675 [9.000, 59.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.130405, mean_absolute_error: 2.785747, mean_q: 3.592089
208 (array([22]),) False
  35120/500000: episode: 878, duration: 32.228s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 23.475 [1.000, 58.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.150298, mean_absolute_error: 2.773477, mean_q: 3.570735
466 (array([22]),) False
  35160/500000: episode: 879, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.350 [6.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.147863, mean_absolute_error: 2.776109, mean_q: 3.577929
225 (array([48]),) False
  35200/500000: episode: 880, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 33.850 [2.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.153641, mean_absolute_error: 2.807492, mean_q: 3.607437
50 (array([22]),) False
  35240/500000: episode: 881, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.450 [7.000, 55.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.133966, mean_absolute_error: 2.791302, mean_q: 3.605043
606 (array([22]),) False
  35280/500000: episode: 882, duration: 32.271s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.725 [0.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.139120, mean_absolute_error: 2.795158, mean_q: 3.594411
333 (array([12]),) False
  35320/500000: episode: 883, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.100 [12.000, 58.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.144001, mean_absolute_error: 2.746880, mean_q: 3.550069
232 (array([22]),) False
  35360/500000: episode: 884, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.225 [4.000, 56.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.130353, mean_absolute_error: 2.768254, mean_q: 3.591569
323 (array([55]),) False
  35400/500000: episode: 885, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.500 [0.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.148072, mean_absolute_error: 2.734467, mean_q: 3.556380
718 (array([12]),) False
  35440/500000: episode: 886, duration: 32.248s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 24.525 [3.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.133997, mean_absolute_error: 2.757191, mean_q: 3.562044
260 (array([22]),) False
  35480/500000: episode: 887, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.025 [9.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.137781, mean_absolute_error: 2.752964, mean_q: 3.562586
9 (array([14]),) False
  35520/500000: episode: 888, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.100 [3.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.135369, mean_absolute_error: 2.750633, mean_q: 3.555627
82 (array([22]),) False
  35560/500000: episode: 889, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.050 [9.000, 52.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.132041, mean_absolute_error: 2.777884, mean_q: 3.576303
572 (array([58]),) False
  35600/500000: episode: 890, duration: 32.201s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 46.350 [2.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.137834, mean_absolute_error: 2.747135, mean_q: 3.537445
729 (array([22]),) False
  35640/500000: episode: 891, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 38.000 [3.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.146092, mean_absolute_error: 2.752367, mean_q: 3.554805
566 (array([12]),) False
  35680/500000: episode: 892, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 29.525 [6.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.143852, mean_absolute_error: 2.751348, mean_q: 3.557590
796 (array([38]),) False
  35720/500000: episode: 893, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.300 [7.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.143091, mean_absolute_error: 2.758796, mean_q: 3.570685
148 (array([22]),) False
  35760/500000: episode: 894, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.550 [0.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.140579, mean_absolute_error: 2.740017, mean_q: 3.548383
577 (array([12]),) False
  35800/500000: episode: 895, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 22.750 [2.000, 50.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.131463, mean_absolute_error: 2.746904, mean_q: 3.564273
307 (array([22]),) False
  35840/500000: episode: 896, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.150 [3.000, 47.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.143770, mean_absolute_error: 2.746732, mean_q: 3.551391
601 (array([14]),) False
  35880/500000: episode: 897, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 46.000 [4.000, 60.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.146898, mean_absolute_error: 2.748805, mean_q: 3.550648
843 (array([3]),) False
  35920/500000: episode: 898, duration: 32.238s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 22.950 [0.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.138998, mean_absolute_error: 2.724776, mean_q: 3.529122
390 (array([22]),) False
  35960/500000: episode: 899, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 27.275 [2.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.144453, mean_absolute_error: 2.762429, mean_q: 3.554125
48 (array([12]),) False
  36000/500000: episode: 900, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.575 [0.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.141181, mean_absolute_error: 2.726789, mean_q: 3.526415
21 (array([3]),) False
  36040/500000: episode: 901, duration: 33.146s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 26.275 [3.000, 51.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.126332, mean_absolute_error: 2.747214, mean_q: 3.548287
10 (array([3]),) False
  36080/500000: episode: 902, duration: 32.239s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 28.450 [0.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.135738, mean_absolute_error: 2.747644, mean_q: 3.535995
723 (array([48]),) False
  36120/500000: episode: 903, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 18.525 [1.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.133526, mean_absolute_error: 2.737534, mean_q: 3.540915
162 (array([22]),) False
  36160/500000: episode: 904, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.775 [0.000, 60.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.137103, mean_absolute_error: 2.742805, mean_q: 3.547807
395 (array([22]),) False
  36200/500000: episode: 905, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.950 [1.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.137919, mean_absolute_error: 2.738124, mean_q: 3.541723
203 (array([48]),) False
  36240/500000: episode: 906, duration: 32.294s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.550 [1.000, 58.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.147718, mean_absolute_error: 2.746907, mean_q: 3.542612
681 (array([12]),) False
  36280/500000: episode: 907, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 23.175 [6.000, 59.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.147267, mean_absolute_error: 2.744504, mean_q: 3.564346
245 (array([22]),) False
  36320/500000: episode: 908, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.675 [4.000, 60.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.143591, mean_absolute_error: 2.718704, mean_q: 3.544141
103 (array([22]),) False
  36360/500000: episode: 909, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 26.575 [1.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.142860, mean_absolute_error: 2.750050, mean_q: 3.547211
730 (array([54]),) False
  36400/500000: episode: 910, duration: 32.319s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 39.500 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.152269, mean_absolute_error: 2.741029, mean_q: 3.526716
347 (array([22]),) False
  36440/500000: episode: 911, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.275 [3.000, 57.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.131302, mean_absolute_error: 2.728676, mean_q: 3.523154
626 (array([22]),) False
  36480/500000: episode: 912, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.000 [0.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.138765, mean_absolute_error: 2.717512, mean_q: 3.515561
298 (array([22]),) False
  36520/500000: episode: 913, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.950 [10.000, 55.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.125309, mean_absolute_error: 2.729967, mean_q: 3.524592
572 (array([58]),) False
  36560/500000: episode: 914, duration: 32.341s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 46.400 [3.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.139275, mean_absolute_error: 2.713860, mean_q: 3.516038
669 (array([15]),) False
  36600/500000: episode: 915, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 43.875 [7.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.132737, mean_absolute_error: 2.716415, mean_q: 3.500575
59 (array([12]),) False
  36640/500000: episode: 916, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 25.575 [1.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.142569, mean_absolute_error: 2.729652, mean_q: 3.529667
860 (array([12]),) False
  36680/500000: episode: 917, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 15.175 [4.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.149862, mean_absolute_error: 2.687898, mean_q: 3.498954
505 (array([22]),) False
  36720/500000: episode: 918, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.400 [10.000, 56.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.134667, mean_absolute_error: 2.702051, mean_q: 3.511070
318 (array([48]),) False
  36760/500000: episode: 919, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 42.550 [4.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.148637, mean_absolute_error: 2.685791, mean_q: 3.469943
74 (array([22]),) False
  36800/500000: episode: 920, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.850 [1.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.128166, mean_absolute_error: 2.679507, mean_q: 3.483936
11 (array([22]),) False
  36840/500000: episode: 921, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 28.150 [12.000, 58.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.143910, mean_absolute_error: 2.677428, mean_q: 3.463528
102 (array([22]),) False
  36880/500000: episode: 922, duration: 32.267s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.850 [7.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.125650, mean_absolute_error: 2.659955, mean_q: 3.450871
620 (array([44]),) False
  36920/500000: episode: 923, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 31.200 [4.000, 57.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.128205, mean_absolute_error: 2.666948, mean_q: 3.455770
89 (array([58]),) False
  36960/500000: episode: 924, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 34.475 [1.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.133767, mean_absolute_error: 2.700837, mean_q: 3.499826
255 (array([12]),) False
  37000/500000: episode: 925, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 25.100 [1.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.130760, mean_absolute_error: 2.678645, mean_q: 3.477576
381 (array([22]),) False
  37040/500000: episode: 926, duration: 32.310s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.025 [7.000, 55.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.134493, mean_absolute_error: 2.685953, mean_q: 3.484418
404 (array([12]),) False
  37080/500000: episode: 927, duration: 33.253s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 25.325 [5.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.133723, mean_absolute_error: 2.665007, mean_q: 3.475003
861 (array([22]),) False
  37120/500000: episode: 928, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 26.500 [4.000, 53.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.140451, mean_absolute_error: 2.696657, mean_q: 3.487666
422 (array([48]),) False
  37160/500000: episode: 929, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 38.350 [1.000, 58.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.135745, mean_absolute_error: 2.679998, mean_q: 3.469208
592 (array([22]),) False
  37200/500000: episode: 930, duration: 32.333s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.600 [0.000, 56.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.138708, mean_absolute_error: 2.660653, mean_q: 3.462159
790 (array([48]),) False
  37240/500000: episode: 931, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 42.675 [2.000, 51.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.121987, mean_absolute_error: 2.699011, mean_q: 3.497099
61 (array([48]),) False
  37280/500000: episode: 932, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 33.625 [8.000, 60.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.132711, mean_absolute_error: 2.691185, mean_q: 3.493913
830 (array([22]),) False
  37320/500000: episode: 933, duration: 33.280s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.225 [2.000, 50.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.142022, mean_absolute_error: 2.645930, mean_q: 3.427056
621 (array([22]),) False
  37360/500000: episode: 934, duration: 32.263s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.600 [8.000, 59.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.128892, mean_absolute_error: 2.684060, mean_q: 3.479064
189 (array([12]),) False
  37400/500000: episode: 935, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.025 [4.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.140733, mean_absolute_error: 2.684573, mean_q: 3.478432
481 (array([22]),) False
  37440/500000: episode: 936, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.925 [0.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.132830, mean_absolute_error: 2.656474, mean_q: 3.461465
748 (array([22]),) False
  37480/500000: episode: 937, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.750 [10.000, 57.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.134500, mean_absolute_error: 2.663556, mean_q: 3.468984
740 (array([58]),) False
  37520/500000: episode: 938, duration: 32.264s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 48.550 [0.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.143386, mean_absolute_error: 2.648466, mean_q: 3.456977
211 (array([22]),) False
  37560/500000: episode: 939, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.300 [2.000, 57.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.133992, mean_absolute_error: 2.651310, mean_q: 3.456474
783 (array([22]),) False
  37600/500000: episode: 940, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.775 [11.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.133472, mean_absolute_error: 2.654336, mean_q: 3.446079
600 (array([48]),) False
  37640/500000: episode: 941, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 41.800 [2.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.121870, mean_absolute_error: 2.681417, mean_q: 3.495551
179 (array([18]),) False
  37680/500000: episode: 942, duration: 32.351s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 24.925 [3.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.129521, mean_absolute_error: 2.696473, mean_q: 3.493418
375 (array([22]),) False
  37720/500000: episode: 943, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.575 [1.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.136766, mean_absolute_error: 2.689628, mean_q: 3.491493
519 (array([58]),) False
  37760/500000: episode: 944, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 50.925 [0.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.140287, mean_absolute_error: 2.702763, mean_q: 3.504367
80 (array([42]),) False
  37800/500000: episode: 945, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 38.250 [1.000, 56.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.127490, mean_absolute_error: 2.703724, mean_q: 3.503324
726 (array([12]),) False
  37840/500000: episode: 946, duration: 32.316s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 17.325 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.143213, mean_absolute_error: 2.692373, mean_q: 3.491492
461 (array([22]),) False
  37880/500000: episode: 947, duration: 32.115s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.775 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.140295, mean_absolute_error: 2.703989, mean_q: 3.509269
568 (array([22]),) False
  37920/500000: episode: 948, duration: 31.584s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.125 [0.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.137604, mean_absolute_error: 2.732890, mean_q: 3.540540
698 (array([22]),) False
  37960/500000: episode: 949, duration: 31.522s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 29.925 [6.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.126928, mean_absolute_error: 2.712341, mean_q: 3.515087
220 (array([22]),) False
  38000/500000: episode: 950, duration: 31.131s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.450 [0.000, 48.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.132054, mean_absolute_error: 2.716137, mean_q: 3.518324
675 (array([22]),) False
  38040/500000: episode: 951, duration: 31.589s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.150 [3.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.140403, mean_absolute_error: 2.718551, mean_q: 3.525085
729 (array([22]),) False
  38080/500000: episode: 952, duration: 31.606s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 38.025 [9.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.144157, mean_absolute_error: 2.713217, mean_q: 3.519182
491 (array([22]),) False
  38120/500000: episode: 953, duration: 31.504s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.500 [2.000, 57.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.150422, mean_absolute_error: 2.711296, mean_q: 3.499724
149 (array([8]),) False
  38160/500000: episode: 954, duration: 31.127s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 40.100 [10.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.146880, mean_absolute_error: 2.712865, mean_q: 3.511468
341 (array([22]),) False
  38200/500000: episode: 955, duration: 31.519s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.625 [12.000, 47.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.143192, mean_absolute_error: 2.735257, mean_q: 3.534146
400 (array([22]),) False
  38240/500000: episode: 956, duration: 31.588s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.675 [0.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.130688, mean_absolute_error: 2.752094, mean_q: 3.566093
834 (array([44]),) False
  38280/500000: episode: 957, duration: 31.564s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 23.975 [0.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.136231, mean_absolute_error: 2.728702, mean_q: 3.541733
328 (array([12]),) False
  38320/500000: episode: 958, duration: 31.122s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 16.650 [0.000, 43.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.142932, mean_absolute_error: 2.715640, mean_q: 3.515688
287 (array([48]),) False
  38360/500000: episode: 959, duration: 31.538s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 29.225 [4.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.134556, mean_absolute_error: 2.751314, mean_q: 3.557148
724 (array([58]),) False
  38400/500000: episode: 960, duration: 31.550s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 50.000 [6.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.136942, mean_absolute_error: 2.750777, mean_q: 3.551671
712 (array([22]),) False
  38440/500000: episode: 961, duration: 31.550s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.100 [0.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.148268, mean_absolute_error: 2.759230, mean_q: 3.563859
509 (array([22]),) False
  38480/500000: episode: 962, duration: 31.102s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.950 [5.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.147741, mean_absolute_error: 2.720672, mean_q: 3.525409
739 (array([22]),) False
  38520/500000: episode: 963, duration: 31.514s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 23.075 [6.000, 56.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.139602, mean_absolute_error: 2.729827, mean_q: 3.534497
683 (array([22]),) False
  38560/500000: episode: 964, duration: 31.523s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 26.450 [1.000, 59.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.131725, mean_absolute_error: 2.735452, mean_q: 3.542304
188 (array([22]),) False
  38600/500000: episode: 965, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 21.575 [3.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.138542, mean_absolute_error: 2.709806, mean_q: 3.519309
640 (array([22]),) False
  38640/500000: episode: 966, duration: 31.104s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.050 [0.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.143349, mean_absolute_error: 2.696049, mean_q: 3.490879
646 (array([44]),) False
  38680/500000: episode: 967, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 43.150 [0.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.140654, mean_absolute_error: 2.729609, mean_q: 3.529137
673 (array([3]),) False
  38720/500000: episode: 968, duration: 31.522s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 16.650 [3.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.135874, mean_absolute_error: 2.741078, mean_q: 3.545709
416 (array([22]),) False
  38760/500000: episode: 969, duration: 31.541s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.700 [0.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.129052, mean_absolute_error: 2.703404, mean_q: 3.505389
446 (array([22]),) False
  38800/500000: episode: 970, duration: 31.124s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.800 [7.000, 54.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.138945, mean_absolute_error: 2.735744, mean_q: 3.558171
180 (array([48]),) False
  38840/500000: episode: 971, duration: 31.595s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 45.100 [12.000, 49.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.139096, mean_absolute_error: 2.723558, mean_q: 3.532666
443 (array([22]),) False
  38880/500000: episode: 972, duration: 31.472s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.550 [9.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.141024, mean_absolute_error: 2.724391, mean_q: 3.530859
719 (array([22]),) False
  38920/500000: episode: 973, duration: 31.537s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 38.725 [5.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.131311, mean_absolute_error: 2.740216, mean_q: 3.546514
522 (array([22]),) False
  38960/500000: episode: 974, duration: 31.099s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.375 [13.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.134528, mean_absolute_error: 2.755667, mean_q: 3.544600
627 (array([48]),) False
  39000/500000: episode: 975, duration: 31.493s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.350 [17.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.138238, mean_absolute_error: 2.731303, mean_q: 3.555874
392 (array([40]),) False
  39040/500000: episode: 976, duration: 31.462s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.800 [4.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.135232, mean_absolute_error: 2.751609, mean_q: 3.560905
497 (array([33]),) False
  39080/500000: episode: 977, duration: 31.509s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 31.350 [3.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.142565, mean_absolute_error: 2.763454, mean_q: 3.584503
432 (array([22]),) False
  39120/500000: episode: 978, duration: 31.147s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.050 [1.000, 51.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.155294, mean_absolute_error: 2.757982, mean_q: 3.576342
806 (array([22]),) False
  39160/500000: episode: 979, duration: 31.559s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.700 [3.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.148730, mean_absolute_error: 2.764642, mean_q: 3.582751
194 (array([44]),) False
  39200/500000: episode: 980, duration: 31.481s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 25.050 [4.000, 56.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.135901, mean_absolute_error: 2.785325, mean_q: 3.607901
234 (array([22]),) False
  39240/500000: episode: 981, duration: 31.545s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.150 [1.000, 51.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.148409, mean_absolute_error: 2.767929, mean_q: 3.578861
754 (array([52]),) False
  39280/500000: episode: 982, duration: 31.127s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 17.850 [4.000, 52.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.138604, mean_absolute_error: 2.782380, mean_q: 3.591227
660 (array([2]),) False
  39320/500000: episode: 983, duration: 31.581s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 33.875 [0.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.145279, mean_absolute_error: 2.750783, mean_q: 3.559257
401 (array([12]),) False
  39360/500000: episode: 984, duration: 31.485s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 20.100 [2.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.147244, mean_absolute_error: 2.787132, mean_q: 3.594510
6 (array([58]),) False
  39400/500000: episode: 985, duration: 31.575s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.825 [9.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.138497, mean_absolute_error: 2.794835, mean_q: 3.603106
633 (array([22]),) False
  39440/500000: episode: 986, duration: 31.117s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.075 [5.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.151286, mean_absolute_error: 2.774676, mean_q: 3.591877
749 (array([22]),) False
  39480/500000: episode: 987, duration: 31.514s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.825 [1.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.148925, mean_absolute_error: 2.784939, mean_q: 3.603472
224 (array([12]),) False
  39520/500000: episode: 988, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 26.675 [4.000, 54.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.148960, mean_absolute_error: 2.767685, mean_q: 3.583999
78 (array([55]),) False
  39560/500000: episode: 989, duration: 31.529s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 27.375 [1.000, 60.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.140940, mean_absolute_error: 2.780399, mean_q: 3.600654
480 (array([22]),) False
  39600/500000: episode: 990, duration: 31.049s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.950 [20.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.143616, mean_absolute_error: 2.756354, mean_q: 3.573546
297 (array([15]),) False
  39640/500000: episode: 991, duration: 31.527s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.900 [0.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.131458, mean_absolute_error: 2.751382, mean_q: 3.579987
63 (array([18]),) False
  39680/500000: episode: 992, duration: 31.533s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 20.550 [0.000, 54.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.141580, mean_absolute_error: 2.774865, mean_q: 3.586569
610 (array([48]),) False
  39720/500000: episode: 993, duration: 31.578s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 21.825 [1.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.127983, mean_absolute_error: 2.783650, mean_q: 3.586420
29 (array([22]),) False
  39760/500000: episode: 994, duration: 31.129s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.575 [1.000, 43.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.144390, mean_absolute_error: 2.760302, mean_q: 3.564842
328 (array([12]),) False
  39800/500000: episode: 995, duration: 31.578s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 20.050 [4.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.136352, mean_absolute_error: 2.806012, mean_q: 3.599403
295 (array([22]),) False
  39840/500000: episode: 996, duration: 31.516s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.000 [0.000, 54.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.155105, mean_absolute_error: 2.792933, mean_q: 3.603385
762 (array([22]),) False
  39880/500000: episode: 997, duration: 31.524s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.000 [9.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.144481, mean_absolute_error: 2.754035, mean_q: 3.572702
452 (array([22]),) False
  39920/500000: episode: 998, duration: 31.112s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.025 [16.000, 60.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.142357, mean_absolute_error: 2.796408, mean_q: 3.620826
674 (array([48]),) False
  39960/500000: episode: 999, duration: 31.478s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 27.300 [0.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.141564, mean_absolute_error: 2.787029, mean_q: 3.612011
489 (array([22]),) False
  40000/500000: episode: 1000, duration: 31.556s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.125 [4.000, 60.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.131802, mean_absolute_error: 2.803423, mean_q: 3.620527
730 (array([54]),) False
  40040/500000: episode: 1001, duration: 31.555s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 47.700 [12.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.150364, mean_absolute_error: 2.800334, mean_q: 3.618312
144 (array([22]),) False
  40080/500000: episode: 1002, duration: 31.150s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 20.325 [0.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.163255, mean_absolute_error: 2.764277, mean_q: 3.575855
17 (array([22]),) False
  40120/500000: episode: 1003, duration: 31.568s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.350 [3.000, 57.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.153408, mean_absolute_error: 2.777981, mean_q: 3.593218
351 (array([22]),) False
  40160/500000: episode: 1004, duration: 31.606s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.450 [3.000, 52.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.134108, mean_absolute_error: 2.797678, mean_q: 3.591066
632 (array([22]),) False
  40200/500000: episode: 1005, duration: 31.549s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.250 [1.000, 57.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.135044, mean_absolute_error: 2.808558, mean_q: 3.619600
517 (array([22]),) False
  40240/500000: episode: 1006, duration: 31.072s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.750 [2.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.148316, mean_absolute_error: 2.783317, mean_q: 3.583832
217 (array([12]),) False
  40280/500000: episode: 1007, duration: 31.504s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 23.450 [11.000, 51.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.146608, mean_absolute_error: 2.779440, mean_q: 3.584370
453 (array([22]),) False
  40320/500000: episode: 1008, duration: 31.476s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 26.475 [0.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.142260, mean_absolute_error: 2.803573, mean_q: 3.597373
160 (array([12]),) False
  40360/500000: episode: 1009, duration: 31.519s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 22.925 [12.000, 60.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.133636, mean_absolute_error: 2.787420, mean_q: 3.587547
491 (array([22]),) False
  40400/500000: episode: 1010, duration: 31.137s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 28.150 [18.000, 55.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.136195, mean_absolute_error: 2.765284, mean_q: 3.575083
20 (array([22]),) False
  40440/500000: episode: 1011, duration: 31.560s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.125 [2.000, 54.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.129711, mean_absolute_error: 2.772107, mean_q: 3.562930
381 (array([22]),) False
  40480/500000: episode: 1012, duration: 31.530s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.375 [2.000, 50.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.145914, mean_absolute_error: 2.766638, mean_q: 3.581018
175 (array([22]),) False
  40520/500000: episode: 1013, duration: 31.585s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.775 [4.000, 59.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.154132, mean_absolute_error: 2.742193, mean_q: 3.542840
107 (array([22]),) False
  40560/500000: episode: 1014, duration: 31.107s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.900 [1.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.137439, mean_absolute_error: 2.769073, mean_q: 3.579428
745 (array([22]),) False
  40600/500000: episode: 1015, duration: 31.590s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 34.000 [1.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.131913, mean_absolute_error: 2.742140, mean_q: 3.554501
624 (array([48]),) False
  40640/500000: episode: 1016, duration: 31.537s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.700 [4.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.130162, mean_absolute_error: 2.717669, mean_q: 3.533197
579 (array([58]),) False
  40680/500000: episode: 1017, duration: 31.474s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 52.600 [4.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.141500, mean_absolute_error: 2.753836, mean_q: 3.567225
221 (array([22]),) False
  40720/500000: episode: 1018, duration: 31.146s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.400 [9.000, 59.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.136875, mean_absolute_error: 2.766411, mean_q: 3.581992
476 (array([48]),) False
  40760/500000: episode: 1019, duration: 31.585s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 41.375 [6.000, 56.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.142880, mean_absolute_error: 2.761356, mean_q: 3.583298
127 (array([22]),) False
  40800/500000: episode: 1020, duration: 31.470s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.625 [3.000, 49.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.132145, mean_absolute_error: 2.751336, mean_q: 3.558084
705 (array([22]),) False
  40840/500000: episode: 1021, duration: 31.490s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.250 [8.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.141729, mean_absolute_error: 2.733131, mean_q: 3.528348
301 (array([22]),) False
  40880/500000: episode: 1022, duration: 31.079s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 33.350 [12.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.144179, mean_absolute_error: 2.736009, mean_q: 3.542629
251 (array([3]),) False
  40920/500000: episode: 1023, duration: 31.527s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 9.475 [1.000, 49.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.144423, mean_absolute_error: 2.709939, mean_q: 3.516248
262 (array([22]),) False
  40960/500000: episode: 1024, duration: 31.488s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 26.200 [2.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.136189, mean_absolute_error: 2.694487, mean_q: 3.486277
627 (array([48]),) False
  41000/500000: episode: 1025, duration: 31.512s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 42.575 [4.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.135534, mean_absolute_error: 2.713179, mean_q: 3.508044
525 (array([22]),) False
  41040/500000: episode: 1026, duration: 31.122s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.775 [1.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.131335, mean_absolute_error: 2.694386, mean_q: 3.485464
375 (array([22]),) False
  41080/500000: episode: 1027, duration: 31.504s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.475 [0.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.124271, mean_absolute_error: 2.678780, mean_q: 3.474002
339 (array([22]),) False
  41120/500000: episode: 1028, duration: 31.586s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.350 [15.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.137779, mean_absolute_error: 2.677800, mean_q: 3.471417
618 (array([12]),) False
  41160/500000: episode: 1029, duration: 31.517s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 27.500 [2.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.147140, mean_absolute_error: 2.693800, mean_q: 3.497160
606 (array([22]),) False
  41200/500000: episode: 1030, duration: 31.054s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.775 [1.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.144225, mean_absolute_error: 2.673339, mean_q: 3.465438
302 (array([22]),) False
  41240/500000: episode: 1031, duration: 31.518s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.575 [5.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.131470, mean_absolute_error: 2.661489, mean_q: 3.452727
701 (array([48]),) False
  41280/500000: episode: 1032, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 41.275 [3.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.137491, mean_absolute_error: 2.635211, mean_q: 3.429359
487 (array([48]),) False
  41320/500000: episode: 1033, duration: 31.512s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 39.125 [2.000, 55.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.124650, mean_absolute_error: 2.660452, mean_q: 3.459097
541 (array([57]),) False
  41360/500000: episode: 1034, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 33.600 [9.000, 55.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.125803, mean_absolute_error: 2.651515, mean_q: 3.461226
119 (array([45]),) False
  41400/500000: episode: 1035, duration: 31.523s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.000 [4.000, 54.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.132168, mean_absolute_error: 2.648588, mean_q: 3.449545
29 (array([22]),) False
  41440/500000: episode: 1036, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.950 [6.000, 58.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.137479, mean_absolute_error: 2.627269, mean_q: 3.419880
533 (array([22]),) False
  41480/500000: episode: 1037, duration: 31.553s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.400 [0.000, 53.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.132822, mean_absolute_error: 2.637967, mean_q: 3.438316
656 (array([48]),) False
  41520/500000: episode: 1038, duration: 31.105s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 41.825 [3.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.113411, mean_absolute_error: 2.637308, mean_q: 3.433243
464 (array([22]),) False
  41560/500000: episode: 1039, duration: 31.603s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.750 [0.000, 46.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.140299, mean_absolute_error: 2.653850, mean_q: 3.464899
543 (array([12]),) False
  41600/500000: episode: 1040, duration: 31.505s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.200 [7.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.133450, mean_absolute_error: 2.641773, mean_q: 3.440710
857 (array([22]),) False
  41640/500000: episode: 1041, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 22.725 [9.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.126224, mean_absolute_error: 2.637350, mean_q: 3.438921
577 (array([12]),) False
  41680/500000: episode: 1042, duration: 31.117s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 15.850 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.125286, mean_absolute_error: 2.669215, mean_q: 3.462032
456 (array([22]),) False
  41720/500000: episode: 1043, duration: 31.527s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.950 [1.000, 56.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.128006, mean_absolute_error: 2.655171, mean_q: 3.445537
669 (array([15]),) False
  41760/500000: episode: 1044, duration: 31.480s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.950 [2.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.128572, mean_absolute_error: 2.635055, mean_q: 3.421224
38 (array([22]),) False
  41800/500000: episode: 1045, duration: 31.567s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.475 [5.000, 59.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.132328, mean_absolute_error: 2.639397, mean_q: 3.427890
836 (array([22]),) False
  41840/500000: episode: 1046, duration: 31.129s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.225 [7.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.127621, mean_absolute_error: 2.637817, mean_q: 3.443753
578 (array([22]),) False
  41880/500000: episode: 1047, duration: 31.557s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.425 [0.000, 51.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.136828, mean_absolute_error: 2.639241, mean_q: 3.446567
380 (array([22]),) False
  41920/500000: episode: 1048, duration: 31.534s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.975 [7.000, 53.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.135098, mean_absolute_error: 2.626328, mean_q: 3.433483
84 (array([22]),) False
  41960/500000: episode: 1049, duration: 31.639s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.375 [4.000, 55.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.138128, mean_absolute_error: 2.627552, mean_q: 3.461058
167 (array([22]),) False
  42000/500000: episode: 1050, duration: 31.105s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.350 [0.000, 46.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.134908, mean_absolute_error: 2.651861, mean_q: 3.461917
528 (array([12]),) False
  42040/500000: episode: 1051, duration: 31.506s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 21.875 [0.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.134076, mean_absolute_error: 2.623147, mean_q: 3.431100
591 (array([22]),) False
  42080/500000: episode: 1052, duration: 31.450s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.200 [3.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.137933, mean_absolute_error: 2.626326, mean_q: 3.437560
785 (array([22]),) False
  42120/500000: episode: 1053, duration: 31.551s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.600 [5.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.137500, mean_absolute_error: 2.634954, mean_q: 3.441840
392 (array([40]),) False
  42160/500000: episode: 1054, duration: 31.155s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 22.425 [0.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.135108, mean_absolute_error: 2.619610, mean_q: 3.424011
72 (array([12]),) False
  42200/500000: episode: 1055, duration: 31.614s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 22.850 [2.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.126687, mean_absolute_error: 2.628897, mean_q: 3.425887
313 (array([22]),) False
  42240/500000: episode: 1056, duration: 31.510s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.675 [1.000, 54.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.130405, mean_absolute_error: 2.671464, mean_q: 3.473160
265 (array([22]),) False
  42280/500000: episode: 1057, duration: 31.555s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 24.375 [2.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.129518, mean_absolute_error: 2.663494, mean_q: 3.466950
838 (array([21]),) False
  42320/500000: episode: 1058, duration: 31.157s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 23.225 [0.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.125884, mean_absolute_error: 2.687387, mean_q: 3.494155
708 (array([40]),) False
  42360/500000: episode: 1059, duration: 31.552s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.075 [13.000, 51.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.126903, mean_absolute_error: 2.681779, mean_q: 3.477023
596 (array([22]),) False
  42400/500000: episode: 1060, duration: 31.510s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.550 [4.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.140952, mean_absolute_error: 2.683984, mean_q: 3.496403
844 (array([48]),) False
  42440/500000: episode: 1061, duration: 31.550s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 37.925 [1.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.127104, mean_absolute_error: 2.672469, mean_q: 3.480271
430 (array([22]),) False
  42480/500000: episode: 1062, duration: 31.111s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.950 [3.000, 56.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.140139, mean_absolute_error: 2.669072, mean_q: 3.472751
120 (array([44]),) False
  42520/500000: episode: 1063, duration: 31.510s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 34.175 [2.000, 54.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.134028, mean_absolute_error: 2.670943, mean_q: 3.475989
459 (array([22]),) False
  42560/500000: episode: 1064, duration: 31.602s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.150 [5.000, 50.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.130487, mean_absolute_error: 2.687259, mean_q: 3.496650
689 (array([12]),) False
  42600/500000: episode: 1065, duration: 31.603s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.275 [0.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.124794, mean_absolute_error: 2.699374, mean_q: 3.513219
86 (array([22]),) False
  42640/500000: episode: 1066, duration: 31.144s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.050 [5.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.130827, mean_absolute_error: 2.685836, mean_q: 3.491130
231 (array([22]),) False
  42680/500000: episode: 1067, duration: 31.532s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.075 [1.000, 60.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.138642, mean_absolute_error: 2.690709, mean_q: 3.499065
717 (array([22]),) False
  42720/500000: episode: 1068, duration: 31.570s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.250 [0.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.141689, mean_absolute_error: 2.694940, mean_q: 3.503778
264 (array([12]),) False
  42760/500000: episode: 1069, duration: 31.548s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.125 [11.000, 45.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.127050, mean_absolute_error: 2.693969, mean_q: 3.493344
178 (array([38]),) False
  42800/500000: episode: 1070, duration: 31.079s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.500 [11.000, 60.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.136766, mean_absolute_error: 2.727885, mean_q: 3.531204
470 (array([22]),) False
  42840/500000: episode: 1071, duration: 31.560s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 22.625 [0.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.135294, mean_absolute_error: 2.725352, mean_q: 3.535263
204 (array([22]),) False
  42880/500000: episode: 1072, duration: 31.551s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.825 [2.000, 58.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.134336, mean_absolute_error: 2.707455, mean_q: 3.524129
368 (array([22]),) False
  42920/500000: episode: 1073, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.125 [3.000, 53.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.131141, mean_absolute_error: 2.731353, mean_q: 3.546803
15 (array([22]),) False
  42960/500000: episode: 1074, duration: 31.104s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.900 [0.000, 54.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.124564, mean_absolute_error: 2.725416, mean_q: 3.526904
629 (array([22]),) False
  43000/500000: episode: 1075, duration: 31.591s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 38.975 [0.000, 60.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.128157, mean_absolute_error: 2.717793, mean_q: 3.531828
586 (array([12]),) False
  43040/500000: episode: 1076, duration: 31.500s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 26.275 [9.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.121921, mean_absolute_error: 2.711792, mean_q: 3.520917
650 (array([22]),) False
  43080/500000: episode: 1077, duration: 31.522s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.650 [0.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.142686, mean_absolute_error: 2.689269, mean_q: 3.497050
333 (array([12]),) False
  43120/500000: episode: 1078, duration: 31.082s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 18.425 [4.000, 59.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.134441, mean_absolute_error: 2.682033, mean_q: 3.477135
215 (array([22]),) False
  43160/500000: episode: 1079, duration: 31.628s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.525 [3.000, 57.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.130437, mean_absolute_error: 2.666691, mean_q: 3.476685
133 (array([22]),) False
  43200/500000: episode: 1080, duration: 31.583s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.775 [1.000, 53.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.139873, mean_absolute_error: 2.658585, mean_q: 3.454657
521 (array([22]),) False
  43240/500000: episode: 1081, duration: 31.513s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.300 [0.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.128815, mean_absolute_error: 2.674581, mean_q: 3.484903
262 (array([22]),) False
  43280/500000: episode: 1082, duration: 31.045s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.875 [5.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.124214, mean_absolute_error: 2.672570, mean_q: 3.470978
132 (array([22]),) False
  43320/500000: episode: 1083, duration: 31.541s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.700 [5.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.135033, mean_absolute_error: 2.669186, mean_q: 3.473572
486 (array([22]),) False
  43360/500000: episode: 1084, duration: 31.550s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.000 [4.000, 53.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.128864, mean_absolute_error: 2.679572, mean_q: 3.480541
737 (array([15]),) False
  43400/500000: episode: 1085, duration: 31.564s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.775 [7.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.134791, mean_absolute_error: 2.686473, mean_q: 3.496317
255 (array([12]),) False
  43440/500000: episode: 1086, duration: 31.118s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 25.925 [3.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.123756, mean_absolute_error: 2.669769, mean_q: 3.475483
133 (array([22]),) False
  43480/500000: episode: 1087, duration: 31.475s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.825 [3.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.135951, mean_absolute_error: 2.673460, mean_q: 3.492696
388 (array([22]),) False
  43520/500000: episode: 1088, duration: 31.506s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.700 [7.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.136455, mean_absolute_error: 2.663558, mean_q: 3.472482
120 (array([44]),) False
  43560/500000: episode: 1089, duration: 31.565s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 34.400 [5.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.134600, mean_absolute_error: 2.670653, mean_q: 3.477236
401 (array([12]),) False
  43600/500000: episode: 1090, duration: 31.144s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 21.275 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.129376, mean_absolute_error: 2.682402, mean_q: 3.491854
654 (array([22]),) False
  43640/500000: episode: 1091, duration: 31.457s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.400 [8.000, 55.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.124052, mean_absolute_error: 2.661383, mean_q: 3.462708
787 (array([3]),) False
  43680/500000: episode: 1092, duration: 31.505s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.600 [1.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.131164, mean_absolute_error: 2.674425, mean_q: 3.490068
189 (array([12]),) False
  43720/500000: episode: 1093, duration: 31.539s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 15.675 [0.000, 51.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.128459, mean_absolute_error: 2.639889, mean_q: 3.453809
489 (array([22]),) False
  43760/500000: episode: 1094, duration: 31.152s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.050 [4.000, 52.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.127635, mean_absolute_error: 2.665804, mean_q: 3.495809
807 (array([22]),) False
  43800/500000: episode: 1095, duration: 31.595s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.250 [7.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.134823, mean_absolute_error: 2.670361, mean_q: 3.499664
280 (array([48]),) False
  43840/500000: episode: 1096, duration: 31.455s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.850 [5.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.135008, mean_absolute_error: 2.672586, mean_q: 3.477944
585 (array([48]),) False
  43880/500000: episode: 1097, duration: 31.531s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.975 [8.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.130857, mean_absolute_error: 2.670438, mean_q: 3.484210
146 (array([12]),) False
  43920/500000: episode: 1098, duration: 31.101s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.825 [2.000, 60.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.142459, mean_absolute_error: 2.666797, mean_q: 3.471894
856 (array([48]),) False
  43960/500000: episode: 1099, duration: 31.571s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 42.600 [6.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.127901, mean_absolute_error: 2.652810, mean_q: 3.457279
356 (array([22]),) False
  44000/500000: episode: 1100, duration: 31.561s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.825 [2.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.115629, mean_absolute_error: 2.675486, mean_q: 3.481665
740 (array([58]),) False
  44040/500000: episode: 1101, duration: 31.558s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 50.225 [1.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.133383, mean_absolute_error: 2.666084, mean_q: 3.480439
515 (array([22]),) False
  44080/500000: episode: 1102, duration: 31.103s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.100 [4.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.134233, mean_absolute_error: 2.663411, mean_q: 3.469444
373 (array([22]),) False
  44120/500000: episode: 1103, duration: 31.565s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.725 [3.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.128998, mean_absolute_error: 2.693676, mean_q: 3.508054
379 (array([22]),) False
  44160/500000: episode: 1104, duration: 31.564s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.375 [10.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.133259, mean_absolute_error: 2.658742, mean_q: 3.459361
489 (array([22]),) False
  44200/500000: episode: 1105, duration: 31.535s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.825 [6.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.143732, mean_absolute_error: 2.659965, mean_q: 3.475041
27 (array([22]),) False
  44240/500000: episode: 1106, duration: 31.034s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.400 [3.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.129930, mean_absolute_error: 2.643365, mean_q: 3.452100
330 (array([38]),) False
  44280/500000: episode: 1107, duration: 31.509s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 23.175 [7.000, 54.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.128219, mean_absolute_error: 2.651998, mean_q: 3.462547
624 (array([48]),) False
  44320/500000: episode: 1108, duration: 31.563s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.400 [0.000, 53.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.126477, mean_absolute_error: 2.651945, mean_q: 3.479809
24 (array([22]),) False
  44360/500000: episode: 1109, duration: 31.492s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.725 [0.000, 58.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.125314, mean_absolute_error: 2.662721, mean_q: 3.468019
279 (array([22]),) False
  44400/500000: episode: 1110, duration: 31.122s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 40.025 [4.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.129805, mean_absolute_error: 2.648252, mean_q: 3.456307
459 (array([22]),) False
  44440/500000: episode: 1111, duration: 31.513s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.650 [2.000, 58.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.125263, mean_absolute_error: 2.641362, mean_q: 3.458143
571 (array([48]),) False
  44480/500000: episode: 1112, duration: 31.543s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 26.000 [10.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.141220, mean_absolute_error: 2.663752, mean_q: 3.461987
732 (array([12]),) False
  44520/500000: episode: 1113, duration: 31.630s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 13.850 [3.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.133137, mean_absolute_error: 2.654434, mean_q: 3.459429
475 (array([22]),) False
  44560/500000: episode: 1114, duration: 31.102s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.900 [0.000, 56.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.135935, mean_absolute_error: 2.665602, mean_q: 3.460936
266 (array([12]),) False
  44600/500000: episode: 1115, duration: 31.519s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.900 [5.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.131966, mean_absolute_error: 2.657702, mean_q: 3.464053
208 (array([22]),) False
  44640/500000: episode: 1116, duration: 31.577s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 27.475 [0.000, 60.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.130342, mean_absolute_error: 2.669000, mean_q: 3.475048
650 (array([22]),) False
  44680/500000: episode: 1117, duration: 31.565s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.800 [0.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.133323, mean_absolute_error: 2.656370, mean_q: 3.457905
424 (array([22]),) False
  44720/500000: episode: 1118, duration: 31.077s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.050 [1.000, 53.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.121890, mean_absolute_error: 2.669079, mean_q: 3.474885
806 (array([22]),) False
  44760/500000: episode: 1119, duration: 31.472s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.675 [2.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.134448, mean_absolute_error: 2.667014, mean_q: 3.468478
560 (array([22]),) False
  44800/500000: episode: 1120, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 28.575 [6.000, 51.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.130177, mean_absolute_error: 2.641883, mean_q: 3.451682
281 (array([48]),) False
  44840/500000: episode: 1121, duration: 30.897s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 18.225 [0.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.130241, mean_absolute_error: 2.621691, mean_q: 3.404571
756 (array([48]),) False
  44880/500000: episode: 1122, duration: 30.063s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 24.675 [5.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.131184, mean_absolute_error: 2.632415, mean_q: 3.423907
812 (array([22]),) False
  44920/500000: episode: 1123, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.400 [17.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.120160, mean_absolute_error: 2.647504, mean_q: 3.447095
113 (array([22]),) False
  44960/500000: episode: 1124, duration: 30.854s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.950 [1.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.124835, mean_absolute_error: 2.627265, mean_q: 3.416051
112 (array([12]),) False
  45000/500000: episode: 1125, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 21.875 [3.000, 52.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.136488, mean_absolute_error: 2.626053, mean_q: 3.434666
140 (array([12]),) False
  45040/500000: episode: 1126, duration: 30.113s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 17.400 [5.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.135145, mean_absolute_error: 2.629318, mean_q: 3.420389
636 (array([12]),) False
  45080/500000: episode: 1127, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 41.925 [4.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.138405, mean_absolute_error: 2.626477, mean_q: 3.423423
83 (array([22]),) False
  45120/500000: episode: 1128, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.150 [3.000, 49.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.136491, mean_absolute_error: 2.626792, mean_q: 3.435701
447 (array([44]),) False
  45160/500000: episode: 1129, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 29.800 [3.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.125400, mean_absolute_error: 2.609293, mean_q: 3.406117
294 (array([22]),) False
  45200/500000: episode: 1130, duration: 30.025s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.175 [10.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.119934, mean_absolute_error: 2.600946, mean_q: 3.401434
220 (array([22]),) False
  45240/500000: episode: 1131, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.025 [1.000, 59.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.125186, mean_absolute_error: 2.626034, mean_q: 3.421886
493 (array([22]),) False
  45280/500000: episode: 1132, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.850 [0.000, 46.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.127194, mean_absolute_error: 2.554911, mean_q: 3.353788
426 (array([22]),) False
  45320/500000: episode: 1133, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.550 [0.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.135861, mean_absolute_error: 2.588132, mean_q: 3.378504
67 (array([8]),) False
  45360/500000: episode: 1134, duration: 30.095s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 31.300 [5.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.130494, mean_absolute_error: 2.611279, mean_q: 3.417612
434 (array([22]),) False
  45400/500000: episode: 1135, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.625 [5.000, 58.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.123562, mean_absolute_error: 2.611649, mean_q: 3.418995
219 (array([36]),) False
  45440/500000: episode: 1136, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 33.975 [10.000, 53.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.132422, mean_absolute_error: 2.591131, mean_q: 3.390675
365 (array([22]),) False
  45480/500000: episode: 1137, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.625 [0.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.135943, mean_absolute_error: 2.615681, mean_q: 3.409122
189 (array([12]),) False
  45520/500000: episode: 1138, duration: 30.077s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 18.175 [8.000, 56.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.135726, mean_absolute_error: 2.609143, mean_q: 3.411041
852 (array([44]),) False
  45560/500000: episode: 1139, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 31.050 [13.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.122651, mean_absolute_error: 2.599306, mean_q: 3.410129
137 (array([22]),) False
  45600/500000: episode: 1140, duration: 30.825s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.675 [6.000, 44.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.124987, mean_absolute_error: 2.642382, mean_q: 3.439726
746 (array([37]),) False
  45640/500000: episode: 1141, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 39.450 [2.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.130962, mean_absolute_error: 2.642191, mean_q: 3.434932
500 (array([22]),) False
  45680/500000: episode: 1142, duration: 30.168s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.925 [5.000, 49.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.117040, mean_absolute_error: 2.651878, mean_q: 3.455864
470 (array([22]),) False
  45720/500000: episode: 1143, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.050 [0.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.132721, mean_absolute_error: 2.646322, mean_q: 3.452111
656 (array([48]),) False
  45760/500000: episode: 1144, duration: 30.843s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 43.075 [9.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.127578, mean_absolute_error: 2.623602, mean_q: 3.443426
88 (array([22]),) False
  45800/500000: episode: 1145, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.925 [0.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.127546, mean_absolute_error: 2.682367, mean_q: 3.502687
551 (array([22]),) False
  45840/500000: episode: 1146, duration: 30.104s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.675 [2.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.123537, mean_absolute_error: 2.656925, mean_q: 3.471210
147 (array([44]),) False
  45880/500000: episode: 1147, duration: 30.973s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.300 [8.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.139017, mean_absolute_error: 2.643313, mean_q: 3.445441
719 (array([22]),) False
  45920/500000: episode: 1148, duration: 30.873s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 28.500 [12.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.139681, mean_absolute_error: 2.667669, mean_q: 3.479194
109 (array([48]),) False
  45960/500000: episode: 1149, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.275 [1.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.129149, mean_absolute_error: 2.650667, mean_q: 3.466146
462 (array([12]),) False
  46000/500000: episode: 1150, duration: 30.047s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 20.850 [1.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.130475, mean_absolute_error: 2.653560, mean_q: 3.450401
599 (array([48]),) False
  46040/500000: episode: 1151, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 38.525 [0.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.120685, mean_absolute_error: 2.679293, mean_q: 3.489523
784 (array([22]),) False
  46080/500000: episode: 1152, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.300 [0.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.120763, mean_absolute_error: 2.674817, mean_q: 3.492210
325 (array([22]),) False
  46120/500000: episode: 1153, duration: 30.871s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.250 [2.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.124489, mean_absolute_error: 2.653991, mean_q: 3.466498
253 (array([44]),) False
  46160/500000: episode: 1154, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.600 [9.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.119515, mean_absolute_error: 2.674021, mean_q: 3.491565
620 (array([44]),) False
  46200/500000: episode: 1155, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 36.100 [2.000, 59.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.128052, mean_absolute_error: 2.685901, mean_q: 3.498648
614 (array([22]),) False
  46240/500000: episode: 1156, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 22.500 [3.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.136905, mean_absolute_error: 2.668301, mean_q: 3.475366
555 (array([22]),) False
  46280/500000: episode: 1157, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.300 [1.000, 53.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.122968, mean_absolute_error: 2.662844, mean_q: 3.462135
666 (array([22]),) False
  46320/500000: episode: 1158, duration: 30.117s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.150 [4.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.129951, mean_absolute_error: 2.659573, mean_q: 3.459042
379 (array([22]),) False
  46360/500000: episode: 1159, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.475 [0.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.132564, mean_absolute_error: 2.665740, mean_q: 3.462008
541 (array([57]),) False
  46400/500000: episode: 1160, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 16.675 [0.000, 52.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.117805, mean_absolute_error: 2.683247, mean_q: 3.491891
499 (array([8]),) False
  46440/500000: episode: 1161, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 32.575 [12.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.133813, mean_absolute_error: 2.664227, mean_q: 3.463554
818 (array([48]),) False
  46480/500000: episode: 1162, duration: 30.569s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 26.900 [8.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.143030, mean_absolute_error: 2.674795, mean_q: 3.471022
760 (array([22]),) False
  46520/500000: episode: 1163, duration: 31.371s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 25.350 [4.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.137455, mean_absolute_error: 2.668356, mean_q: 3.469214
520 (array([22]),) False
  46560/500000: episode: 1164, duration: 31.175s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.650 [1.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.132496, mean_absolute_error: 2.660751, mean_q: 3.468750
213 (array([22]),) False
  46600/500000: episode: 1165, duration: 31.482s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.525 [1.000, 54.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.130125, mean_absolute_error: 2.653450, mean_q: 3.470784
766 (array([12]),) False
  46640/500000: episode: 1166, duration: 30.627s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 40.325 [1.000, 51.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.126659, mean_absolute_error: 2.662116, mean_q: 3.474001
789 (array([22]),) False
  46680/500000: episode: 1167, duration: 31.239s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.850 [10.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.125950, mean_absolute_error: 2.657366, mean_q: 3.457664
182 (array([54]),) False
  46720/500000: episode: 1168, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.825 [4.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.125442, mean_absolute_error: 2.670839, mean_q: 3.481799
415 (array([22]),) False
  46760/500000: episode: 1169, duration: 31.525s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.250 [0.000, 54.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.132264, mean_absolute_error: 2.659439, mean_q: 3.463070
821 (array([22]),) False
  46800/500000: episode: 1170, duration: 31.141s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 27.825 [1.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.118806, mean_absolute_error: 2.644045, mean_q: 3.443000
109 (array([48]),) False
  46840/500000: episode: 1171, duration: 31.742s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.575 [3.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.131096, mean_absolute_error: 2.645897, mean_q: 3.448009
795 (array([3]),) False
  46880/500000: episode: 1172, duration: 31.642s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 10.050 [1.000, 56.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.136794, mean_absolute_error: 2.600828, mean_q: 3.397666
220 (array([22]),) False
  46920/500000: episode: 1173, duration: 31.430s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.100 [3.000, 58.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.119009, mean_absolute_error: 2.665295, mean_q: 3.477005
79 (array([22]),) False
  46960/500000: episode: 1174, duration: 30.724s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.225 [9.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.132152, mean_absolute_error: 2.644880, mean_q: 3.450612
654 (array([22]),) False
  47000/500000: episode: 1175, duration: 31.505s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.150 [0.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.130409, mean_absolute_error: 2.624396, mean_q: 3.439720
117 (array([44]),) False
  47040/500000: episode: 1176, duration: 31.448s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.950 [2.000, 35.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.125764, mean_absolute_error: 2.650350, mean_q: 3.460231
855 (array([12]),) False
  47080/500000: episode: 1177, duration: 31.483s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 15.075 [8.000, 46.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.138105, mean_absolute_error: 2.668319, mean_q: 3.482290
355 (array([22]),) False
  47120/500000: episode: 1178, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.675 [1.000, 43.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.126300, mean_absolute_error: 2.663472, mean_q: 3.468000
121 (array([22]),) False
  47160/500000: episode: 1179, duration: 31.433s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.125 [4.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.127319, mean_absolute_error: 2.646409, mean_q: 3.447606
836 (array([22]),) False
  47200/500000: episode: 1180, duration: 31.383s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.875 [3.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.126405, mean_absolute_error: 2.645570, mean_q: 3.449661
259 (array([12]),) False
  47240/500000: episode: 1181, duration: 31.451s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 23.975 [7.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.130670, mean_absolute_error: 2.634970, mean_q: 3.439568
493 (array([22]),) False
  47280/500000: episode: 1182, duration: 31.083s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.225 [9.000, 58.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.134556, mean_absolute_error: 2.635506, mean_q: 3.437004
426 (array([22]),) False
  47320/500000: episode: 1183, duration: 31.488s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.475 [0.000, 51.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.130585, mean_absolute_error: 2.617694, mean_q: 3.422019
104 (array([22]),) False
  47360/500000: episode: 1184, duration: 31.926s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.375 [11.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.129401, mean_absolute_error: 2.616867, mean_q: 3.414346
675 (array([22]),) False
  47400/500000: episode: 1185, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.375 [2.000, 54.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.124560, mean_absolute_error: 2.644725, mean_q: 3.459916
671 (array([57]),) False
  47440/500000: episode: 1186, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 38.800 [3.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.118616, mean_absolute_error: 2.648967, mean_q: 3.441878
359 (array([22]),) False
  47480/500000: episode: 1187, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 29.150 [1.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.126859, mean_absolute_error: 2.643423, mean_q: 3.442519
629 (array([22]),) False
  47520/500000: episode: 1188, duration: 32.989s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 37.875 [3.000, 49.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.139636, mean_absolute_error: 2.627480, mean_q: 3.419739
353 (array([22]),) False
  47560/500000: episode: 1189, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.675 [1.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.130454, mean_absolute_error: 2.608894, mean_q: 3.395174
602 (array([36]),) False
  47600/500000: episode: 1190, duration: 32.263s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.300 [0.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.129195, mean_absolute_error: 2.628410, mean_q: 3.430677
594 (array([48]),) False
  47640/500000: episode: 1191, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.450 [1.000, 53.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.128556, mean_absolute_error: 2.620003, mean_q: 3.429399
560 (array([22]),) False
  47680/500000: episode: 1192, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 28.175 [7.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.120901, mean_absolute_error: 2.594461, mean_q: 3.392461
769 (array([12]),) False
  47720/500000: episode: 1193, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 31.800 [2.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.132971, mean_absolute_error: 2.634030, mean_q: 3.433559
161 (array([22]),) False
  47760/500000: episode: 1194, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 20.425 [3.000, 58.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.133267, mean_absolute_error: 2.630473, mean_q: 3.431750
116 (array([22]),) False
  47800/500000: episode: 1195, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 23.575 [12.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.132252, mean_absolute_error: 2.604709, mean_q: 3.406501
509 (array([22]),) False
  47840/500000: episode: 1196, duration: 33.023s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.975 [12.000, 58.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.136683, mean_absolute_error: 2.608527, mean_q: 3.412223
771 (array([12]),) False
  47880/500000: episode: 1197, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 14.750 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.131632, mean_absolute_error: 2.612268, mean_q: 3.416661
284 (array([12]),) False
  47920/500000: episode: 1198, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 31.050 [1.000, 59.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.121405, mean_absolute_error: 2.625761, mean_q: 3.444656
816 (array([4]),) False
  47960/500000: episode: 1199, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 50.475 [12.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.138937, mean_absolute_error: 2.601609, mean_q: 3.400532
440 (array([22]),) False
  48000/500000: episode: 1200, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.475 [0.000, 55.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.121015, mean_absolute_error: 2.622964, mean_q: 3.424255
480 (array([22]),) False
  48040/500000: episode: 1201, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.925 [14.000, 55.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.132646, mean_absolute_error: 2.612711, mean_q: 3.409211
56 (array([12]),) False
  48080/500000: episode: 1202, duration: 32.194s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 44.775 [1.000, 55.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.129081, mean_absolute_error: 2.615247, mean_q: 3.420029
589 (array([22]),) False
  48120/500000: episode: 1203, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.475 [1.000, 51.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.132528, mean_absolute_error: 2.628462, mean_q: 3.438028
608 (array([36]),) False
  48160/500000: episode: 1204, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.700 [0.000, 57.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.134215, mean_absolute_error: 2.634097, mean_q: 3.437094
281 (array([48]),) False
  48200/500000: episode: 1205, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 18.225 [1.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.132758, mean_absolute_error: 2.647100, mean_q: 3.461371
306 (array([22]),) False
  48240/500000: episode: 1206, duration: 32.287s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.300 [20.000, 46.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.129890, mean_absolute_error: 2.613519, mean_q: 3.415722
738 (array([12]),) False
  48280/500000: episode: 1207, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 31.950 [1.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.128471, mean_absolute_error: 2.651447, mean_q: 3.452940
40 (array([22]),) False
  48320/500000: episode: 1208, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.550 [6.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.127521, mean_absolute_error: 2.639826, mean_q: 3.446334
171 (array([22]),) False
  48360/500000: episode: 1209, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.675 [1.000, 58.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.125637, mean_absolute_error: 2.680036, mean_q: 3.488330
679 (array([44]),) False
  48400/500000: episode: 1210, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.625 [2.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.134729, mean_absolute_error: 2.676266, mean_q: 3.478379
450 (array([8]),) False
  48440/500000: episode: 1211, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 31.650 [8.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.137706, mean_absolute_error: 2.660797, mean_q: 3.469361
748 (array([22]),) False
  48480/500000: episode: 1212, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.800 [0.000, 47.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.126133, mean_absolute_error: 2.674747, mean_q: 3.482759
148 (array([22]),) False
  48520/500000: episode: 1213, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.800 [0.000, 55.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.135566, mean_absolute_error: 2.705615, mean_q: 3.511262
86 (array([22]),) False
  48560/500000: episode: 1214, duration: 32.214s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.900 [0.000, 53.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.128795, mean_absolute_error: 2.681442, mean_q: 3.482205
362 (array([22]),) False
  48600/500000: episode: 1215, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.125 [4.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.126642, mean_absolute_error: 2.692384, mean_q: 3.489877
19 (array([12]),) False
  48640/500000: episode: 1216, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.650 [7.000, 53.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.136654, mean_absolute_error: 2.668352, mean_q: 3.469463
2 (array([12]),) False
  48680/500000: episode: 1217, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.575 [5.000, 57.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.129292, mean_absolute_error: 2.698274, mean_q: 3.508093
336 (array([12]),) False
  48720/500000: episode: 1218, duration: 32.320s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 22.000 [12.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.122615, mean_absolute_error: 2.703239, mean_q: 3.523991
756 (array([48]),) False
  48760/500000: episode: 1219, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 39.700 [0.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.133614, mean_absolute_error: 2.685632, mean_q: 3.497729
767 (array([48]),) False
  48800/500000: episode: 1220, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 43.600 [4.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.134893, mean_absolute_error: 2.716358, mean_q: 3.534430
665 (array([12]),) False
  48840/500000: episode: 1221, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.675 [10.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.137017, mean_absolute_error: 2.695322, mean_q: 3.505487
777 (array([48]),) False
  48880/500000: episode: 1222, duration: 32.210s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 20.000 [2.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.139587, mean_absolute_error: 2.709723, mean_q: 3.516181
166 (array([22]),) False
  48920/500000: episode: 1223, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 22.025 [12.000, 56.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.133777, mean_absolute_error: 2.700483, mean_q: 3.520425
336 (array([12]),) False
  48960/500000: episode: 1224, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 20.400 [8.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.139924, mean_absolute_error: 2.707003, mean_q: 3.524165
8 (array([22]),) False
  49000/500000: episode: 1225, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 30.300 [0.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.121686, mean_absolute_error: 2.702693, mean_q: 3.520249
840 (array([12]),) False
  49040/500000: episode: 1226, duration: 32.166s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 24.200 [0.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.128446, mean_absolute_error: 2.667294, mean_q: 3.475120
361 (array([22]),) False
  49080/500000: episode: 1227, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 23.850 [1.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.131651, mean_absolute_error: 2.677425, mean_q: 3.480204
60 (array([22]),) False
  49120/500000: episode: 1228, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 43.400 [6.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.130897, mean_absolute_error: 2.637047, mean_q: 3.434458
248 (array([12]),) False
  49160/500000: episode: 1229, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 24.500 [3.000, 57.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.140712, mean_absolute_error: 2.664342, mean_q: 3.479827
421 (array([22]),) False
  49200/500000: episode: 1230, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.950 [3.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.147215, mean_absolute_error: 2.641362, mean_q: 3.445954
754 (array([52]),) False
  49240/500000: episode: 1231, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 20.700 [5.000, 53.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.129491, mean_absolute_error: 2.665912, mean_q: 3.487307
176 (array([3]),) False
  49280/500000: episode: 1232, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 33.450 [1.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.125660, mean_absolute_error: 2.625668, mean_q: 3.435268
88 (array([22]),) False
  49320/500000: episode: 1233, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.650 [8.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.127591, mean_absolute_error: 2.666392, mean_q: 3.477158
410 (array([22]),) False
  49360/500000: episode: 1234, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.125 [4.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.132955, mean_absolute_error: 2.664350, mean_q: 3.480270
320 (array([22]),) False
  49400/500000: episode: 1235, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.825 [6.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.128408, mean_absolute_error: 2.668605, mean_q: 3.474515
583 (array([22]),) False
  49440/500000: episode: 1236, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 16.225 [5.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.128761, mean_absolute_error: 2.645795, mean_q: 3.455448
35 (array([48]),) False
  49480/500000: episode: 1237, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 39.250 [0.000, 48.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.135866, mean_absolute_error: 2.660709, mean_q: 3.461257
517 (array([22]),) False
  49520/500000: episode: 1238, duration: 32.202s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.625 [8.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.127973, mean_absolute_error: 2.678131, mean_q: 3.479327
595 (array([22]),) False
  49560/500000: episode: 1239, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.500 [18.000, 49.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.136305, mean_absolute_error: 2.673357, mean_q: 3.475339
498 (array([12]),) False
  49600/500000: episode: 1240, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 38.650 [3.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.124911, mean_absolute_error: 2.660599, mean_q: 3.462380
35 (array([48]),) False
  49640/500000: episode: 1241, duration: 32.987s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 42.175 [5.000, 60.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.129854, mean_absolute_error: 2.683498, mean_q: 3.494112
183 (array([22]),) False
  49680/500000: episode: 1242, duration: 32.200s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 27.575 [12.000, 58.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.133519, mean_absolute_error: 2.669099, mean_q: 3.477430
250 (array([22]),) False
  49720/500000: episode: 1243, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.850 [8.000, 58.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.125442, mean_absolute_error: 2.672755, mean_q: 3.469017
740 (array([58]),) False
  49760/500000: episode: 1244, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 49.475 [2.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.132841, mean_absolute_error: 2.683165, mean_q: 3.484454
589 (array([22]),) False
  49800/500000: episode: 1245, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.250 [19.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.129878, mean_absolute_error: 2.678921, mean_q: 3.484571
625 (array([22]),) False
  49840/500000: episode: 1246, duration: 32.145s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.450 [1.000, 57.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.126425, mean_absolute_error: 2.653507, mean_q: 3.451202
282 (array([22]),) False
  49880/500000: episode: 1247, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.175 [2.000, 49.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.144640, mean_absolute_error: 2.654194, mean_q: 3.444324
424 (array([22]),) False
  49920/500000: episode: 1248, duration: 32.159s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.725 [2.000, 57.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.128826, mean_absolute_error: 2.657962, mean_q: 3.442392
203 (array([48]),) False
  49960/500000: episode: 1249, duration: 31.449s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 42.875 [9.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.130260, mean_absolute_error: 2.634020, mean_q: 3.422148
581 (array([22]),) False
  50000/500000: episode: 1250, duration: 31.050s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.150 [0.000, 54.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.130655, mean_absolute_error: 2.619269, mean_q: 3.415369
641 (array([22]),) False
  50040/500000: episode: 1251, duration: 31.523s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.150 [0.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.127249, mean_absolute_error: 2.656390, mean_q: 3.458317
352 (array([22]),) False
  50080/500000: episode: 1252, duration: 31.471s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.125 [0.000, 51.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.128230, mean_absolute_error: 2.615947, mean_q: 3.423512
665 (array([12]),) False
  50120/500000: episode: 1253, duration: 31.480s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 30.475 [8.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.122972, mean_absolute_error: 2.638321, mean_q: 3.449366
306 (array([22]),) False
  50160/500000: episode: 1254, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.250 [0.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.124993, mean_absolute_error: 2.631779, mean_q: 3.439869
476 (array([48]),) False
  50200/500000: episode: 1255, duration: 31.441s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 45.125 [2.000, 57.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.121834, mean_absolute_error: 2.637576, mean_q: 3.430991
389 (array([48]),) False
  50240/500000: episode: 1256, duration: 31.439s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 46.400 [8.000, 60.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.125600, mean_absolute_error: 2.674183, mean_q: 3.470302
101 (array([22]),) False
  50280/500000: episode: 1257, duration: 31.438s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.050 [0.000, 52.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.120171, mean_absolute_error: 2.671373, mean_q: 3.457728
257 (array([22]),) False
  50320/500000: episode: 1258, duration: 31.790s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.525 [2.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.135007, mean_absolute_error: 2.687862, mean_q: 3.497546
73 (array([22]),) False
  50360/500000: episode: 1259, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.425 [4.000, 56.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.137771, mean_absolute_error: 2.674698, mean_q: 3.474129
437 (array([12]),) False
  50400/500000: episode: 1260, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.650 [3.000, 59.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.129511, mean_absolute_error: 2.700845, mean_q: 3.502979
83 (array([22]),) False
  50440/500000: episode: 1261, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.650 [6.000, 55.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.130937, mean_absolute_error: 2.683772, mean_q: 3.476193
474 (array([22]),) False
  50480/500000: episode: 1262, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.625 [9.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.128889, mean_absolute_error: 2.702673, mean_q: 3.505830
715 (array([22]),) False
  50520/500000: episode: 1263, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.425 [4.000, 45.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.125643, mean_absolute_error: 2.684146, mean_q: 3.492642
99 (array([22]),) False
  50560/500000: episode: 1264, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.050 [7.000, 57.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.134368, mean_absolute_error: 2.695116, mean_q: 3.491415
790 (array([48]),) False
  50600/500000: episode: 1265, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 46.100 [17.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.130054, mean_absolute_error: 2.683511, mean_q: 3.490953
263 (array([8]),) False
  50640/500000: episode: 1266, duration: 32.191s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.650 [3.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.128199, mean_absolute_error: 2.706125, mean_q: 3.513549
321 (array([22]),) False
  50680/500000: episode: 1267, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.100 [0.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.141737, mean_absolute_error: 2.702320, mean_q: 3.504806
623 (array([37]),) False
  50720/500000: episode: 1268, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 27.475 [4.000, 56.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.135063, mean_absolute_error: 2.675365, mean_q: 3.468515
121 (array([22]),) False
  50760/500000: episode: 1269, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 25.375 [0.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.130533, mean_absolute_error: 2.677029, mean_q: 3.478528
240 (array([22]),) False
  50800/500000: episode: 1270, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.725 [9.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.131171, mean_absolute_error: 2.683414, mean_q: 3.482019
661 (array([48]),) False
  50840/500000: episode: 1271, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.950 [4.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.130846, mean_absolute_error: 2.670894, mean_q: 3.472728
140 (array([12]),) False
  50880/500000: episode: 1272, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 21.175 [2.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.133575, mean_absolute_error: 2.661288, mean_q: 3.463290
829 (array([21]),) False
  50920/500000: episode: 1273, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.175 [5.000, 47.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.134671, mean_absolute_error: 2.688303, mean_q: 3.491122
716 (array([48]),) False
  50960/500000: episode: 1274, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 32.500 [1.000, 52.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.124841, mean_absolute_error: 2.699898, mean_q: 3.517350
19 (array([12]),) False
  51000/500000: episode: 1275, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.275 [0.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.129629, mean_absolute_error: 2.698000, mean_q: 3.515138
616 (array([22]),) False
  51040/500000: episode: 1276, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 22.450 [3.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.130068, mean_absolute_error: 2.720407, mean_q: 3.538442
366 (array([22]),) False
  51080/500000: episode: 1277, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 34.925 [3.000, 52.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.141916, mean_absolute_error: 2.712521, mean_q: 3.520370
35 (array([48]),) False
  51120/500000: episode: 1278, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 40.125 [13.000, 56.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.151249, mean_absolute_error: 2.708127, mean_q: 3.506758
780 (array([22]),) False
  51160/500000: episode: 1279, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.175 [1.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.142898, mean_absolute_error: 2.711739, mean_q: 3.515202
814 (array([22]),) False
  51200/500000: episode: 1280, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.725 [1.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.127817, mean_absolute_error: 2.697849, mean_q: 3.507999
82 (array([22]),) False
  51240/500000: episode: 1281, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.275 [2.000, 60.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.122757, mean_absolute_error: 2.708979, mean_q: 3.528466
853 (array([22]),) False
  51280/500000: episode: 1282, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.550 [5.000, 53.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.129293, mean_absolute_error: 2.724820, mean_q: 3.535257
830 (array([22]),) False
  51320/500000: episode: 1283, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.625 [0.000, 56.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.130776, mean_absolute_error: 2.720422, mean_q: 3.527311
714 (array([22]),) False
  51360/500000: episode: 1284, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.300 [2.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.144582, mean_absolute_error: 2.727348, mean_q: 3.537740
799 (array([36]),) False
  51400/500000: episode: 1285, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 43.050 [6.000, 51.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.137629, mean_absolute_error: 2.685115, mean_q: 3.478683
500 (array([22]),) False
  51440/500000: episode: 1286, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 31.450 [1.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.144020, mean_absolute_error: 2.716915, mean_q: 3.508152
540 (array([22]),) False
  51480/500000: episode: 1287, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 40.400 [3.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.128034, mean_absolute_error: 2.730172, mean_q: 3.527019
842 (array([22]),) False
  51520/500000: episode: 1288, duration: 32.943s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.600 [0.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.133914, mean_absolute_error: 2.756988, mean_q: 3.574419
499 (array([8]),) False
  51560/500000: episode: 1289, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 33.200 [6.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.137167, mean_absolute_error: 2.735076, mean_q: 3.538216
33 (array([48]),) False
  51600/500000: episode: 1290, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.500 [3.000, 52.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.134976, mean_absolute_error: 2.726114, mean_q: 3.532972
862 (array([14]),) False
  51640/500000: episode: 1291, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 41.000 [12.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.129275, mean_absolute_error: 2.710415, mean_q: 3.513032
692 (array([22]),) False
  51680/500000: episode: 1292, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.600 [3.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.142392, mean_absolute_error: 2.707445, mean_q: 3.515727
668 (array([22]),) False
  51720/500000: episode: 1293, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 24.525 [4.000, 52.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.135908, mean_absolute_error: 2.710689, mean_q: 3.515501
256 (array([22]),) False
  51760/500000: episode: 1294, duration: 32.247s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.050 [0.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.144231, mean_absolute_error: 2.733592, mean_q: 3.535618
540 (array([22]),) False
  51800/500000: episode: 1295, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 41.700 [1.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.140446, mean_absolute_error: 2.682658, mean_q: 3.469152
129 (array([22]),) False
  51840/500000: episode: 1296, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.775 [0.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.130450, mean_absolute_error: 2.692488, mean_q: 3.472787
829 (array([21]),) False
  51880/500000: episode: 1297, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.650 [6.000, 53.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.133209, mean_absolute_error: 2.679531, mean_q: 3.456577
546 (array([22]),) False
  51920/500000: episode: 1298, duration: 32.243s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.800 [16.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.130078, mean_absolute_error: 2.673905, mean_q: 3.465089
839 (array([22]),) False
  51960/500000: episode: 1299, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.300 [7.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.126472, mean_absolute_error: 2.686189, mean_q: 3.485806
511 (array([22]),) False
  52000/500000: episode: 1300, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.825 [6.000, 60.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.131997, mean_absolute_error: 2.671974, mean_q: 3.470153
756 (array([48]),) False
  52040/500000: episode: 1301, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 40.625 [4.000, 53.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.132130, mean_absolute_error: 2.679040, mean_q: 3.461142
226 (array([22]),) False
  52080/500000: episode: 1302, duration: 32.183s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.800 [0.000, 58.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.129646, mean_absolute_error: 2.635451, mean_q: 3.431397
489 (array([22]),) False
  52120/500000: episode: 1303, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.325 [1.000, 50.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.131298, mean_absolute_error: 2.659645, mean_q: 3.460894
485 (array([22]),) False
  52160/500000: episode: 1304, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.675 [6.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.130549, mean_absolute_error: 2.645578, mean_q: 3.446118
443 (array([22]),) False
  52200/500000: episode: 1305, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.450 [3.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.140763, mean_absolute_error: 2.682820, mean_q: 3.483783
19 (array([12]),) False
  52240/500000: episode: 1306, duration: 32.199s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.825 [2.000, 59.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.125119, mean_absolute_error: 2.664379, mean_q: 3.448643
858 (array([12]),) False
  52280/500000: episode: 1307, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 20.275 [1.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.141739, mean_absolute_error: 2.658584, mean_q: 3.450589
803 (array([58]),) False
  52320/500000: episode: 1308, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 12.950 [2.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.134766, mean_absolute_error: 2.666636, mean_q: 3.466529
573 (array([22]),) False
  52360/500000: episode: 1309, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 31.925 [8.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.128350, mean_absolute_error: 2.691056, mean_q: 3.488242
551 (array([22]),) False
  52400/500000: episode: 1310, duration: 32.210s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.850 [0.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.131169, mean_absolute_error: 2.667320, mean_q: 3.462014
457 (array([38]),) False
  52440/500000: episode: 1311, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.525 [3.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.129148, mean_absolute_error: 2.684874, mean_q: 3.499213
654 (array([22]),) False
  52480/500000: episode: 1312, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.625 [6.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.123383, mean_absolute_error: 2.635749, mean_q: 3.434433
466 (array([22]),) False
  52520/500000: episode: 1313, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.050 [3.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.120152, mean_absolute_error: 2.638967, mean_q: 3.443313
20 (array([22]),) False
  52560/500000: episode: 1314, duration: 32.220s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.800 [1.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.129639, mean_absolute_error: 2.634515, mean_q: 3.439565
245 (array([22]),) False
  52600/500000: episode: 1315, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.725 [9.000, 47.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.130532, mean_absolute_error: 2.652980, mean_q: 3.448680
464 (array([22]),) False
  52640/500000: episode: 1316, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.125 [1.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.142438, mean_absolute_error: 2.639119, mean_q: 3.428373
710 (array([12]),) False
  52680/500000: episode: 1317, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 23.650 [5.000, 52.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.129832, mean_absolute_error: 2.644347, mean_q: 3.445712
547 (array([21]),) False
  52720/500000: episode: 1318, duration: 32.256s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.750 [2.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.129733, mean_absolute_error: 2.643116, mean_q: 3.450278
5 (array([37]),) False
  52760/500000: episode: 1319, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.850 [1.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.129704, mean_absolute_error: 2.625663, mean_q: 3.426101
261 (array([44]),) False
  52800/500000: episode: 1320, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.825 [2.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.126457, mean_absolute_error: 2.626801, mean_q: 3.438677
288 (array([33]),) False
  52840/500000: episode: 1321, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 34.200 [1.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.127418, mean_absolute_error: 2.630480, mean_q: 3.441004
859 (array([22]),) False
  52880/500000: episode: 1322, duration: 32.229s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.050 [0.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.139961, mean_absolute_error: 2.600642, mean_q: 3.387183
679 (array([44]),) False
  52920/500000: episode: 1323, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 20.500 [3.000, 56.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.124674, mean_absolute_error: 2.631876, mean_q: 3.442520
132 (array([22]),) False
  52960/500000: episode: 1324, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.525 [0.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.125680, mean_absolute_error: 2.658912, mean_q: 3.469644
619 (array([3]),) False
  53000/500000: episode: 1325, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 39.150 [1.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.121291, mean_absolute_error: 2.654224, mean_q: 3.474104
533 (array([22]),) False
  53040/500000: episode: 1326, duration: 32.146s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.850 [2.000, 49.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.136036, mean_absolute_error: 2.649963, mean_q: 3.450944
50 (array([22]),) False
  53080/500000: episode: 1327, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.225 [0.000, 50.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.130721, mean_absolute_error: 2.638011, mean_q: 3.457655
475 (array([22]),) False
  53120/500000: episode: 1328, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.675 [3.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.127508, mean_absolute_error: 2.643234, mean_q: 3.455440
547 (array([21]),) False
  53160/500000: episode: 1329, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 24.200 [3.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.130241, mean_absolute_error: 2.675655, mean_q: 3.477986
542 (array([44]),) False
  53200/500000: episode: 1330, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 35.450 [1.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.136708, mean_absolute_error: 2.633470, mean_q: 3.434261
198 (array([22]),) False
  53240/500000: episode: 1331, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 40.675 [4.000, 51.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.125710, mean_absolute_error: 2.665714, mean_q: 3.482898
84 (array([22]),) False
  53280/500000: episode: 1332, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.375 [0.000, 29.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.127133, mean_absolute_error: 2.664792, mean_q: 3.474908
542 (array([44]),) False
  53320/500000: episode: 1333, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 38.875 [1.000, 52.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.124262, mean_absolute_error: 2.654478, mean_q: 3.462296
16 (array([22]),) False
  53360/500000: episode: 1334, duration: 32.230s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.700 [2.000, 55.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.128491, mean_absolute_error: 2.670198, mean_q: 3.484128
35 (array([48]),) False
  53400/500000: episode: 1335, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 41.225 [7.000, 55.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.135486, mean_absolute_error: 2.641387, mean_q: 3.434392
853 (array([22]),) False
  53440/500000: episode: 1336, duration: 33.214s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.025 [1.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.123853, mean_absolute_error: 2.649891, mean_q: 3.446445
727 (array([12]),) False
  53480/500000: episode: 1337, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 18.675 [0.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.125998, mean_absolute_error: 2.672804, mean_q: 3.470973
231 (array([22]),) False
  53520/500000: episode: 1338, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.575 [1.000, 57.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.132924, mean_absolute_error: 2.661089, mean_q: 3.462898
819 (array([48]),) False
  53560/500000: episode: 1339, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 42.600 [3.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.121998, mean_absolute_error: 2.648200, mean_q: 3.449680
52 (array([22]),) False
  53600/500000: episode: 1340, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 27.700 [9.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.132128, mean_absolute_error: 2.646844, mean_q: 3.443755
269 (array([36]),) False
  53640/500000: episode: 1341, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 28.850 [0.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.126448, mean_absolute_error: 2.626858, mean_q: 3.420914
856 (array([48]),) False
  53680/500000: episode: 1342, duration: 32.090s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 42.925 [9.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.127849, mean_absolute_error: 2.651040, mean_q: 3.449122
716 (array([48]),) False
  53720/500000: episode: 1343, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 36.725 [18.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.129572, mean_absolute_error: 2.666631, mean_q: 3.472700
697 (array([22]),) False
  53760/500000: episode: 1344, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.550 [7.000, 50.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.130019, mean_absolute_error: 2.652694, mean_q: 3.442429
485 (array([22]),) False
  53800/500000: episode: 1345, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.325 [5.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.122645, mean_absolute_error: 2.638723, mean_q: 3.432914
455 (array([22]),) False
  53840/500000: episode: 1346, duration: 32.189s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 28.275 [3.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.130320, mean_absolute_error: 2.651670, mean_q: 3.449083
372 (array([22]),) False
  53880/500000: episode: 1347, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.225 [3.000, 59.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.124781, mean_absolute_error: 2.657313, mean_q: 3.459117
217 (array([12]),) False
  53920/500000: episode: 1348, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.000 [5.000, 55.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.133766, mean_absolute_error: 2.660811, mean_q: 3.462862
41 (array([12]),) False
  53960/500000: episode: 1349, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 26.425 [0.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.127710, mean_absolute_error: 2.619676, mean_q: 3.413650
45 (array([22]),) False
  54000/500000: episode: 1350, duration: 32.132s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.025 [7.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.126640, mean_absolute_error: 2.668468, mean_q: 3.471173
4 (array([22]),) False
  54040/500000: episode: 1351, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.975 [4.000, 54.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.134585, mean_absolute_error: 2.630225, mean_q: 3.442567
538 (array([12]),) False
  54080/500000: episode: 1352, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 42.775 [5.000, 56.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.133048, mean_absolute_error: 2.607106, mean_q: 3.395522
106 (array([22]),) False
  54120/500000: episode: 1353, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.925 [3.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.132003, mean_absolute_error: 2.626790, mean_q: 3.424325
860 (array([12]),) False
  54160/500000: episode: 1354, duration: 32.175s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 17.725 [11.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.123854, mean_absolute_error: 2.631280, mean_q: 3.434714
117 (array([44]),) False
  54200/500000: episode: 1355, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.450 [3.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.139797, mean_absolute_error: 2.623066, mean_q: 3.411755
514 (array([54]),) False
  54240/500000: episode: 1356, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.625 [6.000, 54.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.127978, mean_absolute_error: 2.623560, mean_q: 3.410986
259 (array([12]),) False
  54280/500000: episode: 1357, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 21.675 [0.000, 53.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.134473, mean_absolute_error: 2.631828, mean_q: 3.428909
318 (array([48]),) False
  54320/500000: episode: 1358, duration: 32.211s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 34.300 [2.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.127342, mean_absolute_error: 2.648002, mean_q: 3.449264
424 (array([22]),) False
  54360/500000: episode: 1359, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 27.850 [20.000, 56.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.138336, mean_absolute_error: 2.650698, mean_q: 3.448195
284 (array([12]),) False
  54400/500000: episode: 1360, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 21.350 [3.000, 51.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.140444, mean_absolute_error: 2.666946, mean_q: 3.464400
175 (array([22]),) False
  54440/500000: episode: 1361, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.175 [1.000, 46.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.140110, mean_absolute_error: 2.653623, mean_q: 3.444705
401 (array([12]),) False
  54480/500000: episode: 1362, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 18.125 [7.000, 51.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.142255, mean_absolute_error: 2.675313, mean_q: 3.467913
428 (array([22]),) False
  54520/500000: episode: 1363, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.825 [4.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.118931, mean_absolute_error: 2.684749, mean_q: 3.486512
763 (array([48]),) False
  54560/500000: episode: 1364, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 44.000 [0.000, 55.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.142469, mean_absolute_error: 2.652438, mean_q: 3.446550
758 (array([38]),) False
  54600/500000: episode: 1365, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 43.550 [4.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.127682, mean_absolute_error: 2.653180, mean_q: 3.437824
73 (array([22]),) False
  54640/500000: episode: 1366, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.875 [4.000, 60.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.122356, mean_absolute_error: 2.675574, mean_q: 3.477150
224 (array([12]),) False
  54680/500000: episode: 1367, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 22.750 [4.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.127282, mean_absolute_error: 2.675558, mean_q: 3.477079
300 (array([22]),) False
  54720/500000: episode: 1368, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.175 [2.000, 50.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.133214, mean_absolute_error: 2.662414, mean_q: 3.469375
14 (array([48]),) False
  54760/500000: episode: 1369, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 31.750 [8.000, 48.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.128364, mean_absolute_error: 2.677171, mean_q: 3.480260
645 (array([48]),) False
  54800/500000: episode: 1370, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.725 [0.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.131176, mean_absolute_error: 2.656550, mean_q: 3.440325
464 (array([22]),) False
  54840/500000: episode: 1371, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.050 [15.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.124316, mean_absolute_error: 2.662021, mean_q: 3.461475
188 (array([22]),) False
  54880/500000: episode: 1372, duration: 32.195s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.075 [1.000, 54.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.130237, mean_absolute_error: 2.651594, mean_q: 3.447665
598 (array([22]),) False
  54920/500000: episode: 1373, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 28.900 [14.000, 56.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.127497, mean_absolute_error: 2.654974, mean_q: 3.462168
474 (array([22]),) False
  54960/500000: episode: 1374, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.275 [7.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.140131, mean_absolute_error: 2.666346, mean_q: 3.464222
59 (array([12]),) False
  55000/500000: episode: 1375, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 26.275 [2.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.127516, mean_absolute_error: 2.648780, mean_q: 3.437850
537 (array([22]),) False
  55040/500000: episode: 1376, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 30.450 [1.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.126682, mean_absolute_error: 2.656434, mean_q: 3.458199
127 (array([22]),) False
  55080/500000: episode: 1377, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.650 [0.000, 49.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.126451, mean_absolute_error: 2.668808, mean_q: 3.474432
834 (array([44]),) False
  55120/500000: episode: 1378, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.675 [4.000, 48.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.135615, mean_absolute_error: 2.624629, mean_q: 3.413078
124 (array([48]),) False
  55160/500000: episode: 1379, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 45.975 [1.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.128366, mean_absolute_error: 2.658885, mean_q: 3.458022
164 (array([22]),) False
  55200/500000: episode: 1380, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.050 [2.000, 58.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.138274, mean_absolute_error: 2.627923, mean_q: 3.429662
571 (array([48]),) False
  55240/500000: episode: 1381, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 22.800 [5.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.121659, mean_absolute_error: 2.664704, mean_q: 3.473046
25 (array([48]),) False
  55280/500000: episode: 1382, duration: 32.141s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 30.875 [1.000, 58.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.139933, mean_absolute_error: 2.655972, mean_q: 3.462866
50 (array([22]),) False
  55320/500000: episode: 1383, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.100 [0.000, 59.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.130452, mean_absolute_error: 2.632235, mean_q: 3.436332
27 (array([22]),) False
  55360/500000: episode: 1384, duration: 32.195s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.550 [6.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.118538, mean_absolute_error: 2.614545, mean_q: 3.415643
46 (array([22]),) False
  55400/500000: episode: 1385, duration: 31.799s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.300 [13.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.133426, mean_absolute_error: 2.646785, mean_q: 3.451630
399 (array([22]),) False
  55440/500000: episode: 1386, duration: 31.485s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 30.875 [8.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.135367, mean_absolute_error: 2.608482, mean_q: 3.414701
383 (array([22]),) False
  55480/500000: episode: 1387, duration: 31.443s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.275 [2.000, 55.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.128322, mean_absolute_error: 2.605619, mean_q: 3.409869
263 (array([8]),) False
  55520/500000: episode: 1388, duration: 31.515s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 37.075 [12.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.128846, mean_absolute_error: 2.629028, mean_q: 3.439512
393 (array([22]),) False
  55560/500000: episode: 1389, duration: 31.463s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.900 [0.000, 55.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.125490, mean_absolute_error: 2.629959, mean_q: 3.437368
435 (array([22]),) False
  55600/500000: episode: 1390, duration: 31.442s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.075 [1.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.130245, mean_absolute_error: 2.630452, mean_q: 3.426902
832 (array([22]),) False
  55640/500000: episode: 1391, duration: 31.480s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.175 [8.000, 56.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.134542, mean_absolute_error: 2.630687, mean_q: 3.432049
324 (array([12]),) False
  55680/500000: episode: 1392, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 26.025 [1.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.129038, mean_absolute_error: 2.635858, mean_q: 3.443345
579 (array([58]),) False
  55720/500000: episode: 1393, duration: 31.465s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 48.175 [5.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.130752, mean_absolute_error: 2.613564, mean_q: 3.403384
134 (array([58]),) False
  55760/500000: episode: 1394, duration: 31.114s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 54.975 [7.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.126720, mean_absolute_error: 2.626278, mean_q: 3.424472
630 (array([22]),) False
  55800/500000: episode: 1395, duration: 32.939s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.925 [8.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.126298, mean_absolute_error: 2.636006, mean_q: 3.435364
387 (array([22]),) False
  55840/500000: episode: 1396, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.575 [15.000, 59.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.137301, mean_absolute_error: 2.623054, mean_q: 3.431489
733 (array([22]),) False
  55880/500000: episode: 1397, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.500 [1.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.133067, mean_absolute_error: 2.625406, mean_q: 3.427591
356 (array([22]),) False
  55920/500000: episode: 1398, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.475 [2.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.141233, mean_absolute_error: 2.658174, mean_q: 3.466062
11 (array([22]),) False
  55960/500000: episode: 1399, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.750 [3.000, 59.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.132885, mean_absolute_error: 2.607771, mean_q: 3.399042
101 (array([22]),) False
  56000/500000: episode: 1400, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.100 [20.000, 59.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.138977, mean_absolute_error: 2.632156, mean_q: 3.441993
443 (array([22]),) False
  56040/500000: episode: 1401, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.875 [9.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.132614, mean_absolute_error: 2.633585, mean_q: 3.426209
241 (array([22]),) False
  56080/500000: episode: 1402, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.825 [10.000, 58.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.130363, mean_absolute_error: 2.631873, mean_q: 3.432289
528 (array([12]),) False
  56120/500000: episode: 1403, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 21.750 [3.000, 46.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.126426, mean_absolute_error: 2.645740, mean_q: 3.461236
236 (array([22]),) False
  56160/500000: episode: 1404, duration: 32.178s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.725 [14.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.131825, mean_absolute_error: 2.646421, mean_q: 3.446669
45 (array([22]),) False
  56200/500000: episode: 1405, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.925 [2.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.134829, mean_absolute_error: 2.605574, mean_q: 3.410137
616 (array([22]),) False
  56240/500000: episode: 1406, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.100 [1.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.117876, mean_absolute_error: 2.654150, mean_q: 3.455821
14 (array([48]),) False
  56280/500000: episode: 1407, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 32.250 [0.000, 54.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.148343, mean_absolute_error: 2.645021, mean_q: 3.429602
854 (array([12]),) False
  56320/500000: episode: 1408, duration: 32.198s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 23.350 [2.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.133221, mean_absolute_error: 2.642406, mean_q: 3.432436
551 (array([22]),) False
  56360/500000: episode: 1409, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.025 [3.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.131081, mean_absolute_error: 2.653411, mean_q: 3.448034
195 (array([22]),) False
  56400/500000: episode: 1410, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.650 [5.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.130490, mean_absolute_error: 2.663109, mean_q: 3.455760
32 (array([48]),) False
  56440/500000: episode: 1411, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 40.200 [13.000, 56.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.123067, mean_absolute_error: 2.681696, mean_q: 3.478132
98 (array([12]),) False
  56480/500000: episode: 1412, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.950 [8.000, 56.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.133354, mean_absolute_error: 2.633661, mean_q: 3.424030
82 (array([22]),) False
  56520/500000: episode: 1413, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.450 [2.000, 54.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.134245, mean_absolute_error: 2.642214, mean_q: 3.458054
425 (array([22]),) False
  56560/500000: episode: 1414, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.250 [4.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.137999, mean_absolute_error: 2.633017, mean_q: 3.423248
810 (array([12]),) False
  56600/500000: episode: 1415, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.350 [3.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.129105, mean_absolute_error: 2.625054, mean_q: 3.427499
288 (array([33]),) False
  56640/500000: episode: 1416, duration: 32.151s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.300 [0.000, 52.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.126221, mean_absolute_error: 2.632411, mean_q: 3.425694
39 (array([22]),) False
  56680/500000: episode: 1417, duration: 32.987s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.750 [16.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.118959, mean_absolute_error: 2.612856, mean_q: 3.413755
121 (array([22]),) False
  56720/500000: episode: 1418, duration: 32.220s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.525 [10.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.133542, mean_absolute_error: 2.656702, mean_q: 3.459785
126 (array([22]),) False
  56760/500000: episode: 1419, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.275 [3.000, 53.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.146402, mean_absolute_error: 2.640244, mean_q: 3.435500
0 (array([48]),) False
  56800/500000: episode: 1420, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.775 [5.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.131312, mean_absolute_error: 2.647003, mean_q: 3.449508
331 (array([22]),) False
  56840/500000: episode: 1421, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 18.275 [0.000, 44.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.131901, mean_absolute_error: 2.640575, mean_q: 3.431473
77 (array([22]),) False
  56880/500000: episode: 1422, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.675 [12.000, 57.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.133320, mean_absolute_error: 2.665288, mean_q: 3.474834
764 (array([48]),) False
  56920/500000: episode: 1423, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 25.600 [3.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.140643, mean_absolute_error: 2.644410, mean_q: 3.454404
259 (array([12]),) False
  56960/500000: episode: 1424, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.625 [6.000, 55.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.124478, mean_absolute_error: 2.652592, mean_q: 3.473183
39 (array([22]),) False
  57000/500000: episode: 1425, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.975 [4.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.131791, mean_absolute_error: 2.661511, mean_q: 3.474271
306 (array([22]),) False
  57040/500000: episode: 1426, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.550 [5.000, 40.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.134769, mean_absolute_error: 2.646751, mean_q: 3.441479
130 (array([22]),) False
  57080/500000: episode: 1427, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.050 [7.000, 32.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.130202, mean_absolute_error: 2.676730, mean_q: 3.478549
796 (array([38]),) False
  57120/500000: episode: 1428, duration: 32.087s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 30.525 [9.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.126000, mean_absolute_error: 2.665676, mean_q: 3.458743
112 (array([12]),) False
  57160/500000: episode: 1429, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 15.950 [1.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.131800, mean_absolute_error: 2.680447, mean_q: 3.484891
750 (array([22]),) False
  57200/500000: episode: 1430, duration: 32.217s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.975 [0.000, 60.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.139034, mean_absolute_error: 2.700127, mean_q: 3.517043
511 (array([22]),) False
  57240/500000: episode: 1431, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.350 [0.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.126690, mean_absolute_error: 2.653104, mean_q: 3.468281
725 (array([36]),) False
  57280/500000: episode: 1432, duration: 32.232s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.700 [12.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.147568, mean_absolute_error: 2.666403, mean_q: 3.476236
150 (array([22]),) False
  57320/500000: episode: 1433, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.750 [0.000, 54.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.140958, mean_absolute_error: 2.674122, mean_q: 3.487316
565 (array([12]),) False
  57360/500000: episode: 1434, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.500 [9.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.141318, mean_absolute_error: 2.669118, mean_q: 3.466350
525 (array([22]),) False
  57400/500000: episode: 1435, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.200 [2.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.139411, mean_absolute_error: 2.645672, mean_q: 3.452101
520 (array([22]),) False
  57440/500000: episode: 1436, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.800 [0.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.142140, mean_absolute_error: 2.691239, mean_q: 3.492806
742 (array([33]),) False
  57480/500000: episode: 1437, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 36.050 [0.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.137896, mean_absolute_error: 2.675122, mean_q: 3.482266
616 (array([22]),) False
  57520/500000: episode: 1438, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.400 [4.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.129699, mean_absolute_error: 2.669556, mean_q: 3.474854
666 (array([22]),) False
  57560/500000: episode: 1439, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.150 [3.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.126477, mean_absolute_error: 2.699772, mean_q: 3.500544
623 (array([37]),) False
  57600/500000: episode: 1440, duration: 32.145s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 25.700 [0.000, 57.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.140821, mean_absolute_error: 2.669066, mean_q: 3.471600
245 (array([22]),) False
  57640/500000: episode: 1441, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.700 [1.000, 59.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.143976, mean_absolute_error: 2.707139, mean_q: 3.492985
616 (array([22]),) False
  57680/500000: episode: 1442, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.725 [0.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.130536, mean_absolute_error: 2.682261, mean_q: 3.486333
641 (array([22]),) False
  57720/500000: episode: 1443, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.875 [5.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.122424, mean_absolute_error: 2.682245, mean_q: 3.493402
244 (array([14]),) False
  57760/500000: episode: 1444, duration: 32.166s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.725 [7.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.131777, mean_absolute_error: 2.669492, mean_q: 3.467265
278 (array([48]),) False
  57800/500000: episode: 1445, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 41.925 [2.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.147147, mean_absolute_error: 2.676148, mean_q: 3.484049
437 (array([12]),) False
  57840/500000: episode: 1446, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.300 [5.000, 47.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.133476, mean_absolute_error: 2.666995, mean_q: 3.465442
199 (array([22]),) False
  57880/500000: episode: 1447, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.375 [7.000, 59.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.141697, mean_absolute_error: 2.660440, mean_q: 3.461654
483 (array([48]),) False
  57920/500000: episode: 1448, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 38.400 [12.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.132698, mean_absolute_error: 2.657550, mean_q: 3.458313
267 (array([22]),) False
  57960/500000: episode: 1449, duration: 33.038s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.400 [7.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.137721, mean_absolute_error: 2.689167, mean_q: 3.506918
460 (array([36]),) False
  58000/500000: episode: 1450, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.725 [2.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.125166, mean_absolute_error: 2.690162, mean_q: 3.518647
241 (array([22]),) False
  58040/500000: episode: 1451, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.200 [2.000, 45.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.127082, mean_absolute_error: 2.654352, mean_q: 3.463660
385 (array([30]),) False
  58080/500000: episode: 1452, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.450 [1.000, 49.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.133944, mean_absolute_error: 2.659093, mean_q: 3.461057
526 (array([22]),) False
  58120/500000: episode: 1453, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.750 [1.000, 52.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.129051, mean_absolute_error: 2.650500, mean_q: 3.454616
369 (array([48]),) False
  58160/500000: episode: 1454, duration: 32.234s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 43.700 [1.000, 59.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.136815, mean_absolute_error: 2.665823, mean_q: 3.456315
71 (array([58]),) False
  58200/500000: episode: 1455, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 41.950 [0.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.134213, mean_absolute_error: 2.645273, mean_q: 3.439562
100 (array([22]),) False
  58240/500000: episode: 1456, duration: 32.276s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.400 [0.000, 53.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.136425, mean_absolute_error: 2.634584, mean_q: 3.440241
799 (array([36]),) False
  58280/500000: episode: 1457, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 38.700 [4.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.130620, mean_absolute_error: 2.644006, mean_q: 3.452074
550 (array([12]),) False
  58320/500000: episode: 1458, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 16.475 [5.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.122288, mean_absolute_error: 2.652909, mean_q: 3.444164
243 (array([12]),) False
  58360/500000: episode: 1459, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.325 [12.000, 58.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.126094, mean_absolute_error: 2.659057, mean_q: 3.464754
835 (array([50]),) False
  58400/500000: episode: 1460, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.675 [5.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.135384, mean_absolute_error: 2.660577, mean_q: 3.458358
105 (array([22]),) False
  58440/500000: episode: 1461, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.775 [9.000, 52.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.138140, mean_absolute_error: 2.658308, mean_q: 3.451886
704 (array([22]),) False
  58480/500000: episode: 1462, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.375 [7.000, 53.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.132221, mean_absolute_error: 2.677253, mean_q: 3.484129
21 (array([3]),) False
  58520/500000: episode: 1463, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.525 [1.000, 50.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.136251, mean_absolute_error: 2.657641, mean_q: 3.454473
712 (array([22]),) False
  58560/500000: episode: 1464, duration: 32.178s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.700 [2.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.127286, mean_absolute_error: 2.674842, mean_q: 3.481567
579 (array([58]),) False
  58600/500000: episode: 1465, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 51.050 [3.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.122929, mean_absolute_error: 2.664207, mean_q: 3.475324
536 (array([22]),) False
  58640/500000: episode: 1466, duration: 32.229s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.800 [6.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.138059, mean_absolute_error: 2.648845, mean_q: 3.449126
344 (array([22]),) False
  58680/500000: episode: 1467, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.550 [6.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.137821, mean_absolute_error: 2.678868, mean_q: 3.478022
38 (array([22]),) False
  58720/500000: episode: 1468, duration: 32.153s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.375 [6.000, 49.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.129402, mean_absolute_error: 2.676694, mean_q: 3.472433
350 (array([12]),) False
  58760/500000: episode: 1469, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 21.400 [0.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.137683, mean_absolute_error: 2.635537, mean_q: 3.426242
43 (array([12]),) False
  58800/500000: episode: 1470, duration: 32.960s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 21.025 [1.000, 38.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.132573, mean_absolute_error: 2.665652, mean_q: 3.473224
343 (array([22]),) False
  58840/500000: episode: 1471, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.250 [1.000, 50.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.139963, mean_absolute_error: 2.678441, mean_q: 3.486398
585 (array([48]),) False
  58880/500000: episode: 1472, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.250 [1.000, 49.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.128209, mean_absolute_error: 2.673067, mean_q: 3.475449
60 (array([22]),) False
  58920/500000: episode: 1473, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 40.500 [10.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.135165, mean_absolute_error: 2.655873, mean_q: 3.457566
546 (array([22]),) False
  58960/500000: episode: 1474, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.150 [10.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.131714, mean_absolute_error: 2.658462, mean_q: 3.461887
798 (array([18]),) False
  59000/500000: episode: 1475, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.725 [12.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.118163, mean_absolute_error: 2.683619, mean_q: 3.484995
646 (array([44]),) False
  59040/500000: episode: 1476, duration: 32.170s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 32.775 [0.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.126783, mean_absolute_error: 2.656813, mean_q: 3.462839
119 (array([45]),) False
  59080/500000: episode: 1477, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 19.475 [3.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.129752, mean_absolute_error: 2.679953, mean_q: 3.490552
605 (array([22]),) False
  59120/500000: episode: 1478, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.375 [3.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.133642, mean_absolute_error: 2.699039, mean_q: 3.512980
755 (array([22]),) False
  59160/500000: episode: 1479, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.725 [11.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.141948, mean_absolute_error: 2.686774, mean_q: 3.502530
268 (array([22]),) False
  59200/500000: episode: 1480, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.025 [10.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.132047, mean_absolute_error: 2.680932, mean_q: 3.487483
13 (array([48]),) False
  59240/500000: episode: 1481, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 35.975 [3.000, 57.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.134104, mean_absolute_error: 2.670930, mean_q: 3.473599
198 (array([22]),) False
  59280/500000: episode: 1482, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 16.275 [0.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.129910, mean_absolute_error: 2.672787, mean_q: 3.463230
628 (array([22]),) False
  59320/500000: episode: 1483, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.675 [0.000, 52.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.124376, mean_absolute_error: 2.664247, mean_q: 3.470822
436 (array([22]),) False
  59360/500000: episode: 1484, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.050 [5.000, 52.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.137534, mean_absolute_error: 2.679953, mean_q: 3.491004
788 (array([3]),) False
  59400/500000: episode: 1485, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 40.675 [5.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.139239, mean_absolute_error: 2.695020, mean_q: 3.501309
53 (array([22]),) False
  59440/500000: episode: 1486, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.625 [22.000, 53.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.128444, mean_absolute_error: 2.675836, mean_q: 3.476943
140 (array([12]),) False
  59480/500000: episode: 1487, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 16.500 [4.000, 53.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.127303, mean_absolute_error: 2.676991, mean_q: 3.494031
334 (array([48]),) False
  59520/500000: episode: 1488, duration: 32.202s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 43.400 [5.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.134465, mean_absolute_error: 2.678097, mean_q: 3.489007
463 (array([22]),) False
  59560/500000: episode: 1489, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.850 [1.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.128038, mean_absolute_error: 2.704356, mean_q: 3.503615
658 (array([48]),) False
  59600/500000: episode: 1490, duration: 32.188s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.575 [2.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.143725, mean_absolute_error: 2.696497, mean_q: 3.492377
668 (array([22]),) False
  59640/500000: episode: 1491, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 24.275 [2.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.131884, mean_absolute_error: 2.671331, mean_q: 3.470220
91 (array([48]),) False
  59680/500000: episode: 1492, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 41.700 [14.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.132042, mean_absolute_error: 2.676547, mean_q: 3.475625
453 (array([22]),) False
  59720/500000: episode: 1493, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 20.150 [0.000, 50.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.142222, mean_absolute_error: 2.690313, mean_q: 3.493401
689 (array([12]),) False
  59760/500000: episode: 1494, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 15.525 [7.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.135594, mean_absolute_error: 2.643516, mean_q: 3.454037
424 (array([22]),) False
  59800/500000: episode: 1495, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.675 [10.000, 52.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.130935, mean_absolute_error: 2.671502, mean_q: 3.469510
695 (array([22]),) False
  59840/500000: episode: 1496, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.075 [5.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.132528, mean_absolute_error: 2.675247, mean_q: 3.476941
773 (array([22]),) False
  59880/500000: episode: 1497, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.075 [3.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.138583, mean_absolute_error: 2.658813, mean_q: 3.458808
834 (array([44]),) False
  59920/500000: episode: 1498, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.250 [5.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.120291, mean_absolute_error: 2.678904, mean_q: 3.477126
570 (array([47]),) False
  59960/500000: episode: 1499, duration: 32.360s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.275 [0.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.139821, mean_absolute_error: 2.650437, mean_q: 3.440924
223 (array([48]),) False
  60000/500000: episode: 1500, duration: 31.009s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.950 [12.000, 56.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.129212, mean_absolute_error: 2.699054, mean_q: 3.514093
589 (array([22]),) False
  60040/500000: episode: 1501, duration: 31.462s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.500 [3.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.125541, mean_absolute_error: 2.672076, mean_q: 3.475888
492 (array([22]),) False
  60080/500000: episode: 1502, duration: 31.045s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.675 [9.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.136375, mean_absolute_error: 2.655730, mean_q: 3.449282
724 (array([58]),) False
  60120/500000: episode: 1503, duration: 31.490s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 50.775 [9.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.141409, mean_absolute_error: 2.675680, mean_q: 3.483587
525 (array([22]),) False
  60160/500000: episode: 1504, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.575 [6.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.130678, mean_absolute_error: 2.621655, mean_q: 3.420787
274 (array([12]),) False
  60200/500000: episode: 1505, duration: 31.478s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 22.700 [3.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.125823, mean_absolute_error: 2.620946, mean_q: 3.410922
772 (array([46]),) False
  60240/500000: episode: 1506, duration: 31.467s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 18.775 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.132201, mean_absolute_error: 2.653340, mean_q: 3.462197
413 (array([22]),) False
  60280/500000: episode: 1507, duration: 31.485s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.875 [12.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.131112, mean_absolute_error: 2.654031, mean_q: 3.458948
724 (array([58]),) False
  60320/500000: episode: 1508, duration: 31.421s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 52.575 [5.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.133917, mean_absolute_error: 2.654996, mean_q: 3.456680
368 (array([22]),) False
  60360/500000: episode: 1509, duration: 32.304s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.950 [6.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.128839, mean_absolute_error: 2.666286, mean_q: 3.471713
239 (array([22]),) False
  60400/500000: episode: 1510, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.200 [3.000, 43.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.134699, mean_absolute_error: 2.647902, mean_q: 3.441211
67 (array([8]),) False
  60440/500000: episode: 1511, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 31.150 [8.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.131565, mean_absolute_error: 2.662112, mean_q: 3.465700
498 (array([12]),) False
  60480/500000: episode: 1512, duration: 31.850s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 34.475 [5.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.126318, mean_absolute_error: 2.649432, mean_q: 3.459670
327 (array([22]),) False
  60520/500000: episode: 1513, duration: 31.450s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.500 [12.000, 43.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.134607, mean_absolute_error: 2.653771, mean_q: 3.455889
233 (array([54]),) False
  60560/500000: episode: 1514, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 31.450 [13.000, 58.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.131738, mean_absolute_error: 2.625061, mean_q: 3.434700
218 (array([22]),) False
  60600/500000: episode: 1515, duration: 31.610s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.150 [0.000, 58.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.126516, mean_absolute_error: 2.641832, mean_q: 3.445714
93 (array([22]),) False
  60640/500000: episode: 1516, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.700 [0.000, 47.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.129413, mean_absolute_error: 2.649719, mean_q: 3.451485
538 (array([12]),) False
  60680/500000: episode: 1517, duration: 31.671s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 40.350 [0.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.130298, mean_absolute_error: 2.629158, mean_q: 3.437248
665 (array([12]),) False
  60720/500000: episode: 1518, duration: 31.551s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 36.925 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.133736, mean_absolute_error: 2.651463, mean_q: 3.454958
294 (array([22]),) False
  60760/500000: episode: 1519, duration: 31.591s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.050 [1.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.132597, mean_absolute_error: 2.708422, mean_q: 3.516593
596 (array([22]),) False
  60800/500000: episode: 1520, duration: 31.804s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.400 [10.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.127049, mean_absolute_error: 2.693079, mean_q: 3.521296
130 (array([22]),) False
  60840/500000: episode: 1521, duration: 31.479s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.750 [4.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.153062, mean_absolute_error: 2.666501, mean_q: 3.478889
578 (array([22]),) False
  60880/500000: episode: 1522, duration: 31.491s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.725 [9.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.133778, mean_absolute_error: 2.667587, mean_q: 3.479165
791 (array([54]),) False
  60920/500000: episode: 1523, duration: 31.451s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.775 [6.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.131667, mean_absolute_error: 2.695010, mean_q: 3.506810
247 (array([14]),) False
  60960/500000: episode: 1524, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 22.300 [0.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.127087, mean_absolute_error: 2.686508, mean_q: 3.497236
377 (array([22]),) False
  61000/500000: episode: 1525, duration: 31.455s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.275 [3.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.134085, mean_absolute_error: 2.679422, mean_q: 3.482162
191 (array([38]),) False
  61040/500000: episode: 1526, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.475 [6.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.124453, mean_absolute_error: 2.670241, mean_q: 3.474534
203 (array([48]),) False
  61080/500000: episode: 1527, duration: 31.499s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 43.000 [1.000, 56.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.132684, mean_absolute_error: 2.691056, mean_q: 3.494815
75 (array([22]),) False
  61120/500000: episode: 1528, duration: 31.070s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.550 [1.000, 51.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.137216, mean_absolute_error: 2.689012, mean_q: 3.498611
237 (array([22]),) False
  61160/500000: episode: 1529, duration: 31.534s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.975 [0.000, 55.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.133501, mean_absolute_error: 2.682022, mean_q: 3.489958
735 (array([22]),) False
  61200/500000: episode: 1530, duration: 31.449s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 32.475 [8.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.134380, mean_absolute_error: 2.680237, mean_q: 3.485646
818 (array([48]),) False
  61240/500000: episode: 1531, duration: 32.763s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 41.925 [0.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.128672, mean_absolute_error: 2.697537, mean_q: 3.498002
450 (array([8]),) False
  61280/500000: episode: 1532, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 25.025 [0.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.134670, mean_absolute_error: 2.657950, mean_q: 3.455659
520 (array([22]),) False
  61320/500000: episode: 1533, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.225 [3.000, 55.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.135674, mean_absolute_error: 2.678571, mean_q: 3.477977
9 (array([14]),) False
  61360/500000: episode: 1534, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.500 [1.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.134282, mean_absolute_error: 2.671679, mean_q: 3.475569
704 (array([22]),) False
  61400/500000: episode: 1535, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.750 [5.000, 57.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.135458, mean_absolute_error: 2.669721, mean_q: 3.474391
280 (array([48]),) False
  61440/500000: episode: 1536, duration: 32.094s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.075 [11.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.132025, mean_absolute_error: 2.658076, mean_q: 3.458973
504 (array([48]),) False
  61480/500000: episode: 1537, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 42.325 [2.000, 54.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.127404, mean_absolute_error: 2.661298, mean_q: 3.469390
738 (array([12]),) False
  61520/500000: episode: 1538, duration: 32.199s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 27.750 [0.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.135953, mean_absolute_error: 2.666998, mean_q: 3.462958
468 (array([22]),) False
  61560/500000: episode: 1539, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.700 [13.000, 55.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.138341, mean_absolute_error: 2.667598, mean_q: 3.472460
481 (array([22]),) False
  61600/500000: episode: 1540, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.025 [5.000, 50.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.127429, mean_absolute_error: 2.652051, mean_q: 3.447902
722 (array([22]),) False
  61640/500000: episode: 1541, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.450 [3.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.134215, mean_absolute_error: 2.654181, mean_q: 3.464520
845 (array([22]),) False
  61680/500000: episode: 1542, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.900 [22.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.127722, mean_absolute_error: 2.657986, mean_q: 3.461576
415 (array([22]),) False
  61720/500000: episode: 1543, duration: 33.155s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.700 [1.000, 53.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.129789, mean_absolute_error: 2.638973, mean_q: 3.447909
708 (array([40]),) False
  61760/500000: episode: 1544, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 20.475 [1.000, 36.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.140571, mean_absolute_error: 2.616725, mean_q: 3.414333
173 (array([3]),) False
  61800/500000: episode: 1545, duration: 32.965s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 11.575 [3.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.138057, mean_absolute_error: 2.641330, mean_q: 3.438614
534 (array([22]),) False
  61840/500000: episode: 1546, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.800 [11.000, 40.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.134239, mean_absolute_error: 2.629821, mean_q: 3.434874
181 (array([22]),) False
  61880/500000: episode: 1547, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.875 [1.000, 52.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.141925, mean_absolute_error: 2.649796, mean_q: 3.456447
453 (array([22]),) False
  61920/500000: episode: 1548, duration: 32.094s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 25.000 [3.000, 57.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.132294, mean_absolute_error: 2.626335, mean_q: 3.439611
527 (array([58]),) False
  61960/500000: episode: 1549, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 30.925 [6.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.126717, mean_absolute_error: 2.623260, mean_q: 3.432617
849 (array([3]),) False
  62000/500000: episode: 1550, duration: 32.115s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 37.125 [3.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.125966, mean_absolute_error: 2.623632, mean_q: 3.424631
531 (array([22]),) False
  62040/500000: episode: 1551, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.550 [5.000, 52.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.131625, mean_absolute_error: 2.604679, mean_q: 3.408330
89 (array([58]),) False
  62080/500000: episode: 1552, duration: 32.162s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 40.325 [12.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.133820, mean_absolute_error: 2.632443, mean_q: 3.443551
663 (array([22]),) False
  62120/500000: episode: 1553, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 28.100 [3.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.131030, mean_absolute_error: 2.630210, mean_q: 3.438555
224 (array([12]),) False
  62160/500000: episode: 1554, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 23.650 [0.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.131961, mean_absolute_error: 2.600142, mean_q: 3.391176
481 (array([22]),) False
  62200/500000: episode: 1555, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.500 [12.000, 49.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.135059, mean_absolute_error: 2.631673, mean_q: 3.424065
560 (array([22]),) False
  62240/500000: episode: 1556, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.950 [9.000, 51.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.136292, mean_absolute_error: 2.634328, mean_q: 3.436307
807 (array([22]),) False
  62280/500000: episode: 1557, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.675 [7.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.132451, mean_absolute_error: 2.619301, mean_q: 3.422239
474 (array([22]),) False
  62320/500000: episode: 1558, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.075 [2.000, 53.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.130774, mean_absolute_error: 2.617834, mean_q: 3.419204
266 (array([12]),) False
  62360/500000: episode: 1559, duration: 32.911s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.075 [0.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.134054, mean_absolute_error: 2.602102, mean_q: 3.403899
323 (array([55]),) False
  62400/500000: episode: 1560, duration: 32.111s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.750 [5.000, 50.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.132830, mean_absolute_error: 2.631789, mean_q: 3.429635
834 (array([44]),) False
  62440/500000: episode: 1561, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 28.700 [0.000, 54.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.129270, mean_absolute_error: 2.626603, mean_q: 3.427746
778 (array([12]),) False
  62480/500000: episode: 1562, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 16.950 [5.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.125171, mean_absolute_error: 2.613586, mean_q: 3.416715
399 (array([22]),) False
  62520/500000: episode: 1563, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.850 [0.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.139867, mean_absolute_error: 2.570503, mean_q: 3.371663
89 (array([58]),) False
  62560/500000: episode: 1564, duration: 32.095s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 41.750 [12.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.125803, mean_absolute_error: 2.603988, mean_q: 3.413244
853 (array([22]),) False
  62600/500000: episode: 1565, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.400 [7.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.129565, mean_absolute_error: 2.617493, mean_q: 3.422044
474 (array([22]),) False
  62640/500000: episode: 1566, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.975 [4.000, 50.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.133051, mean_absolute_error: 2.609033, mean_q: 3.399465
624 (array([48]),) False
  62680/500000: episode: 1567, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 35.225 [0.000, 53.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.121183, mean_absolute_error: 2.604029, mean_q: 3.405437
258 (array([22]),) False
  62720/500000: episode: 1568, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.550 [14.000, 44.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.126295, mean_absolute_error: 2.609653, mean_q: 3.422296
203 (array([48]),) False
  62760/500000: episode: 1569, duration: 32.967s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 45.125 [11.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.128845, mean_absolute_error: 2.604936, mean_q: 3.418269
350 (array([12]),) False
  62800/500000: episode: 1570, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.550 [19.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.124848, mean_absolute_error: 2.589544, mean_q: 3.404451
77 (array([22]),) False
  62840/500000: episode: 1571, duration: 32.982s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.750 [7.000, 51.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.141074, mean_absolute_error: 2.582232, mean_q: 3.391875
166 (array([22]),) False
  62880/500000: episode: 1572, duration: 32.087s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.900 [0.000, 60.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.133854, mean_absolute_error: 2.594438, mean_q: 3.401852
301 (array([22]),) False
  62920/500000: episode: 1573, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 28.275 [5.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.137250, mean_absolute_error: 2.583398, mean_q: 3.394278
292 (array([22]),) False
  62960/500000: episode: 1574, duration: 32.102s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.300 [1.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.128264, mean_absolute_error: 2.586586, mean_q: 3.403991
718 (array([12]),) False
  63000/500000: episode: 1575, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 20.775 [1.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.138262, mean_absolute_error: 2.591960, mean_q: 3.402716
522 (array([22]),) False
  63040/500000: episode: 1576, duration: 32.139s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.925 [0.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.127532, mean_absolute_error: 2.610699, mean_q: 3.430151
858 (array([12]),) False
  63080/500000: episode: 1577, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 15.050 [10.000, 43.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.143172, mean_absolute_error: 2.559315, mean_q: 3.363560
63 (array([18]),) False
  63120/500000: episode: 1578, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 19.750 [0.000, 55.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.139213, mean_absolute_error: 2.614980, mean_q: 3.426984
111 (array([22]),) False
  63160/500000: episode: 1579, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.000 [15.000, 53.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.130810, mean_absolute_error: 2.606292, mean_q: 3.417940
656 (array([48]),) False
  63200/500000: episode: 1580, duration: 32.999s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.725 [0.000, 55.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.134427, mean_absolute_error: 2.606638, mean_q: 3.423232
664 (array([22]),) False
  63240/500000: episode: 1581, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.600 [3.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.121608, mean_absolute_error: 2.604584, mean_q: 3.418717
693 (array([22]),) False
  63280/500000: episode: 1582, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.300 [1.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.141116, mean_absolute_error: 2.636657, mean_q: 3.450275
376 (array([22]),) False
  63320/500000: episode: 1583, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 38.425 [3.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.133028, mean_absolute_error: 2.672566, mean_q: 3.499454
530 (array([22]),) False
  63360/500000: episode: 1584, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.825 [12.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.126905, mean_absolute_error: 2.664852, mean_q: 3.482988
189 (array([12]),) False
  63400/500000: episode: 1585, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 17.550 [12.000, 55.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.149383, mean_absolute_error: 2.648332, mean_q: 3.468140
34 (array([22]),) False
  63440/500000: episode: 1586, duration: 32.165s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.725 [15.000, 59.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.141004, mean_absolute_error: 2.643093, mean_q: 3.446362
237 (array([22]),) False
  63480/500000: episode: 1587, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.325 [10.000, 51.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.142822, mean_absolute_error: 2.628568, mean_q: 3.436739
298 (array([22]),) False
  63520/500000: episode: 1588, duration: 32.158s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.700 [4.000, 56.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.127422, mean_absolute_error: 2.621033, mean_q: 3.434889
53 (array([22]),) False
  63560/500000: episode: 1589, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.450 [8.000, 60.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.133080, mean_absolute_error: 2.636129, mean_q: 3.444480
523 (array([22]),) False
  63600/500000: episode: 1590, duration: 32.985s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.250 [4.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.130382, mean_absolute_error: 2.645123, mean_q: 3.456518
71 (array([58]),) False
  63640/500000: episode: 1591, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 48.300 [1.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.127431, mean_absolute_error: 2.639885, mean_q: 3.449786
25 (array([48]),) False
  63680/500000: episode: 1592, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 29.300 [1.000, 60.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.141064, mean_absolute_error: 2.649856, mean_q: 3.451548
248 (array([12]),) False
  63720/500000: episode: 1593, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 24.175 [10.000, 57.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.131776, mean_absolute_error: 2.679115, mean_q: 3.485252
695 (array([22]),) False
  63760/500000: episode: 1594, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.475 [19.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.139671, mean_absolute_error: 2.629550, mean_q: 3.430672
140 (array([12]),) False
  63800/500000: episode: 1595, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 15.650 [7.000, 49.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.136913, mean_absolute_error: 2.629117, mean_q: 3.432012
365 (array([22]),) False
  63840/500000: episode: 1596, duration: 32.180s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.350 [1.000, 51.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.135362, mean_absolute_error: 2.612014, mean_q: 3.413024
812 (array([22]),) False
  63880/500000: episode: 1597, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 21.450 [4.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.130491, mean_absolute_error: 2.621060, mean_q: 3.438010
12 (array([22]),) False
  63920/500000: episode: 1598, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.750 [3.000, 42.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.131260, mean_absolute_error: 2.599851, mean_q: 3.399501
99 (array([22]),) False
  63960/500000: episode: 1599, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.400 [13.000, 46.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.139432, mean_absolute_error: 2.622586, mean_q: 3.417434
124 (array([48]),) False
  64000/500000: episode: 1600, duration: 32.092s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.825 [4.000, 48.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.127672, mean_absolute_error: 2.626841, mean_q: 3.432076
461 (array([22]),) False
  64040/500000: episode: 1601, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.675 [1.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.123200, mean_absolute_error: 2.633784, mean_q: 3.443667
663 (array([22]),) False
  64080/500000: episode: 1602, duration: 32.941s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 27.900 [3.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.137231, mean_absolute_error: 2.645867, mean_q: 3.476655
805 (array([22]),) False
  64120/500000: episode: 1603, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 39.025 [6.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.127492, mean_absolute_error: 2.628800, mean_q: 3.449960
303 (array([22]),) False
  64160/500000: episode: 1604, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.225 [0.000, 39.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.130540, mean_absolute_error: 2.649186, mean_q: 3.464384
6 (array([58]),) False
  64200/500000: episode: 1605, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.500 [6.000, 52.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.143196, mean_absolute_error: 2.640604, mean_q: 3.454446
675 (array([22]),) False
  64240/500000: episode: 1606, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.850 [5.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.122998, mean_absolute_error: 2.653927, mean_q: 3.464579
342 (array([12]),) False
  64280/500000: episode: 1607, duration: 32.968s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.525 [6.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.135259, mean_absolute_error: 2.646675, mean_q: 3.448927
612 (array([22]),) False
  64320/500000: episode: 1608, duration: 32.117s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 19.025 [0.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.129905, mean_absolute_error: 2.630639, mean_q: 3.437754
58 (array([48]),) False
  64360/500000: episode: 1609, duration: 32.960s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 43.250 [11.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.120569, mean_absolute_error: 2.657281, mean_q: 3.474446
788 (array([3]),) False
  64400/500000: episode: 1610, duration: 32.076s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 33.250 [12.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.137580, mean_absolute_error: 2.666454, mean_q: 3.480719
371 (array([14]),) False
  64440/500000: episode: 1611, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.800 [5.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.136801, mean_absolute_error: 2.614383, mean_q: 3.420939
169 (array([22]),) False
  64480/500000: episode: 1612, duration: 32.209s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.275 [5.000, 60.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.136731, mean_absolute_error: 2.619899, mean_q: 3.425711
667 (array([48]),) False
  64520/500000: episode: 1613, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 46.175 [14.000, 57.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.135154, mean_absolute_error: 2.637635, mean_q: 3.445740
295 (array([22]),) False
  64560/500000: episode: 1614, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.475 [12.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.129343, mean_absolute_error: 2.597771, mean_q: 3.394395
563 (array([22]),) False
  64600/500000: episode: 1615, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.225 [8.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.124698, mean_absolute_error: 2.635424, mean_q: 3.441242
214 (array([22]),) False
  64640/500000: episode: 1616, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.875 [0.000, 53.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.137147, mean_absolute_error: 2.613476, mean_q: 3.429067
290 (array([22]),) False
  64680/500000: episode: 1617, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.325 [8.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.131432, mean_absolute_error: 2.644059, mean_q: 3.457075
144 (array([22]),) False
  64720/500000: episode: 1618, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 19.450 [3.000, 55.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.131227, mean_absolute_error: 2.659380, mean_q: 3.475565
702 (array([22]),) False
  64760/500000: episode: 1619, duration: 32.964s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.550 [0.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.126623, mean_absolute_error: 2.655287, mean_q: 3.476880
390 (array([22]),) False
  64800/500000: episode: 1620, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 26.025 [1.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.125926, mean_absolute_error: 2.677025, mean_q: 3.497355
281 (array([48]),) False
  64840/500000: episode: 1621, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 22.550 [1.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.147155, mean_absolute_error: 2.646242, mean_q: 3.455495
46 (array([22]),) False
  64880/500000: episode: 1622, duration: 32.111s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.275 [0.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.136748, mean_absolute_error: 2.657345, mean_q: 3.464425
148 (array([22]),) False
  64920/500000: episode: 1623, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.575 [0.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.141477, mean_absolute_error: 2.681695, mean_q: 3.495434
152 (array([58]),) False
  64960/500000: episode: 1624, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 47.275 [0.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.127586, mean_absolute_error: 2.669891, mean_q: 3.477397
679 (array([44]),) False
  65000/500000: episode: 1625, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.350 [2.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.134141, mean_absolute_error: 2.652478, mean_q: 3.458327
248 (array([12]),) False
  65040/500000: episode: 1626, duration: 33.023s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 22.325 [0.000, 50.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.131454, mean_absolute_error: 2.665108, mean_q: 3.476370
27 (array([22]),) False
  65080/500000: episode: 1627, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.625 [1.000, 54.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.130515, mean_absolute_error: 2.660570, mean_q: 3.465812
604 (array([40]),) False
  65120/500000: episode: 1628, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.125 [7.000, 56.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.130102, mean_absolute_error: 2.695279, mean_q: 3.509410
252 (array([22]),) False
  65160/500000: episode: 1629, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.225 [3.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.134308, mean_absolute_error: 2.654052, mean_q: 3.474991
634 (array([57]),) False
  65200/500000: episode: 1630, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 32.000 [3.000, 59.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.141386, mean_absolute_error: 2.646784, mean_q: 3.456854
510 (array([22]),) False
  65240/500000: episode: 1631, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.750 [2.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.140623, mean_absolute_error: 2.653006, mean_q: 3.469821
413 (array([22]),) False
  65280/500000: episode: 1632, duration: 32.112s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.775 [5.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.138236, mean_absolute_error: 2.672940, mean_q: 3.482553
824 (array([22]),) False
  65320/500000: episode: 1633, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 20.600 [2.000, 43.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.150025, mean_absolute_error: 2.658267, mean_q: 3.458677
479 (array([22]),) False
  65360/500000: episode: 1634, duration: 32.202s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.650 [21.000, 54.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.129308, mean_absolute_error: 2.657208, mean_q: 3.466256
713 (array([37]),) False
  65400/500000: episode: 1635, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 43.425 [5.000, 54.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.132016, mean_absolute_error: 2.652611, mean_q: 3.460248
313 (array([22]),) False
  65440/500000: episode: 1636, duration: 32.105s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.275 [7.000, 49.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.130553, mean_absolute_error: 2.631234, mean_q: 3.429311
66 (array([22]),) False
  65480/500000: episode: 1637, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.050 [0.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.129441, mean_absolute_error: 2.630179, mean_q: 3.439433
623 (array([37]),) False
  65520/500000: episode: 1638, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.750 [5.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.140302, mean_absolute_error: 2.622684, mean_q: 3.426005
2 (array([12]),) False
  65560/500000: episode: 1639, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.975 [5.000, 60.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.132096, mean_absolute_error: 2.603617, mean_q: 3.408904
274 (array([12]),) False
  65600/500000: episode: 1640, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.725 [8.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.128931, mean_absolute_error: 2.620979, mean_q: 3.428210
9 (array([14]),) False
  65640/500000: episode: 1641, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 29.175 [9.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.139081, mean_absolute_error: 2.588488, mean_q: 3.380995
79 (array([22]),) False
  65680/500000: episode: 1642, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.675 [0.000, 52.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.137768, mean_absolute_error: 2.588613, mean_q: 3.389922
90 (array([22]),) False
  65720/500000: episode: 1643, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.225 [2.000, 51.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.130802, mean_absolute_error: 2.573999, mean_q: 3.383190
307 (array([22]),) False
  65760/500000: episode: 1644, duration: 32.091s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.150 [0.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.126954, mean_absolute_error: 2.598845, mean_q: 3.414515
761 (array([3]),) False
  65800/500000: episode: 1645, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 7.125 [3.000, 55.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.121915, mean_absolute_error: 2.617382, mean_q: 3.424027
143 (array([12]),) False
  65840/500000: episode: 1646, duration: 32.133s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 20.650 [3.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.122224, mean_absolute_error: 2.591869, mean_q: 3.399828
859 (array([22]),) False
  65880/500000: episode: 1647, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.275 [1.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.136152, mean_absolute_error: 2.582675, mean_q: 3.391578
559 (array([59]),) False
  65920/500000: episode: 1648, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 26.575 [3.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.144896, mean_absolute_error: 2.600513, mean_q: 3.397578
501 (array([12]),) False
  65960/500000: episode: 1649, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.175 [4.000, 55.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.122255, mean_absolute_error: 2.563560, mean_q: 3.368469
246 (array([22]),) False
  66000/500000: episode: 1650, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.650 [6.000, 59.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.131307, mean_absolute_error: 2.588613, mean_q: 3.399111
254 (array([22]),) False
  66040/500000: episode: 1651, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.150 [0.000, 56.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.130047, mean_absolute_error: 2.601576, mean_q: 3.410451
604 (array([40]),) False
  66080/500000: episode: 1652, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.050 [4.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.133032, mean_absolute_error: 2.573256, mean_q: 3.374593
575 (array([44]),) False
  66120/500000: episode: 1653, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 35.425 [4.000, 51.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.130921, mean_absolute_error: 2.600102, mean_q: 3.416029
354 (array([12]),) False
  66160/500000: episode: 1654, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 21.225 [0.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.138855, mean_absolute_error: 2.572700, mean_q: 3.363778
752 (array([3]),) False
  66200/500000: episode: 1655, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 20.250 [1.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.125736, mean_absolute_error: 2.581750, mean_q: 3.379403
827 (array([14]),) False
  66240/500000: episode: 1656, duration: 32.098s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.925 [3.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.129385, mean_absolute_error: 2.568278, mean_q: 3.380888
325 (array([22]),) False
  66280/500000: episode: 1657, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 20.650 [2.000, 32.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.137179, mean_absolute_error: 2.595174, mean_q: 3.408833
340 (array([12]),) False
  66320/500000: episode: 1658, duration: 32.106s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.050 [22.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.139523, mean_absolute_error: 2.560643, mean_q: 3.353831
862 (array([14]),) False
  66360/500000: episode: 1659, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 35.375 [1.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.138257, mean_absolute_error: 2.596983, mean_q: 3.407480
740 (array([58]),) False
  66400/500000: episode: 1660, duration: 32.168s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 52.050 [5.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.128369, mean_absolute_error: 2.600366, mean_q: 3.417594
628 (array([22]),) False
  66440/500000: episode: 1661, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.900 [1.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.129983, mean_absolute_error: 2.575974, mean_q: 3.384458
714 (array([22]),) False
  66480/500000: episode: 1662, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.100 [2.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.130687, mean_absolute_error: 2.620515, mean_q: 3.421891
495 (array([48]),) False
  66520/500000: episode: 1663, duration: 33.038s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 45.850 [2.000, 48.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.130405, mean_absolute_error: 2.586133, mean_q: 3.391794
206 (array([22]),) False
  66560/500000: episode: 1664, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 20.350 [7.000, 38.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.140613, mean_absolute_error: 2.591929, mean_q: 3.404823
389 (array([48]),) False
  66600/500000: episode: 1665, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.925 [3.000, 57.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.132728, mean_absolute_error: 2.584445, mean_q: 3.391851
784 (array([22]),) False
  66640/500000: episode: 1666, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.250 [16.000, 53.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.139863, mean_absolute_error: 2.580761, mean_q: 3.390057
268 (array([22]),) False
  66680/500000: episode: 1667, duration: 32.956s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 26.775 [9.000, 51.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.124731, mean_absolute_error: 2.563899, mean_q: 3.366728
128 (array([22]),) False
  66720/500000: episode: 1668, duration: 31.976s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.350 [5.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.130462, mean_absolute_error: 2.583846, mean_q: 3.397739
661 (array([48]),) False
  66760/500000: episode: 1669, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.750 [0.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.136322, mean_absolute_error: 2.576982, mean_q: 3.371913
308 (array([22]),) False
  66800/500000: episode: 1670, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.675 [9.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.130963, mean_absolute_error: 2.574347, mean_q: 3.374765
510 (array([22]),) False
  66840/500000: episode: 1671, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.075 [0.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.142168, mean_absolute_error: 2.581794, mean_q: 3.384019
466 (array([22]),) False
  66880/500000: episode: 1672, duration: 32.063s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.725 [5.000, 33.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.126294, mean_absolute_error: 2.572396, mean_q: 3.364728
503 (array([3]),) False
  66920/500000: episode: 1673, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 15.400 [1.000, 58.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.140059, mean_absolute_error: 2.565683, mean_q: 3.360806
772 (array([46]),) False
  66960/500000: episode: 1674, duration: 32.946s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.825 [1.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.126376, mean_absolute_error: 2.558196, mean_q: 3.373700
215 (array([22]),) False
  67000/500000: episode: 1675, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.675 [17.000, 51.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.140660, mean_absolute_error: 2.578951, mean_q: 3.390815
270 (array([3]),) False
  67040/500000: episode: 1676, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 27.025 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.140765, mean_absolute_error: 2.586465, mean_q: 3.391820
56 (array([12]),) False
  67080/500000: episode: 1677, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.725 [4.000, 53.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.130610, mean_absolute_error: 2.615000, mean_q: 3.422638
315 (array([12]),) False
  67120/500000: episode: 1678, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 23.500 [2.000, 55.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.134303, mean_absolute_error: 2.578044, mean_q: 3.379533
263 (array([8]),) False
  67160/500000: episode: 1679, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 35.450 [13.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.125568, mean_absolute_error: 2.584847, mean_q: 3.381931
733 (array([22]),) False
  67200/500000: episode: 1680, duration: 32.106s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.550 [11.000, 51.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.132778, mean_absolute_error: 2.586189, mean_q: 3.378267
482 (array([22]),) False
  67240/500000: episode: 1681, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 24.025 [0.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.133811, mean_absolute_error: 2.565816, mean_q: 3.365514
817 (array([12]),) False
  67280/500000: episode: 1682, duration: 32.092s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 39.425 [4.000, 54.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.136423, mean_absolute_error: 2.603247, mean_q: 3.409218
516 (array([48]),) False
  67320/500000: episode: 1683, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.950 [2.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.136617, mean_absolute_error: 2.556829, mean_q: 3.357726
686 (array([48]),) False
  67360/500000: episode: 1684, duration: 32.116s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 41.475 [5.000, 52.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.128083, mean_absolute_error: 2.566762, mean_q: 3.370319
768 (array([22]),) False
  67400/500000: episode: 1685, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 40.950 [9.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.135939, mean_absolute_error: 2.577222, mean_q: 3.385973
738 (array([12]),) False
  67440/500000: episode: 1686, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.350 [2.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.135013, mean_absolute_error: 2.575532, mean_q: 3.371947
313 (array([22]),) False
  67480/500000: episode: 1687, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.250 [7.000, 55.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.127967, mean_absolute_error: 2.554806, mean_q: 3.354757
662 (array([12]),) False
  67520/500000: episode: 1688, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 16.875 [2.000, 58.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.128706, mean_absolute_error: 2.560643, mean_q: 3.364072
721 (array([22]),) False
  67560/500000: episode: 1689, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.350 [0.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.128039, mean_absolute_error: 2.538954, mean_q: 3.330854
821 (array([22]),) False
  67600/500000: episode: 1690, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.925 [5.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.129959, mean_absolute_error: 2.558586, mean_q: 3.370101
619 (array([3]),) False
  67640/500000: episode: 1691, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 21.150 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.142274, mean_absolute_error: 2.561341, mean_q: 3.373801
721 (array([22]),) False
  67680/500000: episode: 1692, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.050 [3.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.122741, mean_absolute_error: 2.564516, mean_q: 3.380034
665 (array([12]),) False
  67720/500000: episode: 1693, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 22.250 [3.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.120457, mean_absolute_error: 2.569093, mean_q: 3.377565
58 (array([48]),) False
  67760/500000: episode: 1694, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.650 [2.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.136330, mean_absolute_error: 2.535384, mean_q: 3.346769
1 (array([22]),) False
  67800/500000: episode: 1695, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.200 [3.000, 57.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.126912, mean_absolute_error: 2.550582, mean_q: 3.354633
342 (array([12]),) False
  67840/500000: episode: 1696, duration: 32.097s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.600 [10.000, 40.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.138860, mean_absolute_error: 2.523660, mean_q: 3.320245
79 (array([22]),) False
  67880/500000: episode: 1697, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.025 [7.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.132938, mean_absolute_error: 2.577559, mean_q: 3.387286
91 (array([48]),) False
  67920/500000: episode: 1698, duration: 32.969s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 42.200 [22.000, 54.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.129888, mean_absolute_error: 2.550212, mean_q: 3.359519
449 (array([22]),) False
  67960/500000: episode: 1699, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.700 [2.000, 56.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.136075, mean_absolute_error: 2.563996, mean_q: 3.357887
273 (array([22]),) False
  68000/500000: episode: 1700, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.675 [7.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.124419, mean_absolute_error: 2.545337, mean_q: 3.341276
260 (array([22]),) False
  68040/500000: episode: 1701, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.475 [0.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.126145, mean_absolute_error: 2.565003, mean_q: 3.369053
425 (array([22]),) False
  68080/500000: episode: 1702, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.300 [5.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.142520, mean_absolute_error: 2.568106, mean_q: 3.379062
522 (array([22]),) False
  68120/500000: episode: 1703, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 20.750 [1.000, 36.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.139155, mean_absolute_error: 2.573033, mean_q: 3.373349
680 (array([22]),) False
  68160/500000: episode: 1704, duration: 32.089s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 20.375 [1.000, 53.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.121508, mean_absolute_error: 2.598437, mean_q: 3.408095
334 (array([48]),) False
  68200/500000: episode: 1705, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 46.125 [8.000, 54.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.141472, mean_absolute_error: 2.583428, mean_q: 3.391762
739 (array([22]),) False
  68240/500000: episode: 1706, duration: 32.063s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.625 [12.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.130370, mean_absolute_error: 2.562826, mean_q: 3.369529
704 (array([22]),) False
  68280/500000: episode: 1707, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.750 [1.000, 52.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.131869, mean_absolute_error: 2.560255, mean_q: 3.367786
688 (array([22]),) False
  68320/500000: episode: 1708, duration: 32.116s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.725 [11.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.140538, mean_absolute_error: 2.574455, mean_q: 3.386840
741 (array([22]),) False
  68360/500000: episode: 1709, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.900 [1.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.126118, mean_absolute_error: 2.568212, mean_q: 3.379858
862 (array([14]),) False
  68400/500000: episode: 1710, duration: 32.973s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 29.775 [12.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.131544, mean_absolute_error: 2.591873, mean_q: 3.408900
626 (array([22]),) False
  68440/500000: episode: 1711, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.925 [15.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.126237, mean_absolute_error: 2.577414, mean_q: 3.397350
138 (array([3]),) False
  68480/500000: episode: 1712, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 20.650 [3.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.137115, mean_absolute_error: 2.560687, mean_q: 3.376616
508 (array([22]),) False
  68520/500000: episode: 1713, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 27.350 [1.000, 50.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.135642, mean_absolute_error: 2.580215, mean_q: 3.407687
294 (array([22]),) False
  68560/500000: episode: 1714, duration: 32.999s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.900 [13.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.135354, mean_absolute_error: 2.572571, mean_q: 3.388625
636 (array([12]),) False
  68600/500000: episode: 1715, duration: 33.007s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 42.900 [13.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.130698, mean_absolute_error: 2.559795, mean_q: 3.370202
618 (array([12]),) False
  68640/500000: episode: 1716, duration: 32.107s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 38.475 [15.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.126043, mean_absolute_error: 2.569547, mean_q: 3.382704
6 (array([58]),) False
  68680/500000: episode: 1717, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.050 [6.000, 60.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.133240, mean_absolute_error: 2.578746, mean_q: 3.383155
116 (array([22]),) False
  68720/500000: episode: 1718, duration: 32.093s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 19.850 [3.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.127005, mean_absolute_error: 2.572018, mean_q: 3.362454
476 (array([48]),) False
  68760/500000: episode: 1719, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 43.075 [6.000, 60.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.129170, mean_absolute_error: 2.589689, mean_q: 3.388945
248 (array([12]),) False
  68800/500000: episode: 1720, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 21.050 [0.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.139033, mean_absolute_error: 2.549290, mean_q: 3.357457
12 (array([22]),) False
  68840/500000: episode: 1721, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.575 [1.000, 55.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.128663, mean_absolute_error: 2.563628, mean_q: 3.377277
186 (array([22]),) False
  68880/500000: episode: 1722, duration: 32.954s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.975 [1.000, 53.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.139830, mean_absolute_error: 2.561245, mean_q: 3.347933
340 (array([12]),) False
  68920/500000: episode: 1723, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 26.300 [18.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.131616, mean_absolute_error: 2.576352, mean_q: 3.380201
120 (array([44]),) False
  68960/500000: episode: 1724, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 34.975 [5.000, 44.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.127365, mean_absolute_error: 2.539336, mean_q: 3.353914
526 (array([22]),) False
  69000/500000: episode: 1725, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.475 [4.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.130100, mean_absolute_error: 2.528385, mean_q: 3.332047
111 (array([22]),) False
  69040/500000: episode: 1726, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 20.950 [1.000, 34.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.132881, mean_absolute_error: 2.538708, mean_q: 3.337753
741 (array([22]),) False
  69080/500000: episode: 1727, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 22.975 [12.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.128830, mean_absolute_error: 2.553812, mean_q: 3.368862
521 (array([22]),) False
  69120/500000: episode: 1728, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.075 [2.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.139577, mean_absolute_error: 2.550129, mean_q: 3.355219
794 (array([22]),) False
  69160/500000: episode: 1729, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.875 [3.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.123729, mean_absolute_error: 2.537452, mean_q: 3.343684
543 (array([12]),) False
  69200/500000: episode: 1730, duration: 32.135s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 19.375 [4.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.132974, mean_absolute_error: 2.554232, mean_q: 3.367202
14 (array([48]),) False
  69240/500000: episode: 1731, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 31.425 [0.000, 48.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.124351, mean_absolute_error: 2.530777, mean_q: 3.339125
598 (array([22]),) False
  69280/500000: episode: 1732, duration: 32.169s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.475 [7.000, 54.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.121834, mean_absolute_error: 2.535721, mean_q: 3.343859
395 (array([22]),) False
  69320/500000: episode: 1733, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.900 [0.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.138149, mean_absolute_error: 2.534964, mean_q: 3.342113
314 (array([22]),) False
  69360/500000: episode: 1734, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 38.800 [2.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.128580, mean_absolute_error: 2.524923, mean_q: 3.330461
773 (array([22]),) False
  69400/500000: episode: 1735, duration: 32.994s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.650 [0.000, 47.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.130381, mean_absolute_error: 2.537095, mean_q: 3.342374
756 (array([48]),) False
  69440/500000: episode: 1736, duration: 32.983s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 44.000 [13.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.148593, mean_absolute_error: 2.559011, mean_q: 3.374420
666 (array([22]),) False
  69480/500000: episode: 1737, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.150 [5.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.128610, mean_absolute_error: 2.538307, mean_q: 3.340718
729 (array([22]),) False
  69520/500000: episode: 1738, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 23.275 [7.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.130886, mean_absolute_error: 2.534613, mean_q: 3.330873
687 (array([44]),) False
  69560/500000: episode: 1739, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.900 [1.000, 55.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.128376, mean_absolute_error: 2.549825, mean_q: 3.347831
291 (array([22]),) False
  69600/500000: episode: 1740, duration: 32.106s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.425 [1.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.124493, mean_absolute_error: 2.550847, mean_q: 3.366827
62 (array([22]),) False
  69640/500000: episode: 1741, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.075 [9.000, 60.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.129988, mean_absolute_error: 2.551256, mean_q: 3.354931
166 (array([22]),) False
  69680/500000: episode: 1742, duration: 32.137s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.550 [0.000, 41.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.132135, mean_absolute_error: 2.560539, mean_q: 3.366022
410 (array([22]),) False
  69720/500000: episode: 1743, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.300 [4.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.143526, mean_absolute_error: 2.529430, mean_q: 3.338036
20 (array([22]),) False
  69760/500000: episode: 1744, duration: 32.183s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.025 [11.000, 29.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.125682, mean_absolute_error: 2.535247, mean_q: 3.344905
361 (array([22]),) False
  69800/500000: episode: 1745, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 21.500 [1.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.135566, mean_absolute_error: 2.529421, mean_q: 3.323523
845 (array([22]),) False
  69840/500000: episode: 1746, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.150 [2.000, 47.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.128766, mean_absolute_error: 2.529282, mean_q: 3.327497
806 (array([22]),) False
  69880/500000: episode: 1747, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.425 [4.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.134250, mean_absolute_error: 2.496251, mean_q: 3.298477
175 (array([22]),) False
  69920/500000: episode: 1748, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.800 [1.000, 55.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.123049, mean_absolute_error: 2.559021, mean_q: 3.358762
313 (array([22]),) False
  69960/500000: episode: 1749, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.000 [3.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.134492, mean_absolute_error: 2.534380, mean_q: 3.334224
820 (array([48]),) False
  70000/500000: episode: 1750, duration: 32.951s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.475 [5.000, 53.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.132500, mean_absolute_error: 2.546791, mean_q: 3.349056
72 (array([12]),) False
  70040/500000: episode: 1751, duration: 32.984s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 18.625 [12.000, 59.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.132586, mean_absolute_error: 2.497706, mean_q: 3.299201
266 (array([12]),) False
  70080/500000: episode: 1752, duration: 32.135s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.775 [0.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.137882, mean_absolute_error: 2.517118, mean_q: 3.316722
147 (array([44]),) False
  70120/500000: episode: 1753, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 24.425 [0.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.140690, mean_absolute_error: 2.485542, mean_q: 3.284911
211 (array([22]),) False
  70160/500000: episode: 1754, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.525 [9.000, 52.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.128293, mean_absolute_error: 2.497494, mean_q: 3.296142
679 (array([44]),) False
  70200/500000: episode: 1755, duration: 32.839s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.325 [3.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.126805, mean_absolute_error: 2.513446, mean_q: 3.318906
128 (array([22]),) False
  70240/500000: episode: 1756, duration: 32.112s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.225 [3.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.133580, mean_absolute_error: 2.541874, mean_q: 3.344161
34 (array([22]),) False
  70280/500000: episode: 1757, duration: 32.641s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.375 [2.000, 59.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.132653, mean_absolute_error: 2.509887, mean_q: 3.305581
641 (array([22]),) False
  70320/500000: episode: 1758, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.300 [1.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.126170, mean_absolute_error: 2.501065, mean_q: 3.303892
626 (array([22]),) False
  70360/500000: episode: 1759, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.275 [1.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.127701, mean_absolute_error: 2.545457, mean_q: 3.359533
711 (array([22]),) False
  70400/500000: episode: 1760, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.025 [9.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.124431, mean_absolute_error: 2.542412, mean_q: 3.358050
752 (array([3]),) False
  70440/500000: episode: 1761, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 25.600 [0.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.138207, mean_absolute_error: 2.538874, mean_q: 3.364152
784 (array([22]),) False
  70480/500000: episode: 1762, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.275 [1.000, 52.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.127053, mean_absolute_error: 2.502032, mean_q: 3.318079
760 (array([22]),) False
  70520/500000: episode: 1763, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 30.425 [7.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.128421, mean_absolute_error: 2.499845, mean_q: 3.301446
390 (array([22]),) False
  70560/500000: episode: 1764, duration: 29.977s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 26.950 [1.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.122028, mean_absolute_error: 2.516241, mean_q: 3.333686
624 (array([48]),) False
  70600/500000: episode: 1765, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 37.650 [2.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.132555, mean_absolute_error: 2.480952, mean_q: 3.286933
148 (array([22]),) False
  70640/500000: episode: 1766, duration: 30.070s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.400 [6.000, 55.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.129102, mean_absolute_error: 2.478415, mean_q: 3.272589
88 (array([22]),) False
  70680/500000: episode: 1767, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.875 [0.000, 44.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.118688, mean_absolute_error: 2.474486, mean_q: 3.282090
564 (array([22]),) False
  70720/500000: episode: 1768, duration: 30.031s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.675 [3.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.127597, mean_absolute_error: 2.484499, mean_q: 3.288520
627 (array([48]),) False
  70760/500000: episode: 1769, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 43.350 [7.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.127069, mean_absolute_error: 2.482410, mean_q: 3.293760
826 (array([22]),) False
  70800/500000: episode: 1770, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.900 [5.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.135231, mean_absolute_error: 2.490229, mean_q: 3.290495
443 (array([22]),) False
  70840/500000: episode: 1771, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.625 [0.000, 38.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.127806, mean_absolute_error: 2.448119, mean_q: 3.244933
116 (array([22]),) False
  70880/500000: episode: 1772, duration: 30.821s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 13.475 [3.000, 41.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.142252, mean_absolute_error: 2.454881, mean_q: 3.245406
420 (array([22]),) False
  70920/500000: episode: 1773, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 33.975 [3.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.123109, mean_absolute_error: 2.467096, mean_q: 3.275287
144 (array([22]),) False
  70960/500000: episode: 1774, duration: 30.871s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.725 [12.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.126182, mean_absolute_error: 2.451323, mean_q: 3.251474
836 (array([22]),) False
  71000/500000: episode: 1775, duration: 30.935s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.700 [17.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.130538, mean_absolute_error: 2.494303, mean_q: 3.304829
503 (array([3]),) False
  71040/500000: episode: 1776, duration: 30.013s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 13.825 [2.000, 59.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.125249, mean_absolute_error: 2.511393, mean_q: 3.318210
340 (array([12]),) False
  71080/500000: episode: 1777, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 23.975 [10.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.126234, mean_absolute_error: 2.489348, mean_q: 3.299174
38 (array([22]),) False
  71120/500000: episode: 1778, duration: 30.053s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.550 [3.000, 60.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.120200, mean_absolute_error: 2.512666, mean_q: 3.317162
633 (array([22]),) False
  71160/500000: episode: 1779, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.425 [1.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.133690, mean_absolute_error: 2.489960, mean_q: 3.295447
246 (array([22]),) False
  71200/500000: episode: 1780, duration: 30.001s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.050 [2.000, 60.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.118744, mean_absolute_error: 2.492400, mean_q: 3.301833
468 (array([22]),) False
  71240/500000: episode: 1781, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.950 [12.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.133420, mean_absolute_error: 2.501227, mean_q: 3.311333
143 (array([12]),) False
  71280/500000: episode: 1782, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 21.725 [9.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.129282, mean_absolute_error: 2.511875, mean_q: 3.326208
576 (array([58]),) False
  71320/500000: episode: 1783, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 48.300 [1.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.121867, mean_absolute_error: 2.527568, mean_q: 3.341827
15 (array([22]),) False
  71360/500000: episode: 1784, duration: 30.806s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.875 [3.000, 55.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.131915, mean_absolute_error: 2.528754, mean_q: 3.333306
773 (array([22]),) False
  71400/500000: episode: 1785, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.475 [4.000, 44.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.141746, mean_absolute_error: 2.556640, mean_q: 3.366222
251 (array([3]),) False
  71440/500000: episode: 1786, duration: 30.845s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 9.425 [3.000, 52.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.129511, mean_absolute_error: 2.553928, mean_q: 3.354261
680 (array([22]),) False
  71480/500000: episode: 1787, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.575 [22.000, 60.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.118074, mean_absolute_error: 2.540734, mean_q: 3.357994
635 (array([22]),) False
  71520/500000: episode: 1788, duration: 30.012s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.425 [1.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.128490, mean_absolute_error: 2.536379, mean_q: 3.353685
685 (array([22]),) False
  71560/500000: episode: 1789, duration: 30.872s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 39.075 [0.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.134779, mean_absolute_error: 2.537138, mean_q: 3.358578
128 (array([22]),) False
  71600/500000: episode: 1790, duration: 30.074s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.925 [13.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.118545, mean_absolute_error: 2.520792, mean_q: 3.334099
291 (array([22]),) False
  71640/500000: episode: 1791, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.900 [0.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.129834, mean_absolute_error: 2.534619, mean_q: 3.359303
154 (array([44]),) False
  71680/500000: episode: 1792, duration: 30.064s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 20.775 [1.000, 45.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.132380, mean_absolute_error: 2.525415, mean_q: 3.343538
576 (array([58]),) False
  71720/500000: episode: 1793, duration: 30.842s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 49.575 [1.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.133336, mean_absolute_error: 2.553962, mean_q: 3.368481
330 (array([38]),) False
  71760/500000: episode: 1794, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 16.350 [12.000, 56.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.129411, mean_absolute_error: 2.525175, mean_q: 3.327152
823 (array([58]),) False
  71800/500000: episode: 1795, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 50.950 [3.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.127288, mean_absolute_error: 2.538394, mean_q: 3.354590
862 (array([14]),) False
  71840/500000: episode: 1796, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.075 [0.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.137938, mean_absolute_error: 2.537645, mean_q: 3.337604
810 (array([12]),) False
  71880/500000: episode: 1797, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.175 [5.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.141023, mean_absolute_error: 2.506886, mean_q: 3.308430
809 (array([48]),) False
  71920/500000: episode: 1798, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 34.500 [6.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.134173, mean_absolute_error: 2.504099, mean_q: 3.309055
641 (array([22]),) False
  71960/500000: episode: 1799, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.025 [7.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.126046, mean_absolute_error: 2.506935, mean_q: 3.313555
604 (array([40]),) False
  72000/500000: episode: 1800, duration: 30.052s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 32.875 [5.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.129207, mean_absolute_error: 2.528832, mean_q: 3.338114
194 (array([44]),) False
  72040/500000: episode: 1801, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 39.250 [0.000, 60.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.130712, mean_absolute_error: 2.519846, mean_q: 3.329432
536 (array([22]),) False
  72080/500000: episode: 1802, duration: 30.074s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.375 [0.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.128686, mean_absolute_error: 2.542457, mean_q: 3.359138
675 (array([22]),) False
  72120/500000: episode: 1803, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 20.975 [1.000, 43.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.135790, mean_absolute_error: 2.508616, mean_q: 3.304136
611 (array([22]),) False
  72160/500000: episode: 1804, duration: 30.045s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 33.750 [0.000, 56.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.133495, mean_absolute_error: 2.545841, mean_q: 3.355372
51 (array([22]),) False
  72200/500000: episode: 1805, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.150 [9.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.135933, mean_absolute_error: 2.536034, mean_q: 3.355080
173 (array([3]),) False
  72240/500000: episode: 1806, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 6.925 [3.000, 58.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.133658, mean_absolute_error: 2.498055, mean_q: 3.311324
243 (array([12]),) False
  72280/500000: episode: 1807, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.650 [4.000, 57.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.128181, mean_absolute_error: 2.511038, mean_q: 3.311558
0 (array([48]),) False
  72320/500000: episode: 1808, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.750 [18.000, 50.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.125007, mean_absolute_error: 2.553563, mean_q: 3.360626
308 (array([22]),) False
  72360/500000: episode: 1809, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 29.800 [12.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.128078, mean_absolute_error: 2.565862, mean_q: 3.373588
786 (array([22]),) False
  72400/500000: episode: 1810, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.650 [20.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.126108, mean_absolute_error: 2.530633, mean_q: 3.336563
714 (array([22]),) False
  72440/500000: episode: 1811, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.325 [0.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.126358, mean_absolute_error: 2.520169, mean_q: 3.337060
658 (array([48]),) False
  72480/500000: episode: 1812, duration: 30.043s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.925 [4.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.132567, mean_absolute_error: 2.511322, mean_q: 3.310507
804 (array([3]),) False
  72520/500000: episode: 1813, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 11.175 [1.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.131272, mean_absolute_error: 2.550033, mean_q: 3.364135
124 (array([48]),) False
  72560/500000: episode: 1814, duration: 30.019s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.200 [2.000, 50.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.126536, mean_absolute_error: 2.501451, mean_q: 3.310062
345 (array([22]),) False
  72600/500000: episode: 1815, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.075 [4.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.136951, mean_absolute_error: 2.521280, mean_q: 3.323471
504 (array([48]),) False
  72640/500000: episode: 1816, duration: 29.992s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 42.875 [0.000, 56.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.125432, mean_absolute_error: 2.501296, mean_q: 3.310355
325 (array([22]),) False
  72680/500000: episode: 1817, duration: 30.780s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 26.575 [22.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.139194, mean_absolute_error: 2.474027, mean_q: 3.270891
760 (array([22]),) False
  72720/500000: episode: 1818, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 37.225 [6.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.146370, mean_absolute_error: 2.503376, mean_q: 3.320875
663 (array([22]),) False
  72760/500000: episode: 1819, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.225 [0.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.135882, mean_absolute_error: 2.506401, mean_q: 3.325978
347 (array([22]),) False
  72800/500000: episode: 1820, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 15.625 [3.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.136972, mean_absolute_error: 2.523921, mean_q: 3.342308
90 (array([22]),) False
  72840/500000: episode: 1821, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.775 [10.000, 54.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.137332, mean_absolute_error: 2.505147, mean_q: 3.312009
490 (array([12]),) False
  72880/500000: episode: 1822, duration: 30.897s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 20.875 [10.000, 58.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.135239, mean_absolute_error: 2.504791, mean_q: 3.321689
523 (array([22]),) False
  72920/500000: episode: 1823, duration: 30.828s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.050 [0.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.125723, mean_absolute_error: 2.478750, mean_q: 3.270723
340 (array([12]),) False
  72960/500000: episode: 1824, duration: 30.021s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.775 [12.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.131662, mean_absolute_error: 2.474852, mean_q: 3.278507
395 (array([22]),) False
  73000/500000: episode: 1825, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.075 [7.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.136184, mean_absolute_error: 2.485948, mean_q: 3.274931
522 (array([22]),) False
  73040/500000: episode: 1826, duration: 30.038s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.850 [0.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.126200, mean_absolute_error: 2.472621, mean_q: 3.274916
798 (array([18]),) False
  73080/500000: episode: 1827, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.950 [1.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.120270, mean_absolute_error: 2.459817, mean_q: 3.268569
307 (array([22]),) False
  73120/500000: episode: 1828, duration: 30.068s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.150 [5.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.122605, mean_absolute_error: 2.466025, mean_q: 3.268788
236 (array([22]),) False
  73160/500000: episode: 1829, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.050 [1.000, 53.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.119106, mean_absolute_error: 2.475106, mean_q: 3.279647
812 (array([22]),) False
  73200/500000: episode: 1830, duration: 30.860s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 27.900 [12.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.128475, mean_absolute_error: 2.473161, mean_q: 3.277107
653 (array([48]),) False
  73240/500000: episode: 1831, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 46.450 [0.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.126327, mean_absolute_error: 2.466539, mean_q: 3.266202
187 (array([15]),) False
  73280/500000: episode: 1832, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.450 [4.000, 52.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.139730, mean_absolute_error: 2.459131, mean_q: 3.252637
532 (array([25]),) False
  73320/500000: episode: 1833, duration: 30.829s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.750 [3.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.118895, mean_absolute_error: 2.481938, mean_q: 3.293540
554 (array([22]),) False
  73360/500000: episode: 1834, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 19.675 [4.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.126877, mean_absolute_error: 2.462233, mean_q: 3.273688
802 (array([22]),) False
  73400/500000: episode: 1835, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.325 [5.000, 50.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.130735, mean_absolute_error: 2.455353, mean_q: 3.264037
28 (array([58]),) False
  73440/500000: episode: 1836, duration: 30.034s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 19.225 [3.000, 51.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.124855, mean_absolute_error: 2.460741, mean_q: 3.268773
326 (array([48]),) False
  73480/500000: episode: 1837, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 33.250 [3.000, 54.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.129390, mean_absolute_error: 2.457616, mean_q: 3.265816
560 (array([22]),) False
  73520/500000: episode: 1838, duration: 30.101s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.025 [1.000, 45.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.128989, mean_absolute_error: 2.481705, mean_q: 3.284335
554 (array([22]),) False
  73560/500000: episode: 1839, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.050 [2.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.127664, mean_absolute_error: 2.461096, mean_q: 3.269861
138 (array([3]),) False
  73600/500000: episode: 1840, duration: 30.036s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 9.925 [3.000, 53.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.121843, mean_absolute_error: 2.438616, mean_q: 3.245891
68 (array([22]),) False
  73640/500000: episode: 1841, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.650 [7.000, 55.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.128162, mean_absolute_error: 2.409967, mean_q: 3.212521
742 (array([33]),) False
  73680/500000: episode: 1842, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 18.950 [0.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.120399, mean_absolute_error: 2.446327, mean_q: 3.265024
12 (array([22]),) False
  73720/500000: episode: 1843, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.050 [10.000, 59.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.127828, mean_absolute_error: 2.445223, mean_q: 3.255439
572 (array([58]),) False
  73760/500000: episode: 1844, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 50.175 [0.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.136637, mean_absolute_error: 2.439494, mean_q: 3.243393
466 (array([22]),) False
  73800/500000: episode: 1845, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 29.050 [22.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.135306, mean_absolute_error: 2.424989, mean_q: 3.217313
434 (array([22]),) False
  73840/500000: episode: 1846, duration: 30.815s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.975 [5.000, 60.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.132739, mean_absolute_error: 2.428947, mean_q: 3.223016
220 (array([22]),) False
  73880/500000: episode: 1847, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.300 [15.000, 58.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.130448, mean_absolute_error: 2.422893, mean_q: 3.211049
108 (array([48]),) False
  73920/500000: episode: 1848, duration: 30.033s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.975 [2.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.134194, mean_absolute_error: 2.449570, mean_q: 3.244743
682 (array([22]),) False
  73960/500000: episode: 1849, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.900 [8.000, 59.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.135415, mean_absolute_error: 2.440995, mean_q: 3.236233
385 (array([30]),) False
  74000/500000: episode: 1850, duration: 30.112s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.925 [1.000, 54.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.128612, mean_absolute_error: 2.429550, mean_q: 3.239360
639 (array([22]),) False
  74040/500000: episode: 1851, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.325 [14.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.137211, mean_absolute_error: 2.439323, mean_q: 3.252095
834 (array([44]),) False
  74080/500000: episode: 1852, duration: 29.999s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 29.450 [8.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.117165, mean_absolute_error: 2.446940, mean_q: 3.268761
319 (array([33]),) False
  74120/500000: episode: 1853, duration: 30.837s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.325 [0.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.134492, mean_absolute_error: 2.455115, mean_q: 3.266210
315 (array([12]),) False
  74160/500000: episode: 1854, duration: 30.878s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 23.250 [0.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.123433, mean_absolute_error: 2.442975, mean_q: 3.256147
487 (array([48]),) False
  74200/500000: episode: 1855, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 27.250 [2.000, 48.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.123881, mean_absolute_error: 2.473727, mean_q: 3.286653
492 (array([22]),) False
  74240/500000: episode: 1856, duration: 30.847s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.275 [10.000, 57.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.128835, mean_absolute_error: 2.470396, mean_q: 3.268089
629 (array([22]),) False
  74280/500000: episode: 1857, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 39.050 [2.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.126697, mean_absolute_error: 2.447106, mean_q: 3.249454
19 (array([12]),) False
  74320/500000: episode: 1858, duration: 30.860s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.075 [0.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.130858, mean_absolute_error: 2.458813, mean_q: 3.264920
124 (array([48]),) False
  74360/500000: episode: 1859, duration: 30.859s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 40.400 [1.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.118320, mean_absolute_error: 2.473799, mean_q: 3.275418
685 (array([22]),) False
  74400/500000: episode: 1860, duration: 30.077s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 29.350 [21.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.123715, mean_absolute_error: 2.489502, mean_q: 3.293027
193 (array([36]),) False
  74440/500000: episode: 1861, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 40.225 [2.000, 60.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.124560, mean_absolute_error: 2.495080, mean_q: 3.299319
546 (array([22]),) False
  74480/500000: episode: 1862, duration: 30.066s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.000 [11.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.136003, mean_absolute_error: 2.486252, mean_q: 3.294955
571 (array([48]),) False
  74520/500000: episode: 1863, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 32.175 [4.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.132406, mean_absolute_error: 2.473483, mean_q: 3.280139
795 (array([3]),) False
  74560/500000: episode: 1864, duration: 30.034s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 7.700 [2.000, 60.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.131397, mean_absolute_error: 2.481151, mean_q: 3.289904
149 (array([8]),) False
  74600/500000: episode: 1865, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 9.775 [3.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.137798, mean_absolute_error: 2.494925, mean_q: 3.312939
446 (array([22]),) False
  74640/500000: episode: 1866, duration: 30.872s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.075 [2.000, 54.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.124584, mean_absolute_error: 2.488522, mean_q: 3.307710
12 (array([22]),) False
  74680/500000: episode: 1867, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.100 [2.000, 58.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.122554, mean_absolute_error: 2.491673, mean_q: 3.303389
471 (array([12]),) False
  74720/500000: episode: 1868, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 25.375 [11.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.129169, mean_absolute_error: 2.495220, mean_q: 3.298005
433 (array([22]),) False
  74760/500000: episode: 1869, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.675 [6.000, 54.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.126581, mean_absolute_error: 2.491908, mean_q: 3.294039
495 (array([48]),) False
  74800/500000: episode: 1870, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 44.675 [8.000, 58.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.133001, mean_absolute_error: 2.494357, mean_q: 3.299192
302 (array([22]),) False
  74840/500000: episode: 1871, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.850 [3.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.127248, mean_absolute_error: 2.485440, mean_q: 3.290308
205 (array([22]),) False
  74880/500000: episode: 1872, duration: 30.062s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 26.150 [22.000, 60.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.126336, mean_absolute_error: 2.492102, mean_q: 3.302476
137 (array([22]),) False
  74920/500000: episode: 1873, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 28.575 [7.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.128165, mean_absolute_error: 2.442765, mean_q: 3.246609
112 (array([12]),) False
  74960/500000: episode: 1874, duration: 30.066s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 13.800 [3.000, 56.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.127330, mean_absolute_error: 2.468574, mean_q: 3.277738
641 (array([22]),) False
  75000/500000: episode: 1875, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.600 [3.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.130942, mean_absolute_error: 2.477691, mean_q: 3.297730
421 (array([22]),) False
  75040/500000: episode: 1876, duration: 30.100s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 31.050 [2.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.124744, mean_absolute_error: 2.481122, mean_q: 3.298264
564 (array([22]),) False
  75080/500000: episode: 1877, duration: 30.953s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.750 [8.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.125379, mean_absolute_error: 2.464062, mean_q: 3.265180
246 (array([22]),) False
  75120/500000: episode: 1878, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.925 [3.000, 52.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.121239, mean_absolute_error: 2.469314, mean_q: 3.284740
580 (array([22]),) False
  75160/500000: episode: 1879, duration: 30.953s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.400 [5.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.126459, mean_absolute_error: 2.491087, mean_q: 3.312112
667 (array([48]),) False
  75200/500000: episode: 1880, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 43.625 [2.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.134927, mean_absolute_error: 2.452229, mean_q: 3.246768
179 (array([18]),) False
  75240/500000: episode: 1881, duration: 30.860s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 23.225 [0.000, 48.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.133525, mean_absolute_error: 2.458134, mean_q: 3.256510
103 (array([22]),) False
  75280/500000: episode: 1882, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 21.950 [3.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.128381, mean_absolute_error: 2.422180, mean_q: 3.219418
595 (array([22]),) False
  75320/500000: episode: 1883, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.950 [4.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.128065, mean_absolute_error: 2.452226, mean_q: 3.261491
720 (array([22]),) False
  75360/500000: episode: 1884, duration: 30.049s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.475 [4.000, 55.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.129435, mean_absolute_error: 2.477079, mean_q: 3.296348
824 (array([22]),) False
  75400/500000: episode: 1885, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.450 [9.000, 38.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.130720, mean_absolute_error: 2.450222, mean_q: 3.259757
441 (array([22]),) False
  75440/500000: episode: 1886, duration: 30.037s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.550 [6.000, 56.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.122519, mean_absolute_error: 2.459815, mean_q: 3.271190
458 (array([22]),) False
  75480/500000: episode: 1887, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.875 [19.000, 50.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.120808, mean_absolute_error: 2.451751, mean_q: 3.267609
427 (array([22]),) False
  75520/500000: episode: 1888, duration: 29.993s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 23.625 [5.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.120405, mean_absolute_error: 2.443452, mean_q: 3.256473
564 (array([22]),) False
  75560/500000: episode: 1889, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.375 [17.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.129649, mean_absolute_error: 2.452950, mean_q: 3.266870
181 (array([22]),) False
  75600/500000: episode: 1890, duration: 30.867s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.175 [0.000, 57.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.128542, mean_absolute_error: 2.460457, mean_q: 3.273705
395 (array([22]),) False
  75640/500000: episode: 1891, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.000 [3.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.118327, mean_absolute_error: 2.463322, mean_q: 3.277798
250 (array([22]),) False
  75680/500000: episode: 1892, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 30.525 [3.000, 48.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.130363, mean_absolute_error: 2.459537, mean_q: 3.270794
837 (array([48]),) False
  75720/500000: episode: 1893, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 41.875 [1.000, 54.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.128803, mean_absolute_error: 2.436607, mean_q: 3.239104
756 (array([48]),) False
  75760/500000: episode: 1894, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.025 [3.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.128708, mean_absolute_error: 2.476935, mean_q: 3.293133
763 (array([48]),) False
  75800/500000: episode: 1895, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 43.825 [5.000, 49.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.130768, mean_absolute_error: 2.440442, mean_q: 3.247291
688 (array([22]),) False
  75840/500000: episode: 1896, duration: 30.044s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 20.350 [2.000, 42.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.124266, mean_absolute_error: 2.423629, mean_q: 3.231620
116 (array([22]),) False
  75880/500000: episode: 1897, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.500 [3.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.127950, mean_absolute_error: 2.439778, mean_q: 3.248746
782 (array([22]),) False
  75920/500000: episode: 1898, duration: 30.037s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 36.625 [2.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.117791, mean_absolute_error: 2.437031, mean_q: 3.246285
428 (array([22]),) False
  75960/500000: episode: 1899, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.425 [8.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.127529, mean_absolute_error: 2.441993, mean_q: 3.257852
155 (array([22]),) False
  76000/500000: episode: 1900, duration: 30.071s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.300 [5.000, 55.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.120222, mean_absolute_error: 2.465580, mean_q: 3.275976
748 (array([22]),) False
  76040/500000: episode: 1901, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.900 [10.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.129645, mean_absolute_error: 2.403914, mean_q: 3.204152
293 (array([22]),) False
  76080/500000: episode: 1902, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.325 [1.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.126919, mean_absolute_error: 2.448321, mean_q: 3.263100
663 (array([22]),) False
  76120/500000: episode: 1903, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.800 [3.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.127726, mean_absolute_error: 2.430719, mean_q: 3.238595
569 (array([22]),) False
  76160/500000: episode: 1904, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.500 [8.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.130093, mean_absolute_error: 2.460779, mean_q: 3.266501
808 (array([22]),) False
  76200/500000: episode: 1905, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.200 [5.000, 46.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.128228, mean_absolute_error: 2.421912, mean_q: 3.222580
790 (array([48]),) False
  76240/500000: episode: 1906, duration: 30.867s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 42.925 [7.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.133933, mean_absolute_error: 2.436758, mean_q: 3.243541
189 (array([12]),) False
  76280/500000: episode: 1907, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 16.575 [0.000, 55.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.128879, mean_absolute_error: 2.430498, mean_q: 3.242495
138 (array([3]),) False
  76320/500000: episode: 1908, duration: 30.069s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 9.325 [1.000, 45.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.122804, mean_absolute_error: 2.457675, mean_q: 3.272060
532 (array([25]),) False
  76360/500000: episode: 1909, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.000 [4.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.132405, mean_absolute_error: 2.459442, mean_q: 3.278085
406 (array([48]),) False
  76400/500000: episode: 1910, duration: 30.057s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 31.575 [4.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.124833, mean_absolute_error: 2.461398, mean_q: 3.284554
218 (array([22]),) False
  76440/500000: episode: 1911, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.600 [5.000, 54.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.136558, mean_absolute_error: 2.440782, mean_q: 3.254890
184 (array([12]),) False
  76480/500000: episode: 1912, duration: 30.049s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 25.625 [1.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.126382, mean_absolute_error: 2.447703, mean_q: 3.260796
348 (array([22]),) False
  76520/500000: episode: 1913, duration: 30.883s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 34.675 [12.000, 52.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.119959, mean_absolute_error: 2.449324, mean_q: 3.263442
485 (array([22]),) False
  76560/500000: episode: 1914, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.900 [1.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.129823, mean_absolute_error: 2.463743, mean_q: 3.281438
269 (array([36]),) False
  76600/500000: episode: 1915, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 33.575 [3.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.126894, mean_absolute_error: 2.461454, mean_q: 3.280889
296 (array([22]),) False
  76640/500000: episode: 1916, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.825 [1.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.129727, mean_absolute_error: 2.465613, mean_q: 3.286752
713 (array([37]),) False
  76680/500000: episode: 1917, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 25.750 [12.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.135372, mean_absolute_error: 2.446658, mean_q: 3.253612
653 (array([48]),) False
  76720/500000: episode: 1918, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 44.550 [2.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.132847, mean_absolute_error: 2.434922, mean_q: 3.236030
611 (array([22]),) False
  76760/500000: episode: 1919, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 33.525 [5.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.128467, mean_absolute_error: 2.472590, mean_q: 3.285942
755 (array([22]),) False
  76800/500000: episode: 1920, duration: 30.016s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.000 [0.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.119017, mean_absolute_error: 2.450966, mean_q: 3.258364
563 (array([22]),) False
  76840/500000: episode: 1921, duration: 30.826s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.325 [3.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.126006, mean_absolute_error: 2.463325, mean_q: 3.264708
324 (array([12]),) False
  76880/500000: episode: 1922, duration: 29.982s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 20.225 [9.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.125981, mean_absolute_error: 2.476207, mean_q: 3.288348
764 (array([48]),) False
  76920/500000: episode: 1923, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 40.425 [11.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.135060, mean_absolute_error: 2.449100, mean_q: 3.252543
198 (array([22]),) False
  76960/500000: episode: 1924, duration: 30.054s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 21.900 [0.000, 51.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.125775, mean_absolute_error: 2.463452, mean_q: 3.281277
655 (array([22]),) False
  77000/500000: episode: 1925, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.250 [1.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.123984, mean_absolute_error: 2.449635, mean_q: 3.265481
495 (array([48]),) False
  77040/500000: episode: 1926, duration: 30.862s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 42.875 [1.000, 48.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.126098, mean_absolute_error: 2.466078, mean_q: 3.284228
845 (array([22]),) False
  77080/500000: episode: 1927, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.700 [7.000, 51.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.122350, mean_absolute_error: 2.458529, mean_q: 3.269393
472 (array([22]),) False
  77120/500000: episode: 1928, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.350 [14.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.125103, mean_absolute_error: 2.465333, mean_q: 3.277340
156 (array([22]),) False
  77160/500000: episode: 1929, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 27.075 [17.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.130574, mean_absolute_error: 2.458723, mean_q: 3.262969
757 (array([48]),) False
  77200/500000: episode: 1930, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 44.275 [3.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.123628, mean_absolute_error: 2.420808, mean_q: 3.235258
815 (array([22]),) False
  77240/500000: episode: 1931, duration: 30.925s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.950 [0.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.119916, mean_absolute_error: 2.444776, mean_q: 3.256028
462 (array([12]),) False
  77280/500000: episode: 1932, duration: 29.937s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.700 [2.000, 53.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.122003, mean_absolute_error: 2.444469, mean_q: 3.257758
725 (array([36]),) False
  77320/500000: episode: 1933, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 38.300 [12.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.129652, mean_absolute_error: 2.428784, mean_q: 3.243434
630 (array([22]),) False
  77360/500000: episode: 1934, duration: 30.139s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.575 [4.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.128830, mean_absolute_error: 2.453427, mean_q: 3.276849
215 (array([22]),) False
  77400/500000: episode: 1935, duration: 30.962s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.100 [14.000, 56.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.129357, mean_absolute_error: 2.447002, mean_q: 3.258703
210 (array([58]),) False
  77440/500000: episode: 1936, duration: 30.041s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 51.725 [3.000, 58.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.131156, mean_absolute_error: 2.487328, mean_q: 3.303347
318 (array([48]),) False
  77480/500000: episode: 1937, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 40.575 [5.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.131733, mean_absolute_error: 2.453551, mean_q: 3.274097
84 (array([22]),) False
  77520/500000: episode: 1938, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.275 [13.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.127802, mean_absolute_error: 2.441190, mean_q: 3.266514
535 (array([22]),) False
  77560/500000: episode: 1939, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.825 [1.000, 47.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.129944, mean_absolute_error: 2.466097, mean_q: 3.290300
802 (array([22]),) False
  77600/500000: episode: 1940, duration: 30.881s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.475 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.130406, mean_absolute_error: 2.460478, mean_q: 3.279400
576 (array([58]),) False
  77640/500000: episode: 1941, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 51.500 [18.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.138580, mean_absolute_error: 2.480032, mean_q: 3.307151
501 (array([12]),) False
  77680/500000: episode: 1942, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.925 [1.000, 57.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.129261, mean_absolute_error: 2.456222, mean_q: 3.272322
361 (array([22]),) False
  77720/500000: episode: 1943, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 26.350 [2.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.130711, mean_absolute_error: 2.484161, mean_q: 3.301350
267 (array([22]),) False
  77760/500000: episode: 1944, duration: 30.060s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.550 [8.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.137299, mean_absolute_error: 2.494939, mean_q: 3.321604
152 (array([58]),) False
  77800/500000: episode: 1945, duration: 30.847s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 52.150 [1.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.135040, mean_absolute_error: 2.472714, mean_q: 3.294774
676 (array([40]),) False
  77840/500000: episode: 1946, duration: 30.060s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 21.800 [1.000, 53.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.139262, mean_absolute_error: 2.492321, mean_q: 3.316932
347 (array([22]),) False
  77880/500000: episode: 1947, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 29.500 [15.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.144033, mean_absolute_error: 2.492934, mean_q: 3.313266
767 (array([48]),) False
  77920/500000: episode: 1948, duration: 30.081s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 42.625 [10.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.130810, mean_absolute_error: 2.503295, mean_q: 3.321230
443 (array([22]),) False
  77960/500000: episode: 1949, duration: 30.973s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.650 [0.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.133945, mean_absolute_error: 2.485979, mean_q: 3.306127
385 (array([30]),) False
  78000/500000: episode: 1950, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.275 [7.000, 56.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.130623, mean_absolute_error: 2.507591, mean_q: 3.334229
449 (array([22]),) False
  78040/500000: episode: 1951, duration: 30.881s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.325 [1.000, 53.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.134522, mean_absolute_error: 2.522627, mean_q: 3.349003
18 (array([22]),) False
  78080/500000: episode: 1952, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.275 [19.000, 41.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.130524, mean_absolute_error: 2.518853, mean_q: 3.344219
408 (array([12]),) False
  78120/500000: episode: 1953, duration: 30.860s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.775 [0.000, 50.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.137958, mean_absolute_error: 2.523764, mean_q: 3.351508
130 (array([22]),) False
  78160/500000: episode: 1954, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.800 [3.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.131545, mean_absolute_error: 2.549790, mean_q: 3.372316
462 (array([12]),) False
  78200/500000: episode: 1955, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.500 [5.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.136115, mean_absolute_error: 2.519442, mean_q: 3.342863
578 (array([22]),) False
  78240/500000: episode: 1956, duration: 30.044s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.800 [5.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.135241, mean_absolute_error: 2.506814, mean_q: 3.328464
239 (array([22]),) False
  78280/500000: episode: 1957, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.550 [17.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.126910, mean_absolute_error: 2.542417, mean_q: 3.367051
535 (array([22]),) False
  78320/500000: episode: 1958, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.075 [1.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.137680, mean_absolute_error: 2.540816, mean_q: 3.360935
46 (array([22]),) False
  78360/500000: episode: 1959, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.650 [12.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.133859, mean_absolute_error: 2.528861, mean_q: 3.339301
694 (array([22]),) False
  78400/500000: episode: 1960, duration: 30.057s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.575 [12.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.132893, mean_absolute_error: 2.555313, mean_q: 3.378368
263 (array([8]),) False
  78440/500000: episode: 1961, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 26.625 [3.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.136787, mean_absolute_error: 2.517056, mean_q: 3.333384
595 (array([22]),) False
  78480/500000: episode: 1962, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.225 [0.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.132195, mean_absolute_error: 2.531782, mean_q: 3.346952
765 (array([48]),) False
  78520/500000: episode: 1963, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.550 [6.000, 56.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.123651, mean_absolute_error: 2.507982, mean_q: 3.312812
717 (array([22]),) False
  78560/500000: episode: 1964, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.500 [6.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.132401, mean_absolute_error: 2.539287, mean_q: 3.349829
743 (array([48]),) False
  78600/500000: episode: 1965, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 30.425 [3.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.126815, mean_absolute_error: 2.527051, mean_q: 3.345677
446 (array([22]),) False
  78640/500000: episode: 1966, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.325 [4.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.134537, mean_absolute_error: 2.533121, mean_q: 3.350346
244 (array([14]),) False
  78680/500000: episode: 1967, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.575 [14.000, 50.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.135461, mean_absolute_error: 2.509828, mean_q: 3.329530
290 (array([22]),) False
  78720/500000: episode: 1968, duration: 30.030s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.025 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.134210, mean_absolute_error: 2.513807, mean_q: 3.334700
633 (array([22]),) False
  78760/500000: episode: 1969, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.150 [3.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.131890, mean_absolute_error: 2.536266, mean_q: 3.363746
414 (array([48]),) False
  78800/500000: episode: 1970, duration: 30.104s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 37.575 [1.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.131549, mean_absolute_error: 2.508159, mean_q: 3.333461
267 (array([22]),) False
  78840/500000: episode: 1971, duration: 30.839s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.250 [16.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.129208, mean_absolute_error: 2.514520, mean_q: 3.331437
272 (array([12]),) False
  78880/500000: episode: 1972, duration: 30.033s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.275 [9.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.134494, mean_absolute_error: 2.484673, mean_q: 3.301001
512 (array([48]),) False
  78920/500000: episode: 1973, duration: 30.962s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 25.175 [1.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.140334, mean_absolute_error: 2.492471, mean_q: 3.304963
781 (array([8]),) False
  78960/500000: episode: 1974, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.800 [1.000, 50.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.129521, mean_absolute_error: 2.532828, mean_q: 3.357510
187 (array([15]),) False
  79000/500000: episode: 1975, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 18.100 [8.000, 60.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.128494, mean_absolute_error: 2.504988, mean_q: 3.323509
309 (array([22]),) False
  79040/500000: episode: 1976, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.300 [3.000, 38.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.129585, mean_absolute_error: 2.499872, mean_q: 3.316602
449 (array([22]),) False
  79080/500000: episode: 1977, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.900 [2.000, 46.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.142048, mean_absolute_error: 2.509507, mean_q: 3.325484
177 (array([22]),) False
  79120/500000: episode: 1978, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.825 [10.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.129036, mean_absolute_error: 2.509747, mean_q: 3.334457
722 (array([22]),) False
  79160/500000: episode: 1979, duration: 30.871s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.325 [3.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.129492, mean_absolute_error: 2.522220, mean_q: 3.345851
276 (array([56]),) False
  79200/500000: episode: 1980, duration: 30.048s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.150 [0.000, 58.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.138388, mean_absolute_error: 2.534816, mean_q: 3.358443
31 (array([48]),) False
  79240/500000: episode: 1981, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.725 [0.000, 46.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.140632, mean_absolute_error: 2.518497, mean_q: 3.341061
556 (array([48]),) False
  79280/500000: episode: 1982, duration: 30.040s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 23.875 [12.000, 52.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.130552, mean_absolute_error: 2.511919, mean_q: 3.340181
855 (array([12]),) False
  79320/500000: episode: 1983, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 17.400 [3.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.126801, mean_absolute_error: 2.477576, mean_q: 3.295736
817 (array([12]),) False
  79360/500000: episode: 1984, duration: 30.063s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 15.400 [0.000, 56.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.125636, mean_absolute_error: 2.476602, mean_q: 3.293053
75 (array([22]),) False
  79400/500000: episode: 1985, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.525 [0.000, 60.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.125273, mean_absolute_error: 2.441793, mean_q: 3.255167
503 (array([3]),) False
  79440/500000: episode: 1986, duration: 30.854s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 8.475 [3.000, 54.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.124755, mean_absolute_error: 2.459077, mean_q: 3.280628
750 (array([22]),) False
  79480/500000: episode: 1987, duration: 30.862s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 25.275 [22.000, 56.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.131530, mean_absolute_error: 2.442202, mean_q: 3.252322
11 (array([22]),) False
  79520/500000: episode: 1988, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.625 [0.000, 48.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.126450, mean_absolute_error: 2.430429, mean_q: 3.249093
859 (array([22]),) False
  79560/500000: episode: 1989, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.375 [1.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.125540, mean_absolute_error: 2.446590, mean_q: 3.255475
513 (array([12]),) False
  79600/500000: episode: 1990, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 23.650 [10.000, 48.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.128681, mean_absolute_error: 2.453656, mean_q: 3.277602
691 (array([22]),) False
  79640/500000: episode: 1991, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.025 [19.000, 56.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.125073, mean_absolute_error: 2.435676, mean_q: 3.250957
205 (array([22]),) False
  79680/500000: episode: 1992, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.925 [3.000, 56.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.125240, mean_absolute_error: 2.455930, mean_q: 3.272179
400 (array([22]),) False
  79720/500000: episode: 1993, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.675 [1.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.131886, mean_absolute_error: 2.467884, mean_q: 3.291172
247 (array([14]),) False
  79760/500000: episode: 1994, duration: 30.040s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 20.275 [12.000, 40.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.133675, mean_absolute_error: 2.464186, mean_q: 3.274276
799 (array([36]),) False
  79800/500000: episode: 1995, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 39.450 [3.000, 49.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.122890, mean_absolute_error: 2.469731, mean_q: 3.277797
355 (array([22]),) False
  79840/500000: episode: 1996, duration: 30.054s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.700 [11.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.122634, mean_absolute_error: 2.456896, mean_q: 3.272794
567 (array([22]),) False
  79880/500000: episode: 1997, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.375 [0.000, 60.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.123125, mean_absolute_error: 2.454405, mean_q: 3.268181
388 (array([22]),) False
  79920/500000: episode: 1998, duration: 30.801s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 20.700 [0.000, 40.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.123313, mean_absolute_error: 2.440746, mean_q: 3.242153
544 (array([22]),) False
  79960/500000: episode: 1999, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.050 [5.000, 49.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.137428, mean_absolute_error: 2.432618, mean_q: 3.241558
397 (array([22]),) False
  80000/500000: episode: 2000, duration: 30.880s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.525 [2.000, 55.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.125542, mean_absolute_error: 2.405509, mean_q: 3.224196
41 (array([12]),) False
  80040/500000: episode: 2001, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.450 [4.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.132818, mean_absolute_error: 2.408926, mean_q: 3.216798
552 (array([22]),) False
  80080/500000: episode: 2002, duration: 30.086s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.050 [6.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.125878, mean_absolute_error: 2.384858, mean_q: 3.193913
345 (array([22]),) False
  80120/500000: episode: 2003, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.750 [5.000, 49.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.133000, mean_absolute_error: 2.433522, mean_q: 3.261423
182 (array([54]),) False
  80160/500000: episode: 2004, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 30.975 [3.000, 54.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.126837, mean_absolute_error: 2.425417, mean_q: 3.231607
484 (array([22]),) False
  80200/500000: episode: 2005, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.550 [13.000, 50.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.122800, mean_absolute_error: 2.431837, mean_q: 3.237041
642 (array([22]),) False
  80240/500000: episode: 2006, duration: 30.030s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.900 [1.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.135809, mean_absolute_error: 2.461133, mean_q: 3.267853
297 (array([15]),) False
  80280/500000: episode: 2007, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.800 [1.000, 53.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.122094, mean_absolute_error: 2.454946, mean_q: 3.263706
72 (array([12]),) False
  80320/500000: episode: 2008, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 16.975 [5.000, 57.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.127483, mean_absolute_error: 2.424200, mean_q: 3.236991
438 (array([22]),) False
  80360/500000: episode: 2009, duration: 30.842s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.075 [7.000, 55.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.123233, mean_absolute_error: 2.440545, mean_q: 3.251350
849 (array([3]),) False
  80400/500000: episode: 2010, duration: 30.064s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 40.050 [3.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.127487, mean_absolute_error: 2.435011, mean_q: 3.246982
30 (array([22]),) False
  80440/500000: episode: 2011, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.475 [2.000, 50.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.129498, mean_absolute_error: 2.415742, mean_q: 3.219173
203 (array([48]),) False
  80480/500000: episode: 2012, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 42.525 [4.000, 54.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.120029, mean_absolute_error: 2.443872, mean_q: 3.254200
489 (array([22]),) False
  80520/500000: episode: 2013, duration: 30.815s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.175 [4.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.124494, mean_absolute_error: 2.418702, mean_q: 3.229067
101 (array([22]),) False
  80560/500000: episode: 2014, duration: 30.010s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.400 [3.000, 44.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.117974, mean_absolute_error: 2.461334, mean_q: 3.277154
787 (array([3]),) False
  80600/500000: episode: 2015, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 19.950 [3.000, 46.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.130248, mean_absolute_error: 2.430639, mean_q: 3.240699
680 (array([22]),) False
  80640/500000: episode: 2016, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.075 [1.000, 43.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.123581, mean_absolute_error: 2.463297, mean_q: 3.278948
184 (array([12]),) False
  80680/500000: episode: 2017, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 21.950 [11.000, 51.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.125477, mean_absolute_error: 2.434499, mean_q: 3.252113
629 (array([22]),) False
  80720/500000: episode: 2018, duration: 30.085s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 41.300 [7.000, 51.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.117734, mean_absolute_error: 2.412827, mean_q: 3.218607
671 (array([57]),) False
  80760/500000: episode: 2019, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 16.100 [3.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.120881, mean_absolute_error: 2.452219, mean_q: 3.279480
48 (array([12]),) False
  80800/500000: episode: 2020, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 43.250 [0.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.129555, mean_absolute_error: 2.438283, mean_q: 3.246171
353 (array([22]),) False
  80840/500000: episode: 2021, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.900 [0.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.127722, mean_absolute_error: 2.452310, mean_q: 3.271872
191 (array([38]),) False
  80880/500000: episode: 2022, duration: 30.075s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 19.150 [7.000, 54.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.136116, mean_absolute_error: 2.395178, mean_q: 3.207993
458 (array([22]),) False
  80920/500000: episode: 2023, duration: 30.926s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.825 [22.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.117886, mean_absolute_error: 2.419104, mean_q: 3.240020
826 (array([22]),) False
  80960/500000: episode: 2024, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.800 [7.000, 49.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.130858, mean_absolute_error: 2.397142, mean_q: 3.209823
778 (array([12]),) False
  81000/500000: episode: 2025, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 17.975 [6.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.129391, mean_absolute_error: 2.397423, mean_q: 3.201078
6 (array([58]),) False
  81040/500000: episode: 2026, duration: 29.988s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.100 [17.000, 55.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.132029, mean_absolute_error: 2.405046, mean_q: 3.212307
202 (array([22]),) False
  81080/500000: episode: 2027, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.175 [5.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.126797, mean_absolute_error: 2.411653, mean_q: 3.215407
115 (array([22]),) False
  81120/500000: episode: 2028, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.750 [5.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.135208, mean_absolute_error: 2.413939, mean_q: 3.223634
695 (array([22]),) False
  81160/500000: episode: 2029, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 27.850 [9.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.122234, mean_absolute_error: 2.393302, mean_q: 3.201746
199 (array([22]),) False
  81200/500000: episode: 2030, duration: 30.082s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.875 [7.000, 40.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.131346, mean_absolute_error: 2.401288, mean_q: 3.205102
152 (array([58]),) False
  81240/500000: episode: 2031, duration: 30.973s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 50.350 [0.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.125733, mean_absolute_error: 2.399988, mean_q: 3.213610
131 (array([22]),) False
  81280/500000: episode: 2032, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.725 [12.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.123187, mean_absolute_error: 2.413892, mean_q: 3.230494
428 (array([22]),) False
  81320/500000: episode: 2033, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.375 [15.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.125675, mean_absolute_error: 2.414866, mean_q: 3.229080
418 (array([22]),) False
  81360/500000: episode: 2034, duration: 30.043s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.350 [11.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.126856, mean_absolute_error: 2.436397, mean_q: 3.260787
366 (array([22]),) False
  81400/500000: episode: 2035, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.375 [5.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.126536, mean_absolute_error: 2.417192, mean_q: 3.243020
79 (array([22]),) False
  81440/500000: episode: 2036, duration: 30.856s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.725 [5.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.131756, mean_absolute_error: 2.452958, mean_q: 3.278551
748 (array([22]),) False
  81480/500000: episode: 2037, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.250 [2.000, 54.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.123649, mean_absolute_error: 2.420582, mean_q: 3.250372
333 (array([12]),) False
  81520/500000: episode: 2038, duration: 30.044s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 19.750 [11.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.126038, mean_absolute_error: 2.433170, mean_q: 3.249123
348 (array([22]),) False
  81560/500000: episode: 2039, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 21.950 [3.000, 52.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.128509, mean_absolute_error: 2.430823, mean_q: 3.259490
86 (array([22]),) False
  81600/500000: episode: 2040, duration: 30.844s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.475 [1.000, 60.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.138425, mean_absolute_error: 2.459071, mean_q: 3.280011
835 (array([50]),) False
  81640/500000: episode: 2041, duration: 30.892s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.050 [0.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.124481, mean_absolute_error: 2.442479, mean_q: 3.273613
368 (array([22]),) False
  81680/500000: episode: 2042, duration: 30.088s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.425 [0.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.132273, mean_absolute_error: 2.438967, mean_q: 3.257083
486 (array([22]),) False
  81720/500000: episode: 2043, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.300 [1.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.117029, mean_absolute_error: 2.478019, mean_q: 3.290303
233 (array([54]),) False
  81760/500000: episode: 2044, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.300 [3.000, 58.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.129224, mean_absolute_error: 2.486088, mean_q: 3.305631
214 (array([22]),) False
  81800/500000: episode: 2045, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.500 [10.000, 57.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.127008, mean_absolute_error: 2.487079, mean_q: 3.301806
215 (array([22]),) False
  81840/500000: episode: 2046, duration: 30.056s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.825 [1.000, 58.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.128739, mean_absolute_error: 2.473623, mean_q: 3.286166
68 (array([22]),) False
  81880/500000: episode: 2047, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.575 [2.000, 53.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.124964, mean_absolute_error: 2.500780, mean_q: 3.316425
567 (array([22]),) False
  81920/500000: episode: 2048, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 32.925 [9.000, 58.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.134104, mean_absolute_error: 2.496089, mean_q: 3.315636
525 (array([22]),) False
  81960/500000: episode: 2049, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.800 [8.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.134748, mean_absolute_error: 2.494483, mean_q: 3.322659
406 (array([48]),) False
  82000/500000: episode: 2050, duration: 30.032s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 31.875 [10.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.128902, mean_absolute_error: 2.508282, mean_q: 3.325155
379 (array([22]),) False
  82040/500000: episode: 2051, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.575 [3.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.126952, mean_absolute_error: 2.526065, mean_q: 3.339210
782 (array([22]),) False
  82080/500000: episode: 2052, duration: 30.958s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 17.875 [3.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.134787, mean_absolute_error: 2.530224, mean_q: 3.348278
773 (array([22]),) False
  82120/500000: episode: 2053, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.375 [8.000, 46.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.125623, mean_absolute_error: 2.509256, mean_q: 3.332470
431 (array([22]),) False
  82160/500000: episode: 2054, duration: 30.026s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.825 [17.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.128772, mean_absolute_error: 2.533295, mean_q: 3.363342
274 (array([12]),) False
  82200/500000: episode: 2055, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.625 [1.000, 56.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.131898, mean_absolute_error: 2.523770, mean_q: 3.349575
805 (array([22]),) False
  82240/500000: episode: 2056, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.975 [4.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.125955, mean_absolute_error: 2.505522, mean_q: 3.326357
149 (array([8]),) False
  82280/500000: episode: 2057, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 17.175 [4.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.130062, mean_absolute_error: 2.497251, mean_q: 3.312808
137 (array([22]),) False
  82320/500000: episode: 2058, duration: 30.054s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.075 [15.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.140166, mean_absolute_error: 2.518352, mean_q: 3.333572
557 (array([22]),) False
  82360/500000: episode: 2059, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.475 [12.000, 50.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.127337, mean_absolute_error: 2.507329, mean_q: 3.316465
455 (array([22]),) False
  82400/500000: episode: 2060, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 33.200 [3.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.128446, mean_absolute_error: 2.527767, mean_q: 3.352240
688 (array([22]),) False
  82440/500000: episode: 2061, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.575 [4.000, 51.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.125300, mean_absolute_error: 2.519143, mean_q: 3.343350
621 (array([22]),) False
  82480/500000: episode: 2062, duration: 30.004s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.375 [3.000, 57.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.121644, mean_absolute_error: 2.523851, mean_q: 3.355688
17 (array([22]),) False
  82520/500000: episode: 2063, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.600 [0.000, 58.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.132821, mean_absolute_error: 2.514803, mean_q: 3.338113
661 (array([48]),) False
  82560/500000: episode: 2064, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.300 [9.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.130118, mean_absolute_error: 2.487084, mean_q: 3.315536
711 (array([22]),) False
  82600/500000: episode: 2065, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.475 [9.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.128740, mean_absolute_error: 2.523661, mean_q: 3.355671
173 (array([3]),) False
  82640/500000: episode: 2066, duration: 30.109s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 8.650 [3.000, 45.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.127480, mean_absolute_error: 2.513430, mean_q: 3.345742
384 (array([22]),) False
  82680/500000: episode: 2067, duration: 30.953s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.750 [3.000, 48.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.124680, mean_absolute_error: 2.514570, mean_q: 3.344081
52 (array([22]),) False
  82720/500000: episode: 2068, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.375 [4.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.124128, mean_absolute_error: 2.496312, mean_q: 3.320872
68 (array([22]),) False
  82760/500000: episode: 2069, duration: 30.843s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.525 [8.000, 40.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.125491, mean_absolute_error: 2.521114, mean_q: 3.338584
174 (array([33]),) False
  82800/500000: episode: 2070, duration: 30.010s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.950 [1.000, 56.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.128753, mean_absolute_error: 2.514481, mean_q: 3.338323
494 (array([48]),) False
  82840/500000: episode: 2071, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 43.800 [1.000, 58.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.131736, mean_absolute_error: 2.506202, mean_q: 3.327019
551 (array([22]),) False
  82880/500000: episode: 2072, duration: 30.953s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 27.000 [14.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.136757, mean_absolute_error: 2.511017, mean_q: 3.318085
769 (array([12]),) False
  82920/500000: episode: 2073, duration: 30.880s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 32.050 [10.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.123769, mean_absolute_error: 2.492160, mean_q: 3.297611
168 (array([22]),) False
  82960/500000: episode: 2074, duration: 30.084s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.725 [11.000, 51.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.129343, mean_absolute_error: 2.512076, mean_q: 3.320365
32 (array([48]),) False
  83000/500000: episode: 2075, duration: 30.987s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 29.775 [2.000, 48.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.131138, mean_absolute_error: 2.521408, mean_q: 3.330760
343 (array([22]),) False
  83040/500000: episode: 2076, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 19.225 [0.000, 34.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.126991, mean_absolute_error: 2.510624, mean_q: 3.322507
338 (array([12]),) False
  83080/500000: episode: 2077, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 16.925 [7.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.130137, mean_absolute_error: 2.509478, mean_q: 3.318627
431 (array([22]),) False
  83120/500000: episode: 2078, duration: 30.014s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.925 [11.000, 54.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.134948, mean_absolute_error: 2.530918, mean_q: 3.352268
606 (array([22]),) False
  83160/500000: episode: 2079, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.600 [0.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.129195, mean_absolute_error: 2.551655, mean_q: 3.368054
800 (array([22]),) False
  83200/500000: episode: 2080, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.275 [12.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.124318, mean_absolute_error: 2.527437, mean_q: 3.344908
490 (array([12]),) False
  83240/500000: episode: 2081, duration: 30.850s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 16.525 [3.000, 58.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.123629, mean_absolute_error: 2.522452, mean_q: 3.345072
777 (array([48]),) False
  83280/500000: episode: 2082, duration: 30.076s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 15.775 [5.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.121332, mean_absolute_error: 2.551165, mean_q: 3.372912
410 (array([22]),) False
  83320/500000: episode: 2083, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.125 [2.000, 51.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.131770, mean_absolute_error: 2.530337, mean_q: 3.348747
589 (array([22]),) False
  83360/500000: episode: 2084, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.550 [6.000, 51.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.130719, mean_absolute_error: 2.552542, mean_q: 3.376134
642 (array([22]),) False
  83400/500000: episode: 2085, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.875 [0.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.133716, mean_absolute_error: 2.529455, mean_q: 3.350384
463 (array([22]),) False
  83440/500000: episode: 2086, duration: 30.081s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.275 [4.000, 25.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.128156, mean_absolute_error: 2.575612, mean_q: 3.401494
26 (array([22]),) False
  83480/500000: episode: 2087, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.350 [2.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.137058, mean_absolute_error: 2.570811, mean_q: 3.391107
770 (array([22]),) False
  83520/500000: episode: 2088, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 40.125 [8.000, 49.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.135324, mean_absolute_error: 2.579061, mean_q: 3.402772
819 (array([48]),) False
  83560/500000: episode: 2089, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 43.975 [6.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.128083, mean_absolute_error: 2.561336, mean_q: 3.392045
269 (array([36]),) False
  83600/500000: episode: 2090, duration: 30.120s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 18.675 [2.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.129962, mean_absolute_error: 2.544276, mean_q: 3.372123
411 (array([22]),) False
  83640/500000: episode: 2091, duration: 30.850s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.450 [5.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.138167, mean_absolute_error: 2.570625, mean_q: 3.399716
322 (array([12]),) False
  83680/500000: episode: 2092, duration: 30.903s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 20.200 [11.000, 54.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.138081, mean_absolute_error: 2.547829, mean_q: 3.378442
498 (array([12]),) False
  83720/500000: episode: 2093, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 33.875 [6.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.137006, mean_absolute_error: 2.540489, mean_q: 3.362074
264 (array([12]),) False
  83760/500000: episode: 2094, duration: 29.997s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.425 [3.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.127011, mean_absolute_error: 2.531192, mean_q: 3.345887
462 (array([12]),) False
  83800/500000: episode: 2095, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.425 [9.000, 45.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.138445, mean_absolute_error: 2.554193, mean_q: 3.378823
334 (array([48]),) False
  83840/500000: episode: 2096, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.275 [0.000, 55.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.137560, mean_absolute_error: 2.561418, mean_q: 3.377567
227 (array([22]),) False
  83880/500000: episode: 2097, duration: 30.860s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.325 [7.000, 54.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.130241, mean_absolute_error: 2.536814, mean_q: 3.360909
752 (array([3]),) False
  83920/500000: episode: 2098, duration: 30.014s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 16.975 [3.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.133073, mean_absolute_error: 2.523052, mean_q: 3.343149
482 (array([22]),) False
  83960/500000: episode: 2099, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 27.825 [6.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.124302, mean_absolute_error: 2.551116, mean_q: 3.373027
422 (array([48]),) False
  84000/500000: episode: 2100, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 39.175 [15.000, 60.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.123549, mean_absolute_error: 2.540288, mean_q: 3.364211
446 (array([22]),) False
  84040/500000: episode: 2101, duration: 30.842s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.350 [9.000, 43.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.126999, mean_absolute_error: 2.521732, mean_q: 3.339835
538 (array([12]),) False
  84080/500000: episode: 2102, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 33.675 [12.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.134193, mean_absolute_error: 2.538296, mean_q: 3.356789
194 (array([44]),) False
  84120/500000: episode: 2103, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 40.450 [0.000, 59.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.140982, mean_absolute_error: 2.534358, mean_q: 3.340984
122 (array([12]),) False
  84160/500000: episode: 2104, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 25.050 [4.000, 58.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.136671, mean_absolute_error: 2.538596, mean_q: 3.357233
351 (array([22]),) False
  84200/500000: episode: 2105, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.200 [1.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.131566, mean_absolute_error: 2.533669, mean_q: 3.358401
221 (array([22]),) False
  84240/500000: episode: 2106, duration: 30.042s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.075 [4.000, 60.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.132303, mean_absolute_error: 2.547386, mean_q: 3.379434
422 (array([48]),) False
  84280/500000: episode: 2107, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 34.250 [9.000, 57.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.144484, mean_absolute_error: 2.527997, mean_q: 3.354214
63 (array([18]),) False
  84320/500000: episode: 2108, duration: 30.849s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 18.850 [9.000, 53.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.129601, mean_absolute_error: 2.532681, mean_q: 3.364814
817 (array([12]),) False
  84360/500000: episode: 2109, duration: 30.850s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 16.250 [7.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.129324, mean_absolute_error: 2.544689, mean_q: 3.373213
394 (array([22]),) False
  84400/500000: episode: 2110, duration: 30.127s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.350 [1.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.144221, mean_absolute_error: 2.547727, mean_q: 3.364294
16 (array([22]),) False
  84440/500000: episode: 2111, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.575 [6.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.129866, mean_absolute_error: 2.545729, mean_q: 3.364768
674 (array([48]),) False
  84480/500000: episode: 2112, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.300 [9.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.135540, mean_absolute_error: 2.553118, mean_q: 3.366585
353 (array([22]),) False
  84520/500000: episode: 2113, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.400 [3.000, 57.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.137855, mean_absolute_error: 2.557725, mean_q: 3.377906
30 (array([22]),) False
  84560/500000: episode: 2114, duration: 30.039s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.975 [0.000, 57.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.127129, mean_absolute_error: 2.567180, mean_q: 3.398505
433 (array([22]),) False
  84600/500000: episode: 2115, duration: 30.879s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.725 [1.000, 54.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.134064, mean_absolute_error: 2.570765, mean_q: 3.404203
648 (array([22]),) False
  84640/500000: episode: 2116, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.975 [1.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.126239, mean_absolute_error: 2.599870, mean_q: 3.424202
357 (array([22]),) False
  84680/500000: episode: 2117, duration: 30.881s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.750 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.134821, mean_absolute_error: 2.575289, mean_q: 3.401832
508 (array([22]),) False
  84720/500000: episode: 2118, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.925 [0.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.140179, mean_absolute_error: 2.547849, mean_q: 3.371801
346 (array([12]),) False
  84760/500000: episode: 2119, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.100 [2.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.139963, mean_absolute_error: 2.578085, mean_q: 3.404765
722 (array([22]),) False
  84800/500000: episode: 2120, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.375 [13.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.138589, mean_absolute_error: 2.575974, mean_q: 3.405387
762 (array([22]),) False
  84840/500000: episode: 2121, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 27.975 [0.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.133874, mean_absolute_error: 2.559369, mean_q: 3.391288
480 (array([22]),) False
  84880/500000: episode: 2122, duration: 30.053s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.275 [1.000, 56.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.146349, mean_absolute_error: 2.542073, mean_q: 3.361427
148 (array([22]),) False
  84920/500000: episode: 2123, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.775 [2.000, 52.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.135369, mean_absolute_error: 2.558287, mean_q: 3.390414
355 (array([22]),) False
  84960/500000: episode: 2124, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.300 [3.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.133324, mean_absolute_error: 2.518573, mean_q: 3.349994
198 (array([22]),) False
  85000/500000: episode: 2125, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.975 [12.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.138349, mean_absolute_error: 2.549512, mean_q: 3.381949
524 (array([22]),) False
  85040/500000: episode: 2126, duration: 30.062s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.700 [3.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.132175, mean_absolute_error: 2.528941, mean_q: 3.348417
257 (array([22]),) False
  85080/500000: episode: 2127, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.175 [0.000, 51.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.132305, mean_absolute_error: 2.510265, mean_q: 3.330302
623 (array([37]),) False
  85120/500000: episode: 2128, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 30.600 [1.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.126810, mean_absolute_error: 2.531196, mean_q: 3.353669
293 (array([22]),) False
  85160/500000: episode: 2129, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 27.100 [20.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.133609, mean_absolute_error: 2.515922, mean_q: 3.336722
167 (array([22]),) False
  85200/500000: episode: 2130, duration: 30.034s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.700 [22.000, 55.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.135029, mean_absolute_error: 2.534049, mean_q: 3.359681
685 (array([22]),) False
  85240/500000: episode: 2131, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.725 [0.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.130540, mean_absolute_error: 2.521779, mean_q: 3.347616
708 (array([40]),) False
  85280/500000: episode: 2132, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.500 [2.000, 53.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.130562, mean_absolute_error: 2.523530, mean_q: 3.357018
337 (array([22]),) False
  85320/500000: episode: 2133, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.000 [2.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.124101, mean_absolute_error: 2.543527, mean_q: 3.375890
214 (array([22]),) False
  85360/500000: episode: 2134, duration: 30.056s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.325 [5.000, 55.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.127900, mean_absolute_error: 2.501186, mean_q: 3.325666
636 (array([12]),) False
  85400/500000: episode: 2135, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 37.950 [8.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.126973, mean_absolute_error: 2.553983, mean_q: 3.385239
426 (array([22]),) False
  85440/500000: episode: 2136, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.175 [0.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.133269, mean_absolute_error: 2.537690, mean_q: 3.367577
79 (array([22]),) False
  85480/500000: episode: 2137, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.925 [18.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.126696, mean_absolute_error: 2.532338, mean_q: 3.359642
24 (array([22]),) False
  85520/500000: episode: 2138, duration: 30.019s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.900 [0.000, 58.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.128823, mean_absolute_error: 2.533469, mean_q: 3.356296
165 (array([34]),) False
  85560/500000: episode: 2139, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 22.300 [11.000, 51.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.128210, mean_absolute_error: 2.550301, mean_q: 3.375522
861 (array([22]),) False
  85600/500000: episode: 2140, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.100 [14.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.120017, mean_absolute_error: 2.543694, mean_q: 3.370837
439 (array([12]),) False
  85640/500000: episode: 2141, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.650 [2.000, 44.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.118670, mean_absolute_error: 2.521612, mean_q: 3.348820
427 (array([22]),) False
  85680/500000: episode: 2142, duration: 30.035s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 23.075 [15.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.135985, mean_absolute_error: 2.529987, mean_q: 3.360642
612 (array([22]),) False
  85720/500000: episode: 2143, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 31.625 [12.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.139548, mean_absolute_error: 2.570039, mean_q: 3.409681
496 (array([48]),) False
  85760/500000: episode: 2144, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 41.350 [3.000, 52.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.132303, mean_absolute_error: 2.534880, mean_q: 3.363522
835 (array([50]),) False
  85800/500000: episode: 2145, duration: 30.847s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.675 [0.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.139048, mean_absolute_error: 2.529769, mean_q: 3.353149
354 (array([12]),) False
  85840/500000: episode: 2146, duration: 30.032s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 20.850 [3.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.137980, mean_absolute_error: 2.528871, mean_q: 3.358371
477 (array([22]),) False
  85880/500000: episode: 2147, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.050 [22.000, 55.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.135498, mean_absolute_error: 2.541524, mean_q: 3.374052
258 (array([22]),) False
  85920/500000: episode: 2148, duration: 30.814s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.800 [7.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.135685, mean_absolute_error: 2.528086, mean_q: 3.353983
766 (array([12]),) False
  85960/500000: episode: 2149, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 46.900 [10.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.128147, mean_absolute_error: 2.525789, mean_q: 3.352565
542 (array([44]),) False
  86000/500000: episode: 2150, duration: 30.114s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 41.975 [18.000, 46.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.127773, mean_absolute_error: 2.516521, mean_q: 3.342212
698 (array([22]),) False
  86040/500000: episode: 2151, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.650 [14.000, 52.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.132100, mean_absolute_error: 2.521527, mean_q: 3.347899
781 (array([8]),) False
  86080/500000: episode: 2152, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 22.325 [5.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.130804, mean_absolute_error: 2.531049, mean_q: 3.352547
237 (array([22]),) False
  86120/500000: episode: 2153, duration: 30.518s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.200 [4.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.136419, mean_absolute_error: 2.509609, mean_q: 3.333843
550 (array([12]),) False
  86160/500000: episode: 2154, duration: 30.012s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 19.100 [4.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.129126, mean_absolute_error: 2.532231, mean_q: 3.355921
81 (array([22]),) False
  86200/500000: episode: 2155, duration: 30.838s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.725 [6.000, 60.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.128782, mean_absolute_error: 2.516469, mean_q: 3.339647
782 (array([22]),) False
  86240/500000: episode: 2156, duration: 30.858s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 24.600 [3.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.122500, mean_absolute_error: 2.540691, mean_q: 3.370012
327 (array([22]),) False
  86280/500000: episode: 2157, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.650 [6.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.139342, mean_absolute_error: 2.528080, mean_q: 3.349360
682 (array([22]),) False
  86320/500000: episode: 2158, duration: 30.052s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.875 [22.000, 58.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.130447, mean_absolute_error: 2.525894, mean_q: 3.356578
607 (array([12]),) False
  86360/500000: episode: 2159, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 31.900 [11.000, 57.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.128373, mean_absolute_error: 2.504309, mean_q: 3.333916
298 (array([22]),) False
  86400/500000: episode: 2160, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.275 [5.000, 45.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.133451, mean_absolute_error: 2.557699, mean_q: 3.393225
382 (array([22]),) False
  86440/500000: episode: 2161, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.100 [0.000, 48.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.135699, mean_absolute_error: 2.524484, mean_q: 3.345821
349 (array([48]),) False
  86480/500000: episode: 2162, duration: 30.059s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 20.850 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.125342, mean_absolute_error: 2.515895, mean_q: 3.333527
808 (array([22]),) False
  86520/500000: episode: 2163, duration: 30.860s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.725 [1.000, 43.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.127020, mean_absolute_error: 2.554186, mean_q: 3.391454
439 (array([12]),) False
  86560/500000: episode: 2164, duration: 30.850s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.075 [9.000, 52.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.131305, mean_absolute_error: 2.541041, mean_q: 3.366256
26 (array([22]),) False
  86600/500000: episode: 2165, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.175 [5.000, 41.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.129111, mean_absolute_error: 2.501342, mean_q: 3.318614
57 (array([37]),) False
  86640/500000: episode: 2166, duration: 30.041s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 39.525 [2.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.121337, mean_absolute_error: 2.521363, mean_q: 3.337608
80 (array([42]),) False
  86680/500000: episode: 2167, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 43.250 [12.000, 59.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.140427, mean_absolute_error: 2.510527, mean_q: 3.326713
354 (array([12]),) False
  86720/500000: episode: 2168, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 20.750 [4.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.125053, mean_absolute_error: 2.529410, mean_q: 3.345804
624 (array([48]),) False
  86760/500000: episode: 2169, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.725 [0.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.128968, mean_absolute_error: 2.483848, mean_q: 3.294318
271 (array([18]),) False
  86800/500000: episode: 2170, duration: 29.967s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 22.475 [2.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.126528, mean_absolute_error: 2.494995, mean_q: 3.310829
53 (array([22]),) False
  86840/500000: episode: 2171, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.075 [4.000, 56.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.134425, mean_absolute_error: 2.479285, mean_q: 3.288711
628 (array([22]),) False
  86880/500000: episode: 2172, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.925 [8.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.125222, mean_absolute_error: 2.480607, mean_q: 3.302761
843 (array([3]),) False
  86920/500000: episode: 2173, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 31.975 [3.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.129671, mean_absolute_error: 2.480793, mean_q: 3.300756
72 (array([12]),) False
  86960/500000: episode: 2174, duration: 30.044s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 16.275 [5.000, 59.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.140750, mean_absolute_error: 2.469754, mean_q: 3.291145
323 (array([55]),) False
  87000/500000: episode: 2175, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 29.550 [3.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.131553, mean_absolute_error: 2.500548, mean_q: 3.327009
775 (array([58]),) False
  87040/500000: episode: 2176, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 19.075 [10.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.122618, mean_absolute_error: 2.477300, mean_q: 3.309697
268 (array([22]),) False
  87080/500000: episode: 2177, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.650 [6.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.128988, mean_absolute_error: 2.500829, mean_q: 3.323632
161 (array([22]),) False
  87120/500000: episode: 2178, duration: 30.085s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.125 [1.000, 54.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.133795, mean_absolute_error: 2.504662, mean_q: 3.321204
96 (array([22]),) False
  87160/500000: episode: 2179, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.100 [8.000, 49.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.131535, mean_absolute_error: 2.488595, mean_q: 3.308305
739 (array([22]),) False
  87200/500000: episode: 2180, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.925 [12.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.137588, mean_absolute_error: 2.524545, mean_q: 3.354530
1 (array([22]),) False
  87240/500000: episode: 2181, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 20.475 [1.000, 45.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.131554, mean_absolute_error: 2.505522, mean_q: 3.336361
385 (array([30]),) False
  87280/500000: episode: 2182, duration: 29.990s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.325 [3.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.127909, mean_absolute_error: 2.534382, mean_q: 3.367327
525 (array([22]),) False
  87320/500000: episode: 2183, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.500 [9.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.120001, mean_absolute_error: 2.515169, mean_q: 3.337341
318 (array([48]),) False
  87360/500000: episode: 2184, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.600 [1.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.131435, mean_absolute_error: 2.559078, mean_q: 3.393005
427 (array([22]),) False
  87400/500000: episode: 2185, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.375 [10.000, 45.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.124872, mean_absolute_error: 2.552605, mean_q: 3.383636
408 (array([12]),) False
  87440/500000: episode: 2186, duration: 30.059s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.250 [2.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.137615, mean_absolute_error: 2.522811, mean_q: 3.339764
774 (array([57]),) False
  87480/500000: episode: 2187, duration: 30.722s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.025 [6.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.133881, mean_absolute_error: 2.513170, mean_q: 3.330596
845 (array([22]),) False
  87520/500000: episode: 2188, duration: 30.827s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.625 [9.000, 54.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.130473, mean_absolute_error: 2.519228, mean_q: 3.331463
673 (array([3]),) False
  87560/500000: episode: 2189, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 6.650 [3.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.128470, mean_absolute_error: 2.532706, mean_q: 3.347225
247 (array([14]),) False
  87600/500000: episode: 2190, duration: 30.061s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 15.450 [0.000, 54.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.130054, mean_absolute_error: 2.511382, mean_q: 3.338328
734 (array([48]),) False
  87640/500000: episode: 2191, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 20.525 [2.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.133203, mean_absolute_error: 2.470057, mean_q: 3.299070
51 (array([22]),) False
  87680/500000: episode: 2192, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.200 [0.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.133413, mean_absolute_error: 2.478879, mean_q: 3.300544
701 (array([48]),) False
  87720/500000: episode: 2193, duration: 30.903s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 45.000 [0.000, 59.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.135626, mean_absolute_error: 2.483037, mean_q: 3.304232
775 (array([58]),) False
  87760/500000: episode: 2194, duration: 30.075s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 41.750 [5.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.125096, mean_absolute_error: 2.444024, mean_q: 3.259341
191 (array([38]),) False
  87800/500000: episode: 2195, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 22.700 [2.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.130100, mean_absolute_error: 2.508777, mean_q: 3.331439
30 (array([22]),) False
  87840/500000: episode: 2196, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.525 [3.000, 57.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.134178, mean_absolute_error: 2.490680, mean_q: 3.314622
120 (array([44]),) False
  87880/500000: episode: 2197, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 34.400 [11.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.128347, mean_absolute_error: 2.516230, mean_q: 3.346415
220 (array([22]),) False
  87920/500000: episode: 2198, duration: 30.107s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.550 [0.000, 59.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.131926, mean_absolute_error: 2.482093, mean_q: 3.307489
273 (array([22]),) False
  87960/500000: episode: 2199, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.350 [5.000, 43.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.130727, mean_absolute_error: 2.525679, mean_q: 3.363917
599 (array([48]),) False
  88000/500000: episode: 2200, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.875 [6.000, 55.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.130966, mean_absolute_error: 2.491694, mean_q: 3.316373
135 (array([22]),) False
  88040/500000: episode: 2201, duration: 30.858s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.800 [8.000, 49.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.129850, mean_absolute_error: 2.500817, mean_q: 3.329543
99 (array([22]),) False
  88080/500000: episode: 2202, duration: 30.143s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.900 [5.000, 51.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.127870, mean_absolute_error: 2.512636, mean_q: 3.334415
410 (array([22]),) False
  88120/500000: episode: 2203, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.100 [21.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.132843, mean_absolute_error: 2.525337, mean_q: 3.358308
70 (array([22]),) False
  88160/500000: episode: 2204, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 43.150 [2.000, 49.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.133138, mean_absolute_error: 2.487813, mean_q: 3.319457
400 (array([22]),) False
  88200/500000: episode: 2205, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 20.775 [1.000, 40.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.126288, mean_absolute_error: 2.510704, mean_q: 3.349597
234 (array([22]),) False
  88240/500000: episode: 2206, duration: 30.077s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.625 [1.000, 50.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.128631, mean_absolute_error: 2.467387, mean_q: 3.297190
557 (array([22]),) False
  88280/500000: episode: 2207, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.450 [22.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.124194, mean_absolute_error: 2.499435, mean_q: 3.327341
107 (array([22]),) False
  88320/500000: episode: 2208, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.650 [10.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.123230, mean_absolute_error: 2.535388, mean_q: 3.359058
385 (array([30]),) False
  88360/500000: episode: 2209, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.400 [5.000, 55.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.130293, mean_absolute_error: 2.538317, mean_q: 3.369818
124 (array([48]),) False
  88400/500000: episode: 2210, duration: 30.061s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 44.375 [1.000, 59.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.130491, mean_absolute_error: 2.544187, mean_q: 3.366987
526 (array([22]),) False
  88440/500000: episode: 2211, duration: 30.892s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.475 [13.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.129499, mean_absolute_error: 2.524862, mean_q: 3.351815
123 (array([22]),) False
  88480/500000: episode: 2212, duration: 30.879s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.325 [7.000, 46.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.129135, mean_absolute_error: 2.567943, mean_q: 3.414731
684 (array([22]),) False
  88520/500000: episode: 2213, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.175 [4.000, 60.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.131953, mean_absolute_error: 2.561663, mean_q: 3.402649
433 (array([22]),) False
  88560/500000: episode: 2214, duration: 30.058s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.150 [9.000, 22.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.132767, mean_absolute_error: 2.548345, mean_q: 3.389271
850 (array([12]),) False
  88600/500000: episode: 2215, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.075 [3.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.128059, mean_absolute_error: 2.551965, mean_q: 3.380952
224 (array([12]),) False
  88640/500000: episode: 2216, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.775 [3.000, 56.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.130094, mean_absolute_error: 2.565444, mean_q: 3.402581
178 (array([38]),) False
  88680/500000: episode: 2217, duration: 30.880s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.475 [0.000, 58.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.148932, mean_absolute_error: 2.569584, mean_q: 3.398061
627 (array([48]),) False
  88720/500000: episode: 2218, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.200 [1.000, 56.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.128840, mean_absolute_error: 2.550210, mean_q: 3.379531
351 (array([22]),) False
  88760/500000: episode: 2219, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.000 [2.000, 57.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.139426, mean_absolute_error: 2.545541, mean_q: 3.379133
180 (array([48]),) False
  88800/500000: episode: 2220, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 38.725 [1.000, 54.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.134439, mean_absolute_error: 2.540113, mean_q: 3.362660
368 (array([22]),) False
  88840/500000: episode: 2221, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.250 [5.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.130106, mean_absolute_error: 2.516037, mean_q: 3.339921
377 (array([22]),) False
  88880/500000: episode: 2222, duration: 30.038s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.650 [5.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.128300, mean_absolute_error: 2.524169, mean_q: 3.358774
465 (array([48]),) False
  88920/500000: episode: 2223, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 38.450 [0.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.129996, mean_absolute_error: 2.547141, mean_q: 3.381383
768 (array([22]),) False
  88960/500000: episode: 2224, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.650 [3.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.132796, mean_absolute_error: 2.535691, mean_q: 3.357644
430 (array([22]),) False
  89000/500000: episode: 2225, duration: 30.846s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 27.350 [4.000, 52.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.125433, mean_absolute_error: 2.533966, mean_q: 3.360313
546 (array([22]),) False
  89040/500000: episode: 2226, duration: 30.035s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.050 [22.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.128659, mean_absolute_error: 2.494092, mean_q: 3.322255
199 (array([22]),) False
  89080/500000: episode: 2227, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.750 [12.000, 50.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.132099, mean_absolute_error: 2.538233, mean_q: 3.366848
642 (array([22]),) False
  89120/500000: episode: 2228, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.825 [7.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.132655, mean_absolute_error: 2.521583, mean_q: 3.342299
120 (array([44]),) False
  89160/500000: episode: 2229, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 34.125 [2.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.129616, mean_absolute_error: 2.529443, mean_q: 3.359568
838 (array([21]),) False
  89200/500000: episode: 2230, duration: 29.988s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 21.800 [2.000, 49.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.125993, mean_absolute_error: 2.495668, mean_q: 3.319592
271 (array([18]),) False
  89240/500000: episode: 2231, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 20.550 [2.000, 33.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.131298, mean_absolute_error: 2.534868, mean_q: 3.369320
787 (array([3]),) False
  89280/500000: episode: 2232, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 22.550 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.136750, mean_absolute_error: 2.506655, mean_q: 3.328289
461 (array([22]),) False
  89320/500000: episode: 2233, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.375 [5.000, 42.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.129665, mean_absolute_error: 2.485631, mean_q: 3.314955
306 (array([22]),) False
  89360/500000: episode: 2234, duration: 30.073s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.000 [1.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.135210, mean_absolute_error: 2.517315, mean_q: 3.355401
261 (array([44]),) False
  89400/500000: episode: 2235, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.925 [8.000, 53.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.145473, mean_absolute_error: 2.487750, mean_q: 3.316319
276 (array([56]),) False
  89440/500000: episode: 2236, duration: 30.850s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.450 [1.000, 51.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.132864, mean_absolute_error: 2.486221, mean_q: 3.325679
608 (array([36]),) False
  89480/500000: episode: 2237, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 31.400 [3.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.130085, mean_absolute_error: 2.509387, mean_q: 3.347721
760 (array([22]),) False
  89520/500000: episode: 2238, duration: 30.091s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 45.900 [13.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.138819, mean_absolute_error: 2.532146, mean_q: 3.363740
497 (array([33]),) False
  89560/500000: episode: 2239, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.225 [3.000, 56.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.124580, mean_absolute_error: 2.502077, mean_q: 3.332053
364 (array([14]),) False
  89600/500000: episode: 2240, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.825 [7.000, 53.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.138977, mean_absolute_error: 2.533242, mean_q: 3.366765
798 (array([18]),) False
  89640/500000: episode: 2241, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.225 [3.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.130156, mean_absolute_error: 2.521193, mean_q: 3.353700
200 (array([22]),) False
  89680/500000: episode: 2242, duration: 30.068s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 27.050 [3.000, 56.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.130741, mean_absolute_error: 2.525398, mean_q: 3.356308
671 (array([57]),) False
  89720/500000: episode: 2243, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 30.500 [0.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.129408, mean_absolute_error: 2.525635, mean_q: 3.347478
35 (array([48]),) False
  89760/500000: episode: 2244, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 46.000 [6.000, 58.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.127527, mean_absolute_error: 2.519555, mean_q: 3.341534
178 (array([38]),) False
  89800/500000: episode: 2245, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.200 [3.000, 49.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.137715, mean_absolute_error: 2.495123, mean_q: 3.308923
764 (array([48]),) False
  89840/500000: episode: 2246, duration: 30.070s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.450 [3.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.144961, mean_absolute_error: 2.536739, mean_q: 3.361654
769 (array([12]),) False
  89880/500000: episode: 2247, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 28.475 [0.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.127828, mean_absolute_error: 2.542231, mean_q: 3.368460
188 (array([22]),) False
  89920/500000: episode: 2248, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.625 [2.000, 51.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.136674, mean_absolute_error: 2.540316, mean_q: 3.357307
66 (array([22]),) False
  89960/500000: episode: 2249, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.600 [0.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.128147, mean_absolute_error: 2.525424, mean_q: 3.341702
262 (array([22]),) False
  90000/500000: episode: 2250, duration: 30.054s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.125 [11.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.128531, mean_absolute_error: 2.531782, mean_q: 3.356985
828 (array([48]),) False
  90040/500000: episode: 2251, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.625 [0.000, 55.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.135786, mean_absolute_error: 2.541270, mean_q: 3.363016
338 (array([12]),) False
  90080/500000: episode: 2252, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 15.750 [1.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.125142, mean_absolute_error: 2.536235, mean_q: 3.354832
692 (array([22]),) False
  90120/500000: episode: 2253, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.675 [16.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.132204, mean_absolute_error: 2.543822, mean_q: 3.361420
483 (array([48]),) False
  90160/500000: episode: 2254, duration: 30.050s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 42.700 [0.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.130067, mean_absolute_error: 2.554639, mean_q: 3.373303
335 (array([22]),) False
  90200/500000: episode: 2255, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 19.675 [1.000, 41.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.146429, mean_absolute_error: 2.547837, mean_q: 3.373908
360 (array([22]),) False
  90240/500000: episode: 2256, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 23.950 [0.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.129012, mean_absolute_error: 2.612998, mean_q: 3.456460
216 (array([22]),) False
  90280/500000: episode: 2257, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.200 [8.000, 48.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.137431, mean_absolute_error: 2.567204, mean_q: 3.394604
696 (array([36]),) False
  90320/500000: episode: 2258, duration: 30.081s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.725 [3.000, 47.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.129700, mean_absolute_error: 2.559016, mean_q: 3.393934
700 (array([44]),) False
  90360/500000: episode: 2259, duration: 30.925s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.950 [2.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.130970, mean_absolute_error: 2.574038, mean_q: 3.407356
796 (array([38]),) False
  90400/500000: episode: 2260, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.650 [3.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.140794, mean_absolute_error: 2.557598, mean_q: 3.392478
121 (array([22]),) False
  90440/500000: episode: 2261, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 29.450 [2.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.135842, mean_absolute_error: 2.552792, mean_q: 3.369132
655 (array([22]),) False
  90480/500000: episode: 2262, duration: 30.074s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.500 [0.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.132641, mean_absolute_error: 2.585938, mean_q: 3.415549
595 (array([22]),) False
  90520/500000: episode: 2263, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.750 [1.000, 55.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.131847, mean_absolute_error: 2.574710, mean_q: 3.399123
733 (array([22]),) False
  90560/500000: episode: 2264, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.025 [4.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.144018, mean_absolute_error: 2.579965, mean_q: 3.404224
88 (array([22]),) False
  90600/500000: episode: 2265, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.775 [6.000, 33.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.140411, mean_absolute_error: 2.570637, mean_q: 3.387283
27 (array([22]),) False
  90640/500000: episode: 2266, duration: 30.075s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.900 [0.000, 49.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.136904, mean_absolute_error: 2.575233, mean_q: 3.402613
860 (array([12]),) False
  90680/500000: episode: 2267, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 15.350 [9.000, 57.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.136383, mean_absolute_error: 2.574927, mean_q: 3.394733
409 (array([22]),) False
  90720/500000: episode: 2268, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.175 [12.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.136901, mean_absolute_error: 2.585887, mean_q: 3.409493
427 (array([22]),) False
  90760/500000: episode: 2269, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.175 [20.000, 31.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.142883, mean_absolute_error: 2.565408, mean_q: 3.388950
629 (array([22]),) False
  90800/500000: episode: 2270, duration: 30.059s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 43.950 [7.000, 55.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.144345, mean_absolute_error: 2.540606, mean_q: 3.358200
606 (array([22]),) False
  90840/500000: episode: 2271, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.450 [14.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.137154, mean_absolute_error: 2.556639, mean_q: 3.371200
131 (array([22]),) False
  90880/500000: episode: 2272, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 22.950 [7.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.142147, mean_absolute_error: 2.552611, mean_q: 3.383677
437 (array([12]),) False
  90920/500000: episode: 2273, duration: 30.871s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 29.425 [9.000, 49.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.134181, mean_absolute_error: 2.540043, mean_q: 3.365159
94 (array([44]),) False
  90960/500000: episode: 2274, duration: 30.073s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.150 [3.000, 49.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.136310, mean_absolute_error: 2.568740, mean_q: 3.404379
309 (array([22]),) False
  91000/500000: episode: 2275, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.925 [2.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.137096, mean_absolute_error: 2.546485, mean_q: 3.378912
101 (array([22]),) False
  91040/500000: episode: 2276, duration: 30.878s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.900 [2.000, 59.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.128097, mean_absolute_error: 2.558490, mean_q: 3.385677
17 (array([22]),) False
  91080/500000: episode: 2277, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.200 [16.000, 60.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.133490, mean_absolute_error: 2.541912, mean_q: 3.372329
122 (array([12]),) False
  91120/500000: episode: 2278, duration: 30.075s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 26.175 [16.000, 51.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.128526, mean_absolute_error: 2.584868, mean_q: 3.416281
815 (array([22]),) False
  91160/500000: episode: 2279, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.675 [2.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.135888, mean_absolute_error: 2.512000, mean_q: 3.326838
452 (array([22]),) False
  91200/500000: episode: 2280, duration: 30.856s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.025 [3.000, 51.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.131979, mean_absolute_error: 2.523953, mean_q: 3.353076
624 (array([48]),) False
  91240/500000: episode: 2281, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 42.825 [6.000, 49.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.138926, mean_absolute_error: 2.527810, mean_q: 3.356068
475 (array([22]),) False
  91280/500000: episode: 2282, duration: 30.085s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.350 [1.000, 41.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.127602, mean_absolute_error: 2.547438, mean_q: 3.375733
796 (array([38]),) False
  91320/500000: episode: 2283, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.950 [1.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.139938, mean_absolute_error: 2.522554, mean_q: 3.345697
634 (array([57]),) False
  91360/500000: episode: 2284, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 28.225 [1.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.130370, mean_absolute_error: 2.518388, mean_q: 3.328575
309 (array([22]),) False
  91400/500000: episode: 2285, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.425 [4.000, 46.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.126317, mean_absolute_error: 2.471864, mean_q: 3.291608
252 (array([22]),) False
  91440/500000: episode: 2286, duration: 30.053s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.250 [8.000, 47.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.135263, mean_absolute_error: 2.513014, mean_q: 3.335774
765 (array([48]),) False
  91480/500000: episode: 2287, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 43.300 [14.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.132132, mean_absolute_error: 2.490157, mean_q: 3.309681
64 (array([12]),) False
  91520/500000: episode: 2288, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.175 [6.000, 55.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.141004, mean_absolute_error: 2.487566, mean_q: 3.311024
700 (array([44]),) False
  91560/500000: episode: 2289, duration: 31.280s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 38.200 [3.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.138388, mean_absolute_error: 2.489050, mean_q: 3.308019
602 (array([36]),) False
  91600/500000: episode: 2290, duration: 30.611s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 18.700 [8.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.127193, mean_absolute_error: 2.494010, mean_q: 3.316198
524 (array([22]),) False
  91640/500000: episode: 2291, duration: 31.307s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 27.250 [3.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.132611, mean_absolute_error: 2.475545, mean_q: 3.294877
667 (array([48]),) False
  91680/500000: episode: 2292, duration: 31.125s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 43.125 [3.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.143732, mean_absolute_error: 2.484351, mean_q: 3.300779
106 (array([22]),) False
  91720/500000: episode: 2293, duration: 31.259s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.275 [9.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.127410, mean_absolute_error: 2.481204, mean_q: 3.307215
385 (array([30]),) False
  91760/500000: episode: 2294, duration: 30.689s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.700 [4.000, 57.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.128065, mean_absolute_error: 2.482733, mean_q: 3.303987
70 (array([22]),) False
  91800/500000: episode: 2295, duration: 31.182s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 44.550 [11.000, 50.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.128781, mean_absolute_error: 2.480131, mean_q: 3.309191
584 (array([36]),) False
  91840/500000: episode: 2296, duration: 31.142s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 8.375 [3.000, 45.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.130421, mean_absolute_error: 2.470067, mean_q: 3.292611
662 (array([12]),) False
  91880/500000: episode: 2297, duration: 31.346s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 15.000 [0.000, 54.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.131526, mean_absolute_error: 2.475876, mean_q: 3.298114
593 (array([37]),) False
  91920/500000: episode: 2298, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 32.575 [1.000, 57.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.132423, mean_absolute_error: 2.490985, mean_q: 3.320056
529 (array([3]),) False
  91960/500000: episode: 2299, duration: 31.295s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 7.100 [2.000, 46.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.128764, mean_absolute_error: 2.448376, mean_q: 3.281522
802 (array([22]),) False
  92000/500000: episode: 2300, duration: 31.028s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.175 [5.000, 53.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.133181, mean_absolute_error: 2.471744, mean_q: 3.301994
542 (array([44]),) False
  92040/500000: episode: 2301, duration: 31.516s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 42.000 [0.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.138987, mean_absolute_error: 2.485912, mean_q: 3.314651
256 (array([22]),) False
  92080/500000: episode: 2302, duration: 30.631s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.800 [1.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.131255, mean_absolute_error: 2.491946, mean_q: 3.313829
598 (array([22]),) False
  92120/500000: episode: 2303, duration: 31.347s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.050 [6.000, 54.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.126639, mean_absolute_error: 2.481656, mean_q: 3.297243
794 (array([22]),) False
  92160/500000: episode: 2304, duration: 31.473s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.375 [1.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.125628, mean_absolute_error: 2.457782, mean_q: 3.283952
479 (array([22]),) False
  92200/500000: episode: 2305, duration: 31.571s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.300 [9.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.139411, mean_absolute_error: 2.476060, mean_q: 3.308381
395 (array([22]),) False
  92240/500000: episode: 2306, duration: 30.733s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.550 [6.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.135874, mean_absolute_error: 2.445726, mean_q: 3.264125
588 (array([22]),) False
  92280/500000: episode: 2307, duration: 31.323s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 32.550 [2.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.127913, mean_absolute_error: 2.458841, mean_q: 3.281996
591 (array([22]),) False
  92320/500000: episode: 2308, duration: 31.675s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.175 [4.000, 51.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.137758, mean_absolute_error: 2.456640, mean_q: 3.275542
227 (array([22]),) False
  92360/500000: episode: 2309, duration: 31.627s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.900 [10.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.130913, mean_absolute_error: 2.477865, mean_q: 3.297653
707 (array([48]),) False
  92400/500000: episode: 2310, duration: 31.352s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.500 [4.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.131162, mean_absolute_error: 2.460863, mean_q: 3.287601
392 (array([40]),) False
  92440/500000: episode: 2311, duration: 31.566s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 25.500 [18.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.122696, mean_absolute_error: 2.469763, mean_q: 3.301176
583 (array([22]),) False
  92480/500000: episode: 2312, duration: 31.569s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 14.675 [2.000, 55.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.131821, mean_absolute_error: 2.435343, mean_q: 3.259264
763 (array([48]),) False
  92520/500000: episode: 2313, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 47.750 [40.000, 50.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.138941, mean_absolute_error: 2.459231, mean_q: 3.277158
631 (array([22]),) False
  92560/500000: episode: 2314, duration: 31.199s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.450 [3.000, 57.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.131736, mean_absolute_error: 2.455438, mean_q: 3.277766
798 (array([18]),) False
  92600/500000: episode: 2315, duration: 31.543s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.350 [1.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.135701, mean_absolute_error: 2.427927, mean_q: 3.255159
647 (array([22]),) False
  92640/500000: episode: 2316, duration: 31.559s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.225 [12.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.125176, mean_absolute_error: 2.413656, mean_q: 3.245724
367 (array([12]),) False
  92680/500000: episode: 2317, duration: 31.541s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.575 [0.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.124377, mean_absolute_error: 2.464134, mean_q: 3.309370
685 (array([22]),) False
  92720/500000: episode: 2318, duration: 31.150s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.125 [13.000, 52.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.127275, mean_absolute_error: 2.472668, mean_q: 3.306729
324 (array([12]),) False
  92760/500000: episode: 2319, duration: 31.550s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 23.000 [0.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.129396, mean_absolute_error: 2.449075, mean_q: 3.282687
186 (array([22]),) False
  92800/500000: episode: 2320, duration: 31.816s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.625 [1.000, 48.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.136281, mean_absolute_error: 2.449047, mean_q: 3.276301
182 (array([54]),) False
  92840/500000: episode: 2321, duration: 33.319s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 28.975 [3.000, 56.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.125191, mean_absolute_error: 2.475485, mean_q: 3.294013
704 (array([22]),) False
  92880/500000: episode: 2322, duration: 32.340s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.800 [1.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.125008, mean_absolute_error: 2.445960, mean_q: 3.277639
310 (array([12]),) False
  92920/500000: episode: 2323, duration: 33.381s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 14.500 [3.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.128030, mean_absolute_error: 2.503219, mean_q: 3.332755
111 (array([22]),) False
  92960/500000: episode: 2324, duration: 33.256s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.875 [9.000, 50.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.137100, mean_absolute_error: 2.440003, mean_q: 3.265593
245 (array([22]),) False
  93000/500000: episode: 2325, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.300 [10.000, 41.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.136120, mean_absolute_error: 2.472812, mean_q: 3.300727
408 (array([12]),) False
  93040/500000: episode: 2326, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 34.325 [3.000, 51.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.136998, mean_absolute_error: 2.487470, mean_q: 3.315345
736 (array([22]),) False
  93080/500000: episode: 2327, duration: 33.406s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 21.475 [9.000, 51.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.132166, mean_absolute_error: 2.477433, mean_q: 3.299037
646 (array([44]),) False
  93120/500000: episode: 2328, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.450 [2.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.140786, mean_absolute_error: 2.465324, mean_q: 3.288132
339 (array([22]),) False
  93160/500000: episode: 2329, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.875 [19.000, 47.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.127636, mean_absolute_error: 2.492960, mean_q: 3.320680
672 (array([44]),) False
  93200/500000: episode: 2330, duration: 32.364s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 49.825 [7.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.142873, mean_absolute_error: 2.473769, mean_q: 3.289263
592 (array([22]),) False
  93240/500000: episode: 2331, duration: 33.260s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 20.900 [2.000, 49.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.134399, mean_absolute_error: 2.458992, mean_q: 3.272639
446 (array([22]),) False
  93280/500000: episode: 2332, duration: 33.264s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.375 [0.000, 44.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.138408, mean_absolute_error: 2.474084, mean_q: 3.294330
598 (array([22]),) False
  93320/500000: episode: 2333, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.850 [0.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.135060, mean_absolute_error: 2.463372, mean_q: 3.286682
55 (array([22]),) False
  93360/500000: episode: 2334, duration: 32.285s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.050 [19.000, 53.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.135546, mean_absolute_error: 2.439779, mean_q: 3.246368
542 (array([44]),) False
  93400/500000: episode: 2335, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 37.900 [1.000, 46.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.134564, mean_absolute_error: 2.454241, mean_q: 3.274519
68 (array([22]),) False
  93440/500000: episode: 2336, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.625 [9.000, 54.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.135075, mean_absolute_error: 2.472381, mean_q: 3.302858
770 (array([22]),) False
  93480/500000: episode: 2337, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 36.875 [0.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.128003, mean_absolute_error: 2.475389, mean_q: 3.304226
501 (array([12]),) False
  93520/500000: episode: 2338, duration: 32.353s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.775 [0.000, 54.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.137414, mean_absolute_error: 2.489626, mean_q: 3.318284
755 (array([22]),) False
  93560/500000: episode: 2339, duration: 33.373s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.450 [3.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.128490, mean_absolute_error: 2.467880, mean_q: 3.298450
638 (array([22]),) False
  93600/500000: episode: 2340, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.725 [22.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.128949, mean_absolute_error: 2.470311, mean_q: 3.298026
220 (array([22]),) False
  93640/500000: episode: 2341, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.150 [0.000, 43.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.133443, mean_absolute_error: 2.494297, mean_q: 3.324152
584 (array([36]),) False
  93680/500000: episode: 2342, duration: 32.406s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 10.800 [3.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.131806, mean_absolute_error: 2.488910, mean_q: 3.317827
508 (array([22]),) False
  93720/500000: episode: 2343, duration: 33.295s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 33.975 [22.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.131791, mean_absolute_error: 2.483394, mean_q: 3.311095
693 (array([22]),) False
  93760/500000: episode: 2344, duration: 33.299s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.800 [1.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.129757, mean_absolute_error: 2.484309, mean_q: 3.308246
727 (array([12]),) False
  93800/500000: episode: 2345, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 14.225 [9.000, 46.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.133274, mean_absolute_error: 2.485133, mean_q: 3.314891
143 (array([12]),) False
  93840/500000: episode: 2346, duration: 32.353s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.250 [12.000, 46.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.138365, mean_absolute_error: 2.485799, mean_q: 3.314235
277 (array([56]),) False
  93880/500000: episode: 2347, duration: 33.323s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 47.200 [3.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.141363, mean_absolute_error: 2.481107, mean_q: 3.307956
123 (array([22]),) False
  93920/500000: episode: 2348, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.750 [2.000, 53.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.132436, mean_absolute_error: 2.491615, mean_q: 3.311659
15 (array([22]),) False
  93960/500000: episode: 2349, duration: 33.251s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.775 [0.000, 48.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.130111, mean_absolute_error: 2.484015, mean_q: 3.299471
474 (array([22]),) False
  94000/500000: episode: 2350, duration: 32.278s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.000 [13.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.127247, mean_absolute_error: 2.469170, mean_q: 3.297578
95 (array([22]),) False
  94040/500000: episode: 2351, duration: 33.305s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.800 [9.000, 53.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.129384, mean_absolute_error: 2.490955, mean_q: 3.315810
742 (array([33]),) False
  94080/500000: episode: 2352, duration: 33.286s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.125 [2.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.123416, mean_absolute_error: 2.453363, mean_q: 3.280490
756 (array([48]),) False
  94120/500000: episode: 2353, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 43.850 [8.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.123587, mean_absolute_error: 2.454840, mean_q: 3.283069
28 (array([58]),) False
  94160/500000: episode: 2354, duration: 32.331s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 22.850 [3.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.133245, mean_absolute_error: 2.467300, mean_q: 3.294754
428 (array([22]),) False
  94200/500000: episode: 2355, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.300 [6.000, 53.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.124828, mean_absolute_error: 2.457748, mean_q: 3.284005
71 (array([58]),) False
  94240/500000: episode: 2356, duration: 32.666s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 52.350 [12.000, 60.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.129318, mean_absolute_error: 2.467523, mean_q: 3.294862
560 (array([22]),) False
  94280/500000: episode: 2357, duration: 32.025s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.775 [8.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.130409, mean_absolute_error: 2.468946, mean_q: 3.292927
672 (array([44]),) False
  94320/500000: episode: 2358, duration: 32.280s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 50.300 [4.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.134011, mean_absolute_error: 2.453657, mean_q: 3.286415
733 (array([22]),) False
  94360/500000: episode: 2359, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.775 [3.000, 46.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.138590, mean_absolute_error: 2.437512, mean_q: 3.257869
573 (array([22]),) False
  94400/500000: episode: 2360, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.000 [0.000, 43.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.122859, mean_absolute_error: 2.450704, mean_q: 3.269612
254 (array([22]),) False
  94440/500000: episode: 2361, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.925 [4.000, 56.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.127778, mean_absolute_error: 2.470857, mean_q: 3.300721
402 (array([22]),) False
  94480/500000: episode: 2362, duration: 32.243s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.600 [17.000, 43.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.128972, mean_absolute_error: 2.466871, mean_q: 3.293689
784 (array([22]),) False
  94520/500000: episode: 2363, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.550 [5.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.133501, mean_absolute_error: 2.457911, mean_q: 3.282149
335 (array([22]),) False
  94560/500000: episode: 2364, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.325 [22.000, 53.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.129739, mean_absolute_error: 2.455839, mean_q: 3.283947
593 (array([37]),) False
  94600/500000: episode: 2365, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 26.450 [5.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.131033, mean_absolute_error: 2.434617, mean_q: 3.260491
348 (array([22]),) False
  94640/500000: episode: 2366, duration: 32.353s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.150 [3.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.125384, mean_absolute_error: 2.445877, mean_q: 3.280183
122 (array([12]),) False
  94680/500000: episode: 2367, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 31.700 [0.000, 58.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.126973, mean_absolute_error: 2.459581, mean_q: 3.303020
594 (array([48]),) False
  94720/500000: episode: 2368, duration: 33.300s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.950 [0.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.127194, mean_absolute_error: 2.436263, mean_q: 3.265933
841 (array([21]),) False
  94760/500000: episode: 2369, duration: 33.306s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.900 [3.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.125915, mean_absolute_error: 2.428731, mean_q: 3.247976
454 (array([12]),) False
  94800/500000: episode: 2370, duration: 32.353s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 43.600 [11.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.128384, mean_absolute_error: 2.389482, mean_q: 3.205148
522 (array([22]),) False
  94840/500000: episode: 2371, duration: 33.358s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.825 [2.000, 47.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.122211, mean_absolute_error: 2.432503, mean_q: 3.261356
417 (array([12]),) False
  94880/500000: episode: 2372, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 21.725 [1.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.135658, mean_absolute_error: 2.397598, mean_q: 3.218473
22 (array([37]),) False
  94920/500000: episode: 2373, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 31.350 [6.000, 54.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.131144, mean_absolute_error: 2.432353, mean_q: 3.252966
683 (array([22]),) False
  94960/500000: episode: 2374, duration: 32.385s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.150 [4.000, 51.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.127436, mean_absolute_error: 2.425860, mean_q: 3.244804
32 (array([48]),) False
  95000/500000: episode: 2375, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 36.575 [1.000, 48.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.130670, mean_absolute_error: 2.431578, mean_q: 3.263069
389 (array([48]),) False
  95040/500000: episode: 2376, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 42.850 [1.000, 53.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.124178, mean_absolute_error: 2.458366, mean_q: 3.291527
814 (array([22]),) False
  95080/500000: episode: 2377, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.450 [2.000, 31.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.129739, mean_absolute_error: 2.424675, mean_q: 3.244287
279 (array([22]),) False
  95120/500000: episode: 2378, duration: 32.333s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 37.300 [1.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.132130, mean_absolute_error: 2.427139, mean_q: 3.258489
570 (array([47]),) False
  95160/500000: episode: 2379, duration: 33.304s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 23.525 [1.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.131649, mean_absolute_error: 2.474879, mean_q: 3.313818
113 (array([22]),) False
  95200/500000: episode: 2380, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.175 [5.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.126855, mean_absolute_error: 2.449741, mean_q: 3.282031
856 (array([48]),) False
  95240/500000: episode: 2381, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 47.125 [23.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.130706, mean_absolute_error: 2.503190, mean_q: 3.336083
557 (array([22]),) False
  95280/500000: episode: 2382, duration: 32.323s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.700 [9.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.131168, mean_absolute_error: 2.453481, mean_q: 3.279056
243 (array([12]),) False
  95320/500000: episode: 2383, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.175 [8.000, 37.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.131134, mean_absolute_error: 2.433478, mean_q: 3.261713
545 (array([22]),) False
  95360/500000: episode: 2384, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.975 [11.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.134204, mean_absolute_error: 2.435656, mean_q: 3.257133
819 (array([48]),) False
  95400/500000: episode: 2385, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 45.175 [16.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.133527, mean_absolute_error: 2.461346, mean_q: 3.282222
473 (array([22]),) False
  95440/500000: episode: 2386, duration: 32.269s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.175 [0.000, 53.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.130446, mean_absolute_error: 2.435478, mean_q: 3.260050
74 (array([22]),) False
  95480/500000: episode: 2387, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.825 [7.000, 54.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.130651, mean_absolute_error: 2.447870, mean_q: 3.274056
9 (array([14]),) False
  95520/500000: episode: 2388, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 39.775 [6.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.142089, mean_absolute_error: 2.448833, mean_q: 3.268738
60 (array([22]),) False
  95560/500000: episode: 2389, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 20.925 [12.000, 51.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.131698, mean_absolute_error: 2.446337, mean_q: 3.283229
309 (array([22]),) False
  95600/500000: episode: 2390, duration: 32.276s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.275 [3.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.136199, mean_absolute_error: 2.430024, mean_q: 3.263949
26 (array([22]),) False
  95640/500000: episode: 2391, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.625 [5.000, 47.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.140248, mean_absolute_error: 2.432820, mean_q: 3.251607
605 (array([22]),) False
  95680/500000: episode: 2392, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.875 [0.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.128012, mean_absolute_error: 2.440981, mean_q: 3.275454
70 (array([22]),) False
  95720/500000: episode: 2393, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 39.900 [4.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.128748, mean_absolute_error: 2.444272, mean_q: 3.279193
271 (array([18]),) False
  95760/500000: episode: 2394, duration: 32.322s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.425 [3.000, 48.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.143728, mean_absolute_error: 2.432420, mean_q: 3.256060
56 (array([12]),) False
  95800/500000: episode: 2395, duration: 33.294s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.400 [11.000, 58.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.125096, mean_absolute_error: 2.431635, mean_q: 3.258115
600 (array([48]),) False
  95840/500000: episode: 2396, duration: 33.272s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 44.275 [1.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.135230, mean_absolute_error: 2.437014, mean_q: 3.267921
581 (array([22]),) False
  95880/500000: episode: 2397, duration: 33.204s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.475 [6.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.128182, mean_absolute_error: 2.445455, mean_q: 3.272224
676 (array([40]),) False
  95920/500000: episode: 2398, duration: 32.362s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.425 [1.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.146436, mean_absolute_error: 2.401897, mean_q: 3.227465
431 (array([22]),) False
  95960/500000: episode: 2399, duration: 33.269s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.675 [18.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.131751, mean_absolute_error: 2.418077, mean_q: 3.240405
657 (array([48]),) False
  96000/500000: episode: 2400, duration: 33.204s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 47.175 [1.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.137705, mean_absolute_error: 2.412751, mean_q: 3.231757
537 (array([22]),) False
  96040/500000: episode: 2401, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.950 [11.000, 44.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.129344, mean_absolute_error: 2.443564, mean_q: 3.267396
35 (array([48]),) False
  96080/500000: episode: 2402, duration: 32.334s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 43.950 [8.000, 55.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.129606, mean_absolute_error: 2.441554, mean_q: 3.273824
722 (array([22]),) False
  96120/500000: episode: 2403, duration: 33.263s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.925 [5.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.128511, mean_absolute_error: 2.429025, mean_q: 3.259436
39 (array([22]),) False
  96160/500000: episode: 2404, duration: 33.300s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.275 [7.000, 46.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.127866, mean_absolute_error: 2.436808, mean_q: 3.268697
644 (array([12]),) False
  96200/500000: episode: 2405, duration: 33.243s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 25.425 [13.000, 53.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.127021, mean_absolute_error: 2.451782, mean_q: 3.274296
707 (array([48]),) False
  96240/500000: episode: 2406, duration: 32.403s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 41.800 [0.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.132087, mean_absolute_error: 2.488805, mean_q: 3.320304
75 (array([22]),) False
  96280/500000: episode: 2407, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.325 [17.000, 59.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.132416, mean_absolute_error: 2.461902, mean_q: 3.292772
638 (array([22]),) False
  96320/500000: episode: 2408, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.500 [2.000, 47.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.128781, mean_absolute_error: 2.461500, mean_q: 3.284919
781 (array([8]),) False
  96360/500000: episode: 2409, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 31.150 [12.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.137678, mean_absolute_error: 2.489871, mean_q: 3.324271
203 (array([48]),) False
  96400/500000: episode: 2410, duration: 32.340s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 45.575 [14.000, 56.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.141989, mean_absolute_error: 2.482083, mean_q: 3.305527
255 (array([12]),) False
  96440/500000: episode: 2411, duration: 33.356s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 23.075 [15.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.131899, mean_absolute_error: 2.479358, mean_q: 3.302631
196 (array([22]),) False
  96480/500000: episode: 2412, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.700 [8.000, 48.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.134480, mean_absolute_error: 2.485666, mean_q: 3.308585
661 (array([48]),) False
  96520/500000: episode: 2413, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.525 [1.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.132644, mean_absolute_error: 2.460881, mean_q: 3.279035
199 (array([22]),) False
  96560/500000: episode: 2414, duration: 32.271s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.450 [11.000, 56.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.129531, mean_absolute_error: 2.475346, mean_q: 3.301136
88 (array([22]),) False
  96600/500000: episode: 2415, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.175 [8.000, 42.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.132805, mean_absolute_error: 2.473578, mean_q: 3.303297
748 (array([22]),) False
  96640/500000: episode: 2416, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.400 [22.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.130708, mean_absolute_error: 2.516397, mean_q: 3.354897
748 (array([22]),) False
  96680/500000: episode: 2417, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.050 [2.000, 57.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.134507, mean_absolute_error: 2.466694, mean_q: 3.302037
537 (array([22]),) False
  96720/500000: episode: 2418, duration: 32.412s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.450 [21.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.130418, mean_absolute_error: 2.462898, mean_q: 3.292403
234 (array([22]),) False
  96760/500000: episode: 2419, duration: 33.310s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.650 [6.000, 54.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.128665, mean_absolute_error: 2.473860, mean_q: 3.302384
575 (array([44]),) False
  96800/500000: episode: 2420, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 42.925 [4.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.131425, mean_absolute_error: 2.437316, mean_q: 3.264234
162 (array([22]),) False
  96840/500000: episode: 2421, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.250 [19.000, 54.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.123559, mean_absolute_error: 2.470648, mean_q: 3.299515
514 (array([54]),) False
  96880/500000: episode: 2422, duration: 32.378s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.325 [0.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.135696, mean_absolute_error: 2.473478, mean_q: 3.309510
341 (array([22]),) False
  96920/500000: episode: 2423, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.175 [0.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.137105, mean_absolute_error: 2.481414, mean_q: 3.312791
411 (array([22]),) False
  96960/500000: episode: 2424, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.550 [6.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.131511, mean_absolute_error: 2.487637, mean_q: 3.315016
861 (array([22]),) False
  97000/500000: episode: 2425, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.600 [5.000, 44.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.136580, mean_absolute_error: 2.466216, mean_q: 3.301278
282 (array([22]),) False
  97040/500000: episode: 2426, duration: 32.313s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.375 [18.000, 57.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.139180, mean_absolute_error: 2.457915, mean_q: 3.294922
636 (array([12]),) False
  97080/500000: episode: 2427, duration: 33.242s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 41.875 [1.000, 53.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.133845, mean_absolute_error: 2.477852, mean_q: 3.317611
650 (array([22]),) False
  97120/500000: episode: 2428, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.500 [4.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.133098, mean_absolute_error: 2.478080, mean_q: 3.309581
159 (array([48]),) False
  97160/500000: episode: 2429, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.325 [3.000, 57.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.136492, mean_absolute_error: 2.487659, mean_q: 3.319897
670 (array([22]),) False
  97200/500000: episode: 2430, duration: 32.380s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 32.875 [1.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.137598, mean_absolute_error: 2.454804, mean_q: 3.287733
262 (array([22]),) False
  97240/500000: episode: 2431, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 23.800 [3.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.125048, mean_absolute_error: 2.453821, mean_q: 3.288659
291 (array([22]),) False
  97280/500000: episode: 2432, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.575 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.131893, mean_absolute_error: 2.472710, mean_q: 3.305894
383 (array([22]),) False
  97320/500000: episode: 2433, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.250 [12.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.137227, mean_absolute_error: 2.449463, mean_q: 3.293164
679 (array([44]),) False
  97360/500000: episode: 2434, duration: 32.331s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.325 [2.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.125439, mean_absolute_error: 2.463700, mean_q: 3.304622
341 (array([22]),) False
  97400/500000: episode: 2435, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.825 [6.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.125255, mean_absolute_error: 2.445535, mean_q: 3.272142
831 (array([3]),) False
  97440/500000: episode: 2436, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 11.425 [0.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.132727, mean_absolute_error: 2.454585, mean_q: 3.284098
34 (array([22]),) False
  97480/500000: episode: 2437, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.850 [2.000, 54.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.127830, mean_absolute_error: 2.465375, mean_q: 3.290736
736 (array([22]),) False
  97520/500000: episode: 2438, duration: 32.341s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.675 [1.000, 44.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.131786, mean_absolute_error: 2.450738, mean_q: 3.270305
552 (array([22]),) False
  97560/500000: episode: 2439, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.825 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.134616, mean_absolute_error: 2.461260, mean_q: 3.273695
592 (array([22]),) False
  97600/500000: episode: 2440, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.800 [15.000, 56.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.132428, mean_absolute_error: 2.475074, mean_q: 3.307949
151 (array([22]),) False
  97640/500000: episode: 2441, duration: 33.299s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.850 [5.000, 51.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.126594, mean_absolute_error: 2.442146, mean_q: 3.273286
237 (array([22]),) False
  97680/500000: episode: 2442, duration: 32.356s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.075 [8.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.129931, mean_absolute_error: 2.436942, mean_q: 3.268123
273 (array([22]),) False
  97720/500000: episode: 2443, duration: 33.370s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.700 [6.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.130926, mean_absolute_error: 2.400613, mean_q: 3.223456
486 (array([22]),) False
  97760/500000: episode: 2444, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 20.450 [0.000, 23.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.126950, mean_absolute_error: 2.426866, mean_q: 3.255076
753 (array([22]),) False
  97800/500000: episode: 2445, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.600 [22.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.131711, mean_absolute_error: 2.442397, mean_q: 3.266888
734 (array([48]),) False
  97840/500000: episode: 2446, duration: 32.349s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 23.725 [5.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.123551, mean_absolute_error: 2.433913, mean_q: 3.266207
184 (array([12]),) False
  97880/500000: episode: 2447, duration: 33.314s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 19.800 [3.000, 48.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.135510, mean_absolute_error: 2.457463, mean_q: 3.287369
138 (array([3]),) False
  97920/500000: episode: 2448, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 9.275 [3.000, 52.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.131418, mean_absolute_error: 2.451976, mean_q: 3.283277
685 (array([22]),) False
  97960/500000: episode: 2449, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.075 [3.000, 53.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.138560, mean_absolute_error: 2.473408, mean_q: 3.305689
791 (array([54]),) False
  98000/500000: episode: 2450, duration: 32.399s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 35.300 [10.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.132365, mean_absolute_error: 2.477192, mean_q: 3.310931
648 (array([22]),) False
  98040/500000: episode: 2451, duration: 33.283s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 25.200 [22.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.132390, mean_absolute_error: 2.479838, mean_q: 3.305964
287 (array([48]),) False
  98080/500000: episode: 2452, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 23.650 [1.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.132678, mean_absolute_error: 2.456913, mean_q: 3.288901
18 (array([22]),) False
  98120/500000: episode: 2453, duration: 33.235s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.325 [22.000, 52.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.135855, mean_absolute_error: 2.467064, mean_q: 3.293348
664 (array([22]),) False
  98160/500000: episode: 2454, duration: 32.232s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.875 [11.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.136788, mean_absolute_error: 2.483850, mean_q: 3.315187
632 (array([22]),) False
  98200/500000: episode: 2455, duration: 33.338s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.975 [8.000, 57.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.134145, mean_absolute_error: 2.489960, mean_q: 3.330292
490 (array([12]),) False
  98240/500000: episode: 2456, duration: 33.295s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 15.525 [4.000, 48.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.140598, mean_absolute_error: 2.468236, mean_q: 3.298758
576 (array([58]),) False
  98280/500000: episode: 2457, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 53.925 [4.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.132011, mean_absolute_error: 2.461890, mean_q: 3.290868
20 (array([22]),) False
  98320/500000: episode: 2458, duration: 32.248s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.125 [5.000, 42.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.133934, mean_absolute_error: 2.464540, mean_q: 3.293280
799 (array([36]),) False
  98360/500000: episode: 2459, duration: 31.513s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 42.250 [6.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.132561, mean_absolute_error: 2.472336, mean_q: 3.305252
174 (array([33]),) False
  98400/500000: episode: 2460, duration: 31.499s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.800 [7.000, 58.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.126875, mean_absolute_error: 2.476916, mean_q: 3.311368
614 (array([22]),) False
  98440/500000: episode: 2461, duration: 31.561s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.800 [1.000, 50.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.141169, mean_absolute_error: 2.460704, mean_q: 3.289233
399 (array([22]),) False
  98480/500000: episode: 2462, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 28.925 [1.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.134223, mean_absolute_error: 2.467825, mean_q: 3.306844
254 (array([22]),) False
  98520/500000: episode: 2463, duration: 31.497s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.350 [19.000, 39.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.136109, mean_absolute_error: 2.455140, mean_q: 3.285110
344 (array([22]),) False
  98560/500000: episode: 2464, duration: 31.476s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.500 [2.000, 35.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.128267, mean_absolute_error: 2.462971, mean_q: 3.298024
193 (array([36]),) False
  98600/500000: episode: 2465, duration: 31.507s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 43.825 [22.000, 58.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.134396, mean_absolute_error: 2.470044, mean_q: 3.297775
452 (array([22]),) False
  98640/500000: episode: 2466, duration: 31.053s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.100 [19.000, 52.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.133622, mean_absolute_error: 2.466397, mean_q: 3.301774
279 (array([22]),) False
  98680/500000: episode: 2467, duration: 31.500s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 39.800 [0.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.133818, mean_absolute_error: 2.446298, mean_q: 3.280649
791 (array([54]),) False
  98720/500000: episode: 2468, duration: 31.470s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 29.400 [1.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.133011, mean_absolute_error: 2.414567, mean_q: 3.250468
739 (array([22]),) False
  98760/500000: episode: 2469, duration: 31.471s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.575 [2.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.132601, mean_absolute_error: 2.443032, mean_q: 3.286582
198 (array([22]),) False
  98800/500000: episode: 2470, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 21.600 [8.000, 48.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.128280, mean_absolute_error: 2.436153, mean_q: 3.277409
700 (array([44]),) False
  98840/500000: episode: 2471, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 17.175 [1.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.137115, mean_absolute_error: 2.441478, mean_q: 3.284274
80 (array([42]),) False
  98880/500000: episode: 2472, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 40.875 [22.000, 59.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.133642, mean_absolute_error: 2.450883, mean_q: 3.292907
364 (array([14]),) False
  98920/500000: episode: 2473, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 28.625 [3.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.131268, mean_absolute_error: 2.439544, mean_q: 3.280686
148 (array([22]),) False
  98960/500000: episode: 2474, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.625 [4.000, 51.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.127536, mean_absolute_error: 2.471779, mean_q: 3.319414
638 (array([22]),) False
  99000/500000: episode: 2475, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.025 [14.000, 51.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.138308, mean_absolute_error: 2.465036, mean_q: 3.303817
418 (array([22]),) False
  99040/500000: episode: 2476, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 25.000 [22.000, 51.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.132538, mean_absolute_error: 2.468297, mean_q: 3.304467
804 (array([3]),) False
  99080/500000: episode: 2477, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 9.500 [3.000, 46.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.134770, mean_absolute_error: 2.441225, mean_q: 3.278460
222 (array([22]),) False
  99120/500000: episode: 2478, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.125 [14.000, 54.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.133010, mean_absolute_error: 2.472177, mean_q: 3.315246
83 (array([22]),) False
  99160/500000: episode: 2479, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.000 [11.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.130052, mean_absolute_error: 2.467331, mean_q: 3.303804
596 (array([22]),) False
  99200/500000: episode: 2480, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.875 [2.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.133602, mean_absolute_error: 2.489135, mean_q: 3.322706
723 (array([48]),) False
  99240/500000: episode: 2481, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 22.150 [12.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.142353, mean_absolute_error: 2.458368, mean_q: 3.291602
689 (array([12]),) False
  99280/500000: episode: 2482, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 16.275 [4.000, 56.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.129898, mean_absolute_error: 2.480000, mean_q: 3.318957
295 (array([22]),) False
  99320/500000: episode: 2483, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.650 [5.000, 44.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.135973, mean_absolute_error: 2.465286, mean_q: 3.295975
466 (array([22]),) False
  99360/500000: episode: 2484, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.975 [2.000, 50.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.132413, mean_absolute_error: 2.450335, mean_q: 3.285648
593 (array([37]),) False
  99400/500000: episode: 2485, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.150 [3.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.127327, mean_absolute_error: 2.443345, mean_q: 3.288716
139 (array([48]),) False
  99440/500000: episode: 2486, duration: 32.217s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 21.700 [4.000, 39.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.137281, mean_absolute_error: 2.470970, mean_q: 3.308158
627 (array([48]),) False
  99480/500000: episode: 2487, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 42.750 [2.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.132983, mean_absolute_error: 2.480791, mean_q: 3.308771
152 (array([58]),) False
  99520/500000: episode: 2488, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 54.075 [0.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.131550, mean_absolute_error: 2.483960, mean_q: 3.332721
611 (array([22]),) False
  99560/500000: episode: 2489, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 45.075 [8.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.137335, mean_absolute_error: 2.478237, mean_q: 3.326963
438 (array([22]),) False
  99600/500000: episode: 2490, duration: 32.246s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.250 [3.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.139066, mean_absolute_error: 2.482749, mean_q: 3.329753
841 (array([21]),) False
  99640/500000: episode: 2491, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.175 [0.000, 50.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.125564, mean_absolute_error: 2.475393, mean_q: 3.324761
138 (array([3]),) False
  99680/500000: episode: 2492, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 9.600 [3.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.130885, mean_absolute_error: 2.490413, mean_q: 3.343108
465 (array([48]),) False
  99720/500000: episode: 2493, duration: 31.765s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 43.975 [4.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.137338, mean_absolute_error: 2.515114, mean_q: 3.361209
594 (array([48]),) False
  99760/500000: episode: 2494, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.525 [3.000, 52.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.137104, mean_absolute_error: 2.523547, mean_q: 3.365655
58 (array([48]),) False
  99800/500000: episode: 2495, duration: 31.599s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.475 [1.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.131757, mean_absolute_error: 2.525069, mean_q: 3.373341
290 (array([22]),) False
  99840/500000: episode: 2496, duration: 31.539s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.850 [21.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.132281, mean_absolute_error: 2.511917, mean_q: 3.362358
122 (array([12]),) False
  99880/500000: episode: 2497, duration: 31.559s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 31.075 [6.000, 58.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.140918, mean_absolute_error: 2.540697, mean_q: 3.396495
166 (array([22]),) False
  99920/500000: episode: 2498, duration: 31.119s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 20.725 [3.000, 47.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.144677, mean_absolute_error: 2.539392, mean_q: 3.393481
858 (array([12]),) False
  99960/500000: episode: 2499, duration: 31.588s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 14.225 [1.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.140406, mean_absolute_error: 2.515100, mean_q: 3.349924
812 (array([22]),) False
 100000/500000: episode: 2500, duration: 31.630s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.550 [7.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.134982, mean_absolute_error: 2.517280, mean_q: 3.343817
83 (array([22]),) False
 100040/500000: episode: 2501, duration: 31.464s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.150 [13.000, 54.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.140529, mean_absolute_error: 2.520009, mean_q: 3.356728
234 (array([22]),) False
 100080/500000: episode: 2502, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.325 [15.000, 48.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.135534, mean_absolute_error: 2.513246, mean_q: 3.354165
839 (array([22]),) False
 100120/500000: episode: 2503, duration: 31.787s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.400 [1.000, 52.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.138473, mean_absolute_error: 2.522970, mean_q: 3.360723
36 (array([22]),) False
 100160/500000: episode: 2504, duration: 31.753s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.225 [9.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.129390, mean_absolute_error: 2.536038, mean_q: 3.378434
591 (array([22]),) False
 100200/500000: episode: 2505, duration: 31.448s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.100 [9.000, 51.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.136937, mean_absolute_error: 2.532524, mean_q: 3.381633
160 (array([12]),) False
 100240/500000: episode: 2506, duration: 31.117s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 17.800 [3.000, 44.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.140613, mean_absolute_error: 2.513277, mean_q: 3.337457
702 (array([22]),) False
 100280/500000: episode: 2507, duration: 31.500s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.200 [9.000, 50.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.136537, mean_absolute_error: 2.504831, mean_q: 3.325702
205 (array([22]),) False
 100320/500000: episode: 2508, duration: 31.545s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.850 [21.000, 57.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.133198, mean_absolute_error: 2.511308, mean_q: 3.351189
725 (array([36]),) False
 100360/500000: episode: 2509, duration: 31.581s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 7.775 [3.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.123828, mean_absolute_error: 2.509404, mean_q: 3.342095
771 (array([12]),) False
 100400/500000: episode: 2510, duration: 31.110s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 15.925 [7.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.141961, mean_absolute_error: 2.483257, mean_q: 3.316652
709 (array([41]),) False
 100440/500000: episode: 2511, duration: 31.581s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.650 [0.000, 53.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.137686, mean_absolute_error: 2.501320, mean_q: 3.341021
263 (array([8]),) False
 100480/500000: episode: 2512, duration: 31.530s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 15.175 [8.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.132109, mean_absolute_error: 2.514402, mean_q: 3.354519
624 (array([48]),) False
 100520/500000: episode: 2513, duration: 31.501s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.200 [1.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.139753, mean_absolute_error: 2.537971, mean_q: 3.378613
844 (array([48]),) False
 100560/500000: episode: 2514, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 38.100 [5.000, 49.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.137395, mean_absolute_error: 2.525977, mean_q: 3.369500
491 (array([22]),) False
 100600/500000: episode: 2515, duration: 32.965s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.175 [7.000, 47.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.136678, mean_absolute_error: 2.550616, mean_q: 3.389581
778 (array([12]),) False
 100640/500000: episode: 2516, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 15.250 [1.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.128829, mean_absolute_error: 2.541760, mean_q: 3.375970
59 (array([12]),) False
 100680/500000: episode: 2517, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.775 [11.000, 50.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.137591, mean_absolute_error: 2.520327, mean_q: 3.357893
668 (array([22]),) False
 100720/500000: episode: 2518, duration: 32.415s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.350 [3.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.137495, mean_absolute_error: 2.499028, mean_q: 3.332284
504 (array([48]),) False
 100760/500000: episode: 2519, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.775 [18.000, 53.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.144891, mean_absolute_error: 2.509070, mean_q: 3.347008
336 (array([12]),) False
 100800/500000: episode: 2520, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.075 [3.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.142843, mean_absolute_error: 2.536935, mean_q: 3.372397
650 (array([22]),) False
 100840/500000: episode: 2521, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.475 [4.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.146328, mean_absolute_error: 2.522443, mean_q: 3.358002
111 (array([22]),) False
 100880/500000: episode: 2522, duration: 32.334s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.050 [3.000, 53.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.140806, mean_absolute_error: 2.486501, mean_q: 3.305734
500 (array([22]),) False
 100920/500000: episode: 2523, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 43.400 [1.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.140570, mean_absolute_error: 2.510205, mean_q: 3.329093
482 (array([22]),) False
 100960/500000: episode: 2524, duration: 33.303s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.250 [22.000, 53.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.131371, mean_absolute_error: 2.526004, mean_q: 3.352685
520 (array([22]),) False
 101000/500000: episode: 2525, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.275 [22.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.144743, mean_absolute_error: 2.538225, mean_q: 3.379263
781 (array([8]),) False
 101040/500000: episode: 2526, duration: 32.372s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 28.075 [12.000, 44.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.147561, mean_absolute_error: 2.547329, mean_q: 3.383900
114 (array([22]),) False
 101080/500000: episode: 2527, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.175 [3.000, 59.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.138603, mean_absolute_error: 2.540223, mean_q: 3.377686
801 (array([58]),) False
 101120/500000: episode: 2528, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.500 [3.000, 49.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.135863, mean_absolute_error: 2.513671, mean_q: 3.346381
552 (array([22]),) False
 101160/500000: episode: 2529, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.400 [12.000, 37.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.133424, mean_absolute_error: 2.527774, mean_q: 3.368840
787 (array([3]),) False
 101200/500000: episode: 2530, duration: 31.663s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 24.575 [4.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.137038, mean_absolute_error: 2.490901, mean_q: 3.316663
414 (array([48]),) False
 101240/500000: episode: 2531, duration: 31.766s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 43.875 [7.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.137187, mean_absolute_error: 2.538683, mean_q: 3.379038
583 (array([22]),) False
 101280/500000: episode: 2532, duration: 31.601s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 15.175 [2.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.138892, mean_absolute_error: 2.520823, mean_q: 3.355817
95 (array([22]),) False
 101320/500000: episode: 2533, duration: 31.537s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.375 [5.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.135759, mean_absolute_error: 2.525403, mean_q: 3.359408
254 (array([22]),) False
 101360/500000: episode: 2534, duration: 31.115s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.125 [4.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.127375, mean_absolute_error: 2.496547, mean_q: 3.321895
320 (array([22]),) False
 101400/500000: episode: 2535, duration: 31.518s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.550 [8.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.134174, mean_absolute_error: 2.526849, mean_q: 3.367528
358 (array([22]),) False
 101440/500000: episode: 2536, duration: 31.550s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 43.750 [0.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.133865, mean_absolute_error: 2.510246, mean_q: 3.341870
293 (array([22]),) False
 101480/500000: episode: 2537, duration: 31.475s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.500 [0.000, 54.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.146287, mean_absolute_error: 2.521093, mean_q: 3.345578
313 (array([22]),) False
 101520/500000: episode: 2538, duration: 31.121s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.250 [6.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.149903, mean_absolute_error: 2.504934, mean_q: 3.345284
240 (array([22]),) False
 101560/500000: episode: 2539, duration: 31.608s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.925 [0.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.147272, mean_absolute_error: 2.514378, mean_q: 3.343134
779 (array([12]),) False
 101600/500000: episode: 2540, duration: 31.519s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 11.900 [0.000, 27.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.135613, mean_absolute_error: 2.494761, mean_q: 3.327282
151 (array([22]),) False
 101640/500000: episode: 2541, duration: 31.591s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.350 [8.000, 47.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.126782, mean_absolute_error: 2.521121, mean_q: 3.360443
364 (array([14]),) False
 101680/500000: episode: 2542, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.525 [3.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.132921, mean_absolute_error: 2.506243, mean_q: 3.348569
281 (array([48]),) False
 101720/500000: episode: 2543, duration: 31.654s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 22.675 [2.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.136972, mean_absolute_error: 2.493699, mean_q: 3.328941
733 (array([22]),) False
 101760/500000: episode: 2544, duration: 32.486s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.625 [7.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.137690, mean_absolute_error: 2.543071, mean_q: 3.382082
823 (array([58]),) False
 101800/500000: episode: 2545, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 39.050 [14.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.136839, mean_absolute_error: 2.528731, mean_q: 3.369320
625 (array([22]),) False
 101840/500000: episode: 2546, duration: 32.457s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 28.700 [22.000, 52.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.148692, mean_absolute_error: 2.511025, mean_q: 3.346246
130 (array([22]),) False
 101880/500000: episode: 2547, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.875 [13.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.148580, mean_absolute_error: 2.475603, mean_q: 3.330226
290 (array([22]),) False
 101920/500000: episode: 2548, duration: 32.293s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.650 [22.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.139866, mean_absolute_error: 2.496144, mean_q: 3.336161
853 (array([22]),) False
 101960/500000: episode: 2549, duration: 31.014s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.050 [6.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.140557, mean_absolute_error: 2.492102, mean_q: 3.333133
483 (array([48]),) False
 102000/500000: episode: 2550, duration: 30.161s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 46.300 [2.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.144155, mean_absolute_error: 2.520233, mean_q: 3.385705
284 (array([12]),) False
 102040/500000: episode: 2551, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.725 [0.000, 59.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.141667, mean_absolute_error: 2.495024, mean_q: 3.332546
460 (array([36]),) False
 102080/500000: episode: 2552, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.650 [6.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.132632, mean_absolute_error: 2.535702, mean_q: 3.376389
76 (array([38]),) False
 102120/500000: episode: 2553, duration: 31.067s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.525 [4.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.138390, mean_absolute_error: 2.491526, mean_q: 3.329208
494 (array([48]),) False
 102160/500000: episode: 2554, duration: 30.215s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 44.125 [1.000, 59.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.137153, mean_absolute_error: 2.498351, mean_q: 3.332626
592 (array([22]),) False
 102200/500000: episode: 2555, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.350 [22.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.137445, mean_absolute_error: 2.529396, mean_q: 3.363422
13 (array([48]),) False
 102240/500000: episode: 2556, duration: 31.213s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 35.950 [5.000, 57.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.133618, mean_absolute_error: 2.518155, mean_q: 3.362109
129 (array([22]),) False
 102280/500000: episode: 2557, duration: 31.187s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.925 [6.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.146258, mean_absolute_error: 2.495439, mean_q: 3.319781
107 (array([22]),) False
 102320/500000: episode: 2558, duration: 30.732s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.625 [1.000, 52.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.137456, mean_absolute_error: 2.526692, mean_q: 3.353680
791 (array([54]),) False
 102360/500000: episode: 2559, duration: 31.750s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 39.300 [8.000, 52.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.140464, mean_absolute_error: 2.503640, mean_q: 3.339022
301 (array([22]),) False
 102400/500000: episode: 2560, duration: 31.673s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.500 [2.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.137033, mean_absolute_error: 2.515986, mean_q: 3.348175
675 (array([22]),) False
 102440/500000: episode: 2561, duration: 31.876s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.625 [10.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.147864, mean_absolute_error: 2.526880, mean_q: 3.364707
214 (array([22]),) False
 102480/500000: episode: 2562, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.450 [9.000, 42.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.137310, mean_absolute_error: 2.484381, mean_q: 3.304859
336 (array([12]),) False
 102520/500000: episode: 2563, duration: 31.575s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.425 [3.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.139875, mean_absolute_error: 2.487615, mean_q: 3.315478
112 (array([12]),) False
 102560/500000: episode: 2564, duration: 31.477s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 13.125 [12.000, 52.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.139797, mean_absolute_error: 2.507863, mean_q: 3.337589
593 (array([37]),) False
 102600/500000: episode: 2565, duration: 31.525s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.225 [12.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.134286, mean_absolute_error: 2.512205, mean_q: 3.339202
261 (array([44]),) False
 102640/500000: episode: 2566, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.925 [8.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.138733, mean_absolute_error: 2.522917, mean_q: 3.362862
59 (array([12]),) False
 102680/500000: episode: 2567, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 24.250 [2.000, 54.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.138393, mean_absolute_error: 2.525356, mean_q: 3.359539
196 (array([22]),) False
 102720/500000: episode: 2568, duration: 31.467s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.925 [6.000, 51.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.139172, mean_absolute_error: 2.515569, mean_q: 3.352451
313 (array([22]),) False
 102760/500000: episode: 2569, duration: 31.529s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.225 [0.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.148801, mean_absolute_error: 2.477146, mean_q: 3.296777
531 (array([22]),) False
 102800/500000: episode: 2570, duration: 30.994s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.025 [12.000, 34.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.141428, mean_absolute_error: 2.521802, mean_q: 3.370254
232 (array([22]),) False
 102840/500000: episode: 2571, duration: 31.931s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.975 [1.000, 60.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.141139, mean_absolute_error: 2.490747, mean_q: 3.319340
518 (array([22]),) False
 102880/500000: episode: 2572, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.325 [2.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.140706, mean_absolute_error: 2.494911, mean_q: 3.327296
640 (array([22]),) False
 102920/500000: episode: 2573, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.475 [5.000, 53.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.136294, mean_absolute_error: 2.506663, mean_q: 3.344692
517 (array([22]),) False
 102960/500000: episode: 2574, duration: 32.162s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.900 [15.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.139750, mean_absolute_error: 2.482857, mean_q: 3.320899
793 (array([12]),) False
 103000/500000: episode: 2575, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.775 [4.000, 58.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.135138, mean_absolute_error: 2.488394, mean_q: 3.328831
643 (array([44]),) False
 103040/500000: episode: 2576, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 37.475 [2.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.133956, mean_absolute_error: 2.481078, mean_q: 3.322277
774 (array([57]),) False
 103080/500000: episode: 2577, duration: 32.967s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.450 [12.000, 50.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.142097, mean_absolute_error: 2.487729, mean_q: 3.323933
721 (array([22]),) False
 103120/500000: episode: 2578, duration: 32.108s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 27.125 [5.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.135473, mean_absolute_error: 2.507808, mean_q: 3.347348
79 (array([22]),) False
 103160/500000: episode: 2579, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.850 [1.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.133935, mean_absolute_error: 2.485701, mean_q: 3.315491
555 (array([22]),) False
 103200/500000: episode: 2580, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.400 [1.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.142631, mean_absolute_error: 2.495319, mean_q: 3.337006
179 (array([18]),) False
 103240/500000: episode: 2581, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 28.550 [1.000, 51.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.140996, mean_absolute_error: 2.485661, mean_q: 3.305759
833 (array([22]),) False
 103280/500000: episode: 2582, duration: 32.135s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.900 [18.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.146690, mean_absolute_error: 2.489108, mean_q: 3.324542
861 (array([22]),) False
 103320/500000: episode: 2583, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 29.050 [1.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.135854, mean_absolute_error: 2.476900, mean_q: 3.316418
305 (array([12]),) False
 103360/500000: episode: 2584, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.950 [15.000, 44.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.131641, mean_absolute_error: 2.466344, mean_q: 3.305597
312 (array([12]),) False
 103400/500000: episode: 2585, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 12.900 [0.000, 42.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.146078, mean_absolute_error: 2.461186, mean_q: 3.300111
843 (array([3]),) False
 103440/500000: episode: 2586, duration: 32.107s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 32.925 [3.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.132231, mean_absolute_error: 2.484479, mean_q: 3.325249
234 (array([22]),) False
 103480/500000: episode: 2587, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.825 [0.000, 55.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.142912, mean_absolute_error: 2.518255, mean_q: 3.359642
392 (array([40]),) False
 103520/500000: episode: 2588, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.425 [6.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.143099, mean_absolute_error: 2.528377, mean_q: 3.360922
280 (array([48]),) False
 103560/500000: episode: 2589, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 26.175 [0.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.135926, mean_absolute_error: 2.516537, mean_q: 3.340144
40 (array([22]),) False
 103600/500000: episode: 2590, duration: 32.124s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.625 [10.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.151535, mean_absolute_error: 2.491964, mean_q: 3.314364
507 (array([44]),) False
 103640/500000: episode: 2591, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.025 [3.000, 48.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.132702, mean_absolute_error: 2.478568, mean_q: 3.309709
681 (array([12]),) False
 103680/500000: episode: 2592, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.750 [0.000, 48.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.134498, mean_absolute_error: 2.497235, mean_q: 3.326246
482 (array([22]),) False
 103720/500000: episode: 2593, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.625 [22.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.137873, mean_absolute_error: 2.485083, mean_q: 3.317228
727 (array([12]),) False
 103760/500000: episode: 2594, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 15.275 [0.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.140141, mean_absolute_error: 2.522882, mean_q: 3.346716
148 (array([22]),) False
 103800/500000: episode: 2595, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.675 [3.000, 55.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.142165, mean_absolute_error: 2.486653, mean_q: 3.317105
143 (array([12]),) False
 103840/500000: episode: 2596, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.450 [14.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.159795, mean_absolute_error: 2.514439, mean_q: 3.337205
304 (array([22]),) False
 103880/500000: episode: 2597, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 29.325 [1.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.140382, mean_absolute_error: 2.512101, mean_q: 3.352046
268 (array([22]),) False
 103920/500000: episode: 2598, duration: 32.137s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.225 [2.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.140901, mean_absolute_error: 2.501916, mean_q: 3.332237
716 (array([48]),) False
 103960/500000: episode: 2599, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 36.325 [12.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.144999, mean_absolute_error: 2.495364, mean_q: 3.333739
112 (array([12]),) False
 104000/500000: episode: 2600, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 14.750 [5.000, 51.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.138815, mean_absolute_error: 2.500546, mean_q: 3.353750
729 (array([22]),) False
 104040/500000: episode: 2601, duration: 32.991s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 30.325 [4.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.137553, mean_absolute_error: 2.483264, mean_q: 3.329984
414 (array([48]),) False
 104080/500000: episode: 2602, duration: 32.141s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.675 [3.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.142448, mean_absolute_error: 2.493017, mean_q: 3.334595
443 (array([22]),) False
 104120/500000: episode: 2603, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.200 [1.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.144475, mean_absolute_error: 2.479588, mean_q: 3.314079
265 (array([22]),) False
 104160/500000: episode: 2604, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.975 [3.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.131744, mean_absolute_error: 2.502967, mean_q: 3.343642
252 (array([22]),) False
 104200/500000: episode: 2605, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.675 [0.000, 49.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.139617, mean_absolute_error: 2.525343, mean_q: 3.361329
154 (array([44]),) False
 104240/500000: episode: 2606, duration: 32.173s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 20.150 [9.000, 22.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.144933, mean_absolute_error: 2.479664, mean_q: 3.314388
440 (array([22]),) False
 104280/500000: episode: 2607, duration: 32.977s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.750 [19.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.141215, mean_absolute_error: 2.488322, mean_q: 3.314646
373 (array([22]),) False
 104320/500000: episode: 2608, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.425 [14.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.133019, mean_absolute_error: 2.483441, mean_q: 3.305765
615 (array([36]),) False
 104360/500000: episode: 2609, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 31.625 [8.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.152277, mean_absolute_error: 2.496820, mean_q: 3.337382
251 (array([3]),) False
 104400/500000: episode: 2610, duration: 32.153s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 5.875 [3.000, 46.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.130356, mean_absolute_error: 2.446020, mean_q: 3.280067
4 (array([22]),) False
 104440/500000: episode: 2611, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 24.550 [0.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.136534, mean_absolute_error: 2.487272, mean_q: 3.331733
19 (array([12]),) False
 104480/500000: episode: 2612, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.650 [4.000, 33.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.143759, mean_absolute_error: 2.472895, mean_q: 3.307334
130 (array([22]),) False
 104520/500000: episode: 2613, duration: 32.928s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.475 [4.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.136670, mean_absolute_error: 2.454932, mean_q: 3.288037
690 (array([22]),) False
 104560/500000: episode: 2614, duration: 31.979s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [6.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.135674, mean_absolute_error: 2.487270, mean_q: 3.316793
22 (array([37]),) False
 104600/500000: episode: 2615, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 27.375 [9.000, 51.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.136182, mean_absolute_error: 2.461413, mean_q: 3.291568
469 (array([22]),) False
 104640/500000: episode: 2616, duration: 32.750s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.250 [6.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.136967, mean_absolute_error: 2.465224, mean_q: 3.295763
53 (array([22]),) False
 104680/500000: episode: 2617, duration: 32.041s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.875 [1.000, 39.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.143265, mean_absolute_error: 2.485943, mean_q: 3.321314
641 (array([22]),) False
 104720/500000: episode: 2618, duration: 31.589s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.600 [4.000, 40.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.136838, mean_absolute_error: 2.465276, mean_q: 3.292934
109 (array([48]),) False
 104760/500000: episode: 2619, duration: 32.035s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.825 [4.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.140952, mean_absolute_error: 2.477808, mean_q: 3.311139
773 (array([22]),) False
 104800/500000: episode: 2620, duration: 32.714s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.350 [1.000, 36.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.137370, mean_absolute_error: 2.458689, mean_q: 3.290084
504 (array([48]),) False
 104840/500000: episode: 2621, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.775 [13.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.146761, mean_absolute_error: 2.467597, mean_q: 3.307192
296 (array([22]),) False
 104880/500000: episode: 2622, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.950 [2.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.141676, mean_absolute_error: 2.465396, mean_q: 3.298258
633 (array([22]),) False
 104920/500000: episode: 2623, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 29.825 [5.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.140836, mean_absolute_error: 2.475568, mean_q: 3.306979
22 (array([37]),) False
 104960/500000: episode: 2624, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 28.200 [1.000, 59.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.141719, mean_absolute_error: 2.479069, mean_q: 3.318460
401 (array([12]),) False
 105000/500000: episode: 2625, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 19.600 [12.000, 42.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.136902, mean_absolute_error: 2.497592, mean_q: 3.346183
764 (array([48]),) False
 105040/500000: episode: 2626, duration: 32.039s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.275 [8.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.147016, mean_absolute_error: 2.494701, mean_q: 3.334462
298 (array([22]),) False
 105080/500000: episode: 2627, duration: 32.965s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.100 [22.000, 48.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.135674, mean_absolute_error: 2.471736, mean_q: 3.299522
807 (array([22]),) False
 105120/500000: episode: 2628, duration: 32.381s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.100 [7.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.141428, mean_absolute_error: 2.483794, mean_q: 3.312678
217 (array([12]),) False
 105160/500000: episode: 2629, duration: 32.002s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 25.000 [12.000, 60.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.145648, mean_absolute_error: 2.526985, mean_q: 3.365220
437 (array([12]),) False
 105200/500000: episode: 2630, duration: 31.530s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 45.000 [13.000, 58.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.140152, mean_absolute_error: 2.484505, mean_q: 3.317020
369 (array([48]),) False
 105240/500000: episode: 2631, duration: 32.094s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 44.100 [1.000, 53.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.143281, mean_absolute_error: 2.483886, mean_q: 3.315703
235 (array([14]),) False
 105280/500000: episode: 2632, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 23.100 [4.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.137253, mean_absolute_error: 2.469683, mean_q: 3.289925
816 (array([4]),) False
 105320/500000: episode: 2633, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 54.650 [8.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.143298, mean_absolute_error: 2.489161, mean_q: 3.313872
112 (array([12]),) False
 105360/500000: episode: 2634, duration: 32.053s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 16.000 [12.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.137835, mean_absolute_error: 2.482735, mean_q: 3.317613
657 (array([48]),) False
 105400/500000: episode: 2635, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 41.950 [3.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.141093, mean_absolute_error: 2.502896, mean_q: 3.334270
844 (array([48]),) False
 105440/500000: episode: 2636, duration: 32.935s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 40.350 [6.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.139471, mean_absolute_error: 2.469108, mean_q: 3.292755
583 (array([22]),) False
 105480/500000: episode: 2637, duration: 32.917s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 15.625 [12.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.142243, mean_absolute_error: 2.479547, mean_q: 3.305340
731 (array([21]),) False
 105520/500000: episode: 2638, duration: 32.068s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.300 [1.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.140097, mean_absolute_error: 2.479722, mean_q: 3.315701
120 (array([44]),) False
 105560/500000: episode: 2639, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 35.825 [22.000, 44.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.147599, mean_absolute_error: 2.476665, mean_q: 3.299256
735 (array([22]),) False
 105600/500000: episode: 2640, duration: 32.936s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.025 [2.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.139761, mean_absolute_error: 2.477174, mean_q: 3.309134
395 (array([22]),) False
 105640/500000: episode: 2641, duration: 32.999s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.425 [2.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.141505, mean_absolute_error: 2.454576, mean_q: 3.274438
151 (array([22]),) False
 105680/500000: episode: 2642, duration: 32.119s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.275 [21.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.143961, mean_absolute_error: 2.475397, mean_q: 3.306336
388 (array([22]),) False
 105720/500000: episode: 2643, duration: 32.853s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.500 [1.000, 52.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.144423, mean_absolute_error: 2.462967, mean_q: 3.302122
225 (array([48]),) False
 105760/500000: episode: 2644, duration: 32.676s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 28.750 [3.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.142319, mean_absolute_error: 2.453154, mean_q: 3.291506
428 (array([22]),) False
 105800/500000: episode: 2645, duration: 32.379s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.800 [3.000, 47.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.140081, mean_absolute_error: 2.468791, mean_q: 3.309691
799 (array([36]),) False
 105840/500000: episode: 2646, duration: 31.535s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 42.000 [9.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.148217, mean_absolute_error: 2.462369, mean_q: 3.300699
103 (array([22]),) False
 105880/500000: episode: 2647, duration: 31.776s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.225 [1.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.143673, mean_absolute_error: 2.452420, mean_q: 3.286234
96 (array([22]),) False
 105920/500000: episode: 2648, duration: 31.545s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.525 [4.000, 36.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.145989, mean_absolute_error: 2.467261, mean_q: 3.306241
768 (array([22]),) False
 105960/500000: episode: 2649, duration: 31.496s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.725 [6.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.133153, mean_absolute_error: 2.441426, mean_q: 3.279695
607 (array([12]),) False
 106000/500000: episode: 2650, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 23.100 [12.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.144474, mean_absolute_error: 2.445668, mean_q: 3.283440
330 (array([38]),) False
 106040/500000: episode: 2651, duration: 31.449s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.875 [2.000, 57.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.144693, mean_absolute_error: 2.448748, mean_q: 3.277374
650 (array([22]),) False
 106080/500000: episode: 2652, duration: 31.511s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.000 [8.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.139688, mean_absolute_error: 2.470479, mean_q: 3.316887
68 (array([22]),) False
 106120/500000: episode: 2653, duration: 31.456s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.850 [10.000, 47.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.135643, mean_absolute_error: 2.441740, mean_q: 3.273320
717 (array([22]),) False
 106160/500000: episode: 2654, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.500 [3.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.144012, mean_absolute_error: 2.478393, mean_q: 3.315130
719 (array([22]),) False
 106200/500000: episode: 2655, duration: 31.501s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 18.600 [12.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.132494, mean_absolute_error: 2.468930, mean_q: 3.300367
63 (array([18]),) False
 106240/500000: episode: 2656, duration: 31.458s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 19.550 [9.000, 57.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.128589, mean_absolute_error: 2.482929, mean_q: 3.318082
540 (array([22]),) False
 106280/500000: episode: 2657, duration: 31.487s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.450 [19.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.140215, mean_absolute_error: 2.451303, mean_q: 3.284037
836 (array([22]),) False
 106320/500000: episode: 2658, duration: 31.876s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.475 [22.000, 54.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.142504, mean_absolute_error: 2.445209, mean_q: 3.279283
819 (array([48]),) False
 106360/500000: episode: 2659, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 41.550 [3.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.141506, mean_absolute_error: 2.447715, mean_q: 3.277870
71 (array([58]),) False
 106400/500000: episode: 2660, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 48.850 [8.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.149179, mean_absolute_error: 2.452271, mean_q: 3.290698
182 (array([54]),) False
 106440/500000: episode: 2661, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 34.825 [0.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.143556, mean_absolute_error: 2.440732, mean_q: 3.276873
616 (array([22]),) False
 106480/500000: episode: 2662, duration: 32.189s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.850 [6.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.142417, mean_absolute_error: 2.427857, mean_q: 3.260598
862 (array([14]),) False
 106520/500000: episode: 2663, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.325 [1.000, 52.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.138536, mean_absolute_error: 2.469539, mean_q: 3.315389
469 (array([22]),) False
 106560/500000: episode: 2664, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.900 [19.000, 22.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.139047, mean_absolute_error: 2.478585, mean_q: 3.330218
109 (array([48]),) False
 106600/500000: episode: 2665, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.600 [11.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.144270, mean_absolute_error: 2.471984, mean_q: 3.320462
380 (array([22]),) False
 106640/500000: episode: 2666, duration: 32.305s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.150 [9.000, 54.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.141759, mean_absolute_error: 2.494025, mean_q: 3.350647
731 (array([21]),) False
 106680/500000: episode: 2667, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.225 [3.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.142482, mean_absolute_error: 2.473578, mean_q: 3.321831
790 (array([48]),) False
 106720/500000: episode: 2668, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 46.000 [9.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.138509, mean_absolute_error: 2.443979, mean_q: 3.289536
625 (array([22]),) False
 106760/500000: episode: 2669, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.950 [0.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.137554, mean_absolute_error: 2.446629, mean_q: 3.299433
825 (array([22]),) False
 106800/500000: episode: 2670, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.200 [2.000, 55.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.142665, mean_absolute_error: 2.469035, mean_q: 3.304351
651 (array([22]),) False
 106840/500000: episode: 2671, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.325 [12.000, 33.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.139843, mean_absolute_error: 2.461215, mean_q: 3.301251
320 (array([22]),) False
 106880/500000: episode: 2672, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.075 [6.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.139581, mean_absolute_error: 2.499296, mean_q: 3.347380
635 (array([22]),) False
 106920/500000: episode: 2673, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.325 [2.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.139689, mean_absolute_error: 2.468350, mean_q: 3.314202
857 (array([22]),) False
 106960/500000: episode: 2674, duration: 30.001s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.175 [1.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.147684, mean_absolute_error: 2.466901, mean_q: 3.314559
760 (array([22]),) False
 107000/500000: episode: 2675, duration: 30.948s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 40.925 [5.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.150539, mean_absolute_error: 2.457115, mean_q: 3.310475
370 (array([58]),) False
 107040/500000: episode: 2676, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 32.800 [3.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.137083, mean_absolute_error: 2.460558, mean_q: 3.309223
623 (array([37]),) False
 107080/500000: episode: 2677, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 38.800 [3.000, 50.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.139354, mean_absolute_error: 2.465732, mean_q: 3.314365
789 (array([22]),) False
 107120/500000: episode: 2678, duration: 30.070s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.850 [15.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.136948, mean_absolute_error: 2.471349, mean_q: 3.314126
382 (array([22]),) False
 107160/500000: episode: 2679, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.075 [1.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.134221, mean_absolute_error: 2.473175, mean_q: 3.316390
706 (array([22]),) False
 107200/500000: episode: 2680, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.075 [9.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.140494, mean_absolute_error: 2.469370, mean_q: 3.318386
231 (array([22]),) False
 107240/500000: episode: 2681, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.150 [20.000, 53.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.132567, mean_absolute_error: 2.463647, mean_q: 3.303687
558 (array([40]),) False
 107280/500000: episode: 2682, duration: 30.079s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 23.125 [4.000, 52.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.133439, mean_absolute_error: 2.426270, mean_q: 3.262026
215 (array([22]),) False
 107320/500000: episode: 2683, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.175 [0.000, 58.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.148380, mean_absolute_error: 2.464067, mean_q: 3.303566
826 (array([22]),) False
 107360/500000: episode: 2684, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.450 [1.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.136887, mean_absolute_error: 2.458373, mean_q: 3.305417
124 (array([48]),) False
 107400/500000: episode: 2685, duration: 30.867s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.675 [17.000, 59.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.147428, mean_absolute_error: 2.425042, mean_q: 3.260215
691 (array([22]),) False
 107440/500000: episode: 2686, duration: 30.061s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.625 [5.000, 46.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.145161, mean_absolute_error: 2.453061, mean_q: 3.292810
106 (array([22]),) False
 107480/500000: episode: 2687, duration: 31.128s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 27.100 [14.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.132615, mean_absolute_error: 2.465914, mean_q: 3.314700
425 (array([22]),) False
 107520/500000: episode: 2688, duration: 31.658s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.350 [0.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.130903, mean_absolute_error: 2.432922, mean_q: 3.277102
398 (array([22]),) False
 107560/500000: episode: 2689, duration: 31.555s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 28.325 [4.000, 56.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.143722, mean_absolute_error: 2.472259, mean_q: 3.323671
663 (array([22]),) False
 107600/500000: episode: 2690, duration: 31.149s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.825 [3.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.139000, mean_absolute_error: 2.450841, mean_q: 3.290663
324 (array([12]),) False
 107640/500000: episode: 2691, duration: 31.607s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 28.725 [8.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.140565, mean_absolute_error: 2.482753, mean_q: 3.338022
585 (array([48]),) False
 107680/500000: episode: 2692, duration: 31.594s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 22.550 [0.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.138418, mean_absolute_error: 2.461761, mean_q: 3.309985
793 (array([12]),) False
 107720/500000: episode: 2693, duration: 31.791s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 21.375 [2.000, 54.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.149845, mean_absolute_error: 2.456962, mean_q: 3.295650
91 (array([48]),) False
 107760/500000: episode: 2694, duration: 31.043s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 43.075 [5.000, 50.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.137755, mean_absolute_error: 2.492187, mean_q: 3.330277
697 (array([22]),) False
 107800/500000: episode: 2695, duration: 31.570s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.850 [0.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.141670, mean_absolute_error: 2.444777, mean_q: 3.266681
773 (array([22]),) False
 107840/500000: episode: 2696, duration: 31.570s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.825 [8.000, 55.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.136163, mean_absolute_error: 2.468323, mean_q: 3.312545
344 (array([22]),) False
 107880/500000: episode: 2697, duration: 31.607s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.300 [8.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.137608, mean_absolute_error: 2.445716, mean_q: 3.280039
502 (array([22]),) False
 107920/500000: episode: 2698, duration: 31.103s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.500 [16.000, 50.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.144646, mean_absolute_error: 2.439106, mean_q: 3.274712
836 (array([22]),) False
 107960/500000: episode: 2699, duration: 31.532s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.500 [0.000, 52.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.147044, mean_absolute_error: 2.470760, mean_q: 3.308095
466 (array([22]),) False
 108000/500000: episode: 2700, duration: 31.529s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.900 [11.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.141922, mean_absolute_error: 2.470403, mean_q: 3.323301
740 (array([58]),) False
 108040/500000: episode: 2701, duration: 31.570s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 51.925 [3.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.141773, mean_absolute_error: 2.478454, mean_q: 3.316996
630 (array([22]),) False
 108080/500000: episode: 2702, duration: 31.098s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.550 [3.000, 59.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.133931, mean_absolute_error: 2.429944, mean_q: 3.261775
828 (array([48]),) False
 108120/500000: episode: 2703, duration: 31.638s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.900 [8.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.136375, mean_absolute_error: 2.469698, mean_q: 3.308131
337 (array([22]),) False
 108160/500000: episode: 2704, duration: 32.240s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.550 [3.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.136411, mean_absolute_error: 2.457753, mean_q: 3.297742
112 (array([12]),) False
 108200/500000: episode: 2705, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 15.725 [0.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.136994, mean_absolute_error: 2.451386, mean_q: 3.288533
152 (array([58]),) False
 108240/500000: episode: 2706, duration: 32.393s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 52.750 [2.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.129534, mean_absolute_error: 2.456818, mean_q: 3.302231
222 (array([22]),) False
 108280/500000: episode: 2707, duration: 33.278s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.500 [19.000, 56.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.137963, mean_absolute_error: 2.406635, mean_q: 3.243013
407 (array([22]),) False
 108320/500000: episode: 2708, duration: 33.286s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.500 [8.000, 50.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.130455, mean_absolute_error: 2.481637, mean_q: 3.331136
327 (array([22]),) False
 108360/500000: episode: 2709, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.850 [0.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.133931, mean_absolute_error: 2.465742, mean_q: 3.305467
701 (array([48]),) False
 108400/500000: episode: 2710, duration: 32.289s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 46.675 [23.000, 52.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.144083, mean_absolute_error: 2.464406, mean_q: 3.301193
692 (array([22]),) False
 108440/500000: episode: 2711, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.025 [2.000, 51.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.140218, mean_absolute_error: 2.460394, mean_q: 3.303928
322 (array([12]),) False
 108480/500000: episode: 2712, duration: 33.260s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 35.150 [0.000, 53.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.141674, mean_absolute_error: 2.447371, mean_q: 3.290875
300 (array([22]),) False
 108520/500000: episode: 2713, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.800 [3.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.137780, mean_absolute_error: 2.425725, mean_q: 3.263743
477 (array([22]),) False
 108560/500000: episode: 2714, duration: 32.305s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.575 [0.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.147942, mean_absolute_error: 2.450203, mean_q: 3.286898
771 (array([12]),) False
 108600/500000: episode: 2715, duration: 33.375s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 17.350 [12.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.134885, mean_absolute_error: 2.488114, mean_q: 3.331346
194 (array([44]),) False
 108640/500000: episode: 2716, duration: 33.257s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 42.200 [16.000, 53.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.147804, mean_absolute_error: 2.452337, mean_q: 3.289954
573 (array([22]),) False
 108680/500000: episode: 2717, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.050 [22.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.137205, mean_absolute_error: 2.447936, mean_q: 3.298981
380 (array([22]),) False
 108720/500000: episode: 2718, duration: 32.355s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.650 [4.000, 58.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.143597, mean_absolute_error: 2.460585, mean_q: 3.307870
603 (array([58]),) False
 108760/500000: episode: 2719, duration: 33.297s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 49.750 [2.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.140830, mean_absolute_error: 2.499256, mean_q: 3.339987
687 (array([44]),) False
 108800/500000: episode: 2720, duration: 33.261s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 34.825 [4.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.138026, mean_absolute_error: 2.456479, mean_q: 3.302713
824 (array([22]),) False
 108840/500000: episode: 2721, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.350 [1.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.141482, mean_absolute_error: 2.443222, mean_q: 3.281120
582 (array([44]),) False
 108880/500000: episode: 2722, duration: 32.328s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 35.300 [3.000, 55.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.147767, mean_absolute_error: 2.454692, mean_q: 3.296111
731 (array([21]),) False
 108920/500000: episode: 2723, duration: 33.290s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 21.650 [4.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.145646, mean_absolute_error: 2.475858, mean_q: 3.322282
442 (array([22]),) False
 108960/500000: episode: 2724, duration: 33.320s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.150 [17.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.142211, mean_absolute_error: 2.473300, mean_q: 3.318219
387 (array([22]),) False
 109000/500000: episode: 2725, duration: 33.251s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 20.750 [2.000, 33.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.143329, mean_absolute_error: 2.497953, mean_q: 3.340783
267 (array([22]),) False
 109040/500000: episode: 2726, duration: 32.365s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.850 [0.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.142131, mean_absolute_error: 2.480906, mean_q: 3.329157
598 (array([22]),) False
 109080/500000: episode: 2727, duration: 33.348s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 27.200 [14.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.145529, mean_absolute_error: 2.481187, mean_q: 3.328092
806 (array([22]),) False
 109120/500000: episode: 2728, duration: 33.286s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.250 [2.000, 26.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.140495, mean_absolute_error: 2.501912, mean_q: 3.343448
235 (array([14]),) False
 109160/500000: episode: 2729, duration: 33.280s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 20.150 [5.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.143421, mean_absolute_error: 2.487103, mean_q: 3.337304
744 (array([22]),) False
 109200/500000: episode: 2730, duration: 32.381s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.350 [10.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.133564, mean_absolute_error: 2.505661, mean_q: 3.367501
662 (array([12]),) False
 109240/500000: episode: 2731, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 20.075 [1.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.145454, mean_absolute_error: 2.464854, mean_q: 3.308181
571 (array([48]),) False
 109280/500000: episode: 2732, duration: 32.270s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 25.100 [8.000, 50.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.131650, mean_absolute_error: 2.508743, mean_q: 3.358006
660 (array([2]),) False
 109320/500000: episode: 2733, duration: 33.301s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 34.500 [22.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.146105, mean_absolute_error: 2.484937, mean_q: 3.333174
44 (array([22]),) False
 109360/500000: episode: 2734, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 23.500 [16.000, 52.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.144202, mean_absolute_error: 2.488329, mean_q: 3.328199
527 (array([58]),) False
 109400/500000: episode: 2735, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 50.125 [3.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.146133, mean_absolute_error: 2.457274, mean_q: 3.296894
648 (array([22]),) False
 109440/500000: episode: 2736, duration: 32.311s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.900 [1.000, 43.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.140653, mean_absolute_error: 2.494624, mean_q: 3.339686
685 (array([22]),) False
 109480/500000: episode: 2737, duration: 33.284s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.525 [15.000, 56.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.140795, mean_absolute_error: 2.472891, mean_q: 3.312985
406 (array([48]),) False
 109520/500000: episode: 2738, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 38.525 [10.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.140383, mean_absolute_error: 2.463771, mean_q: 3.308192
283 (array([34]),) False
 109560/500000: episode: 2739, duration: 33.277s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 21.325 [2.000, 47.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.155208, mean_absolute_error: 2.472790, mean_q: 3.306989
294 (array([22]),) False
 109600/500000: episode: 2740, duration: 32.328s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.100 [0.000, 50.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.144223, mean_absolute_error: 2.486687, mean_q: 3.328356
624 (array([48]),) False
 109640/500000: episode: 2741, duration: 33.312s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 44.325 [7.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.140266, mean_absolute_error: 2.511281, mean_q: 3.367342
572 (array([58]),) False
 109680/500000: episode: 2742, duration: 33.317s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 53.725 [18.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.148776, mean_absolute_error: 2.510387, mean_q: 3.358203
323 (array([55]),) False
 109720/500000: episode: 2743, duration: 33.364s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 43.925 [0.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.141971, mean_absolute_error: 2.530026, mean_q: 3.380573
17 (array([22]),) False
 109760/500000: episode: 2744, duration: 32.954s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.675 [0.000, 54.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.147967, mean_absolute_error: 2.514322, mean_q: 3.356649
136 (array([12]),) False
 109800/500000: episode: 2745, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 45.325 [22.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.138128, mean_absolute_error: 2.499712, mean_q: 3.350171
76 (array([38]),) False
 109840/500000: episode: 2746, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 40.775 [12.000, 60.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.143075, mean_absolute_error: 2.517980, mean_q: 3.370935
151 (array([22]),) False
 109880/500000: episode: 2747, duration: 33.235s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.075 [1.000, 54.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.145223, mean_absolute_error: 2.520470, mean_q: 3.373623
775 (array([58]),) False
 109920/500000: episode: 2748, duration: 32.248s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 50.950 [0.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.145029, mean_absolute_error: 2.488370, mean_q: 3.334946
211 (array([22]),) False
 109960/500000: episode: 2749, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.300 [18.000, 54.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.141031, mean_absolute_error: 2.506429, mean_q: 3.350975
523 (array([22]),) False
 110000/500000: episode: 2750, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.125 [5.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.144430, mean_absolute_error: 2.529376, mean_q: 3.376238
572 (array([58]),) False
 110040/500000: episode: 2751, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 54.400 [10.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.143830, mean_absolute_error: 2.553682, mean_q: 3.414223
556 (array([48]),) False
 110080/500000: episode: 2752, duration: 32.195s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 38.175 [10.000, 50.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.140922, mean_absolute_error: 2.531889, mean_q: 3.389369
354 (array([12]),) False
 110120/500000: episode: 2753, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 28.075 [7.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.139659, mean_absolute_error: 2.489456, mean_q: 3.335550
680 (array([22]),) False
 110160/500000: episode: 2754, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.825 [12.000, 53.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.146552, mean_absolute_error: 2.498511, mean_q: 3.348312
847 (array([21]),) False
 110200/500000: episode: 2755, duration: 32.682s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 27.675 [2.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.146418, mean_absolute_error: 2.548122, mean_q: 3.402022
52 (array([22]),) False
 110240/500000: episode: 2756, duration: 31.573s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.225 [6.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.144282, mean_absolute_error: 2.487168, mean_q: 3.331836
546 (array([22]),) False
 110280/500000: episode: 2757, duration: 31.511s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.500 [5.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.137287, mean_absolute_error: 2.517455, mean_q: 3.370267
332 (array([22]),) False
 110320/500000: episode: 2758, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 46.000 [8.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.148959, mean_absolute_error: 2.464130, mean_q: 3.299561
380 (array([22]),) False
 110360/500000: episode: 2759, duration: 31.492s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.625 [22.000, 59.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.144476, mean_absolute_error: 2.502381, mean_q: 3.353403
431 (array([22]),) False
 110400/500000: episode: 2760, duration: 31.121s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.100 [0.000, 56.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.140593, mean_absolute_error: 2.485697, mean_q: 3.332382
683 (array([22]),) False
 110440/500000: episode: 2761, duration: 31.534s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.325 [14.000, 57.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.146158, mean_absolute_error: 2.506123, mean_q: 3.363670
44 (array([22]),) False
 110480/500000: episode: 2762, duration: 31.172s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.325 [11.000, 54.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.134420, mean_absolute_error: 2.535188, mean_q: 3.395036
340 (array([12]),) False
 110520/500000: episode: 2763, duration: 31.592s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 19.450 [3.000, 41.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.146075, mean_absolute_error: 2.504177, mean_q: 3.353553
534 (array([22]),) False
 110560/500000: episode: 2764, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.300 [14.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.140286, mean_absolute_error: 2.518879, mean_q: 3.378892
769 (array([12]),) False
 110600/500000: episode: 2765, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 24.325 [2.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.156297, mean_absolute_error: 2.511295, mean_q: 3.361707
688 (array([22]),) False
 110640/500000: episode: 2766, duration: 32.907s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.975 [3.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.151099, mean_absolute_error: 2.469456, mean_q: 3.316500
63 (array([18]),) False
 110680/500000: episode: 2767, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 19.775 [3.000, 49.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.153356, mean_absolute_error: 2.504354, mean_q: 3.359446
426 (array([22]),) False
 110720/500000: episode: 2768, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.625 [9.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.149194, mean_absolute_error: 2.498684, mean_q: 3.344775
81 (array([22]),) False
 110760/500000: episode: 2769, duration: 33.286s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [3.000, 42.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.141244, mean_absolute_error: 2.483512, mean_q: 3.329027
304 (array([22]),) False
 110800/500000: episode: 2770, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 26.425 [3.000, 48.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.145946, mean_absolute_error: 2.497992, mean_q: 3.353594
100 (array([22]),) False
 110840/500000: episode: 2771, duration: 33.244s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.075 [22.000, 45.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.135728, mean_absolute_error: 2.509218, mean_q: 3.378344
236 (array([22]),) False
 110880/500000: episode: 2772, duration: 32.368s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.050 [1.000, 50.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.150507, mean_absolute_error: 2.504125, mean_q: 3.355125
755 (array([22]),) False
 110920/500000: episode: 2773, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.075 [12.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.143503, mean_absolute_error: 2.474175, mean_q: 3.326518
704 (array([22]),) False
 110960/500000: episode: 2774, duration: 32.276s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.625 [22.000, 37.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.132910, mean_absolute_error: 2.503227, mean_q: 3.356634
73 (array([22]),) False
 111000/500000: episode: 2775, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 14.975 [1.000, 39.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.152674, mean_absolute_error: 2.501847, mean_q: 3.346633
72 (array([12]),) False
 111040/500000: episode: 2776, duration: 32.323s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 18.000 [6.000, 59.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.146880, mean_absolute_error: 2.506028, mean_q: 3.356544
762 (array([22]),) False
 111080/500000: episode: 2777, duration: 33.264s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.025 [7.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.153655, mean_absolute_error: 2.518175, mean_q: 3.359460
590 (array([22]),) False
 111120/500000: episode: 2778, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.550 [2.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.155876, mean_absolute_error: 2.529051, mean_q: 3.383298
262 (array([22]),) False
 111160/500000: episode: 2779, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 20.425 [2.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.146137, mean_absolute_error: 2.510624, mean_q: 3.359111
683 (array([22]),) False
 111200/500000: episode: 2780, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.475 [22.000, 41.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.144964, mean_absolute_error: 2.518474, mean_q: 3.367407
272 (array([12]),) False
 111240/500000: episode: 2781, duration: 33.354s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.825 [10.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.145575, mean_absolute_error: 2.528534, mean_q: 3.383040
411 (array([22]),) False
 111280/500000: episode: 2782, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.375 [1.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.141057, mean_absolute_error: 2.557713, mean_q: 3.418592
137 (array([22]),) False
 111320/500000: episode: 2783, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.050 [21.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.148082, mean_absolute_error: 2.532858, mean_q: 3.395756
288 (array([33]),) False
 111360/500000: episode: 2784, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.250 [4.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.148165, mean_absolute_error: 2.516295, mean_q: 3.370085
648 (array([22]),) False
 111400/500000: episode: 2785, duration: 33.333s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.025 [16.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.153214, mean_absolute_error: 2.503354, mean_q: 3.360992
765 (array([48]),) False
 111440/500000: episode: 2786, duration: 32.318s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 44.200 [3.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.146579, mean_absolute_error: 2.519228, mean_q: 3.383644
52 (array([22]),) False
 111480/500000: episode: 2787, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.975 [0.000, 55.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.150179, mean_absolute_error: 2.512231, mean_q: 3.379595
464 (array([22]),) False
 111520/500000: episode: 2788, duration: 32.346s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.625 [14.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.142504, mean_absolute_error: 2.537177, mean_q: 3.386226
382 (array([22]),) False
 111560/500000: episode: 2789, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.475 [0.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.153777, mean_absolute_error: 2.510210, mean_q: 3.369667
411 (array([22]),) False
 111600/500000: episode: 2790, duration: 32.373s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.600 [5.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.139797, mean_absolute_error: 2.559499, mean_q: 3.432580
631 (array([22]),) False
 111640/500000: episode: 2791, duration: 33.292s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.725 [0.000, 51.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.151142, mean_absolute_error: 2.555796, mean_q: 3.410175
736 (array([22]),) False
 111680/500000: episode: 2792, duration: 32.343s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.725 [10.000, 40.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.141258, mean_absolute_error: 2.547513, mean_q: 3.408757
155 (array([22]),) False
 111720/500000: episode: 2793, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.500 [1.000, 57.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.152093, mean_absolute_error: 2.544299, mean_q: 3.397355
455 (array([22]),) False
 111760/500000: episode: 2794, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 40.600 [11.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.144578, mean_absolute_error: 2.529398, mean_q: 3.373819
458 (array([22]),) False
 111800/500000: episode: 2795, duration: 33.310s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.375 [11.000, 51.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.153505, mean_absolute_error: 2.577332, mean_q: 3.429883
531 (array([22]),) False
 111840/500000: episode: 2796, duration: 33.282s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.650 [0.000, 43.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.144111, mean_absolute_error: 2.550070, mean_q: 3.401229
718 (array([12]),) False
 111880/500000: episode: 2797, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 21.550 [12.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.149243, mean_absolute_error: 2.560623, mean_q: 3.410359
592 (array([22]),) False
 111920/500000: episode: 2798, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.100 [0.000, 44.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.152421, mean_absolute_error: 2.517305, mean_q: 3.357746
510 (array([22]),) False
 111960/500000: episode: 2799, duration: 33.254s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.700 [12.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.155165, mean_absolute_error: 2.543876, mean_q: 3.387947
149 (array([8]),) False
 112000/500000: episode: 2800, duration: 32.336s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 10.750 [8.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.147958, mean_absolute_error: 2.539388, mean_q: 3.387153
409 (array([22]),) False
 112040/500000: episode: 2801, duration: 33.285s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.800 [22.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.149958, mean_absolute_error: 2.536173, mean_q: 3.379977
640 (array([22]),) False
 112080/500000: episode: 2802, duration: 32.365s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.500 [16.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.140696, mean_absolute_error: 2.498896, mean_q: 3.344688
681 (array([12]),) False
 112120/500000: episode: 2803, duration: 33.356s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 23.075 [9.000, 51.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.143732, mean_absolute_error: 2.515345, mean_q: 3.366660
201 (array([22]),) False
 112160/500000: episode: 2804, duration: 32.370s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.325 [8.000, 54.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.150927, mean_absolute_error: 2.531979, mean_q: 3.379814
325 (array([22]),) False
 112200/500000: episode: 2805, duration: 33.319s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.475 [3.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.139378, mean_absolute_error: 2.530053, mean_q: 3.380259
327 (array([22]),) False
 112240/500000: episode: 2806, duration: 33.245s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.500 [3.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.148344, mean_absolute_error: 2.531680, mean_q: 3.384053
461 (array([22]),) False
 112280/500000: episode: 2807, duration: 33.256s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.375 [1.000, 42.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.142805, mean_absolute_error: 2.509110, mean_q: 3.355077
654 (array([22]),) False
 112320/500000: episode: 2808, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.125 [0.000, 47.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.143461, mean_absolute_error: 2.520437, mean_q: 3.367403
599 (array([48]),) False
 112360/500000: episode: 2809, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.950 [19.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.145051, mean_absolute_error: 2.548937, mean_q: 3.389983
685 (array([22]),) False
 112400/500000: episode: 2810, duration: 33.298s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.550 [16.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.141996, mean_absolute_error: 2.544096, mean_q: 3.390602
610 (array([48]),) False
 112440/500000: episode: 2811, duration: 33.339s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 23.800 [12.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.135465, mean_absolute_error: 2.565454, mean_q: 3.421589
239 (array([22]),) False
 112480/500000: episode: 2812, duration: 32.270s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.925 [1.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.144589, mean_absolute_error: 2.533811, mean_q: 3.380215
228 (array([44]),) False
 112520/500000: episode: 2813, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.900 [7.000, 49.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.146182, mean_absolute_error: 2.552451, mean_q: 3.402827
442 (array([22]),) False
 112560/500000: episode: 2814, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.775 [1.000, 52.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.153652, mean_absolute_error: 2.548011, mean_q: 3.395875
665 (array([12]),) False
 112600/500000: episode: 2815, duration: 31.543s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 14.250 [1.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.150628, mean_absolute_error: 2.531443, mean_q: 3.380784
545 (array([22]),) False
 112640/500000: episode: 2816, duration: 31.526s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.200 [7.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.147708, mean_absolute_error: 2.541383, mean_q: 3.394197
743 (array([48]),) False
 112680/500000: episode: 2817, duration: 31.672s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 38.425 [12.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.138101, mean_absolute_error: 2.516872, mean_q: 3.368409
144 (array([22]),) False
 112720/500000: episode: 2818, duration: 31.500s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.700 [5.000, 38.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.143856, mean_absolute_error: 2.521182, mean_q: 3.376286
162 (array([22]),) False
 112760/500000: episode: 2819, duration: 31.531s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.450 [10.000, 51.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.155307, mean_absolute_error: 2.542561, mean_q: 3.398739
554 (array([22]),) False
 112800/500000: episode: 2820, duration: 31.459s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.825 [10.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.153571, mean_absolute_error: 2.534361, mean_q: 3.391991
403 (array([12]),) False
 112840/500000: episode: 2821, duration: 31.476s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.050 [13.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.147175, mean_absolute_error: 2.564883, mean_q: 3.408052
148 (array([22]),) False
 112880/500000: episode: 2822, duration: 31.474s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.675 [3.000, 40.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.154470, mean_absolute_error: 2.517604, mean_q: 3.357187
511 (array([22]),) False
 112920/500000: episode: 2823, duration: 31.388s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.250 [7.000, 48.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.143312, mean_absolute_error: 2.523131, mean_q: 3.370423
729 (array([22]),) False
 112960/500000: episode: 2824, duration: 31.033s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 29.700 [5.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.153615, mean_absolute_error: 2.539017, mean_q: 3.388304
44 (array([22]),) False
 113000/500000: episode: 2825, duration: 31.521s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.000 [22.000, 59.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.145850, mean_absolute_error: 2.481897, mean_q: 3.323769
832 (array([22]),) False
 113040/500000: episode: 2826, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 26.425 [22.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.155250, mean_absolute_error: 2.509619, mean_q: 3.361379
631 (array([22]),) False
 113080/500000: episode: 2827, duration: 32.962s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.975 [18.000, 57.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.153014, mean_absolute_error: 2.548184, mean_q: 3.422252
479 (array([22]),) False
 113120/500000: episode: 2828, duration: 32.272s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.275 [2.000, 49.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.140965, mean_absolute_error: 2.511832, mean_q: 3.362923
703 (array([3]),) False
 113160/500000: episode: 2829, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 13.050 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.143885, mean_absolute_error: 2.550709, mean_q: 3.402683
90 (array([22]),) False
 113200/500000: episode: 2830, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.400 [8.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.154509, mean_absolute_error: 2.515449, mean_q: 3.367334
428 (array([22]),) False
 113240/500000: episode: 2831, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.825 [22.000, 53.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.141218, mean_absolute_error: 2.531593, mean_q: 3.378380
111 (array([22]),) False
 113280/500000: episode: 2832, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.125 [20.000, 51.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.161383, mean_absolute_error: 2.510436, mean_q: 3.358013
736 (array([22]),) False
 113320/500000: episode: 2833, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.975 [1.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.155565, mean_absolute_error: 2.481479, mean_q: 3.320403
49 (array([22]),) False
 113360/500000: episode: 2834, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.600 [0.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.136319, mean_absolute_error: 2.545038, mean_q: 3.409603
608 (array([36]),) False
 113400/500000: episode: 2835, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 33.375 [2.000, 36.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.138433, mean_absolute_error: 2.506191, mean_q: 3.356467
290 (array([22]),) False
 113440/500000: episode: 2836, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.050 [5.000, 41.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.149444, mean_absolute_error: 2.511055, mean_q: 3.361707
430 (array([22]),) False
 113480/500000: episode: 2837, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.175 [3.000, 59.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.134813, mean_absolute_error: 2.526337, mean_q: 3.378735
636 (array([12]),) False
 113520/500000: episode: 2838, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 40.225 [1.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.146379, mean_absolute_error: 2.506254, mean_q: 3.354491
568 (array([22]),) False
 113560/500000: episode: 2839, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.875 [7.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.155453, mean_absolute_error: 2.528039, mean_q: 3.364379
347 (array([22]),) False
 113600/500000: episode: 2840, duration: 32.280s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 42.500 [7.000, 50.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.142696, mean_absolute_error: 2.526481, mean_q: 3.367606
13 (array([48]),) False
 113640/500000: episode: 2841, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 33.775 [5.000, 48.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.151866, mean_absolute_error: 2.475411, mean_q: 3.316936
624 (array([48]),) False
 113680/500000: episode: 2842, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.000 [13.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.150300, mean_absolute_error: 2.520022, mean_q: 3.365073
613 (array([22]),) False
 113720/500000: episode: 2843, duration: 32.015s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.875 [4.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.140443, mean_absolute_error: 2.525276, mean_q: 3.379634
406 (array([48]),) False
 113760/500000: episode: 2844, duration: 32.613s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 43.925 [22.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.137219, mean_absolute_error: 2.546362, mean_q: 3.396985
476 (array([48]),) False
 113800/500000: episode: 2845, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 44.375 [5.000, 58.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.142088, mean_absolute_error: 2.498245, mean_q: 3.328595
322 (array([12]),) False
 113840/500000: episode: 2846, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 42.400 [12.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.143898, mean_absolute_error: 2.528243, mean_q: 3.375841
134 (array([58]),) False
 113880/500000: episode: 2847, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 42.600 [3.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.139031, mean_absolute_error: 2.521212, mean_q: 3.373163
13 (array([48]),) False
 113920/500000: episode: 2848, duration: 32.275s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 42.200 [7.000, 60.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.149153, mean_absolute_error: 2.514191, mean_q: 3.368882
347 (array([22]),) False
 113960/500000: episode: 2849, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.500 [11.000, 53.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.147809, mean_absolute_error: 2.511501, mean_q: 3.355193
599 (array([48]),) False
 114000/500000: episode: 2850, duration: 32.250s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.675 [7.000, 54.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.142392, mean_absolute_error: 2.495229, mean_q: 3.327580
94 (array([44]),) False
 114040/500000: episode: 2851, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 42.050 [17.000, 56.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.159326, mean_absolute_error: 2.507858, mean_q: 3.346380
527 (array([58]),) False
 114080/500000: episode: 2852, duration: 32.243s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 48.850 [19.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.139154, mean_absolute_error: 2.499468, mean_q: 3.343914
853 (array([22]),) False
 114120/500000: episode: 2853, duration: 33.326s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.525 [6.000, 53.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.149135, mean_absolute_error: 2.503621, mean_q: 3.341704
855 (array([12]),) False
 114160/500000: episode: 2854, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.350 [2.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.160287, mean_absolute_error: 2.489388, mean_q: 3.336241
617 (array([22]),) False
 114200/500000: episode: 2855, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.400 [0.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.144160, mean_absolute_error: 2.538466, mean_q: 3.393860
851 (array([48]),) False
 114240/500000: episode: 2856, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 45.750 [8.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.143064, mean_absolute_error: 2.505101, mean_q: 3.354213
306 (array([22]),) False
 114280/500000: episode: 2857, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.000 [4.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.145309, mean_absolute_error: 2.514714, mean_q: 3.372771
228 (array([44]),) False
 114320/500000: episode: 2858, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.100 [2.000, 50.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.146976, mean_absolute_error: 2.502562, mean_q: 3.354177
856 (array([48]),) False
 114360/500000: episode: 2859, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 42.300 [1.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.137814, mean_absolute_error: 2.495856, mean_q: 3.345709
275 (array([12]),) False
 114400/500000: episode: 2860, duration: 32.281s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.800 [1.000, 53.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.144369, mean_absolute_error: 2.515950, mean_q: 3.371371
150 (array([22]),) False
 114440/500000: episode: 2861, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.700 [8.000, 51.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.144409, mean_absolute_error: 2.527625, mean_q: 3.384612
689 (array([12]),) False
 114480/500000: episode: 2862, duration: 32.312s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 16.600 [5.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.144639, mean_absolute_error: 2.557779, mean_q: 3.420795
841 (array([21]),) False
 114520/500000: episode: 2863, duration: 33.235s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.850 [3.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.154434, mean_absolute_error: 2.579346, mean_q: 3.443613
822 (array([22]),) False
 114560/500000: episode: 2864, duration: 32.183s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.825 [1.000, 51.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.147831, mean_absolute_error: 2.549541, mean_q: 3.411787
259 (array([12]),) False
 114600/500000: episode: 2865, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 22.750 [3.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.151081, mean_absolute_error: 2.534998, mean_q: 3.391746
467 (array([48]),) False
 114640/500000: episode: 2866, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.025 [1.000, 54.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.158087, mean_absolute_error: 2.537016, mean_q: 3.370746
579 (array([58]),) False
 114680/500000: episode: 2867, duration: 33.279s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 52.150 [3.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.146242, mean_absolute_error: 2.535456, mean_q: 3.392664
252 (array([22]),) False
 114720/500000: episode: 2868, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.400 [0.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.142073, mean_absolute_error: 2.525900, mean_q: 3.374131
807 (array([22]),) False
 114760/500000: episode: 2869, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.700 [13.000, 51.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.136003, mean_absolute_error: 2.555752, mean_q: 3.416241
645 (array([48]),) False
 114800/500000: episode: 2870, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 47.425 [20.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.149305, mean_absolute_error: 2.563000, mean_q: 3.418860
293 (array([22]),) False
 114840/500000: episode: 2871, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.550 [6.000, 50.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.153904, mean_absolute_error: 2.560439, mean_q: 3.408607
291 (array([22]),) False
 114880/500000: episode: 2872, duration: 32.325s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.950 [6.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.145546, mean_absolute_error: 2.586940, mean_q: 3.449233
461 (array([22]),) False
 114920/500000: episode: 2873, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.650 [15.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.149034, mean_absolute_error: 2.575984, mean_q: 3.420460
574 (array([8]),) False
 114960/500000: episode: 2874, duration: 32.411s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.550 [16.000, 44.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.147557, mean_absolute_error: 2.601519, mean_q: 3.470295
57 (array([37]),) False
 115000/500000: episode: 2875, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.200 [7.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.151049, mean_absolute_error: 2.577550, mean_q: 3.431979
297 (array([15]),) False
 115040/500000: episode: 2876, duration: 32.342s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.275 [5.000, 49.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.147928, mean_absolute_error: 2.573979, mean_q: 3.423632
775 (array([58]),) False
 115080/500000: episode: 2877, duration: 33.310s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 55.300 [11.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.148860, mean_absolute_error: 2.584825, mean_q: 3.451556
783 (array([22]),) False
 115120/500000: episode: 2878, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.200 [22.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.152559, mean_absolute_error: 2.585749, mean_q: 3.447173
589 (array([22]),) False
 115160/500000: episode: 2879, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.900 [10.000, 56.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.145925, mean_absolute_error: 2.577388, mean_q: 3.437832
703 (array([3]),) False
 115200/500000: episode: 2880, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 7.025 [3.000, 36.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.150712, mean_absolute_error: 2.580203, mean_q: 3.437852
507 (array([44]),) False
 115240/500000: episode: 2881, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 31.900 [2.000, 54.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.156318, mean_absolute_error: 2.607985, mean_q: 3.460688
343 (array([22]),) False
 115280/500000: episode: 2882, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.625 [20.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.147426, mean_absolute_error: 2.607915, mean_q: 3.453162
564 (array([22]),) False
 115320/500000: episode: 2883, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.325 [7.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.154705, mean_absolute_error: 2.539771, mean_q: 3.393537
673 (array([3]),) False
 115360/500000: episode: 2884, duration: 32.340s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 9.325 [3.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.155229, mean_absolute_error: 2.580276, mean_q: 3.436658
676 (array([40]),) False
 115400/500000: episode: 2885, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 28.325 [3.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.150347, mean_absolute_error: 2.587009, mean_q: 3.445553
546 (array([22]),) False
 115440/500000: episode: 2886, duration: 32.260s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.400 [4.000, 45.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.163536, mean_absolute_error: 2.583191, mean_q: 3.440292
663 (array([22]),) False
 115480/500000: episode: 2887, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.200 [3.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.162631, mean_absolute_error: 2.567825, mean_q: 3.415202
797 (array([22]),) False
 115520/500000: episode: 2888, duration: 32.239s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.550 [11.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.157476, mean_absolute_error: 2.557669, mean_q: 3.420249
699 (array([22]),) False
 115560/500000: episode: 2889, duration: 33.290s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.025 [12.000, 57.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.141613, mean_absolute_error: 2.551617, mean_q: 3.400371
492 (array([22]),) False
 115600/500000: episode: 2890, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.575 [2.000, 48.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.146453, mean_absolute_error: 2.600616, mean_q: 3.453446
763 (array([48]),) False
 115640/500000: episode: 2891, duration: 32.443s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 45.800 [9.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.148804, mean_absolute_error: 2.600786, mean_q: 3.469151
217 (array([12]),) False
 115680/500000: episode: 2892, duration: 31.512s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 19.725 [10.000, 50.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.151152, mean_absolute_error: 2.604538, mean_q: 3.465886
513 (array([12]),) False
 115720/500000: episode: 2893, duration: 32.398s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 38.550 [12.000, 54.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.153727, mean_absolute_error: 2.586611, mean_q: 3.447624
461 (array([22]),) False
 115760/500000: episode: 2894, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 20.725 [3.000, 33.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.146438, mean_absolute_error: 2.550872, mean_q: 3.402876
118 (array([22]),) False
 115800/500000: episode: 2895, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.075 [4.000, 50.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.147598, mean_absolute_error: 2.581443, mean_q: 3.432992
666 (array([22]),) False
 115840/500000: episode: 2896, duration: 32.230s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.275 [22.000, 52.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.154495, mean_absolute_error: 2.605520, mean_q: 3.465458
632 (array([22]),) False
 115880/500000: episode: 2897, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.100 [3.000, 47.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.142534, mean_absolute_error: 2.561287, mean_q: 3.429106
111 (array([22]),) False
 115920/500000: episode: 2898, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.550 [12.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.147652, mean_absolute_error: 2.561960, mean_q: 3.421421
183 (array([22]),) False
 115960/500000: episode: 2899, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.875 [1.000, 47.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.149021, mean_absolute_error: 2.577255, mean_q: 3.452832
188 (array([22]),) False
 116000/500000: episode: 2900, duration: 32.187s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.825 [5.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.150728, mean_absolute_error: 2.589206, mean_q: 3.471460
58 (array([48]),) False
 116040/500000: episode: 2901, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 44.700 [2.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.161065, mean_absolute_error: 2.613611, mean_q: 3.492166
188 (array([22]),) False
 116080/500000: episode: 2902, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.325 [17.000, 55.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.160223, mean_absolute_error: 2.593506, mean_q: 3.460316
515 (array([22]),) False
 116120/500000: episode: 2903, duration: 33.370s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [6.000, 56.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.148739, mean_absolute_error: 2.623993, mean_q: 3.492009
114 (array([22]),) False
 116160/500000: episode: 2904, duration: 33.349s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.450 [0.000, 57.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.156982, mean_absolute_error: 2.599674, mean_q: 3.464471
593 (array([37]),) False
 116200/500000: episode: 2905, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.450 [12.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.156694, mean_absolute_error: 2.607205, mean_q: 3.468348
314 (array([22]),) False
 116240/500000: episode: 2906, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.025 [12.000, 49.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.155737, mean_absolute_error: 2.599463, mean_q: 3.458139
15 (array([22]),) False
 116280/500000: episode: 2907, duration: 33.248s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.850 [0.000, 49.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.153262, mean_absolute_error: 2.619502, mean_q: 3.483319
374 (array([22]),) False
 116320/500000: episode: 2908, duration: 32.302s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.950 [14.000, 54.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.153320, mean_absolute_error: 2.624587, mean_q: 3.492145
447 (array([44]),) False
 116360/500000: episode: 2909, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 35.375 [22.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.143184, mean_absolute_error: 2.614413, mean_q: 3.486507
154 (array([44]),) False
 116400/500000: episode: 2910, duration: 32.401s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 25.025 [22.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.157115, mean_absolute_error: 2.622517, mean_q: 3.505904
114 (array([22]),) False
 116440/500000: episode: 2911, duration: 33.246s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.325 [2.000, 54.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.157118, mean_absolute_error: 2.628005, mean_q: 3.493517
687 (array([44]),) False
 116480/500000: episode: 2912, duration: 32.294s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 42.075 [2.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.154049, mean_absolute_error: 2.613656, mean_q: 3.468620
687 (array([44]),) False
 116520/500000: episode: 2913, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 42.700 [10.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.147763, mean_absolute_error: 2.646205, mean_q: 3.517206
150 (array([22]),) False
 116560/500000: episode: 2914, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.625 [2.000, 56.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.154491, mean_absolute_error: 2.651694, mean_q: 3.522122
778 (array([12]),) False
 116600/500000: episode: 2915, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 17.250 [12.000, 45.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.168597, mean_absolute_error: 2.622525, mean_q: 3.481164
14 (array([48]),) False
 116640/500000: episode: 2916, duration: 33.244s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 42.250 [5.000, 53.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.147371, mean_absolute_error: 2.653780, mean_q: 3.521173
862 (array([14]),) False
 116680/500000: episode: 2917, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 27.350 [14.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.145092, mean_absolute_error: 2.637510, mean_q: 3.496545
218 (array([22]),) False
 116720/500000: episode: 2918, duration: 33.202s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.275 [7.000, 57.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.150936, mean_absolute_error: 2.624294, mean_q: 3.485455
26 (array([22]),) False
 116760/500000: episode: 2919, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.425 [9.000, 50.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.160018, mean_absolute_error: 2.617910, mean_q: 3.487955
609 (array([22]),) False
 116800/500000: episode: 2920, duration: 32.300s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.125 [1.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.158618, mean_absolute_error: 2.643523, mean_q: 3.519969
124 (array([48]),) False
 116840/500000: episode: 2921, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 46.275 [23.000, 52.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.147559, mean_absolute_error: 2.642801, mean_q: 3.514063
360 (array([22]),) False
 116880/500000: episode: 2922, duration: 32.343s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 22.200 [5.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.149728, mean_absolute_error: 2.623588, mean_q: 3.484364
719 (array([22]),) False
 116920/500000: episode: 2923, duration: 33.274s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 16.050 [6.000, 39.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.147272, mean_absolute_error: 2.587920, mean_q: 3.437766
440 (array([22]),) False
 116960/500000: episode: 2924, duration: 32.389s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.100 [4.000, 45.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.146225, mean_absolute_error: 2.628096, mean_q: 3.491423
789 (array([22]),) False
 117000/500000: episode: 2925, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.125 [7.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.144518, mean_absolute_error: 2.590771, mean_q: 3.457325
216 (array([22]),) False
 117040/500000: episode: 2926, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.300 [0.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.161133, mean_absolute_error: 2.633794, mean_q: 3.506535
785 (array([22]),) False
 117080/500000: episode: 2927, duration: 33.285s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.625 [0.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.155323, mean_absolute_error: 2.612201, mean_q: 3.459855
243 (array([12]),) False
 117120/500000: episode: 2928, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.650 [1.000, 44.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.163503, mean_absolute_error: 2.621274, mean_q: 3.481771
95 (array([22]),) False
 117160/500000: episode: 2929, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.550 [0.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.152171, mean_absolute_error: 2.645657, mean_q: 3.505650
78 (array([55]),) False
 117200/500000: episode: 2930, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.175 [9.000, 58.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.160430, mean_absolute_error: 2.626565, mean_q: 3.487043
470 (array([22]),) False
 117240/500000: episode: 2931, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.875 [2.000, 44.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.150983, mean_absolute_error: 2.642667, mean_q: 3.503510
272 (array([12]),) False
 117280/500000: episode: 2932, duration: 32.322s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.950 [3.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.154812, mean_absolute_error: 2.637117, mean_q: 3.495818
680 (array([22]),) False
 117320/500000: episode: 2933, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.050 [2.000, 53.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.155330, mean_absolute_error: 2.602988, mean_q: 3.456900
789 (array([22]),) False
 117360/500000: episode: 2934, duration: 32.282s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.650 [4.000, 52.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.161386, mean_absolute_error: 2.626360, mean_q: 3.496579
461 (array([22]),) False
 117400/500000: episode: 2935, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 20.400 [1.000, 31.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.159462, mean_absolute_error: 2.637217, mean_q: 3.494006
457 (array([38]),) False
 117440/500000: episode: 2936, duration: 32.317s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.425 [2.000, 52.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.156270, mean_absolute_error: 2.631977, mean_q: 3.493363
108 (array([48]),) False
 117480/500000: episode: 2937, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 29.125 [5.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.150335, mean_absolute_error: 2.639030, mean_q: 3.501289
106 (array([22]),) False
 117520/500000: episode: 2938, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.000 [8.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.157843, mean_absolute_error: 2.605325, mean_q: 3.464568
853 (array([22]),) False
 117560/500000: episode: 2939, duration: 33.248s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.975 [9.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.157592, mean_absolute_error: 2.622059, mean_q: 3.487336
353 (array([22]),) False
 117600/500000: episode: 2940, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.750 [1.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.150695, mean_absolute_error: 2.665270, mean_q: 3.531277
543 (array([12]),) False
 117640/500000: episode: 2941, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 16.525 [9.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.155173, mean_absolute_error: 2.618316, mean_q: 3.478001
480 (array([22]),) False
 117680/500000: episode: 2942, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.900 [9.000, 33.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.157693, mean_absolute_error: 2.629253, mean_q: 3.490783
329 (array([12]),) False
 117720/500000: episode: 2943, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.000 [12.000, 38.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.152596, mean_absolute_error: 2.607731, mean_q: 3.453725
204 (array([22]),) False
 117760/500000: episode: 2944, duration: 32.356s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.850 [3.000, 40.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.159115, mean_absolute_error: 2.637835, mean_q: 3.497941
570 (array([47]),) False
 117800/500000: episode: 2945, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.700 [22.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.149510, mean_absolute_error: 2.646070, mean_q: 3.503001
728 (array([12]),) False
 117840/500000: episode: 2946, duration: 32.335s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 19.450 [6.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.151689, mean_absolute_error: 2.641504, mean_q: 3.504539
99 (array([22]),) False
 117880/500000: episode: 2947, duration: 33.289s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.500 [9.000, 29.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.153016, mean_absolute_error: 2.646657, mean_q: 3.506365
730 (array([54]),) False
 117920/500000: episode: 2948, duration: 32.311s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 53.000 [1.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.152409, mean_absolute_error: 2.582568, mean_q: 3.441716
823 (array([58]),) False
 117960/500000: episode: 2949, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 48.025 [2.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.146836, mean_absolute_error: 2.601338, mean_q: 3.453779
56 (array([12]),) False
 118000/500000: episode: 2950, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 38.625 [20.000, 40.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.149346, mean_absolute_error: 2.624912, mean_q: 3.477974
153 (array([44]),) False
 118040/500000: episode: 2951, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 34.350 [5.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.151505, mean_absolute_error: 2.627846, mean_q: 3.497263
139 (array([48]),) False
 118080/500000: episode: 2952, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 22.850 [2.000, 47.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.158682, mean_absolute_error: 2.612624, mean_q: 3.468000
777 (array([48]),) False
 118120/500000: episode: 2953, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 16.700 [1.000, 33.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.153128, mean_absolute_error: 2.612322, mean_q: 3.470192
112 (array([12]),) False
 118160/500000: episode: 2954, duration: 33.184s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 15.100 [12.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.154437, mean_absolute_error: 2.636123, mean_q: 3.501645
213 (array([22]),) False
 118200/500000: episode: 2955, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 24.150 [22.000, 56.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.149457, mean_absolute_error: 2.590392, mean_q: 3.448077
736 (array([22]),) False
 118240/500000: episode: 2956, duration: 32.378s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.000 [6.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.156471, mean_absolute_error: 2.590562, mean_q: 3.446881
841 (array([21]),) False
 118280/500000: episode: 2957, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.625 [3.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.156883, mean_absolute_error: 2.645133, mean_q: 3.510773
203 (array([48]),) False
 118320/500000: episode: 2958, duration: 32.406s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 41.800 [2.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.162219, mean_absolute_error: 2.633964, mean_q: 3.492255
774 (array([57]),) False
 118360/500000: episode: 2959, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.825 [4.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.158605, mean_absolute_error: 2.603354, mean_q: 3.449155
277 (array([56]),) False
 118400/500000: episode: 2960, duration: 32.373s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.650 [0.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.152942, mean_absolute_error: 2.631583, mean_q: 3.490445
669 (array([15]),) False
 118440/500000: episode: 2961, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.850 [12.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.163354, mean_absolute_error: 2.632859, mean_q: 3.492436
324 (array([12]),) False
 118480/500000: episode: 2962, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 20.675 [4.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.147581, mean_absolute_error: 2.657472, mean_q: 3.525509
632 (array([22]),) False
 118520/500000: episode: 2963, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.950 [4.000, 54.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.145513, mean_absolute_error: 2.591463, mean_q: 3.443562
124 (array([48]),) False
 118560/500000: episode: 2964, duration: 33.250s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.775 [12.000, 59.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.153650, mean_absolute_error: 2.592889, mean_q: 3.458795
617 (array([22]),) False
 118600/500000: episode: 2965, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.900 [6.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.153966, mean_absolute_error: 2.594081, mean_q: 3.450766
568 (array([22]),) False
 118640/500000: episode: 2966, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.075 [5.000, 42.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.152977, mean_absolute_error: 2.556150, mean_q: 3.408851
31 (array([48]),) False
 118680/500000: episode: 2967, duration: 33.250s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.575 [12.000, 55.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.150051, mean_absolute_error: 2.634343, mean_q: 3.495463
750 (array([22]),) False
 118720/500000: episode: 2968, duration: 32.346s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.950 [22.000, 60.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.157007, mean_absolute_error: 2.588868, mean_q: 3.446269
838 (array([21]),) False
 118760/500000: episode: 2969, duration: 33.235s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 34.825 [3.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.147217, mean_absolute_error: 2.578278, mean_q: 3.429748
516 (array([48]),) False
 118800/500000: episode: 2970, duration: 32.301s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 36.825 [12.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.154284, mean_absolute_error: 2.581902, mean_q: 3.443591
152 (array([58]),) False
 118840/500000: episode: 2971, duration: 33.299s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 54.650 [4.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.166053, mean_absolute_error: 2.622061, mean_q: 3.485316
650 (array([22]),) False
 118880/500000: episode: 2972, duration: 32.396s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.300 [1.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.150970, mean_absolute_error: 2.616360, mean_q: 3.474902
268 (array([22]),) False
 118920/500000: episode: 2973, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.450 [4.000, 22.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.158877, mean_absolute_error: 2.612872, mean_q: 3.468014
758 (array([38]),) False
 118960/500000: episode: 2974, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 29.375 [6.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.157144, mean_absolute_error: 2.632116, mean_q: 3.499957
572 (array([58]),) False
 119000/500000: episode: 2975, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 56.425 [30.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.150028, mean_absolute_error: 2.609396, mean_q: 3.474562
122 (array([12]),) False
 119040/500000: episode: 2976, duration: 33.267s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 35.200 [3.000, 56.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.159137, mean_absolute_error: 2.574343, mean_q: 3.441205
761 (array([3]),) False
 119080/500000: episode: 2977, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 22.900 [3.000, 50.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.149217, mean_absolute_error: 2.550224, mean_q: 3.400368
86 (array([22]),) False
 119120/500000: episode: 2978, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.425 [0.000, 47.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.145914, mean_absolute_error: 2.599709, mean_q: 3.455814
130 (array([22]),) False
 119160/500000: episode: 2979, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.400 [12.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.152751, mean_absolute_error: 2.610915, mean_q: 3.473201
273 (array([22]),) False
 119200/500000: episode: 2980, duration: 32.293s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.400 [3.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.148773, mean_absolute_error: 2.618988, mean_q: 3.490793
149 (array([8]),) False
 119240/500000: episode: 2981, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 13.325 [8.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.143752, mean_absolute_error: 2.609382, mean_q: 3.478111
464 (array([22]),) False
 119280/500000: episode: 2982, duration: 32.346s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.825 [8.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.156794, mean_absolute_error: 2.596901, mean_q: 3.456021
523 (array([22]),) False
 119320/500000: episode: 2983, duration: 33.290s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.600 [22.000, 46.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.150087, mean_absolute_error: 2.633838, mean_q: 3.493392
0 (array([48]),) False
 119360/500000: episode: 2984, duration: 32.334s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 22.625 [4.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.148938, mean_absolute_error: 2.625261, mean_q: 3.500551
504 (array([48]),) False
 119400/500000: episode: 2985, duration: 33.283s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 43.950 [2.000, 48.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.154910, mean_absolute_error: 2.607604, mean_q: 3.473775
279 (array([22]),) False
 119440/500000: episode: 2986, duration: 33.269s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 35.925 [5.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.153292, mean_absolute_error: 2.636873, mean_q: 3.503291
522 (array([22]),) False
 119480/500000: episode: 2987, duration: 33.303s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.300 [6.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.161152, mean_absolute_error: 2.626733, mean_q: 3.484775
722 (array([22]),) False
 119520/500000: episode: 2988, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.775 [0.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.152177, mean_absolute_error: 2.636878, mean_q: 3.494467
576 (array([58]),) False
 119560/500000: episode: 2989, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 54.350 [14.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.153790, mean_absolute_error: 2.634434, mean_q: 3.494182
830 (array([22]),) False
 119600/500000: episode: 2990, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.450 [1.000, 54.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.159928, mean_absolute_error: 2.619977, mean_q: 3.479347
8 (array([22]),) False
 119640/500000: episode: 2991, duration: 33.309s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 30.150 [3.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.152353, mean_absolute_error: 2.612350, mean_q: 3.481720
708 (array([40]),) False
 119680/500000: episode: 2992, duration: 32.223s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.075 [3.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.150266, mean_absolute_error: 2.612104, mean_q: 3.462383
515 (array([22]),) False
 119720/500000: episode: 2993, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.725 [3.000, 51.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.145875, mean_absolute_error: 2.611529, mean_q: 3.464170
331 (array([22]),) False
 119760/500000: episode: 2994, duration: 32.271s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.725 [7.000, 55.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.159109, mean_absolute_error: 2.637083, mean_q: 3.503219
230 (array([22]),) False
 119800/500000: episode: 2995, duration: 33.290s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.500 [2.000, 59.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.152085, mean_absolute_error: 2.622941, mean_q: 3.482879
350 (array([12]),) False
 119840/500000: episode: 2996, duration: 32.369s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 18.050 [3.000, 43.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.156978, mean_absolute_error: 2.637838, mean_q: 3.506245
463 (array([22]),) False
 119880/500000: episode: 2997, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.325 [12.000, 42.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.151350, mean_absolute_error: 2.662059, mean_q: 3.533556
836 (array([22]),) False
 119920/500000: episode: 2998, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.875 [20.000, 55.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.156226, mean_absolute_error: 2.626929, mean_q: 3.482751
112 (array([12]),) False
 119960/500000: episode: 2999, duration: 33.256s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 12.625 [10.000, 33.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.153780, mean_absolute_error: 2.649394, mean_q: 3.506529
192 (array([22]),) False
 120000/500000: episode: 3000, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 18.975 [12.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.168128, mean_absolute_error: 2.616440, mean_q: 3.476196
552 (array([22]),) False
 120040/500000: episode: 3001, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.075 [1.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.153970, mean_absolute_error: 2.649854, mean_q: 3.509600
529 (array([3]),) False
 120080/500000: episode: 3002, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 6.050 [3.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.172128, mean_absolute_error: 2.637341, mean_q: 3.495972
204 (array([22]),) False
 120120/500000: episode: 3003, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.875 [0.000, 52.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.164582, mean_absolute_error: 2.624106, mean_q: 3.483363
825 (array([22]),) False
 120160/500000: episode: 3004, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.450 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.156879, mean_absolute_error: 2.644596, mean_q: 3.512014
598 (array([22]),) False
 120200/500000: episode: 3005, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.375 [4.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.155608, mean_absolute_error: 2.600431, mean_q: 3.458968
861 (array([22]),) False
 120240/500000: episode: 3006, duration: 32.383s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.275 [1.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.158737, mean_absolute_error: 2.643147, mean_q: 3.514410
58 (array([48]),) False
 120280/500000: episode: 3007, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.750 [0.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.160267, mean_absolute_error: 2.649307, mean_q: 3.521963
224 (array([12]),) False
 120320/500000: episode: 3008, duration: 32.294s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.500 [6.000, 54.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.159291, mean_absolute_error: 2.640848, mean_q: 3.513731
394 (array([22]),) False
 120360/500000: episode: 3009, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.850 [3.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.153777, mean_absolute_error: 2.651849, mean_q: 3.510825
193 (array([36]),) False
 120400/500000: episode: 3010, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 28.375 [0.000, 48.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.151134, mean_absolute_error: 2.645630, mean_q: 3.518039
406 (array([48]),) False
 120440/500000: episode: 3011, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 42.050 [3.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.163560, mean_absolute_error: 2.642190, mean_q: 3.512628
593 (array([37]),) False
 120480/500000: episode: 3012, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.725 [1.000, 49.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.161871, mean_absolute_error: 2.625379, mean_q: 3.501777
467 (array([48]),) False
 120520/500000: episode: 3013, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.825 [6.000, 51.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.162563, mean_absolute_error: 2.658687, mean_q: 3.529877
77 (array([22]),) False
 120560/500000: episode: 3014, duration: 33.184s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.650 [13.000, 59.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.158417, mean_absolute_error: 2.651248, mean_q: 3.510184
382 (array([22]),) False
 120600/500000: episode: 3015, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.400 [4.000, 34.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.149442, mean_absolute_error: 2.648708, mean_q: 3.511327
499 (array([8]),) False
 120640/500000: episode: 3016, duration: 32.323s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.850 [3.000, 53.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.154117, mean_absolute_error: 2.628709, mean_q: 3.501279
162 (array([22]),) False
 120680/500000: episode: 3017, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.825 [0.000, 59.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.155478, mean_absolute_error: 2.620590, mean_q: 3.490630
862 (array([14]),) False
 120720/500000: episode: 3018, duration: 32.351s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.875 [10.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.156644, mean_absolute_error: 2.620660, mean_q: 3.493472
804 (array([3]),) False
 120760/500000: episode: 3019, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 9.225 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.157599, mean_absolute_error: 2.651968, mean_q: 3.526917
389 (array([48]),) False
 120800/500000: episode: 3020, duration: 32.272s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.050 [2.000, 54.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.169606, mean_absolute_error: 2.645596, mean_q: 3.522575
11 (array([22]),) False
 120840/500000: episode: 3021, duration: 33.270s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.850 [11.000, 55.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.170813, mean_absolute_error: 2.640767, mean_q: 3.518753
170 (array([44]),) False
 120880/500000: episode: 3022, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 41.850 [6.000, 59.000], mean observation: -0.171 [-1.000, 1.000], loss: 0.160112, mean_absolute_error: 2.626394, mean_q: 3.506931
378 (array([22]),) False
 120920/500000: episode: 3023, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.450 [5.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.159294, mean_absolute_error: 2.639222, mean_q: 3.505143
319 (array([33]),) False
 120960/500000: episode: 3024, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 30.750 [22.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.166468, mean_absolute_error: 2.657104, mean_q: 3.529095
561 (array([22]),) False
 121000/500000: episode: 3025, duration: 33.169s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.675 [22.000, 39.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.165950, mean_absolute_error: 2.646392, mean_q: 3.509767
551 (array([22]),) False
 121040/500000: episode: 3026, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.350 [14.000, 49.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.150498, mean_absolute_error: 2.660121, mean_q: 3.530776
687 (array([44]),) False
 121080/500000: episode: 3027, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 43.025 [9.000, 47.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.159531, mean_absolute_error: 2.670897, mean_q: 3.540656
72 (array([12]),) False
 121120/500000: episode: 3028, duration: 32.331s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 16.500 [2.000, 59.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.156615, mean_absolute_error: 2.654184, mean_q: 3.524821
237 (array([22]),) False
 121160/500000: episode: 3029, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.350 [1.000, 27.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.167912, mean_absolute_error: 2.658176, mean_q: 3.537714
515 (array([22]),) False
 121200/500000: episode: 3030, duration: 32.265s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.025 [15.000, 39.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.161195, mean_absolute_error: 2.649722, mean_q: 3.531550
563 (array([22]),) False
 121240/500000: episode: 3031, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.800 [1.000, 44.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.161742, mean_absolute_error: 2.676172, mean_q: 3.556182
861 (array([22]),) False
 121280/500000: episode: 3032, duration: 32.257s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.950 [0.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.150912, mean_absolute_error: 2.646524, mean_q: 3.508937
353 (array([22]),) False
 121320/500000: episode: 3033, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.700 [2.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.150064, mean_absolute_error: 2.661851, mean_q: 3.532436
284 (array([12]),) False
 121360/500000: episode: 3034, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.000 [3.000, 55.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.163021, mean_absolute_error: 2.669680, mean_q: 3.537667
468 (array([22]),) False
 121400/500000: episode: 3035, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.500 [4.000, 52.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.158464, mean_absolute_error: 2.648248, mean_q: 3.511359
268 (array([22]),) False
 121440/500000: episode: 3036, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.025 [3.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.158244, mean_absolute_error: 2.647628, mean_q: 3.506423
60 (array([22]),) False
 121480/500000: episode: 3037, duration: 33.268s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 28.100 [2.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.160217, mean_absolute_error: 2.637823, mean_q: 3.501290
367 (array([12]),) False
 121520/500000: episode: 3038, duration: 32.144s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 25.975 [4.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.190135, mean_absolute_error: 2.670531, mean_q: 3.517619
184 (array([12]),) False
 121560/500000: episode: 3039, duration: 31.690s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 19.875 [0.000, 49.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.165342, mean_absolute_error: 2.702850, mean_q: 3.563697
699 (array([22]),) False
 121600/500000: episode: 3040, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 20.825 [5.000, 22.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.158560, mean_absolute_error: 2.691044, mean_q: 3.559441
796 (array([38]),) False
 121640/500000: episode: 3041, duration: 31.431s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 36.725 [4.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.171730, mean_absolute_error: 2.646175, mean_q: 3.494125
642 (array([22]),) False
 121680/500000: episode: 3042, duration: 31.481s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.925 [0.000, 44.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.155860, mean_absolute_error: 2.653286, mean_q: 3.501619
545 (array([22]),) False
 121720/500000: episode: 3043, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.125 [8.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.161820, mean_absolute_error: 2.631760, mean_q: 3.481966
644 (array([12]),) False
 121760/500000: episode: 3044, duration: 32.160s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 19.950 [12.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.154298, mean_absolute_error: 2.637379, mean_q: 3.495651
848 (array([44]),) False
 121800/500000: episode: 3045, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 52.775 [23.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.167667, mean_absolute_error: 2.635633, mean_q: 3.487160
642 (array([22]),) False
 121840/500000: episode: 3046, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.550 [1.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.155240, mean_absolute_error: 2.643131, mean_q: 3.499878
199 (array([22]),) False
 121880/500000: episode: 3047, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.500 [12.000, 44.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.175972, mean_absolute_error: 2.634391, mean_q: 3.498796
603 (array([58]),) False
 121920/500000: episode: 3048, duration: 32.968s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 54.975 [18.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.175530, mean_absolute_error: 2.684989, mean_q: 3.549110
689 (array([12]),) False
 121960/500000: episode: 3049, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 11.325 [0.000, 12.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.163382, mean_absolute_error: 2.644307, mean_q: 3.512930
691 (array([22]),) False
 122000/500000: episode: 3050, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.975 [12.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.159808, mean_absolute_error: 2.689085, mean_q: 3.563818
438 (array([22]),) False
 122040/500000: episode: 3051, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.400 [22.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.167701, mean_absolute_error: 2.651866, mean_q: 3.525847
318 (array([48]),) False
 122080/500000: episode: 3052, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 39.125 [3.000, 58.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.158109, mean_absolute_error: 2.653225, mean_q: 3.517369
416 (array([22]),) False
 122120/500000: episode: 3053, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.150 [9.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.158328, mean_absolute_error: 2.679243, mean_q: 3.554868
551 (array([22]),) False
 122160/500000: episode: 3054, duration: 32.204s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.500 [8.000, 59.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.159288, mean_absolute_error: 2.676306, mean_q: 3.536874
403 (array([12]),) False
 122200/500000: episode: 3055, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 21.150 [3.000, 47.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.154819, mean_absolute_error: 2.634112, mean_q: 3.493205
736 (array([22]),) False
 122240/500000: episode: 3056, duration: 32.197s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.000 [0.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.162146, mean_absolute_error: 2.667650, mean_q: 3.532267
436 (array([22]),) False
 122280/500000: episode: 3057, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.175 [6.000, 52.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.150569, mean_absolute_error: 2.675925, mean_q: 3.545570
547 (array([21]),) False
 122320/500000: episode: 3058, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 17.050 [1.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.154938, mean_absolute_error: 2.713059, mean_q: 3.593588
93 (array([22]),) False
 122360/500000: episode: 3059, duration: 33.038s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.350 [8.000, 55.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.166846, mean_absolute_error: 2.697325, mean_q: 3.571961
249 (array([22]),) False
 122400/500000: episode: 3060, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.250 [14.000, 41.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.166714, mean_absolute_error: 2.660787, mean_q: 3.527144
834 (array([44]),) False
 122440/500000: episode: 3061, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 46.175 [4.000, 51.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.157192, mean_absolute_error: 2.675204, mean_q: 3.543622
766 (array([12]),) False
 122480/500000: episode: 3062, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 44.425 [1.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.159844, mean_absolute_error: 2.672148, mean_q: 3.547284
617 (array([22]),) False
 122520/500000: episode: 3063, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.975 [21.000, 22.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.161850, mean_absolute_error: 2.652109, mean_q: 3.513624
217 (array([12]),) False
 122560/500000: episode: 3064, duration: 32.282s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 20.300 [9.000, 60.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.156985, mean_absolute_error: 2.647798, mean_q: 3.521697
107 (array([22]),) False
 122600/500000: episode: 3065, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.225 [2.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.173178, mean_absolute_error: 2.660254, mean_q: 3.532976
743 (array([48]),) False
 122640/500000: episode: 3066, duration: 32.129s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.075 [13.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.159859, mean_absolute_error: 2.681551, mean_q: 3.559383
691 (array([22]),) False
 122680/500000: episode: 3067, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.925 [2.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.155084, mean_absolute_error: 2.668495, mean_q: 3.544075
504 (array([48]),) False
 122720/500000: episode: 3068, duration: 32.201s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.250 [4.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.166576, mean_absolute_error: 2.672202, mean_q: 3.541100
414 (array([48]),) False
 122760/500000: episode: 3069, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 46.100 [1.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.166916, mean_absolute_error: 2.654568, mean_q: 3.517109
357 (array([22]),) False
 122800/500000: episode: 3070, duration: 33.008s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 33.125 [12.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.158221, mean_absolute_error: 2.695495, mean_q: 3.559830
201 (array([22]),) False
 122840/500000: episode: 3071, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.950 [7.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.167728, mean_absolute_error: 2.656473, mean_q: 3.516326
394 (array([22]),) False
 122880/500000: episode: 3072, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.575 [9.000, 53.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.159727, mean_absolute_error: 2.670854, mean_q: 3.544633
524 (array([22]),) False
 122920/500000: episode: 3073, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.475 [16.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.162378, mean_absolute_error: 2.679763, mean_q: 3.547685
858 (array([12]),) False
 122960/500000: episode: 3074, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 21.175 [12.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.170279, mean_absolute_error: 2.714558, mean_q: 3.587253
736 (array([22]),) False
 123000/500000: episode: 3075, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.700 [16.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.161530, mean_absolute_error: 2.681773, mean_q: 3.543672
743 (array([48]),) False
 123040/500000: episode: 3076, duration: 32.197s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 39.775 [0.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.158725, mean_absolute_error: 2.671147, mean_q: 3.528487
709 (array([41]),) False
 123080/500000: episode: 3077, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.975 [2.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.165286, mean_absolute_error: 2.674467, mean_q: 3.532016
102 (array([22]),) False
 123120/500000: episode: 3078, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.050 [20.000, 48.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.162372, mean_absolute_error: 2.670146, mean_q: 3.545766
726 (array([12]),) False
 123160/500000: episode: 3079, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 12.600 [5.000, 29.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.157597, mean_absolute_error: 2.661523, mean_q: 3.535470
358 (array([22]),) False
 123200/500000: episode: 3080, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 37.125 [15.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.168694, mean_absolute_error: 2.693984, mean_q: 3.568091
525 (array([22]),) False
 123240/500000: episode: 3081, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.150 [13.000, 33.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.165318, mean_absolute_error: 2.667001, mean_q: 3.527989
649 (array([22]),) False
 123280/500000: episode: 3082, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.950 [2.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.174932, mean_absolute_error: 2.616419, mean_q: 3.469076
119 (array([45]),) False
 123320/500000: episode: 3083, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 22.950 [7.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.160483, mean_absolute_error: 2.710888, mean_q: 3.579514
216 (array([22]),) False
 123360/500000: episode: 3084, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.925 [1.000, 46.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.153189, mean_absolute_error: 2.678221, mean_q: 3.534023
59 (array([12]),) False
 123400/500000: episode: 3085, duration: 33.169s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.300 [6.000, 57.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.162334, mean_absolute_error: 2.682363, mean_q: 3.544700
652 (array([22]),) False
 123440/500000: episode: 3086, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.200 [1.000, 35.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.164133, mean_absolute_error: 2.686464, mean_q: 3.552298
89 (array([58]),) False
 123480/500000: episode: 3087, duration: 31.993s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 6.925 [3.000, 53.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.155386, mean_absolute_error: 2.672007, mean_q: 3.526688
331 (array([22]),) False
 123520/500000: episode: 3088, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.750 [4.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.155766, mean_absolute_error: 2.689609, mean_q: 3.548330
719 (array([22]),) False
 123560/500000: episode: 3089, duration: 31.477s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.750 [5.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.157104, mean_absolute_error: 2.701386, mean_q: 3.570502
422 (array([48]),) False
 123600/500000: episode: 3090, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 43.100 [1.000, 60.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.154965, mean_absolute_error: 2.645419, mean_q: 3.510532
786 (array([22]),) False
 123640/500000: episode: 3091, duration: 31.454s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.650 [9.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.157642, mean_absolute_error: 2.659572, mean_q: 3.521234
694 (array([22]),) False
 123680/500000: episode: 3092, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.100 [5.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.166266, mean_absolute_error: 2.687073, mean_q: 3.558646
171 (array([22]),) False
 123720/500000: episode: 3093, duration: 31.452s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 19.300 [0.000, 52.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.165688, mean_absolute_error: 2.701962, mean_q: 3.565748
844 (array([48]),) False
 123760/500000: episode: 3094, duration: 31.375s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 41.525 [2.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.164101, mean_absolute_error: 2.725420, mean_q: 3.592662
384 (array([22]),) False
 123800/500000: episode: 3095, duration: 31.421s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.225 [22.000, 57.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.152176, mean_absolute_error: 2.698338, mean_q: 3.568240
450 (array([8]),) False
 123840/500000: episode: 3096, duration: 31.412s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.550 [1.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.168030, mean_absolute_error: 2.672180, mean_q: 3.541244
440 (array([22]),) False
 123880/500000: episode: 3097, duration: 32.612s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 20.975 [5.000, 22.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.147002, mean_absolute_error: 2.674784, mean_q: 3.537308
630 (array([22]),) False
 123920/500000: episode: 3098, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.175 [2.000, 59.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.157205, mean_absolute_error: 2.671509, mean_q: 3.541481
413 (array([22]),) False
 123960/500000: episode: 3099, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 32.450 [11.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.158268, mean_absolute_error: 2.726509, mean_q: 3.603243
271 (array([18]),) False
 124000/500000: episode: 3100, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.800 [15.000, 51.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.179807, mean_absolute_error: 2.701481, mean_q: 3.564057
548 (array([22]),) False
 124040/500000: episode: 3101, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.100 [12.000, 41.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.164383, mean_absolute_error: 2.674222, mean_q: 3.536974
192 (array([22]),) False
 124080/500000: episode: 3102, duration: 32.197s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 20.200 [12.000, 56.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.158319, mean_absolute_error: 2.697316, mean_q: 3.571173
780 (array([22]),) False
 124120/500000: episode: 3103, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.875 [22.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.166902, mean_absolute_error: 2.689505, mean_q: 3.556999
15 (array([22]),) False
 124160/500000: episode: 3104, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.325 [2.000, 43.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.166795, mean_absolute_error: 2.689299, mean_q: 3.558139
263 (array([8]),) False
 124200/500000: episode: 3105, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 11.025 [5.000, 44.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.163404, mean_absolute_error: 2.698293, mean_q: 3.561809
57 (array([37]),) False
 124240/500000: episode: 3106, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.775 [10.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.148895, mean_absolute_error: 2.691830, mean_q: 3.570653
605 (array([22]),) False
 124280/500000: episode: 3107, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.350 [1.000, 28.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.156594, mean_absolute_error: 2.667435, mean_q: 3.550481
378 (array([22]),) False
 124320/500000: episode: 3108, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.500 [4.000, 41.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.157962, mean_absolute_error: 2.684791, mean_q: 3.564680
459 (array([22]),) False
 124360/500000: episode: 3109, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.825 [3.000, 50.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.167298, mean_absolute_error: 2.697320, mean_q: 3.578625
384 (array([22]),) False
 124400/500000: episode: 3110, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.925 [10.000, 60.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.159470, mean_absolute_error: 2.691431, mean_q: 3.563894
833 (array([22]),) False
 124440/500000: episode: 3111, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.025 [8.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.153762, mean_absolute_error: 2.679557, mean_q: 3.541511
420 (array([22]),) False
 124480/500000: episode: 3112, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 38.600 [7.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.161970, mean_absolute_error: 2.679659, mean_q: 3.546970
372 (array([22]),) False
 124520/500000: episode: 3113, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.200 [11.000, 49.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.158876, mean_absolute_error: 2.675412, mean_q: 3.541162
5 (array([37]),) False
 124560/500000: episode: 3114, duration: 32.168s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.425 [22.000, 39.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.157380, mean_absolute_error: 2.689825, mean_q: 3.570480
395 (array([22]),) False
 124600/500000: episode: 3115, duration: 32.045s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.175 [18.000, 44.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.157446, mean_absolute_error: 2.678282, mean_q: 3.552478
27 (array([22]),) False
 124640/500000: episode: 3116, duration: 31.837s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.325 [22.000, 51.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.168062, mean_absolute_error: 2.634656, mean_q: 3.499599
85 (array([48]),) False
 124680/500000: episode: 3117, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.650 [22.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.177296, mean_absolute_error: 2.671421, mean_q: 3.543809
673 (array([3]),) False
 124720/500000: episode: 3118, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 7.300 [2.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.160066, mean_absolute_error: 2.641640, mean_q: 3.507327
761 (array([3]),) False
 124760/500000: episode: 3119, duration: 31.992s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 18.275 [3.000, 55.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.169219, mean_absolute_error: 2.696959, mean_q: 3.565836
650 (array([22]),) False
 124800/500000: episode: 3120, duration: 31.046s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.650 [15.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.156218, mean_absolute_error: 2.675179, mean_q: 3.547405
490 (array([12]),) False
 124840/500000: episode: 3121, duration: 31.071s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 16.175 [10.000, 60.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.157826, mean_absolute_error: 2.716586, mean_q: 3.585327
723 (array([48]),) False
 124880/500000: episode: 3122, duration: 31.114s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.500 [5.000, 50.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.153568, mean_absolute_error: 2.713496, mean_q: 3.583884
343 (array([22]),) False
 124920/500000: episode: 3123, duration: 31.057s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.100 [1.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.162222, mean_absolute_error: 2.668018, mean_q: 3.539220
136 (array([12]),) False
 124960/500000: episode: 3124, duration: 30.181s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.975 [22.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.167058, mean_absolute_error: 2.695850, mean_q: 3.560861
685 (array([22]),) False
 125000/500000: episode: 3125, duration: 31.082s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.725 [9.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.173241, mean_absolute_error: 2.653751, mean_q: 3.518031
459 (array([22]),) False
 125040/500000: episode: 3126, duration: 30.191s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.450 [3.000, 53.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.161413, mean_absolute_error: 2.663588, mean_q: 3.531247
483 (array([48]),) False
 125080/500000: episode: 3127, duration: 31.085s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 38.900 [6.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.176478, mean_absolute_error: 2.709421, mean_q: 3.585889
444 (array([22]),) False
 125120/500000: episode: 3128, duration: 30.241s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.100 [1.000, 55.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.169244, mean_absolute_error: 2.681461, mean_q: 3.542535
46 (array([22]),) False
 125160/500000: episode: 3129, duration: 31.107s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.625 [14.000, 53.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.163395, mean_absolute_error: 2.660836, mean_q: 3.509108
709 (array([41]),) False
 125200/500000: episode: 3130, duration: 31.110s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.200 [12.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.163814, mean_absolute_error: 2.672275, mean_q: 3.537916
456 (array([22]),) False
 125240/500000: episode: 3131, duration: 31.103s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 41.750 [4.000, 48.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.174683, mean_absolute_error: 2.635127, mean_q: 3.496379
73 (array([22]),) False
 125280/500000: episode: 3132, duration: 31.096s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.675 [12.000, 57.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.170648, mean_absolute_error: 2.668198, mean_q: 3.534083
527 (array([58]),) False
 125320/500000: episode: 3133, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 52.325 [1.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.166004, mean_absolute_error: 2.665558, mean_q: 3.533392
569 (array([22]),) False
 125360/500000: episode: 3134, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.975 [4.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.145950, mean_absolute_error: 2.646271, mean_q: 3.511034
543 (array([12]),) False
 125400/500000: episode: 3135, duration: 31.051s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 14.025 [12.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.153242, mean_absolute_error: 2.654090, mean_q: 3.516328
284 (array([12]),) False
 125440/500000: episode: 3136, duration: 30.176s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.925 [5.000, 46.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.158860, mean_absolute_error: 2.641416, mean_q: 3.495597
629 (array([22]),) False
 125480/500000: episode: 3137, duration: 31.050s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 34.175 [2.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.157460, mean_absolute_error: 2.660176, mean_q: 3.514989
549 (array([22]),) False
 125520/500000: episode: 3138, duration: 30.178s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 16.300 [6.000, 50.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.154356, mean_absolute_error: 2.659487, mean_q: 3.508531
148 (array([22]),) False
 125560/500000: episode: 3139, duration: 31.045s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.175 [9.000, 38.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.159919, mean_absolute_error: 2.619323, mean_q: 3.478489
147 (array([44]),) False
 125600/500000: episode: 3140, duration: 30.265s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 23.450 [0.000, 55.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.150017, mean_absolute_error: 2.683136, mean_q: 3.540276
434 (array([22]),) False
 125640/500000: episode: 3141, duration: 31.118s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.000 [22.000, 57.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.150247, mean_absolute_error: 2.619712, mean_q: 3.470830
19 (array([12]),) False
 125680/500000: episode: 3142, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.000 [1.000, 52.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.164305, mean_absolute_error: 2.639096, mean_q: 3.499907
380 (array([22]),) False
 125720/500000: episode: 3143, duration: 31.108s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.300 [22.000, 53.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.170998, mean_absolute_error: 2.643911, mean_q: 3.493314
160 (array([12]),) False
 125760/500000: episode: 3144, duration: 31.079s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 25.600 [5.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.161223, mean_absolute_error: 2.661436, mean_q: 3.530663
256 (array([22]),) False
 125800/500000: episode: 3145, duration: 31.086s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.375 [22.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.158363, mean_absolute_error: 2.641049, mean_q: 3.521976
644 (array([12]),) False
 125840/500000: episode: 3146, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 18.275 [12.000, 55.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.157921, mean_absolute_error: 2.608870, mean_q: 3.474064
20 (array([22]),) False
 125880/500000: episode: 3147, duration: 31.088s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.725 [3.000, 51.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.150365, mean_absolute_error: 2.663214, mean_q: 3.534312
126 (array([22]),) False
 125920/500000: episode: 3148, duration: 31.102s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.225 [12.000, 48.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.151339, mean_absolute_error: 2.602953, mean_q: 3.454514
394 (array([22]),) False
 125960/500000: episode: 3149, duration: 31.660s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.550 [6.000, 31.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.166972, mean_absolute_error: 2.623905, mean_q: 3.484960
505 (array([22]),) False
 126000/500000: episode: 3150, duration: 30.152s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.125 [18.000, 59.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.158324, mean_absolute_error: 2.647535, mean_q: 3.498589
699 (array([22]),) False
 126040/500000: episode: 3151, duration: 31.500s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.400 [13.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.169291, mean_absolute_error: 2.661418, mean_q: 3.518492
697 (array([22]),) False
 126080/500000: episode: 3152, duration: 30.935s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.125 [14.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.173060, mean_absolute_error: 2.620525, mean_q: 3.484931
106 (array([22]),) False
 126120/500000: episode: 3153, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.575 [7.000, 55.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.157902, mean_absolute_error: 2.651595, mean_q: 3.516712
238 (array([22]),) False
 126160/500000: episode: 3154, duration: 31.096s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.425 [22.000, 39.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.153856, mean_absolute_error: 2.608394, mean_q: 3.459414
807 (array([22]),) False
 126200/500000: episode: 3155, duration: 31.538s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.700 [4.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.155347, mean_absolute_error: 2.636757, mean_q: 3.495456
457 (array([38]),) False
 126240/500000: episode: 3156, duration: 31.499s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.675 [2.000, 43.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.150021, mean_absolute_error: 2.644881, mean_q: 3.516160
513 (array([12]),) False
 126280/500000: episode: 3157, duration: 31.432s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 14.625 [3.000, 48.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.163718, mean_absolute_error: 2.648785, mean_q: 3.522125
587 (array([14]),) False
 126320/500000: episode: 3158, duration: 31.477s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 46.650 [20.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.159426, mean_absolute_error: 2.635332, mean_q: 3.498431
437 (array([12]),) False
 126360/500000: episode: 3159, duration: 31.451s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.975 [0.000, 50.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.159580, mean_absolute_error: 2.610252, mean_q: 3.471377
322 (array([12]),) False
 126400/500000: episode: 3160, duration: 31.099s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 13.175 [1.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.163085, mean_absolute_error: 2.620784, mean_q: 3.489278
449 (array([22]),) False
 126440/500000: episode: 3161, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.450 [22.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.164007, mean_absolute_error: 2.614633, mean_q: 3.484024
862 (array([14]),) False
 126480/500000: episode: 3162, duration: 31.693s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 27.625 [14.000, 49.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.165985, mean_absolute_error: 2.618575, mean_q: 3.487941
625 (array([22]),) False
 126520/500000: episode: 3163, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.275 [0.000, 24.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.164450, mean_absolute_error: 2.620130, mean_q: 3.492536
565 (array([12]),) False
 126560/500000: episode: 3164, duration: 32.184s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.225 [22.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.155336, mean_absolute_error: 2.618403, mean_q: 3.484141
499 (array([8]),) False
 126600/500000: episode: 3165, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.500 [5.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.160553, mean_absolute_error: 2.651257, mean_q: 3.531480
575 (array([44]),) False
 126640/500000: episode: 3166, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 37.025 [3.000, 44.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.162698, mean_absolute_error: 2.624568, mean_q: 3.492997
644 (array([12]),) False
 126680/500000: episode: 3167, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 17.750 [12.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.154364, mean_absolute_error: 2.631641, mean_q: 3.491452
20 (array([22]),) False
 126720/500000: episode: 3168, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.400 [19.000, 49.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.159117, mean_absolute_error: 2.635615, mean_q: 3.497842
126 (array([22]),) False
 126760/500000: episode: 3169, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.925 [0.000, 52.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.157024, mean_absolute_error: 2.617763, mean_q: 3.472799
533 (array([22]),) False
 126800/500000: episode: 3170, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.775 [2.000, 53.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.158281, mean_absolute_error: 2.552474, mean_q: 3.404488
513 (array([12]),) False
 126840/500000: episode: 3171, duration: 31.604s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 14.550 [6.000, 54.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.158476, mean_absolute_error: 2.599926, mean_q: 3.464764
508 (array([22]),) False
 126880/500000: episode: 3172, duration: 31.090s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 33.350 [22.000, 56.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.161806, mean_absolute_error: 2.621044, mean_q: 3.487257
396 (array([48]),) False
 126920/500000: episode: 3173, duration: 31.590s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.625 [0.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.154375, mean_absolute_error: 2.626602, mean_q: 3.499127
222 (array([22]),) False
 126960/500000: episode: 3174, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.125 [3.000, 56.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.163760, mean_absolute_error: 2.631572, mean_q: 3.507777
301 (array([22]),) False
 127000/500000: episode: 3175, duration: 31.563s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 29.500 [6.000, 52.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.167294, mean_absolute_error: 2.619877, mean_q: 3.484962
538 (array([12]),) False
 127040/500000: episode: 3176, duration: 31.075s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.000 [5.000, 55.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.154382, mean_absolute_error: 2.634417, mean_q: 3.513009
22 (array([37]),) False
 127080/500000: episode: 3177, duration: 31.622s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 38.625 [2.000, 58.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.152718, mean_absolute_error: 2.617650, mean_q: 3.482861
845 (array([22]),) False
 127120/500000: episode: 3178, duration: 31.594s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.175 [1.000, 41.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.154034, mean_absolute_error: 2.653855, mean_q: 3.524288
429 (array([22]),) False
 127160/500000: episode: 3179, duration: 31.605s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.225 [2.000, 22.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.167203, mean_absolute_error: 2.631217, mean_q: 3.493923
684 (array([22]),) False
 127200/500000: episode: 3180, duration: 31.503s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.075 [6.000, 44.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.174334, mean_absolute_error: 2.608593, mean_q: 3.467629
210 (array([58]),) False
 127240/500000: episode: 3181, duration: 32.603s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 28.550 [2.000, 58.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.163509, mean_absolute_error: 2.663740, mean_q: 3.526738
850 (array([12]),) False
 127280/500000: episode: 3182, duration: 33.369s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 19.500 [2.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.155504, mean_absolute_error: 2.679196, mean_q: 3.561251
513 (array([12]),) False
 127320/500000: episode: 3183, duration: 33.333s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 13.800 [12.000, 33.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.155923, mean_absolute_error: 2.625335, mean_q: 3.492050
32 (array([48]),) False
 127360/500000: episode: 3184, duration: 32.458s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 39.550 [0.000, 60.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.165114, mean_absolute_error: 2.622173, mean_q: 3.490779
434 (array([22]),) False
 127400/500000: episode: 3185, duration: 33.321s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.000 [4.000, 47.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.162453, mean_absolute_error: 2.638922, mean_q: 3.511596
587 (array([14]),) False
 127440/500000: episode: 3186, duration: 32.475s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 44.925 [12.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.152452, mean_absolute_error: 2.660638, mean_q: 3.537716
828 (array([48]),) False
 127480/500000: episode: 3187, duration: 33.309s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 44.850 [3.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.156118, mean_absolute_error: 2.657377, mean_q: 3.530531
707 (array([48]),) False
 127520/500000: episode: 3188, duration: 32.319s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.000 [4.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.162311, mean_absolute_error: 2.660768, mean_q: 3.535928
32 (array([48]),) False
 127560/500000: episode: 3189, duration: 33.423s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 40.550 [0.000, 60.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.158314, mean_absolute_error: 2.653485, mean_q: 3.523081
287 (array([48]),) False
 127600/500000: episode: 3190, duration: 33.412s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.250 [0.000, 46.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.157262, mean_absolute_error: 2.655999, mean_q: 3.514579
815 (array([22]),) False
 127640/500000: episode: 3191, duration: 33.369s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.725 [5.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.163483, mean_absolute_error: 2.687093, mean_q: 3.552883
848 (array([44]),) False
 127680/500000: episode: 3192, duration: 33.385s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 38.275 [0.000, 52.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.160427, mean_absolute_error: 2.721689, mean_q: 3.587001
407 (array([22]),) False
 127720/500000: episode: 3193, duration: 33.338s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.325 [12.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.168737, mean_absolute_error: 2.636976, mean_q: 3.496967
289 (array([21]),) False
 127760/500000: episode: 3194, duration: 33.287s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.250 [9.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.162870, mean_absolute_error: 2.633531, mean_q: 3.479821
680 (array([22]),) False
 127800/500000: episode: 3195, duration: 33.294s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.825 [0.000, 58.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.169773, mean_absolute_error: 2.675941, mean_q: 3.537302
58 (array([48]),) False
 127840/500000: episode: 3196, duration: 32.419s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 44.225 [8.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.161928, mean_absolute_error: 2.695080, mean_q: 3.565108
234 (array([22]),) False
 127880/500000: episode: 3197, duration: 33.350s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.400 [1.000, 43.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.164722, mean_absolute_error: 2.697631, mean_q: 3.566568
403 (array([12]),) False
 127920/500000: episode: 3198, duration: 32.470s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 27.050 [15.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.164712, mean_absolute_error: 2.661872, mean_q: 3.535869
121 (array([22]),) False
 127960/500000: episode: 3199, duration: 33.332s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 21.750 [12.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.172486, mean_absolute_error: 2.674670, mean_q: 3.556292
343 (array([22]),) False
 128000/500000: episode: 3200, duration: 32.416s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.675 [8.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.176261, mean_absolute_error: 2.662231, mean_q: 3.544546
673 (array([3]),) False
 128040/500000: episode: 3201, duration: 33.305s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 6.775 [1.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.155804, mean_absolute_error: 2.656010, mean_q: 3.534415
652 (array([22]),) False
 128080/500000: episode: 3202, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.275 [1.000, 57.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.161789, mean_absolute_error: 2.673926, mean_q: 3.556749
223 (array([48]),) False
 128120/500000: episode: 3203, duration: 33.401s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.925 [2.000, 41.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.157612, mean_absolute_error: 2.696880, mean_q: 3.572632
139 (array([48]),) False
 128160/500000: episode: 3204, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 24.725 [9.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.158154, mean_absolute_error: 2.687653, mean_q: 3.564257
111 (array([22]),) False
 128200/500000: episode: 3205, duration: 33.301s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.300 [0.000, 49.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.168779, mean_absolute_error: 2.650344, mean_q: 3.519128
772 (array([46]),) False
 128240/500000: episode: 3206, duration: 33.289s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 11.650 [3.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.167420, mean_absolute_error: 2.684062, mean_q: 3.563075
5 (array([37]),) False
 128280/500000: episode: 3207, duration: 33.392s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.300 [17.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.162415, mean_absolute_error: 2.657071, mean_q: 3.544987
287 (array([48]),) False
 128320/500000: episode: 3208, duration: 32.484s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.125 [6.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.163005, mean_absolute_error: 2.659585, mean_q: 3.540613
519 (array([58]),) False
 128360/500000: episode: 3209, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 55.100 [0.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.164844, mean_absolute_error: 2.663538, mean_q: 3.535219
535 (array([22]),) False
 128400/500000: episode: 3210, duration: 32.445s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 29.675 [17.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.172790, mean_absolute_error: 2.657392, mean_q: 3.518281
283 (array([34]),) False
 128440/500000: episode: 3211, duration: 33.351s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 16.675 [3.000, 50.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.166632, mean_absolute_error: 2.694731, mean_q: 3.562197
366 (array([22]),) False
 128480/500000: episode: 3212, duration: 32.423s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 44.025 [12.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.167491, mean_absolute_error: 2.677653, mean_q: 3.553636
555 (array([22]),) False
 128520/500000: episode: 3213, duration: 33.409s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.500 [0.000, 44.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.169595, mean_absolute_error: 2.676924, mean_q: 3.563152
293 (array([22]),) False
 128560/500000: episode: 3214, duration: 33.301s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.775 [7.000, 31.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.154022, mean_absolute_error: 2.685419, mean_q: 3.569421
500 (array([22]),) False
 128600/500000: episode: 3215, duration: 33.438s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.725 [12.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.163208, mean_absolute_error: 2.648612, mean_q: 3.517719
579 (array([58]),) False
 128640/500000: episode: 3216, duration: 33.324s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 57.400 [33.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.162534, mean_absolute_error: 2.655919, mean_q: 3.535684
449 (array([22]),) False
 128680/500000: episode: 3217, duration: 33.382s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.150 [11.000, 51.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.174788, mean_absolute_error: 2.693988, mean_q: 3.572406
18 (array([22]),) False
 128720/500000: episode: 3218, duration: 33.296s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 20.675 [3.000, 34.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.172497, mean_absolute_error: 2.654887, mean_q: 3.519050
550 (array([12]),) False
 128760/500000: episode: 3219, duration: 33.334s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 18.200 [2.000, 46.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.171455, mean_absolute_error: 2.686157, mean_q: 3.559587
101 (array([22]),) False
 128800/500000: episode: 3220, duration: 32.367s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.625 [4.000, 60.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.169650, mean_absolute_error: 2.656401, mean_q: 3.529360
246 (array([22]),) False
 128840/500000: episode: 3221, duration: 33.316s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.350 [11.000, 46.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.155898, mean_absolute_error: 2.705636, mean_q: 3.589029
374 (array([22]),) False
 128880/500000: episode: 3222, duration: 32.423s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.100 [22.000, 55.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.163075, mean_absolute_error: 2.704827, mean_q: 3.587448
36 (array([22]),) False
 128920/500000: episode: 3223, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.525 [6.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.172317, mean_absolute_error: 2.728838, mean_q: 3.600813
37 (array([48]),) False
 128960/500000: episode: 3224, duration: 32.444s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 46.250 [3.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.175774, mean_absolute_error: 2.655545, mean_q: 3.512415
404 (array([12]),) False
 129000/500000: episode: 3225, duration: 33.321s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 25.300 [4.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.164661, mean_absolute_error: 2.727057, mean_q: 3.588114
196 (array([22]),) False
 129040/500000: episode: 3226, duration: 33.268s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.175 [8.000, 57.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.172145, mean_absolute_error: 2.654117, mean_q: 3.512681
825 (array([22]),) False
 129080/500000: episode: 3227, duration: 33.367s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.350 [4.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.163172, mean_absolute_error: 2.697981, mean_q: 3.581822
528 (array([12]),) False
 129120/500000: episode: 3228, duration: 33.311s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 25.050 [7.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.155839, mean_absolute_error: 2.677362, mean_q: 3.550538
285 (array([58]),) False
 129160/500000: episode: 3229, duration: 33.379s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 40.350 [1.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.176352, mean_absolute_error: 2.702501, mean_q: 3.573341
481 (array([22]),) False
 129200/500000: episode: 3230, duration: 33.371s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.275 [19.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.167709, mean_absolute_error: 2.723309, mean_q: 3.588983
840 (array([12]),) False
 129240/500000: episode: 3231, duration: 33.399s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.050 [3.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.162276, mean_absolute_error: 2.669141, mean_q: 3.539117
192 (array([22]),) False
 129280/500000: episode: 3232, duration: 32.403s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 17.200 [3.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.164591, mean_absolute_error: 2.659208, mean_q: 3.517406
102 (array([22]),) False
 129320/500000: episode: 3233, duration: 33.320s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.875 [12.000, 49.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.156290, mean_absolute_error: 2.676493, mean_q: 3.534824
550 (array([12]),) False
 129360/500000: episode: 3234, duration: 32.411s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 17.075 [6.000, 37.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.163326, mean_absolute_error: 2.699311, mean_q: 3.572657
596 (array([22]),) False
 129400/500000: episode: 3235, duration: 33.285s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.625 [22.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.162039, mean_absolute_error: 2.646226, mean_q: 3.505471
239 (array([22]),) False
 129440/500000: episode: 3236, duration: 32.365s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.275 [1.000, 27.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.169889, mean_absolute_error: 2.632351, mean_q: 3.485035
460 (array([36]),) False
 129480/500000: episode: 3237, duration: 33.453s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.700 [9.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.176303, mean_absolute_error: 2.671621, mean_q: 3.528789
749 (array([22]),) False
 129520/500000: episode: 3238, duration: 33.321s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.500 [13.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.165447, mean_absolute_error: 2.667815, mean_q: 3.531038
643 (array([44]),) False
 129560/500000: episode: 3239, duration: 33.386s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 39.900 [12.000, 44.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.154586, mean_absolute_error: 2.686438, mean_q: 3.557548
679 (array([44]),) False
 129600/500000: episode: 3240, duration: 33.372s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.425 [11.000, 53.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.181273, mean_absolute_error: 2.699122, mean_q: 3.573430
99 (array([22]),) False
 129640/500000: episode: 3241, duration: 33.384s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.375 [5.000, 54.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.156298, mean_absolute_error: 2.710261, mean_q: 3.587919
715 (array([22]),) False
 129680/500000: episode: 3242, duration: 33.356s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.500 [0.000, 43.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.166460, mean_absolute_error: 2.645627, mean_q: 3.506197
88 (array([22]),) False
 129720/500000: episode: 3243, duration: 33.390s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 25.200 [22.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.157433, mean_absolute_error: 2.669890, mean_q: 3.527407
289 (array([21]),) False
 129760/500000: episode: 3244, duration: 32.448s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.150 [22.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.165102, mean_absolute_error: 2.650046, mean_q: 3.516795
728 (array([12]),) False
 129800/500000: episode: 3245, duration: 33.350s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 15.925 [6.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.168033, mean_absolute_error: 2.663007, mean_q: 3.529980
619 (array([3]),) False
 129840/500000: episode: 3246, duration: 32.480s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.950 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.171605, mean_absolute_error: 2.688582, mean_q: 3.557258
520 (array([22]),) False
 129880/500000: episode: 3247, duration: 33.362s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.150 [4.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.173225, mean_absolute_error: 2.664320, mean_q: 3.526809
530 (array([22]),) False
 129920/500000: episode: 3248, duration: 32.373s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.700 [0.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.166370, mean_absolute_error: 2.664445, mean_q: 3.531279
121 (array([22]),) False
 129960/500000: episode: 3249, duration: 33.339s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 17.975 [7.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.156222, mean_absolute_error: 2.670806, mean_q: 3.552170
116 (array([22]),) False
 130000/500000: episode: 3250, duration: 33.289s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 16.250 [1.000, 33.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.157883, mean_absolute_error: 2.656814, mean_q: 3.531128
736 (array([22]),) False
 130040/500000: episode: 3251, duration: 33.434s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.075 [22.000, 46.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.158817, mean_absolute_error: 2.645199, mean_q: 3.513846
484 (array([22]),) False
 130080/500000: episode: 3252, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.850 [3.000, 56.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.158283, mean_absolute_error: 2.661011, mean_q: 3.530945
529 (array([3]),) False
 130120/500000: episode: 3253, duration: 33.398s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 4.425 [2.000, 30.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.162996, mean_absolute_error: 2.663869, mean_q: 3.531665
344 (array([22]),) False
 130160/500000: episode: 3254, duration: 31.376s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.600 [10.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.152478, mean_absolute_error: 2.654718, mean_q: 3.521789
842 (array([22]),) False
 130200/500000: episode: 3255, duration: 31.257s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.450 [7.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.156566, mean_absolute_error: 2.625091, mean_q: 3.489470
386 (array([12]),) False
 130240/500000: episode: 3256, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.525 [18.000, 44.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.171178, mean_absolute_error: 2.680936, mean_q: 3.553180
784 (array([22]),) False
 130280/500000: episode: 3257, duration: 31.397s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.850 [0.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.164837, mean_absolute_error: 2.680112, mean_q: 3.550695
578 (array([22]),) False
 130320/500000: episode: 3258, duration: 30.340s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.500 [10.000, 39.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.157536, mean_absolute_error: 2.665457, mean_q: 3.522771
356 (array([22]),) False
 130360/500000: episode: 3259, duration: 31.483s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 51.400 [0.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.161884, mean_absolute_error: 2.655364, mean_q: 3.517429
719 (array([22]),) False
 130400/500000: episode: 3260, duration: 31.141s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 16.550 [5.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.176368, mean_absolute_error: 2.666327, mean_q: 3.538783
854 (array([12]),) False
 130440/500000: episode: 3261, duration: 31.655s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.725 [3.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.169999, mean_absolute_error: 2.647536, mean_q: 3.514020
438 (array([22]),) False
 130480/500000: episode: 3262, duration: 31.547s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.525 [1.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.166295, mean_absolute_error: 2.698280, mean_q: 3.578141
443 (array([22]),) False
 130520/500000: episode: 3263, duration: 31.606s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.425 [22.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.168006, mean_absolute_error: 2.690989, mean_q: 3.573400
102 (array([22]),) False
 130560/500000: episode: 3264, duration: 31.466s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.575 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.165849, mean_absolute_error: 2.686600, mean_q: 3.562396
284 (array([12]),) False
 130600/500000: episode: 3265, duration: 31.501s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.075 [3.000, 58.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.182643, mean_absolute_error: 2.699843, mean_q: 3.575827
301 (array([22]),) False
 130640/500000: episode: 3266, duration: 31.560s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.475 [12.000, 55.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.177196, mean_absolute_error: 2.669180, mean_q: 3.541937
468 (array([22]),) False
 130680/500000: episode: 3267, duration: 31.451s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.725 [11.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.168727, mean_absolute_error: 2.683966, mean_q: 3.558026
315 (array([12]),) False
 130720/500000: episode: 3268, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 25.175 [2.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.170361, mean_absolute_error: 2.690644, mean_q: 3.554684
358 (array([22]),) False
 130760/500000: episode: 3269, duration: 31.459s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.400 [5.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.177338, mean_absolute_error: 2.741858, mean_q: 3.615720
264 (array([12]),) False
 130800/500000: episode: 3270, duration: 31.057s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.650 [22.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.173975, mean_absolute_error: 2.703171, mean_q: 3.568132
445 (array([22]),) False
 130840/500000: episode: 3271, duration: 31.560s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.875 [12.000, 48.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.169385, mean_absolute_error: 2.705031, mean_q: 3.566946
23 (array([48]),) False
 130880/500000: episode: 3272, duration: 31.023s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 22.400 [5.000, 56.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.169825, mean_absolute_error: 2.653426, mean_q: 3.509077
701 (array([48]),) False
 130920/500000: episode: 3273, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.575 [15.000, 58.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.168165, mean_absolute_error: 2.676066, mean_q: 3.529908
417 (array([12]),) False
 130960/500000: episode: 3274, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.900 [12.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.172939, mean_absolute_error: 2.705533, mean_q: 3.559927
504 (array([48]),) False
 131000/500000: episode: 3275, duration: 33.259s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 44.875 [2.000, 54.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.166178, mean_absolute_error: 2.670372, mean_q: 3.519303
102 (array([22]),) False
 131040/500000: episode: 3276, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.125 [12.000, 53.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.177861, mean_absolute_error: 2.656258, mean_q: 3.517190
260 (array([22]),) False
 131080/500000: episode: 3277, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.175 [21.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.159223, mean_absolute_error: 2.664337, mean_q: 3.529172
257 (array([22]),) False
 131120/500000: episode: 3278, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 27.125 [3.000, 51.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.155700, mean_absolute_error: 2.666123, mean_q: 3.524254
333 (array([12]),) False
 131160/500000: episode: 3279, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 17.950 [0.000, 58.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.166290, mean_absolute_error: 2.688942, mean_q: 3.556173
779 (array([12]),) False
 131200/500000: episode: 3280, duration: 32.265s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 16.075 [10.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.166859, mean_absolute_error: 2.700487, mean_q: 3.565931
786 (array([22]),) False
 131240/500000: episode: 3281, duration: 33.261s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.850 [22.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.167049, mean_absolute_error: 2.713480, mean_q: 3.558803
105 (array([22]),) False
 131280/500000: episode: 3282, duration: 32.345s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.975 [22.000, 52.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.164283, mean_absolute_error: 2.713329, mean_q: 3.575321
584 (array([36]),) False
 131320/500000: episode: 3283, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 7.450 [3.000, 53.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.161997, mean_absolute_error: 2.681606, mean_q: 3.538378
415 (array([22]),) False
 131360/500000: episode: 3284, duration: 32.374s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.450 [5.000, 39.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.161757, mean_absolute_error: 2.712470, mean_q: 3.581052
96 (array([22]),) False
 131400/500000: episode: 3285, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.600 [4.000, 58.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.174511, mean_absolute_error: 2.701267, mean_q: 3.561089
124 (array([48]),) False
 131440/500000: episode: 3286, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.325 [12.000, 48.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.175059, mean_absolute_error: 2.704583, mean_q: 3.577329
689 (array([12]),) False
 131480/500000: episode: 3287, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 15.075 [0.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.158534, mean_absolute_error: 2.684197, mean_q: 3.554027
489 (array([22]),) False
 131520/500000: episode: 3288, duration: 33.246s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 17.400 [2.000, 57.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.181515, mean_absolute_error: 2.661684, mean_q: 3.524412
74 (array([22]),) False
 131560/500000: episode: 3289, duration: 31.587s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.050 [8.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.168049, mean_absolute_error: 2.680703, mean_q: 3.545824
528 (array([12]),) False
 131600/500000: episode: 3290, duration: 31.479s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 23.475 [15.000, 44.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.164090, mean_absolute_error: 2.723485, mean_q: 3.594333
293 (array([22]),) False
 131640/500000: episode: 3291, duration: 31.430s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.375 [1.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.159342, mean_absolute_error: 2.718650, mean_q: 3.590350
707 (array([48]),) False
 131680/500000: episode: 3292, duration: 31.043s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 48.150 [47.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.169943, mean_absolute_error: 2.711764, mean_q: 3.585607
748 (array([22]),) False
 131720/500000: episode: 3293, duration: 31.539s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.775 [4.000, 49.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.168467, mean_absolute_error: 2.707844, mean_q: 3.578828
839 (array([22]),) False
 131760/500000: episode: 3294, duration: 31.061s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.500 [22.000, 42.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.163047, mean_absolute_error: 2.696943, mean_q: 3.563083
682 (array([22]),) False
 131800/500000: episode: 3295, duration: 31.592s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.875 [22.000, 60.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.171264, mean_absolute_error: 2.679620, mean_q: 3.559721
39 (array([22]),) False
 131840/500000: episode: 3296, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.175 [22.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.161136, mean_absolute_error: 2.698719, mean_q: 3.576176
185 (array([22]),) False
 131880/500000: episode: 3297, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 20.975 [5.000, 53.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.160223, mean_absolute_error: 2.680904, mean_q: 3.562202
803 (array([58]),) False
 131920/500000: episode: 3298, duration: 31.461s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.325 [3.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.163283, mean_absolute_error: 2.698728, mean_q: 3.572805
265 (array([22]),) False
 131960/500000: episode: 3299, duration: 31.471s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.825 [3.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.178087, mean_absolute_error: 2.720783, mean_q: 3.611074
393 (array([22]),) False
 132000/500000: episode: 3300, duration: 31.460s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.350 [0.000, 59.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.182730, mean_absolute_error: 2.675046, mean_q: 3.547507
444 (array([22]),) False
 132040/500000: episode: 3301, duration: 31.470s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.175 [3.000, 48.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.175553, mean_absolute_error: 2.707666, mean_q: 3.586156
155 (array([22]),) False
 132080/500000: episode: 3302, duration: 31.445s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.150 [9.000, 60.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.169181, mean_absolute_error: 2.692928, mean_q: 3.569973
149 (array([8]),) False
 132120/500000: episode: 3303, duration: 31.486s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 9.850 [3.000, 51.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.166072, mean_absolute_error: 2.727270, mean_q: 3.613563
627 (array([48]),) False
 132160/500000: episode: 3304, duration: 31.475s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 44.475 [13.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.165803, mean_absolute_error: 2.716043, mean_q: 3.600729
381 (array([22]),) False
 132200/500000: episode: 3305, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.375 [7.000, 49.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.190204, mean_absolute_error: 2.714130, mean_q: 3.592272
573 (array([22]),) False
 132240/500000: episode: 3306, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.950 [10.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.171977, mean_absolute_error: 2.716330, mean_q: 3.601377
544 (array([22]),) False
 132280/500000: episode: 3307, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.500 [13.000, 43.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.160197, mean_absolute_error: 2.695268, mean_q: 3.577570
209 (array([8]),) False
 132320/500000: episode: 3308, duration: 32.263s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.275 [2.000, 44.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.179906, mean_absolute_error: 2.679829, mean_q: 3.555230
677 (array([48]),) False
 132360/500000: episode: 3309, duration: 32.436s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 31.300 [12.000, 59.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.173684, mean_absolute_error: 2.725320, mean_q: 3.605546
162 (array([22]),) False
 132400/500000: episode: 3310, duration: 31.441s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.900 [2.000, 58.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.176017, mean_absolute_error: 2.746078, mean_q: 3.651608
838 (array([21]),) False
 132440/500000: episode: 3311, duration: 31.580s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 22.500 [12.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.159366, mean_absolute_error: 2.681150, mean_q: 3.562713
721 (array([22]),) False
 132480/500000: episode: 3312, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.425 [2.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.175727, mean_absolute_error: 2.719483, mean_q: 3.610106
208 (array([22]),) False
 132520/500000: episode: 3313, duration: 31.481s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 22.025 [6.000, 49.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.179678, mean_absolute_error: 2.705696, mean_q: 3.595039
727 (array([12]),) False
 132560/500000: episode: 3314, duration: 31.471s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 14.800 [1.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.168635, mean_absolute_error: 2.683419, mean_q: 3.563563
521 (array([22]),) False
 132600/500000: episode: 3315, duration: 31.491s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.000 [6.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.179252, mean_absolute_error: 2.773720, mean_q: 3.670435
670 (array([22]),) False
 132640/500000: episode: 3316, duration: 30.994s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 25.825 [2.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.188607, mean_absolute_error: 2.740934, mean_q: 3.637239
624 (array([48]),) False
 132680/500000: episode: 3317, duration: 31.487s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 25.700 [2.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.180213, mean_absolute_error: 2.716024, mean_q: 3.626546
564 (array([22]),) False
 132720/500000: episode: 3318, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.275 [6.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.177567, mean_absolute_error: 2.715109, mean_q: 3.597214
157 (array([48]),) False
 132760/500000: episode: 3319, duration: 31.538s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 43.575 [3.000, 48.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.178213, mean_absolute_error: 2.738686, mean_q: 3.616881
568 (array([22]),) False
 132800/500000: episode: 3320, duration: 31.034s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.375 [13.000, 40.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.193567, mean_absolute_error: 2.733780, mean_q: 3.613171
2 (array([12]),) False
 132840/500000: episode: 3321, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.350 [10.000, 54.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.172830, mean_absolute_error: 2.718214, mean_q: 3.597814
147 (array([44]),) False
 132880/500000: episode: 3322, duration: 31.535s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 23.675 [5.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.192032, mean_absolute_error: 2.717540, mean_q: 3.581109
742 (array([33]),) False
 132920/500000: episode: 3323, duration: 31.504s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 38.675 [9.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.165605, mean_absolute_error: 2.762157, mean_q: 3.641495
850 (array([12]),) False
 132960/500000: episode: 3324, duration: 31.490s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 17.475 [2.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.162440, mean_absolute_error: 2.757144, mean_q: 3.624409
316 (array([12]),) False
 133000/500000: episode: 3325, duration: 31.501s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 16.450 [3.000, 51.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.177000, mean_absolute_error: 2.747000, mean_q: 3.614501
729 (array([22]),) False
 133040/500000: episode: 3326, duration: 31.473s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 26.250 [22.000, 53.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.166827, mean_absolute_error: 2.731144, mean_q: 3.623777
474 (array([22]),) False
 133080/500000: episode: 3327, duration: 31.476s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.850 [11.000, 53.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.172740, mean_absolute_error: 2.732104, mean_q: 3.604255
11 (array([22]),) False
 133120/500000: episode: 3328, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.925 [7.000, 38.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.174033, mean_absolute_error: 2.760482, mean_q: 3.638216
854 (array([12]),) False
 133160/500000: episode: 3329, duration: 31.480s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 23.325 [4.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.172572, mean_absolute_error: 2.761412, mean_q: 3.642162
414 (array([48]),) False
 133200/500000: episode: 3330, duration: 31.086s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.825 [2.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.174856, mean_absolute_error: 2.695647, mean_q: 3.566729
757 (array([48]),) False
 133240/500000: episode: 3331, duration: 31.442s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 39.400 [8.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.178400, mean_absolute_error: 2.766078, mean_q: 3.642976
615 (array([36]),) False
 133280/500000: episode: 3332, duration: 31.045s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 30.725 [1.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.176112, mean_absolute_error: 2.759007, mean_q: 3.635166
5 (array([37]),) False
 133320/500000: episode: 3333, duration: 31.549s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 11.200 [8.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.176247, mean_absolute_error: 2.751799, mean_q: 3.627693
516 (array([48]),) False
 133360/500000: episode: 3334, duration: 31.525s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 23.450 [10.000, 51.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.177507, mean_absolute_error: 2.748842, mean_q: 3.633326
774 (array([57]),) False
 133400/500000: episode: 3335, duration: 31.461s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 28.325 [3.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.174280, mean_absolute_error: 2.731781, mean_q: 3.596097
201 (array([22]),) False
 133440/500000: episode: 3336, duration: 31.019s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.750 [22.000, 55.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.163949, mean_absolute_error: 2.736696, mean_q: 3.588552
791 (array([54]),) False
 133480/500000: episode: 3337, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 14.700 [3.000, 32.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.178186, mean_absolute_error: 2.757700, mean_q: 3.624268
620 (array([44]),) False
 133520/500000: episode: 3338, duration: 31.516s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 31.475 [2.000, 59.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.171999, mean_absolute_error: 2.782113, mean_q: 3.650355
318 (array([48]),) False
 133560/500000: episode: 3339, duration: 31.539s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 40.125 [12.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.173770, mean_absolute_error: 2.782918, mean_q: 3.656909
55 (array([22]),) False
 133600/500000: episode: 3340, duration: 31.013s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.750 [9.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.189677, mean_absolute_error: 2.749166, mean_q: 3.622631
633 (array([22]),) False
 133640/500000: episode: 3341, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.425 [6.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.195984, mean_absolute_error: 2.786939, mean_q: 3.668562
554 (array([22]),) False
 133680/500000: episode: 3342, duration: 31.529s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.600 [14.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.185735, mean_absolute_error: 2.764292, mean_q: 3.645087
581 (array([22]),) False
 133720/500000: episode: 3343, duration: 31.501s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.425 [1.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.184022, mean_absolute_error: 2.779534, mean_q: 3.644178
729 (array([22]),) False
 133760/500000: episode: 3344, duration: 31.059s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.350 [1.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.188853, mean_absolute_error: 2.763870, mean_q: 3.635888
844 (array([48]),) False
 133800/500000: episode: 3345, duration: 31.486s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 35.700 [2.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.189223, mean_absolute_error: 2.764709, mean_q: 3.651801
543 (array([12]),) False
 133840/500000: episode: 3346, duration: 31.586s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 13.525 [5.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.187127, mean_absolute_error: 2.765047, mean_q: 3.648812
52 (array([22]),) False
 133880/500000: episode: 3347, duration: 31.549s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.800 [17.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.181991, mean_absolute_error: 2.752137, mean_q: 3.634715
573 (array([22]),) False
 133920/500000: episode: 3348, duration: 31.073s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.125 [22.000, 27.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.171123, mean_absolute_error: 2.783478, mean_q: 3.661386
91 (array([48]),) False
 133960/500000: episode: 3349, duration: 31.490s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 42.800 [6.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.177171, mean_absolute_error: 2.734069, mean_q: 3.606977
383 (array([22]),) False
 134000/500000: episode: 3350, duration: 31.491s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.200 [2.000, 51.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.171811, mean_absolute_error: 2.788624, mean_q: 3.654891
226 (array([22]),) False
 134040/500000: episode: 3351, duration: 31.521s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.250 [12.000, 58.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.166289, mean_absolute_error: 2.749623, mean_q: 3.618636
533 (array([22]),) False
 134080/500000: episode: 3352, duration: 31.059s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.925 [8.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.161715, mean_absolute_error: 2.744852, mean_q: 3.625417
356 (array([22]),) False
 134120/500000: episode: 3353, duration: 31.561s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.225 [5.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.177899, mean_absolute_error: 2.763258, mean_q: 3.637667
297 (array([15]),) False
 134160/500000: episode: 3354, duration: 31.472s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.875 [1.000, 48.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.176495, mean_absolute_error: 2.775173, mean_q: 3.641260
714 (array([22]),) False
 134200/500000: episode: 3355, duration: 31.521s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 15.350 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.166584, mean_absolute_error: 2.701643, mean_q: 3.549767
45 (array([22]),) False
 134240/500000: episode: 3356, duration: 31.037s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.475 [4.000, 50.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.182652, mean_absolute_error: 2.784402, mean_q: 3.658065
139 (array([48]),) False
 134280/500000: episode: 3357, duration: 31.538s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 20.875 [1.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.190948, mean_absolute_error: 2.743223, mean_q: 3.603238
257 (array([22]),) False
 134320/500000: episode: 3358, duration: 31.487s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.225 [4.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.165002, mean_absolute_error: 2.749857, mean_q: 3.611943
184 (array([12]),) False
 134360/500000: episode: 3359, duration: 31.493s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 14.375 [12.000, 57.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.185673, mean_absolute_error: 2.740973, mean_q: 3.601934
838 (array([21]),) False
 134400/500000: episode: 3360, duration: 31.077s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 26.200 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.183500, mean_absolute_error: 2.724576, mean_q: 3.584808
571 (array([48]),) False
 134440/500000: episode: 3361, duration: 31.454s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 22.675 [7.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.174684, mean_absolute_error: 2.688949, mean_q: 3.557405
84 (array([22]),) False
 134480/500000: episode: 3362, duration: 31.537s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.050 [8.000, 47.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.185011, mean_absolute_error: 2.731675, mean_q: 3.600472
453 (array([22]),) False
 134520/500000: episode: 3363, duration: 31.558s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 21.950 [1.000, 44.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.164418, mean_absolute_error: 2.748927, mean_q: 3.622077
300 (array([22]),) False
 134560/500000: episode: 3364, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.750 [8.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.166062, mean_absolute_error: 2.735089, mean_q: 3.604332
359 (array([22]),) False
 134600/500000: episode: 3365, duration: 31.537s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.725 [3.000, 44.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.174655, mean_absolute_error: 2.769900, mean_q: 3.641342
551 (array([22]),) False
 134640/500000: episode: 3366, duration: 31.517s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.425 [2.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.175300, mean_absolute_error: 2.758274, mean_q: 3.626694
74 (array([22]),) False
 134680/500000: episode: 3367, duration: 31.473s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.225 [12.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.175210, mean_absolute_error: 2.796093, mean_q: 3.666452
510 (array([22]),) False
 134720/500000: episode: 3368, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.125 [12.000, 52.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.167025, mean_absolute_error: 2.782514, mean_q: 3.649312
191 (array([38]),) False
 134760/500000: episode: 3369, duration: 31.518s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 22.700 [1.000, 56.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.174760, mean_absolute_error: 2.764219, mean_q: 3.627501
482 (array([22]),) False
 134800/500000: episode: 3370, duration: 31.434s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.175 [14.000, 51.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.186550, mean_absolute_error: 2.755601, mean_q: 3.615603
252 (array([22]),) False
 134840/500000: episode: 3371, duration: 31.431s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.325 [0.000, 44.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.184635, mean_absolute_error: 2.772653, mean_q: 3.636135
415 (array([22]),) False
 134880/500000: episode: 3372, duration: 31.532s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.000 [2.000, 22.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.174638, mean_absolute_error: 2.740709, mean_q: 3.602850
467 (array([48]),) False
 134920/500000: episode: 3373, duration: 31.634s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 33.850 [2.000, 55.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.189243, mean_absolute_error: 2.716646, mean_q: 3.579713
423 (array([22]),) False
 134960/500000: episode: 3374, duration: 31.558s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.525 [13.000, 39.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.176321, mean_absolute_error: 2.742089, mean_q: 3.606788
627 (array([48]),) False
 135000/500000: episode: 3375, duration: 31.493s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.375 [37.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.196334, mean_absolute_error: 2.740612, mean_q: 3.612192
823 (array([58]),) False
 135040/500000: episode: 3376, duration: 31.158s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 36.925 [12.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.184289, mean_absolute_error: 2.732670, mean_q: 3.596797
388 (array([22]),) False
 135080/500000: episode: 3377, duration: 31.551s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.600 [22.000, 46.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.172629, mean_absolute_error: 2.750765, mean_q: 3.628277
414 (array([48]),) False
 135120/500000: episode: 3378, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.700 [10.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.167147, mean_absolute_error: 2.776294, mean_q: 3.636815
761 (array([3]),) False
 135160/500000: episode: 3379, duration: 31.550s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 11.550 [1.000, 49.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.164698, mean_absolute_error: 2.764687, mean_q: 3.628770
98 (array([12]),) False
 135200/500000: episode: 3380, duration: 31.095s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.950 [0.000, 52.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.164154, mean_absolute_error: 2.729939, mean_q: 3.603388
308 (array([22]),) False
 135240/500000: episode: 3381, duration: 31.535s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 30.400 [12.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.169816, mean_absolute_error: 2.807550, mean_q: 3.684602
615 (array([36]),) False
 135280/500000: episode: 3382, duration: 31.556s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 34.925 [22.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.200965, mean_absolute_error: 2.729332, mean_q: 3.602071
730 (array([54]),) False
 135320/500000: episode: 3383, duration: 31.501s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.350 [12.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.167819, mean_absolute_error: 2.777008, mean_q: 3.655729
83 (array([22]),) False
 135360/500000: episode: 3384, duration: 31.478s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.425 [0.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.174785, mean_absolute_error: 2.822822, mean_q: 3.714761
100 (array([22]),) False
 135400/500000: episode: 3385, duration: 31.524s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.275 [6.000, 59.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.172104, mean_absolute_error: 2.807548, mean_q: 3.687870
81 (array([22]),) False
 135440/500000: episode: 3386, duration: 31.497s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.825 [21.000, 42.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.198061, mean_absolute_error: 2.774372, mean_q: 3.658639
702 (array([22]),) False
 135480/500000: episode: 3387, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.700 [4.000, 37.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.173321, mean_absolute_error: 2.805888, mean_q: 3.688047
817 (array([12]),) False
 135520/500000: episode: 3388, duration: 31.060s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 17.800 [1.000, 46.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.189124, mean_absolute_error: 2.803373, mean_q: 3.671665
403 (array([12]),) False
 135560/500000: episode: 3389, duration: 31.598s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.900 [4.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.179940, mean_absolute_error: 2.806714, mean_q: 3.692306
508 (array([22]),) False
 135600/500000: episode: 3390, duration: 31.065s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 34.075 [7.000, 51.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.190206, mean_absolute_error: 2.803655, mean_q: 3.671729
127 (array([22]),) False
 135640/500000: episode: 3391, duration: 31.566s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.725 [22.000, 38.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.200880, mean_absolute_error: 2.791204, mean_q: 3.669553
720 (array([22]),) False
 135680/500000: episode: 3392, duration: 31.044s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 25.300 [18.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.186065, mean_absolute_error: 2.836294, mean_q: 3.714500
66 (array([22]),) False
 135720/500000: episode: 3393, duration: 31.478s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.550 [14.000, 46.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.187441, mean_absolute_error: 2.754375, mean_q: 3.633749
116 (array([22]),) False
 135760/500000: episode: 3394, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.200 [3.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.183875, mean_absolute_error: 2.780225, mean_q: 3.666553
519 (array([58]),) False
 135800/500000: episode: 3395, duration: 31.515s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 49.775 [0.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.180294, mean_absolute_error: 2.806376, mean_q: 3.688500
491 (array([22]),) False
 135840/500000: episode: 3396, duration: 31.046s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.500 [2.000, 22.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.182786, mean_absolute_error: 2.805783, mean_q: 3.683642
198 (array([22]),) False
 135880/500000: episode: 3397, duration: 31.658s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.525 [9.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.173782, mean_absolute_error: 2.849021, mean_q: 3.737460
617 (array([22]),) False
 135920/500000: episode: 3398, duration: 31.524s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.750 [5.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.190935, mean_absolute_error: 2.808813, mean_q: 3.690662
501 (array([12]),) False
 135960/500000: episode: 3399, duration: 31.491s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.850 [3.000, 52.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.183846, mean_absolute_error: 2.815005, mean_q: 3.695419
774 (array([57]),) False
 136000/500000: episode: 3400, duration: 31.478s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 31.025 [3.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.170494, mean_absolute_error: 2.822739, mean_q: 3.703684
427 (array([22]),) False
 136040/500000: episode: 3401, duration: 31.514s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.050 [16.000, 50.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.180597, mean_absolute_error: 2.791050, mean_q: 3.661727
422 (array([48]),) False
 136080/500000: episode: 3402, duration: 31.470s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.225 [5.000, 48.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.186491, mean_absolute_error: 2.809380, mean_q: 3.684079
802 (array([22]),) False
 136120/500000: episode: 3403, duration: 31.503s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.025 [3.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.183987, mean_absolute_error: 2.803986, mean_q: 3.669685
91 (array([48]),) False
 136160/500000: episode: 3404, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 41.875 [12.000, 53.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.176675, mean_absolute_error: 2.786608, mean_q: 3.645199
760 (array([22]),) False
 136200/500000: episode: 3405, duration: 31.548s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 27.950 [0.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.190367, mean_absolute_error: 2.833111, mean_q: 3.698730
805 (array([22]),) False
 136240/500000: episode: 3406, duration: 31.063s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.825 [12.000, 50.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.189196, mean_absolute_error: 2.839854, mean_q: 3.726341
69 (array([12]),) False
 136280/500000: episode: 3407, duration: 31.546s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 13.350 [6.000, 37.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.174069, mean_absolute_error: 2.847801, mean_q: 3.727809
721 (array([22]),) False
 136320/500000: episode: 3408, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.425 [9.000, 49.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.181160, mean_absolute_error: 2.826695, mean_q: 3.694213
183 (array([22]),) False
 136360/500000: episode: 3409, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.350 [0.000, 54.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.185306, mean_absolute_error: 2.853759, mean_q: 3.732341
94 (array([44]),) False
 136400/500000: episode: 3410, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 42.675 [0.000, 51.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.186145, mean_absolute_error: 2.843832, mean_q: 3.727834
210 (array([58]),) False
 136440/500000: episode: 3411, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 42.300 [0.000, 58.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.190728, mean_absolute_error: 2.797504, mean_q: 3.680119
811 (array([33]),) False
 136480/500000: episode: 3412, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 22.725 [10.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.179781, mean_absolute_error: 2.784136, mean_q: 3.663870
189 (array([12]),) False
 136520/500000: episode: 3413, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.275 [3.000, 49.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.172131, mean_absolute_error: 2.787841, mean_q: 3.670700
209 (array([8]),) False
 136560/500000: episode: 3414, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 35.550 [3.000, 53.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.180136, mean_absolute_error: 2.766434, mean_q: 3.644803
641 (array([22]),) False
 136600/500000: episode: 3415, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.350 [4.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.181999, mean_absolute_error: 2.813187, mean_q: 3.697816
129 (array([22]),) False
 136640/500000: episode: 3416, duration: 32.256s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.875 [8.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.173976, mean_absolute_error: 2.741995, mean_q: 3.611960
455 (array([22]),) False
 136680/500000: episode: 3417, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 40.925 [7.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.186569, mean_absolute_error: 2.807472, mean_q: 3.682123
825 (array([22]),) False
 136720/500000: episode: 3418, duration: 32.261s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.700 [22.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.188029, mean_absolute_error: 2.790724, mean_q: 3.677158
87 (array([3]),) False
 136760/500000: episode: 3419, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.325 [22.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.167167, mean_absolute_error: 2.796402, mean_q: 3.682616
684 (array([22]),) False
 136800/500000: episode: 3420, duration: 32.259s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.750 [9.000, 35.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.166868, mean_absolute_error: 2.796768, mean_q: 3.679353
293 (array([22]),) False
 136840/500000: episode: 3421, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.950 [0.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.183283, mean_absolute_error: 2.808769, mean_q: 3.686642
622 (array([36]),) False
 136880/500000: episode: 3422, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 33.525 [3.000, 59.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.186798, mean_absolute_error: 2.775038, mean_q: 3.653116
641 (array([22]),) False
 136920/500000: episode: 3423, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.150 [0.000, 41.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.195571, mean_absolute_error: 2.748394, mean_q: 3.619508
302 (array([22]),) False
 136960/500000: episode: 3424, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.550 [11.000, 55.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.161612, mean_absolute_error: 2.798465, mean_q: 3.660198
333 (array([12]),) False
 137000/500000: episode: 3425, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 18.575 [12.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.189654, mean_absolute_error: 2.831450, mean_q: 3.704169
560 (array([22]),) False
 137040/500000: episode: 3426, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.575 [0.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.171667, mean_absolute_error: 2.863333, mean_q: 3.740386
477 (array([22]),) False
 137080/500000: episode: 3427, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.625 [9.000, 50.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.173417, mean_absolute_error: 2.805034, mean_q: 3.683220
320 (array([22]),) False
 137120/500000: episode: 3428, duration: 32.275s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 20.425 [12.000, 22.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.179330, mean_absolute_error: 2.790291, mean_q: 3.661318
557 (array([22]),) False
 137160/500000: episode: 3429, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.100 [21.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.171983, mean_absolute_error: 2.777608, mean_q: 3.642924
122 (array([12]),) False
 137200/500000: episode: 3430, duration: 32.289s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 21.400 [12.000, 44.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.184284, mean_absolute_error: 2.808732, mean_q: 3.676752
341 (array([22]),) False
 137240/500000: episode: 3431, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.075 [0.000, 33.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.172520, mean_absolute_error: 2.826392, mean_q: 3.696553
430 (array([22]),) False
 137280/500000: episode: 3432, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.975 [1.000, 59.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.177625, mean_absolute_error: 2.809819, mean_q: 3.680210
280 (array([48]),) False
 137320/500000: episode: 3433, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 19.275 [0.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.181386, mean_absolute_error: 2.775448, mean_q: 3.641465
36 (array([22]),) False
 137360/500000: episode: 3434, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 26.775 [22.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.194373, mean_absolute_error: 2.790973, mean_q: 3.663658
271 (array([18]),) False
 137400/500000: episode: 3435, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.900 [3.000, 53.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.184221, mean_absolute_error: 2.789235, mean_q: 3.661353
409 (array([22]),) False
 137440/500000: episode: 3436, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.075 [2.000, 29.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.175460, mean_absolute_error: 2.796541, mean_q: 3.668427
725 (array([36]),) False
 137480/500000: episode: 3437, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 29.825 [1.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.188988, mean_absolute_error: 2.796824, mean_q: 3.663281
605 (array([22]),) False
 137520/500000: episode: 3438, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.700 [6.000, 53.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.179043, mean_absolute_error: 2.828259, mean_q: 3.695947
615 (array([36]),) False
 137560/500000: episode: 3439, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 35.850 [8.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.178070, mean_absolute_error: 2.779469, mean_q: 3.651302
473 (array([22]),) False
 137600/500000: episode: 3440, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.550 [22.000, 51.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.180238, mean_absolute_error: 2.777732, mean_q: 3.637103
252 (array([22]),) False
 137640/500000: episode: 3441, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.800 [18.000, 24.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.185695, mean_absolute_error: 2.780035, mean_q: 3.640547
403 (array([12]),) False
 137680/500000: episode: 3442, duration: 32.257s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.650 [12.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.169091, mean_absolute_error: 2.781212, mean_q: 3.640854
539 (array([22]),) False
 137720/500000: episode: 3443, duration: 33.320s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.425 [2.000, 51.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.190149, mean_absolute_error: 2.790890, mean_q: 3.658309
262 (array([22]),) False
 137760/500000: episode: 3444, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 23.600 [8.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.173039, mean_absolute_error: 2.776134, mean_q: 3.633710
520 (array([22]),) False
 137800/500000: episode: 3445, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.675 [10.000, 44.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.174613, mean_absolute_error: 2.823879, mean_q: 3.691560
651 (array([22]),) False
 137840/500000: episode: 3446, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.025 [22.000, 44.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.175997, mean_absolute_error: 2.772310, mean_q: 3.632650
47 (array([44]),) False
 137880/500000: episode: 3447, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 24.325 [4.000, 45.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.169388, mean_absolute_error: 2.809826, mean_q: 3.683117
119 (array([45]),) False
 137920/500000: episode: 3448, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 15.025 [12.000, 44.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.181368, mean_absolute_error: 2.793674, mean_q: 3.664918
830 (array([22]),) False
 137960/500000: episode: 3449, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.750 [7.000, 54.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.163778, mean_absolute_error: 2.780820, mean_q: 3.644984
350 (array([12]),) False
 138000/500000: episode: 3450, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 18.075 [11.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.175514, mean_absolute_error: 2.800873, mean_q: 3.669761
405 (array([22]),) False
 138040/500000: episode: 3451, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.425 [22.000, 32.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.186238, mean_absolute_error: 2.773476, mean_q: 3.632853
736 (array([22]),) False
 138080/500000: episode: 3452, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.850 [3.000, 43.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.192251, mean_absolute_error: 2.781619, mean_q: 3.642961
523 (array([22]),) False
 138120/500000: episode: 3453, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.075 [10.000, 28.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.177413, mean_absolute_error: 2.821629, mean_q: 3.694180
396 (array([48]),) False
 138160/500000: episode: 3454, duration: 32.296s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 44.725 [2.000, 48.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.167306, mean_absolute_error: 2.777387, mean_q: 3.637439
68 (array([22]),) False
 138200/500000: episode: 3455, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.125 [15.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.196001, mean_absolute_error: 2.766898, mean_q: 3.631451
622 (array([36]),) False
 138240/500000: episode: 3456, duration: 32.220s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 32.650 [3.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.182968, mean_absolute_error: 2.775280, mean_q: 3.635739
136 (array([12]),) False
 138280/500000: episode: 3457, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.150 [7.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.177028, mean_absolute_error: 2.818336, mean_q: 3.686077
257 (array([22]),) False
 138320/500000: episode: 3458, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.125 [5.000, 51.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.183584, mean_absolute_error: 2.746262, mean_q: 3.604367
623 (array([37]),) False
 138360/500000: episode: 3459, duration: 33.353s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.025 [3.000, 54.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.179258, mean_absolute_error: 2.767918, mean_q: 3.628187
828 (array([48]),) False
 138400/500000: episode: 3460, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 46.700 [22.000, 49.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.171981, mean_absolute_error: 2.821186, mean_q: 3.686627
335 (array([22]),) False
 138440/500000: episode: 3461, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.425 [5.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.173271, mean_absolute_error: 2.764082, mean_q: 3.626149
190 (array([3]),) False
 138480/500000: episode: 3462, duration: 33.155s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 6.375 [3.000, 49.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.180705, mean_absolute_error: 2.773721, mean_q: 3.656708
500 (array([22]),) False
 138520/500000: episode: 3463, duration: 33.008s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 25.350 [3.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.190555, mean_absolute_error: 2.768718, mean_q: 3.647222
641 (array([22]),) False
 138560/500000: episode: 3464, duration: 32.271s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.775 [6.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.215035, mean_absolute_error: 2.784835, mean_q: 3.665672
30 (array([22]),) False
 138600/500000: episode: 3465, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.450 [2.000, 42.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.188592, mean_absolute_error: 2.809178, mean_q: 3.696564
413 (array([22]),) False
 138640/500000: episode: 3466, duration: 32.272s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 24.875 [11.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.188634, mean_absolute_error: 2.821965, mean_q: 3.690531
177 (array([22]),) False
 138680/500000: episode: 3467, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 20.350 [12.000, 23.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.195885, mean_absolute_error: 2.819247, mean_q: 3.692877
636 (array([12]),) False
 138720/500000: episode: 3468, duration: 32.261s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 40.800 [6.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.174487, mean_absolute_error: 2.810339, mean_q: 3.672020
792 (array([58]),) False
 138760/500000: episode: 3469, duration: 32.131s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 37.250 [3.000, 58.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.175980, mean_absolute_error: 2.790116, mean_q: 3.649234
721 (array([22]),) False
 138800/500000: episode: 3470, duration: 31.969s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.200 [22.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.169984, mean_absolute_error: 2.758085, mean_q: 3.623602
734 (array([48]),) False
 138840/500000: episode: 3471, duration: 31.266s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 25.675 [9.000, 50.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.172085, mean_absolute_error: 2.794759, mean_q: 3.649060
429 (array([22]),) False
 138880/500000: episode: 3472, duration: 31.506s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.200 [20.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.185657, mean_absolute_error: 2.803763, mean_q: 3.670672
784 (array([22]),) False
 138920/500000: episode: 3473, duration: 31.547s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.925 [9.000, 40.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.190405, mean_absolute_error: 2.810037, mean_q: 3.681342
28 (array([58]),) False
 138960/500000: episode: 3474, duration: 31.493s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 29.850 [22.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.178516, mean_absolute_error: 2.796434, mean_q: 3.652804
19 (array([12]),) False
 139000/500000: episode: 3475, duration: 31.497s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.650 [14.000, 48.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.188618, mean_absolute_error: 2.809880, mean_q: 3.678145
76 (array([38]),) False
 139040/500000: episode: 3476, duration: 31.039s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 34.675 [0.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.178984, mean_absolute_error: 2.805040, mean_q: 3.654535
95 (array([22]),) False
 139080/500000: episode: 3477, duration: 31.463s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.075 [6.000, 48.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.173805, mean_absolute_error: 2.792849, mean_q: 3.646082
280 (array([48]),) False
 139120/500000: episode: 3478, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 18.500 [2.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.192106, mean_absolute_error: 2.807335, mean_q: 3.665922
762 (array([22]),) False
 139160/500000: episode: 3479, duration: 31.568s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.525 [1.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.194917, mean_absolute_error: 2.853285, mean_q: 3.714574
576 (array([58]),) False
 139200/500000: episode: 3480, duration: 31.083s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 57.025 [38.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.173165, mean_absolute_error: 2.827543, mean_q: 3.694270
114 (array([22]),) False
 139240/500000: episode: 3481, duration: 31.635s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.625 [3.000, 57.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.173757, mean_absolute_error: 2.839951, mean_q: 3.707226
602 (array([36]),) False
 139280/500000: episode: 3482, duration: 31.928s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 38.650 [3.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.186140, mean_absolute_error: 2.887104, mean_q: 3.760882
818 (array([48]),) False
 139320/500000: episode: 3483, duration: 33.330s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 23.800 [4.000, 50.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.199913, mean_absolute_error: 2.867555, mean_q: 3.743437
60 (array([22]),) False
 139360/500000: episode: 3484, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 34.700 [1.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.175507, mean_absolute_error: 2.778245, mean_q: 3.637528
145 (array([19]),) False
 139400/500000: episode: 3485, duration: 33.277s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.475 [0.000, 44.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.189652, mean_absolute_error: 2.836271, mean_q: 3.722107
228 (array([44]),) False
 139440/500000: episode: 3486, duration: 33.299s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 21.750 [0.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.182775, mean_absolute_error: 2.849092, mean_q: 3.724512
716 (array([48]),) False
 139480/500000: episode: 3487, duration: 33.265s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 34.200 [19.000, 51.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.185537, mean_absolute_error: 2.827499, mean_q: 3.706764
135 (array([22]),) False
 139520/500000: episode: 3488, duration: 32.345s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.450 [1.000, 22.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.183479, mean_absolute_error: 2.846606, mean_q: 3.722888
318 (array([48]),) False
 139560/500000: episode: 3489, duration: 33.277s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 41.425 [7.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.183880, mean_absolute_error: 2.797276, mean_q: 3.652899
784 (array([22]),) False
 139600/500000: episode: 3490, duration: 32.395s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.186290, mean_absolute_error: 2.862782, mean_q: 3.740488
18 (array([22]),) False
 139640/500000: episode: 3491, duration: 33.400s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.250 [3.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.180445, mean_absolute_error: 2.841105, mean_q: 3.713437
123 (array([22]),) False
 139680/500000: episode: 3492, duration: 32.397s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.100 [6.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.176622, mean_absolute_error: 2.820275, mean_q: 3.685282
132 (array([22]),) False
 139720/500000: episode: 3493, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.525 [0.000, 45.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.175763, mean_absolute_error: 2.811110, mean_q: 3.683661
283 (array([34]),) False
 139760/500000: episode: 3494, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 22.750 [8.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.174137, mean_absolute_error: 2.813943, mean_q: 3.691342
297 (array([15]),) False
 139800/500000: episode: 3495, duration: 33.306s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.925 [20.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.182373, mean_absolute_error: 2.863988, mean_q: 3.745512
50 (array([22]),) False
 139840/500000: episode: 3496, duration: 33.361s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.225 [8.000, 45.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.179065, mean_absolute_error: 2.837138, mean_q: 3.701899
780 (array([22]),) False
 139880/500000: episode: 3497, duration: 33.297s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.550 [3.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.189159, mean_absolute_error: 2.872414, mean_q: 3.749497
142 (array([12]),) False
 139920/500000: episode: 3498, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 25.900 [10.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.195949, mean_absolute_error: 2.887215, mean_q: 3.770404
756 (array([48]),) False
 139960/500000: episode: 3499, duration: 33.223s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 44.275 [1.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.206588, mean_absolute_error: 2.819613, mean_q: 3.699878
581 (array([22]),) False
 140000/500000: episode: 3500, duration: 32.375s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.125 [9.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.192278, mean_absolute_error: 2.846673, mean_q: 3.728768
225 (array([48]),) False
 140040/500000: episode: 3501, duration: 33.336s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 23.450 [11.000, 49.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.175491, mean_absolute_error: 2.863199, mean_q: 3.732597
435 (array([22]),) False
 140080/500000: episode: 3502, duration: 32.423s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.225 [22.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.183808, mean_absolute_error: 2.837520, mean_q: 3.699709
672 (array([44]),) False
 140120/500000: episode: 3503, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 49.250 [3.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.197519, mean_absolute_error: 2.799565, mean_q: 3.660391
292 (array([22]),) False
 140160/500000: episode: 3504, duration: 32.351s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.125 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.176010, mean_absolute_error: 2.876365, mean_q: 3.758918
90 (array([22]),) False
 140200/500000: episode: 3505, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.000 [0.000, 39.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.200515, mean_absolute_error: 2.853496, mean_q: 3.716153
855 (array([12]),) False
 140240/500000: episode: 3506, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 15.750 [12.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.187231, mean_absolute_error: 2.859820, mean_q: 3.737733
831 (array([3]),) False
 140280/500000: episode: 3507, duration: 33.397s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 12.700 [3.000, 60.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.170583, mean_absolute_error: 2.873675, mean_q: 3.761011
537 (array([22]),) False
 140320/500000: episode: 3508, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.225 [5.000, 31.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.174134, mean_absolute_error: 2.810167, mean_q: 3.685364
331 (array([22]),) False
 140360/500000: episode: 3509, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.475 [22.000, 41.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.177228, mean_absolute_error: 2.849477, mean_q: 3.739244
333 (array([12]),) False
 140400/500000: episode: 3510, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 18.125 [12.000, 36.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.180322, mean_absolute_error: 2.844554, mean_q: 3.722505
162 (array([22]),) False
 140440/500000: episode: 3511, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.250 [0.000, 46.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.188911, mean_absolute_error: 2.819090, mean_q: 3.699204
37 (array([48]),) False
 140480/500000: episode: 3512, duration: 32.302s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 45.200 [4.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.187875, mean_absolute_error: 2.860161, mean_q: 3.742662
578 (array([22]),) False
 140520/500000: episode: 3513, duration: 33.308s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.600 [22.000, 45.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.200510, mean_absolute_error: 2.841855, mean_q: 3.729195
386 (array([12]),) False
 140560/500000: episode: 3514, duration: 32.361s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.525 [0.000, 53.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.175558, mean_absolute_error: 2.849014, mean_q: 3.743495
669 (array([15]),) False
 140600/500000: episode: 3515, duration: 33.293s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.600 [1.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.190203, mean_absolute_error: 2.860739, mean_q: 3.750776
732 (array([12]),) False
 140640/500000: episode: 3516, duration: 32.413s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 20.775 [9.000, 44.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.198869, mean_absolute_error: 2.809727, mean_q: 3.687793
45 (array([22]),) False
 140680/500000: episode: 3517, duration: 33.334s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.325 [18.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.192902, mean_absolute_error: 2.807718, mean_q: 3.691167
483 (array([48]),) False
 140720/500000: episode: 3518, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 33.575 [3.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.190843, mean_absolute_error: 2.830076, mean_q: 3.699113
163 (array([44]),) False
 140760/500000: episode: 3519, duration: 33.284s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 27.225 [12.000, 44.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.172360, mean_absolute_error: 2.818760, mean_q: 3.700610
94 (array([44]),) False
 140800/500000: episode: 3520, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 42.950 [25.000, 51.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.180319, mean_absolute_error: 2.827384, mean_q: 3.687719
288 (array([33]),) False
 140840/500000: episode: 3521, duration: 33.291s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 30.950 [2.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.195718, mean_absolute_error: 2.842698, mean_q: 3.707584
643 (array([44]),) False
 140880/500000: episode: 3522, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 41.025 [9.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.174450, mean_absolute_error: 2.850150, mean_q: 3.716684
353 (array([22]),) False
 140920/500000: episode: 3523, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.050 [2.000, 54.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.195769, mean_absolute_error: 2.805367, mean_q: 3.674908
263 (array([8]),) False
 140960/500000: episode: 3524, duration: 32.282s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 8.850 [8.000, 23.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.174468, mean_absolute_error: 2.828187, mean_q: 3.702325
424 (array([22]),) False
 141000/500000: episode: 3525, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.250 [13.000, 59.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.183988, mean_absolute_error: 2.842102, mean_q: 3.728672
302 (array([22]),) False
 141040/500000: episode: 3526, duration: 32.303s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.050 [9.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.182293, mean_absolute_error: 2.860924, mean_q: 3.742916
190 (array([3]),) False
 141080/500000: episode: 3527, duration: 33.335s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 6.025 [3.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.179253, mean_absolute_error: 2.796945, mean_q: 3.673818
165 (array([34]),) False
 141120/500000: episode: 3528, duration: 32.395s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 22.150 [6.000, 46.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.195499, mean_absolute_error: 2.836254, mean_q: 3.712489
488 (array([22]),) False
 141160/500000: episode: 3529, duration: 33.290s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.850 [22.000, 46.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.173858, mean_absolute_error: 2.846781, mean_q: 3.715649
238 (array([22]),) False
 141200/500000: episode: 3530, duration: 33.243s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.175 [0.000, 38.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.189222, mean_absolute_error: 2.842952, mean_q: 3.710854
253 (array([44]),) False
 141240/500000: episode: 3531, duration: 33.312s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.575 [5.000, 47.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.176961, mean_absolute_error: 2.857594, mean_q: 3.735533
745 (array([22]),) False
 141280/500000: episode: 3532, duration: 33.245s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 34.300 [12.000, 56.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.192826, mean_absolute_error: 2.871740, mean_q: 3.753223
259 (array([12]),) False
 141320/500000: episode: 3533, duration: 33.310s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 21.200 [5.000, 33.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.184874, mean_absolute_error: 2.866456, mean_q: 3.752584
40 (array([22]),) False
 141360/500000: episode: 3534, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.800 [14.000, 22.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.179777, mean_absolute_error: 2.866325, mean_q: 3.738297
60 (array([22]),) False
 141400/500000: episode: 3535, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 31.325 [9.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.183026, mean_absolute_error: 2.861951, mean_q: 3.724913
566 (array([12]),) False
 141440/500000: episode: 3536, duration: 32.285s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 20.900 [2.000, 43.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.177511, mean_absolute_error: 2.857480, mean_q: 3.721625
458 (array([22]),) False
 141480/500000: episode: 3537, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.275 [10.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.192264, mean_absolute_error: 2.873405, mean_q: 3.742361
825 (array([22]),) False
 141520/500000: episode: 3538, duration: 32.360s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.950 [9.000, 33.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.190826, mean_absolute_error: 2.852390, mean_q: 3.714865
436 (array([22]),) False
 141560/500000: episode: 3539, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.300 [12.000, 44.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.178580, mean_absolute_error: 2.842874, mean_q: 3.711026
37 (array([48]),) False
 141600/500000: episode: 3540, duration: 32.384s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 45.950 [7.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.174382, mean_absolute_error: 2.855981, mean_q: 3.727368
857 (array([22]),) False
 141640/500000: episode: 3541, duration: 33.297s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.175 [3.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.186495, mean_absolute_error: 2.856642, mean_q: 3.718952
829 (array([21]),) False
 141680/500000: episode: 3542, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.450 [12.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.186122, mean_absolute_error: 2.889672, mean_q: 3.760784
749 (array([22]),) False
 141720/500000: episode: 3543, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.075 [1.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.196485, mean_absolute_error: 2.795063, mean_q: 3.653979
387 (array([22]),) False
 141760/500000: episode: 3544, duration: 32.537s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.075 [22.000, 58.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.180735, mean_absolute_error: 2.848699, mean_q: 3.722250
832 (array([22]),) False
 141800/500000: episode: 3545, duration: 31.527s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.725 [21.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.179534, mean_absolute_error: 2.878258, mean_q: 3.761447
89 (array([58]),) False
 141840/500000: episode: 3546, duration: 31.473s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 40.400 [12.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.199008, mean_absolute_error: 2.888852, mean_q: 3.779541
594 (array([48]),) False
 141880/500000: episode: 3547, duration: 31.458s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.450 [22.000, 49.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.184245, mean_absolute_error: 2.839404, mean_q: 3.725629
619 (array([3]),) False
 141920/500000: episode: 3548, duration: 31.059s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 14.925 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.176946, mean_absolute_error: 2.836199, mean_q: 3.715784
252 (array([22]),) False
 141960/500000: episode: 3549, duration: 31.572s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.775 [3.000, 47.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.184991, mean_absolute_error: 2.808018, mean_q: 3.690804
75 (array([22]),) False
 142000/500000: episode: 3550, duration: 31.100s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.425 [6.000, 25.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.176630, mean_absolute_error: 2.834255, mean_q: 3.725323
597 (array([22]),) False
 142040/500000: episode: 3551, duration: 31.482s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.425 [22.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.202105, mean_absolute_error: 2.882236, mean_q: 3.773242
765 (array([48]),) False
 142080/500000: episode: 3552, duration: 31.092s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 41.075 [11.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.199197, mean_absolute_error: 2.844679, mean_q: 3.727163
509 (array([22]),) False
 142120/500000: episode: 3553, duration: 31.534s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.650 [9.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.174023, mean_absolute_error: 2.832525, mean_q: 3.712556
686 (array([48]),) False
 142160/500000: episode: 3554, duration: 31.460s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 45.000 [32.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.180120, mean_absolute_error: 2.890582, mean_q: 3.782226
1 (array([22]),) False
 142200/500000: episode: 3555, duration: 32.676s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.625 [1.000, 52.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.185123, mean_absolute_error: 2.871337, mean_q: 3.753422
27 (array([22]),) False
 142240/500000: episode: 3556, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.075 [22.000, 53.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.176498, mean_absolute_error: 2.863750, mean_q: 3.743675
148 (array([22]),) False
 142280/500000: episode: 3557, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.300 [22.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.180083, mean_absolute_error: 2.904051, mean_q: 3.797330
519 (array([58]),) False
 142320/500000: episode: 3558, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 54.625 [5.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.179898, mean_absolute_error: 2.843107, mean_q: 3.725488
331 (array([22]),) False
 142360/500000: episode: 3559, duration: 31.898s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.300 [0.000, 59.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.193390, mean_absolute_error: 2.841237, mean_q: 3.727355
48 (array([12]),) False
 142400/500000: episode: 3560, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.050 [2.000, 51.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.191669, mean_absolute_error: 2.902580, mean_q: 3.787511
584 (array([36]),) False
 142440/500000: episode: 3561, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 8.900 [3.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.192007, mean_absolute_error: 2.847460, mean_q: 3.722131
12 (array([22]),) False
 142480/500000: episode: 3562, duration: 31.046s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.050 [13.000, 60.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.187681, mean_absolute_error: 2.885043, mean_q: 3.768493
609 (array([22]),) False
 142520/500000: episode: 3563, duration: 31.458s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.750 [4.000, 53.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.204558, mean_absolute_error: 2.842196, mean_q: 3.716920
550 (array([12]),) False
 142560/500000: episode: 3564, duration: 31.056s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 17.425 [4.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.200865, mean_absolute_error: 2.820128, mean_q: 3.684132
744 (array([22]),) False
 142600/500000: episode: 3565, duration: 31.534s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 37.050 [10.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.203356, mean_absolute_error: 2.858887, mean_q: 3.736548
577 (array([12]),) False
 142640/500000: episode: 3566, duration: 31.583s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.600 [12.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.190116, mean_absolute_error: 2.850928, mean_q: 3.723194
605 (array([22]),) False
 142680/500000: episode: 3567, duration: 31.543s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.500 [8.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.204898, mean_absolute_error: 2.861773, mean_q: 3.737607
540 (array([22]),) False
 142720/500000: episode: 3568, duration: 31.472s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.675 [7.000, 49.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.180299, mean_absolute_error: 2.860905, mean_q: 3.735379
149 (array([8]),) False
 142760/500000: episode: 3569, duration: 32.517s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 9.275 [8.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.209127, mean_absolute_error: 2.861718, mean_q: 3.741452
64 (array([12]),) False
 142800/500000: episode: 3570, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 22.875 [12.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.193668, mean_absolute_error: 2.854430, mean_q: 3.733384
145 (array([19]),) False
 142840/500000: episode: 3571, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 16.600 [3.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.178964, mean_absolute_error: 2.903008, mean_q: 3.802547
199 (array([22]),) False
 142880/500000: episode: 3572, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.025 [22.000, 49.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.172838, mean_absolute_error: 2.845380, mean_q: 3.720605
210 (array([58]),) False
 142920/500000: episode: 3573, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 38.175 [11.000, 59.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.184218, mean_absolute_error: 2.884796, mean_q: 3.763725
789 (array([22]),) False
 142960/500000: episode: 3574, duration: 32.247s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.125 [3.000, 50.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.193953, mean_absolute_error: 2.860430, mean_q: 3.745372
323 (array([55]),) False
 143000/500000: episode: 3575, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.050 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.185100, mean_absolute_error: 2.867677, mean_q: 3.750283
610 (array([48]),) False
 143040/500000: episode: 3576, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 33.900 [10.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.191785, mean_absolute_error: 2.897532, mean_q: 3.789634
304 (array([22]),) False
 143080/500000: episode: 3577, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 38.175 [13.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.197079, mean_absolute_error: 2.869674, mean_q: 3.751566
846 (array([48]),) False
 143120/500000: episode: 3578, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.725 [28.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.196377, mean_absolute_error: 2.854202, mean_q: 3.729099
789 (array([22]),) False
 143160/500000: episode: 3579, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.700 [0.000, 47.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.200972, mean_absolute_error: 2.862582, mean_q: 3.745400
247 (array([14]),) False
 143200/500000: episode: 3580, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 19.325 [14.000, 48.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.193825, mean_absolute_error: 2.848958, mean_q: 3.724072
218 (array([22]),) False
 143240/500000: episode: 3581, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.750 [11.000, 43.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.174773, mean_absolute_error: 2.933506, mean_q: 3.822301
177 (array([22]),) False
 143280/500000: episode: 3582, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 20.950 [12.000, 57.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.201641, mean_absolute_error: 2.853799, mean_q: 3.726423
756 (array([48]),) False
 143320/500000: episode: 3583, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 47.500 [25.000, 51.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.191576, mean_absolute_error: 2.886681, mean_q: 3.768759
472 (array([22]),) False
 143360/500000: episode: 3584, duration: 32.228s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.550 [6.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.195926, mean_absolute_error: 2.928013, mean_q: 3.817618
396 (array([48]),) False
 143400/500000: episode: 3585, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 48.050 [38.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.198659, mean_absolute_error: 2.897206, mean_q: 3.781518
725 (array([36]),) False
 143440/500000: episode: 3586, duration: 32.201s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 34.075 [10.000, 47.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.190067, mean_absolute_error: 2.910452, mean_q: 3.794678
625 (array([22]),) False
 143480/500000: episode: 3587, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.025 [1.000, 45.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.189046, mean_absolute_error: 2.899311, mean_q: 3.781725
346 (array([12]),) False
 143520/500000: episode: 3588, duration: 32.289s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 20.275 [12.000, 38.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.193491, mean_absolute_error: 2.877513, mean_q: 3.754917
516 (array([48]),) False
 143560/500000: episode: 3589, duration: 32.778s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 21.725 [3.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.191873, mean_absolute_error: 2.926548, mean_q: 3.814210
316 (array([12]),) False
 143600/500000: episode: 3590, duration: 31.789s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 15.875 [10.000, 58.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.187732, mean_absolute_error: 2.865400, mean_q: 3.732644
100 (array([22]),) False
 143640/500000: episode: 3591, duration: 31.661s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.975 [22.000, 58.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.187206, mean_absolute_error: 2.898415, mean_q: 3.775485
672 (array([44]),) False
 143680/500000: episode: 3592, duration: 31.526s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 47.075 [1.000, 60.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.200624, mean_absolute_error: 2.874068, mean_q: 3.753513
428 (array([22]),) False
 143720/500000: episode: 3593, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.500 [0.000, 48.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.191862, mean_absolute_error: 2.894659, mean_q: 3.776629
757 (array([48]),) False
 143760/500000: episode: 3594, duration: 31.579s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.550 [10.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.195929, mean_absolute_error: 2.867227, mean_q: 3.746431
115 (array([22]),) False
 143800/500000: episode: 3595, duration: 31.579s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.425 [3.000, 51.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.198675, mean_absolute_error: 2.862341, mean_q: 3.748406
725 (array([36]),) False
 143840/500000: episode: 3596, duration: 31.055s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 33.875 [4.000, 44.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.204826, mean_absolute_error: 2.873270, mean_q: 3.765933
594 (array([48]),) False
 143880/500000: episode: 3597, duration: 31.549s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.525 [0.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.185239, mean_absolute_error: 2.871104, mean_q: 3.758993
387 (array([22]),) False
 143920/500000: episode: 3598, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.600 [12.000, 53.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.192932, mean_absolute_error: 2.910031, mean_q: 3.803210
584 (array([36]),) False
 143960/500000: episode: 3599, duration: 31.485s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 8.325 [3.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.194664, mean_absolute_error: 2.887792, mean_q: 3.785176
316 (array([12]),) False
 144000/500000: episode: 3600, duration: 31.054s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 14.750 [8.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.185232, mean_absolute_error: 2.931399, mean_q: 3.827756
345 (array([22]),) False
 144040/500000: episode: 3601, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 24.400 [22.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.192309, mean_absolute_error: 2.875259, mean_q: 3.762962
447 (array([44]),) False
 144080/500000: episode: 3602, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.925 [5.000, 50.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.192508, mean_absolute_error: 2.939566, mean_q: 3.832441
199 (array([22]),) False
 144120/500000: episode: 3603, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.600 [0.000, 45.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.186770, mean_absolute_error: 2.838369, mean_q: 3.723670
851 (array([48]),) False
 144160/500000: episode: 3604, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.250 [0.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.185094, mean_absolute_error: 2.910399, mean_q: 3.779434
515 (array([22]),) False
 144200/500000: episode: 3605, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.250 [22.000, 56.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.186411, mean_absolute_error: 2.921111, mean_q: 3.799295
552 (array([22]),) False
 144240/500000: episode: 3606, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.875 [12.000, 52.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.182234, mean_absolute_error: 2.864820, mean_q: 3.740887
788 (array([3]),) False
 144280/500000: episode: 3607, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 53.675 [9.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.198790, mean_absolute_error: 2.881363, mean_q: 3.770021
342 (array([12]),) False
 144320/500000: episode: 3608, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.750 [1.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.194813, mean_absolute_error: 2.849408, mean_q: 3.736678
265 (array([22]),) False
 144360/500000: episode: 3609, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 24.300 [6.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.201015, mean_absolute_error: 2.858011, mean_q: 3.752043
518 (array([22]),) False
 144400/500000: episode: 3610, duration: 32.229s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.125 [4.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.185135, mean_absolute_error: 2.866308, mean_q: 3.755706
526 (array([22]),) False
 144440/500000: episode: 3611, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.025 [5.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.183132, mean_absolute_error: 2.894328, mean_q: 3.783131
511 (array([22]),) False
 144480/500000: episode: 3612, duration: 32.230s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.025 [22.000, 50.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.204725, mean_absolute_error: 2.832718, mean_q: 3.715767
564 (array([22]),) False
 144520/500000: episode: 3613, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.525 [9.000, 42.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.180564, mean_absolute_error: 2.875681, mean_q: 3.766545
474 (array([22]),) False
 144560/500000: episode: 3614, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.875 [17.000, 22.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.185047, mean_absolute_error: 2.889486, mean_q: 3.778545
862 (array([14]),) False
 144600/500000: episode: 3615, duration: 32.340s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 26.300 [3.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.181951, mean_absolute_error: 2.874947, mean_q: 3.762149
21 (array([3]),) False
 144640/500000: episode: 3616, duration: 31.771s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 24.100 [4.000, 59.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.191829, mean_absolute_error: 2.901458, mean_q: 3.783695
262 (array([22]),) False
 144680/500000: episode: 3617, duration: 31.529s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 22.025 [8.000, 40.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.189281, mean_absolute_error: 2.904436, mean_q: 3.792725
821 (array([22]),) False
 144720/500000: episode: 3618, duration: 31.564s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.450 [5.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.190160, mean_absolute_error: 2.926824, mean_q: 3.818519
147 (array([44]),) False
 144760/500000: episode: 3619, duration: 31.565s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.475 [0.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.192275, mean_absolute_error: 2.823572, mean_q: 3.702818
79 (array([22]),) False
 144800/500000: episode: 3620, duration: 31.060s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.700 [1.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.191953, mean_absolute_error: 2.897546, mean_q: 3.769727
16 (array([22]),) False
 144840/500000: episode: 3621, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.525 [3.000, 53.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.229771, mean_absolute_error: 2.902602, mean_q: 3.779744
112 (array([12]),) False
 144880/500000: episode: 3622, duration: 31.090s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 14.125 [5.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.196818, mean_absolute_error: 2.904943, mean_q: 3.787993
3 (array([48]),) False
 144920/500000: episode: 3623, duration: 31.565s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.400 [3.000, 46.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.185071, mean_absolute_error: 2.894484, mean_q: 3.765641
486 (array([22]),) False
 144960/500000: episode: 3624, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.775 [2.000, 46.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.189871, mean_absolute_error: 2.892703, mean_q: 3.763514
198 (array([22]),) False
 145000/500000: episode: 3625, duration: 31.492s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.100 [12.000, 48.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.192009, mean_absolute_error: 2.870497, mean_q: 3.750556
528 (array([12]),) False
 145040/500000: episode: 3626, duration: 31.459s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 24.000 [6.000, 54.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.184096, mean_absolute_error: 2.900830, mean_q: 3.776146
853 (array([22]),) False
 145080/500000: episode: 3627, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.175 [6.000, 34.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.200463, mean_absolute_error: 2.872874, mean_q: 3.758757
398 (array([22]),) False
 145120/500000: episode: 3628, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.400 [2.000, 54.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.195933, mean_absolute_error: 2.878562, mean_q: 3.762698
299 (array([12]),) False
 145160/500000: episode: 3629, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 27.725 [2.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.191735, mean_absolute_error: 2.885252, mean_q: 3.755493
796 (array([38]),) False
 145200/500000: episode: 3630, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.500 [3.000, 49.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.200299, mean_absolute_error: 2.912694, mean_q: 3.781457
620 (array([44]),) False
 145240/500000: episode: 3631, duration: 33.254s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 38.325 [14.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.188962, mean_absolute_error: 2.858706, mean_q: 3.739760
801 (array([58]),) False
 145280/500000: episode: 3632, duration: 32.364s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.300 [3.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.189981, mean_absolute_error: 2.888240, mean_q: 3.765601
718 (array([12]),) False
 145320/500000: episode: 3633, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 18.225 [12.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.188354, mean_absolute_error: 2.923029, mean_q: 3.818776
584 (array([36]),) False
 145360/500000: episode: 3634, duration: 32.288s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 5.475 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.191822, mean_absolute_error: 2.914164, mean_q: 3.781982
208 (array([22]),) False
 145400/500000: episode: 3635, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.150 [10.000, 48.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.183468, mean_absolute_error: 2.876295, mean_q: 3.753536
758 (array([38]),) False
 145440/500000: episode: 3636, duration: 32.348s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 32.375 [12.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.176479, mean_absolute_error: 2.868649, mean_q: 3.756260
600 (array([48]),) False
 145480/500000: episode: 3637, duration: 33.276s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 42.625 [3.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.194878, mean_absolute_error: 2.890169, mean_q: 3.784194
596 (array([22]),) False
 145520/500000: episode: 3638, duration: 32.872s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.975 [22.000, 51.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.176083, mean_absolute_error: 2.812185, mean_q: 3.696393
50 (array([22]),) False
 145560/500000: episode: 3639, duration: 31.494s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.900 [4.000, 50.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.200545, mean_absolute_error: 2.895896, mean_q: 3.786519
338 (array([12]),) False
 145600/500000: episode: 3640, duration: 31.516s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 15.825 [0.000, 44.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.195024, mean_absolute_error: 2.891717, mean_q: 3.775679
53 (array([22]),) False
 145640/500000: episode: 3641, duration: 31.532s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.350 [1.000, 60.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.179571, mean_absolute_error: 2.845106, mean_q: 3.727763
616 (array([22]),) False
 145680/500000: episode: 3642, duration: 31.607s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.250 [1.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.188489, mean_absolute_error: 2.891552, mean_q: 3.777550
653 (array([48]),) False
 145720/500000: episode: 3643, duration: 31.514s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 43.625 [12.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.209203, mean_absolute_error: 2.864117, mean_q: 3.740398
524 (array([22]),) False
 145760/500000: episode: 3644, duration: 31.062s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.750 [0.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.183122, mean_absolute_error: 2.878298, mean_q: 3.767951
436 (array([22]),) False
 145800/500000: episode: 3645, duration: 31.557s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 20.725 [3.000, 22.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.199276, mean_absolute_error: 2.864064, mean_q: 3.745788
624 (array([48]),) False
 145840/500000: episode: 3646, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 44.975 [5.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.182188, mean_absolute_error: 2.919467, mean_q: 3.806892
82 (array([22]),) False
 145880/500000: episode: 3647, duration: 31.494s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.925 [5.000, 51.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.209640, mean_absolute_error: 2.875324, mean_q: 3.751922
310 (array([12]),) False
 145920/500000: episode: 3648, duration: 31.142s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 12.100 [9.000, 18.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.198983, mean_absolute_error: 2.881520, mean_q: 3.759326
256 (array([22]),) False
 145960/500000: episode: 3649, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.600 [15.000, 55.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.181777, mean_absolute_error: 2.872658, mean_q: 3.756909
848 (array([44]),) False
 146000/500000: episode: 3650, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 44.350 [41.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.195021, mean_absolute_error: 2.899345, mean_q: 3.777704
586 (array([12]),) False
 146040/500000: episode: 3651, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.325 [2.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.192319, mean_absolute_error: 2.870084, mean_q: 3.745515
12 (array([22]),) False
 146080/500000: episode: 3652, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.850 [22.000, 56.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.197034, mean_absolute_error: 2.846078, mean_q: 3.725456
424 (array([22]),) False
 146120/500000: episode: 3653, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.750 [10.000, 32.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.202149, mean_absolute_error: 2.877612, mean_q: 3.763528
279 (array([22]),) False
 146160/500000: episode: 3654, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 37.150 [4.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.179501, mean_absolute_error: 2.852382, mean_q: 3.732426
859 (array([22]),) False
 146200/500000: episode: 3655, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.175 [2.000, 22.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.198396, mean_absolute_error: 2.899819, mean_q: 3.781259
63 (array([18]),) False
 146240/500000: episode: 3656, duration: 31.675s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 19.725 [18.000, 51.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.211865, mean_absolute_error: 2.845717, mean_q: 3.713506
793 (array([12]),) False
 146280/500000: episode: 3657, duration: 31.509s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 32.175 [3.000, 53.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.189303, mean_absolute_error: 2.870471, mean_q: 3.744399
75 (array([22]),) False
 146320/500000: episode: 3658, duration: 31.051s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.100 [3.000, 60.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.192049, mean_absolute_error: 2.900706, mean_q: 3.765687
724 (array([58]),) False
 146360/500000: episode: 3659, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 50.875 [3.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.190324, mean_absolute_error: 2.853889, mean_q: 3.728580
197 (array([22]),) False
 146400/500000: episode: 3660, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.250 [22.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.202811, mean_absolute_error: 2.878540, mean_q: 3.742892
355 (array([22]),) False
 146440/500000: episode: 3661, duration: 31.531s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.250 [12.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.207548, mean_absolute_error: 2.914171, mean_q: 3.778980
757 (array([48]),) False
 146480/500000: episode: 3662, duration: 31.533s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.775 [1.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.202493, mean_absolute_error: 2.890119, mean_q: 3.763753
308 (array([22]),) False
 146520/500000: episode: 3663, duration: 32.415s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.200 [8.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.181017, mean_absolute_error: 2.887381, mean_q: 3.764655
54 (array([8]),) False
 146560/500000: episode: 3664, duration: 32.029s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.950 [3.000, 55.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.186588, mean_absolute_error: 2.861074, mean_q: 3.728262
55 (array([22]),) False
 146600/500000: episode: 3665, duration: 31.924s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.925 [7.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.198151, mean_absolute_error: 2.852633, mean_q: 3.734547
89 (array([58]),) False
 146640/500000: episode: 3666, duration: 32.099s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 46.275 [6.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.196598, mean_absolute_error: 2.855582, mean_q: 3.727604
385 (array([30]),) False
 146680/500000: episode: 3667, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.950 [4.000, 42.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.195828, mean_absolute_error: 2.860526, mean_q: 3.743655
778 (array([12]),) False
 146720/500000: episode: 3668, duration: 32.177s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 17.100 [6.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.200061, mean_absolute_error: 2.842303, mean_q: 3.721259
620 (array([44]),) False
 146760/500000: episode: 3669, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 38.250 [15.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.201030, mean_absolute_error: 2.893594, mean_q: 3.789765
376 (array([22]),) False
 146800/500000: episode: 3670, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 37.425 [0.000, 53.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.201234, mean_absolute_error: 2.904450, mean_q: 3.793681
74 (array([22]),) False
 146840/500000: episode: 3671, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 27.075 [1.000, 60.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.193254, mean_absolute_error: 2.900203, mean_q: 3.790692
550 (array([12]),) False
 146880/500000: episode: 3672, duration: 32.218s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 13.750 [4.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.191385, mean_absolute_error: 2.860178, mean_q: 3.754417
683 (array([22]),) False
 146920/500000: episode: 3673, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.250 [5.000, 52.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.191340, mean_absolute_error: 2.876963, mean_q: 3.767197
295 (array([22]),) False
 146960/500000: episode: 3674, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.300 [9.000, 57.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.197844, mean_absolute_error: 2.896715, mean_q: 3.777402
383 (array([22]),) False
 147000/500000: episode: 3675, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.525 [9.000, 57.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.182591, mean_absolute_error: 2.913715, mean_q: 3.795596
720 (array([22]),) False
 147040/500000: episode: 3676, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.300 [22.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.188707, mean_absolute_error: 2.849753, mean_q: 3.716534
518 (array([22]),) False
 147080/500000: episode: 3677, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.950 [20.000, 22.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.186783, mean_absolute_error: 2.928332, mean_q: 3.819366
443 (array([22]),) False
 147120/500000: episode: 3678, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.500 [19.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.199311, mean_absolute_error: 2.978117, mean_q: 3.870615
847 (array([21]),) False
 147160/500000: episode: 3679, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 40.500 [22.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.201370, mean_absolute_error: 2.949416, mean_q: 3.846284
165 (array([34]),) False
 147200/500000: episode: 3680, duration: 32.168s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 20.625 [12.000, 39.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.204505, mean_absolute_error: 2.886771, mean_q: 3.768609
819 (array([48]),) False
 147240/500000: episode: 3681, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 40.200 [8.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.206022, mean_absolute_error: 2.896132, mean_q: 3.798381
87 (array([3]),) False
 147280/500000: episode: 3682, duration: 32.271s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 11.725 [0.000, 44.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.191540, mean_absolute_error: 2.947879, mean_q: 3.844795
782 (array([22]),) False
 147320/500000: episode: 3683, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 33.325 [6.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.201046, mean_absolute_error: 2.874030, mean_q: 3.746926
478 (array([22]),) False
 147360/500000: episode: 3684, duration: 32.170s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.100 [6.000, 39.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.205846, mean_absolute_error: 2.940763, mean_q: 3.824793
37 (array([48]),) False
 147400/500000: episode: 3685, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 46.525 [9.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.186257, mean_absolute_error: 2.932024, mean_q: 3.826244
86 (array([22]),) False
 147440/500000: episode: 3686, duration: 32.941s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.925 [15.000, 54.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.195896, mean_absolute_error: 2.918726, mean_q: 3.804749
160 (array([12]),) False
 147480/500000: episode: 3687, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 18.800 [7.000, 37.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.188393, mean_absolute_error: 2.934095, mean_q: 3.822447
121 (array([22]),) False
 147520/500000: episode: 3688, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 20.100 [4.000, 22.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.214929, mean_absolute_error: 2.969919, mean_q: 3.857351
626 (array([22]),) False
 147560/500000: episode: 3689, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.400 [1.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.188092, mean_absolute_error: 2.936014, mean_q: 3.817731
835 (array([50]),) False
 147600/500000: episode: 3690, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.800 [12.000, 54.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.191033, mean_absolute_error: 2.955627, mean_q: 3.842376
68 (array([22]),) False
 147640/500000: episode: 3691, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.475 [5.000, 38.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.192603, mean_absolute_error: 2.907133, mean_q: 3.795029
433 (array([22]),) False
 147680/500000: episode: 3692, duration: 31.838s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.750 [8.000, 53.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.204041, mean_absolute_error: 2.955241, mean_q: 3.836566
813 (array([22]),) False
 147720/500000: episode: 3693, duration: 32.031s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 24.025 [6.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.202602, mean_absolute_error: 2.960033, mean_q: 3.846013
81 (array([22]),) False
 147760/500000: episode: 3694, duration: 31.553s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [18.000, 40.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.186764, mean_absolute_error: 2.956852, mean_q: 3.846665
850 (array([12]),) False
 147800/500000: episode: 3695, duration: 32.040s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 31.925 [3.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.206483, mean_absolute_error: 2.968442, mean_q: 3.854853
276 (array([56]),) False
 147840/500000: episode: 3696, duration: 31.630s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.550 [2.000, 60.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.190735, mean_absolute_error: 2.907593, mean_q: 3.785339
571 (array([48]),) False
 147880/500000: episode: 3697, duration: 32.042s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.525 [12.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.199487, mean_absolute_error: 2.930459, mean_q: 3.813781
806 (array([22]),) False
 147920/500000: episode: 3698, duration: 32.033s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.700 [3.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.196623, mean_absolute_error: 2.907000, mean_q: 3.788863
498 (array([12]),) False
 147960/500000: episode: 3699, duration: 32.067s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 26.000 [2.000, 50.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.194086, mean_absolute_error: 2.915132, mean_q: 3.793540
630 (array([22]),) False
 148000/500000: episode: 3700, duration: 32.016s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.300 [9.000, 53.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.181757, mean_absolute_error: 2.954928, mean_q: 3.836155
61 (array([48]),) False
 148040/500000: episode: 3701, duration: 32.051s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.500 [5.000, 59.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.214041, mean_absolute_error: 2.928950, mean_q: 3.810797
13 (array([48]),) False
 148080/500000: episode: 3702, duration: 32.050s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 44.675 [6.000, 57.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.200390, mean_absolute_error: 2.882449, mean_q: 3.760889
167 (array([22]),) False
 148120/500000: episode: 3703, duration: 32.218s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.475 [11.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.202114, mean_absolute_error: 2.988487, mean_q: 3.893832
771 (array([12]),) False
 148160/500000: episode: 3704, duration: 32.182s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 14.150 [12.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.192680, mean_absolute_error: 2.915623, mean_q: 3.817691
786 (array([22]),) False
 148200/500000: episode: 3705, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.700 [22.000, 40.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.195833, mean_absolute_error: 2.932867, mean_q: 3.821921
282 (array([22]),) False
 148240/500000: episode: 3706, duration: 32.203s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.425 [7.000, 48.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.192708, mean_absolute_error: 2.999414, mean_q: 3.887956
778 (array([12]),) False
 148280/500000: episode: 3707, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 12.825 [7.000, 32.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.193687, mean_absolute_error: 2.973015, mean_q: 3.866009
703 (array([3]),) False
 148320/500000: episode: 3708, duration: 32.254s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 2.950 [1.000, 3.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.189386, mean_absolute_error: 2.963779, mean_q: 3.846831
112 (array([12]),) False
 148360/500000: episode: 3709, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 15.425 [12.000, 51.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.215216, mean_absolute_error: 2.949925, mean_q: 3.822299
356 (array([22]),) False
 148400/500000: episode: 3710, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.475 [13.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.200527, mean_absolute_error: 2.948278, mean_q: 3.836513
264 (array([12]),) False
 148440/500000: episode: 3711, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.400 [8.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.200034, mean_absolute_error: 2.949739, mean_q: 3.830994
366 (array([22]),) False
 148480/500000: episode: 3712, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 33.425 [6.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.181870, mean_absolute_error: 2.962261, mean_q: 3.837711
677 (array([48]),) False
 148520/500000: episode: 3713, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.100 [14.000, 57.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.205736, mean_absolute_error: 2.913697, mean_q: 3.801691
686 (array([48]),) False
 148560/500000: episode: 3714, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 30.375 [12.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.197870, mean_absolute_error: 2.928922, mean_q: 3.811916
358 (array([22]),) False
 148600/500000: episode: 3715, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.850 [1.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.200473, mean_absolute_error: 2.949476, mean_q: 3.843108
426 (array([22]),) False
 148640/500000: episode: 3716, duration: 32.187s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.700 [2.000, 37.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.197496, mean_absolute_error: 2.920178, mean_q: 3.805249
520 (array([22]),) False
 148680/500000: episode: 3717, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.100 [18.000, 45.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.193849, mean_absolute_error: 2.975991, mean_q: 3.867288
310 (array([12]),) False
 148720/500000: episode: 3718, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 14.675 [12.000, 53.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.186480, mean_absolute_error: 2.962167, mean_q: 3.849215
576 (array([58]),) False
 148760/500000: episode: 3719, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 54.575 [6.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.225514, mean_absolute_error: 2.917051, mean_q: 3.803871
379 (array([22]),) False
 148800/500000: episode: 3720, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.300 [22.000, 34.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.211004, mean_absolute_error: 2.947046, mean_q: 3.842445
175 (array([22]),) False
 148840/500000: episode: 3721, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.075 [7.000, 50.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.191379, mean_absolute_error: 2.932245, mean_q: 3.828368
535 (array([22]),) False
 148880/500000: episode: 3722, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.075 [15.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.194317, mean_absolute_error: 2.929885, mean_q: 3.827549
733 (array([22]),) False
 148920/500000: episode: 3723, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.000 [7.000, 45.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.197662, mean_absolute_error: 2.918077, mean_q: 3.797749
149 (array([8]),) False
 148960/500000: episode: 3724, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 11.300 [8.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.194016, mean_absolute_error: 2.943717, mean_q: 3.836977
350 (array([12]),) False
 149000/500000: episode: 3725, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 14.700 [3.000, 32.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.193036, mean_absolute_error: 2.896744, mean_q: 3.781887
307 (array([22]),) False
 149040/500000: episode: 3726, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.050 [16.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.192296, mean_absolute_error: 2.911476, mean_q: 3.812665
229 (array([48]),) False
 149080/500000: episode: 3727, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 21.625 [2.000, 37.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.206640, mean_absolute_error: 2.955717, mean_q: 3.852585
822 (array([22]),) False
 149120/500000: episode: 3728, duration: 32.136s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 20.750 [0.000, 22.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.209753, mean_absolute_error: 2.967723, mean_q: 3.868131
813 (array([22]),) False
 149160/500000: episode: 3729, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 21.125 [2.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.195806, mean_absolute_error: 2.965645, mean_q: 3.870222
9 (array([14]),) False
 149200/500000: episode: 3730, duration: 32.160s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.900 [2.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.200919, mean_absolute_error: 2.968956, mean_q: 3.873536
602 (array([36]),) False
 149240/500000: episode: 3731, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.425 [1.000, 46.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.188189, mean_absolute_error: 2.942805, mean_q: 3.834255
730 (array([54]),) False
 149280/500000: episode: 3732, duration: 32.251s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 45.100 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.209514, mean_absolute_error: 2.963147, mean_q: 3.865134
28 (array([58]),) False
 149320/500000: episode: 3733, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.875 [2.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.198401, mean_absolute_error: 2.924922, mean_q: 3.833963
602 (array([36]),) False
 149360/500000: episode: 3734, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 28.100 [3.000, 54.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.204256, mean_absolute_error: 2.942940, mean_q: 3.851908
784 (array([22]),) False
 149400/500000: episode: 3735, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.975 [10.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.211802, mean_absolute_error: 2.958563, mean_q: 3.866437
527 (array([58]),) False
 149440/500000: episode: 3736, duration: 32.851s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 54.650 [5.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.202609, mean_absolute_error: 2.944163, mean_q: 3.845521
820 (array([48]),) False
 149480/500000: episode: 3737, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.275 [14.000, 52.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.207961, mean_absolute_error: 2.983304, mean_q: 3.884618
409 (array([22]),) False
 149520/500000: episode: 3738, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.550 [1.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.200937, mean_absolute_error: 2.985276, mean_q: 3.874721
419 (array([40]),) False
 149560/500000: episode: 3739, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.925 [3.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.215772, mean_absolute_error: 2.999926, mean_q: 3.892208
790 (array([48]),) False
 149600/500000: episode: 3740, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.050 [18.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.190186, mean_absolute_error: 2.997695, mean_q: 3.897977
66 (array([22]),) False
 149640/500000: episode: 3741, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.650 [22.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.196772, mean_absolute_error: 2.948203, mean_q: 3.837329
266 (array([12]),) False
 149680/500000: episode: 3742, duration: 32.139s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.050 [17.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.205193, mean_absolute_error: 2.956740, mean_q: 3.844352
662 (array([12]),) False
 149720/500000: episode: 3743, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 11.850 [5.000, 13.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.198751, mean_absolute_error: 2.983380, mean_q: 3.876004
841 (array([21]),) False
 149760/500000: episode: 3744, duration: 32.239s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.200 [20.000, 52.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.201116, mean_absolute_error: 2.964543, mean_q: 3.861216
14 (array([48]),) False
 149800/500000: episode: 3745, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 42.650 [3.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.187631, mean_absolute_error: 2.991248, mean_q: 3.879787
244 (array([14]),) False
 149840/500000: episode: 3746, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 35.050 [14.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.202794, mean_absolute_error: 2.973942, mean_q: 3.853572
129 (array([22]),) False
 149880/500000: episode: 3747, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.250 [8.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.210027, mean_absolute_error: 3.028500, mean_q: 3.923772
801 (array([58]),) False
 149920/500000: episode: 3748, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.775 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.200480, mean_absolute_error: 2.996163, mean_q: 3.880463
275 (array([12]),) False
 149960/500000: episode: 3749, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 24.150 [3.000, 54.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.213727, mean_absolute_error: 2.972259, mean_q: 3.858563
315 (array([12]),) False
 150000/500000: episode: 3750, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 20.100 [5.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.196771, mean_absolute_error: 3.002513, mean_q: 3.902171
762 (array([22]),) False
 150040/500000: episode: 3751, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.125 [22.000, 47.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.200276, mean_absolute_error: 2.979372, mean_q: 3.883709
831 (array([3]),) False
 150080/500000: episode: 3752, duration: 32.176s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 12.475 [3.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.208121, mean_absolute_error: 2.974551, mean_q: 3.872596
574 (array([8]),) False
 150120/500000: episode: 3753, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 27.250 [22.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.198120, mean_absolute_error: 2.947325, mean_q: 3.851776
476 (array([48]),) False
 150160/500000: episode: 3754, duration: 32.160s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 38.650 [8.000, 56.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.199490, mean_absolute_error: 2.992128, mean_q: 3.902796
684 (array([22]),) False
 150200/500000: episode: 3755, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.350 [8.000, 59.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.187660, mean_absolute_error: 2.991978, mean_q: 3.902659
212 (array([36]),) False
 150240/500000: episode: 3756, duration: 32.203s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.725 [12.000, 58.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.200089, mean_absolute_error: 2.951976, mean_q: 3.845498
528 (array([12]),) False
 150280/500000: episode: 3757, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 23.900 [12.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.216057, mean_absolute_error: 2.980755, mean_q: 3.879044
334 (array([48]),) False
 150320/500000: episode: 3758, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.175 [12.000, 48.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.206459, mean_absolute_error: 3.021190, mean_q: 3.935970
798 (array([18]),) False
 150360/500000: episode: 3759, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.675 [3.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.199346, mean_absolute_error: 2.984792, mean_q: 3.889095
53 (array([22]),) False
 150400/500000: episode: 3760, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.450 [0.000, 42.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.201113, mean_absolute_error: 2.950418, mean_q: 3.850088
417 (array([12]),) False
 150440/500000: episode: 3761, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.975 [9.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.191687, mean_absolute_error: 2.950993, mean_q: 3.850522
340 (array([12]),) False
 150480/500000: episode: 3762, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 20.875 [8.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.192516, mean_absolute_error: 2.948982, mean_q: 3.849188
62 (array([22]),) False
 150520/500000: episode: 3763, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 22.250 [7.000, 47.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.188955, mean_absolute_error: 3.029258, mean_q: 3.924510
129 (array([22]),) False
 150560/500000: episode: 3764, duration: 32.206s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 20.175 [2.000, 39.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.201526, mean_absolute_error: 3.007302, mean_q: 3.900371
683 (array([22]),) False
 150600/500000: episode: 3765, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.200 [7.000, 49.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.209867, mean_absolute_error: 2.994321, mean_q: 3.898478
194 (array([44]),) False
 150640/500000: episode: 3766, duration: 32.283s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 41.000 [22.000, 54.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.196045, mean_absolute_error: 3.036918, mean_q: 3.940408
165 (array([34]),) False
 150680/500000: episode: 3767, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.700 [3.000, 58.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.188745, mean_absolute_error: 2.978323, mean_q: 3.870318
660 (array([2]),) False
 150720/500000: episode: 3768, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 32.875 [12.000, 45.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.201725, mean_absolute_error: 2.980774, mean_q: 3.879854
859 (array([22]),) False
 150760/500000: episode: 3769, duration: 33.169s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.075 [0.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.212935, mean_absolute_error: 2.967754, mean_q: 3.854653
639 (array([22]),) False
 150800/500000: episode: 3770, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.475 [5.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.212932, mean_absolute_error: 3.032112, mean_q: 3.934467
376 (array([22]),) False
 150840/500000: episode: 3771, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 39.575 [3.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.220300, mean_absolute_error: 2.985773, mean_q: 3.871341
481 (array([22]),) False
 150880/500000: episode: 3772, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.150 [9.000, 41.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.206767, mean_absolute_error: 3.001857, mean_q: 3.887948
572 (array([58]),) False
 150920/500000: episode: 3773, duration: 32.876s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 56.550 [13.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.202550, mean_absolute_error: 2.992168, mean_q: 3.872102
602 (array([36]),) False
 150960/500000: episode: 3774, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 33.175 [3.000, 44.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.219079, mean_absolute_error: 3.014950, mean_q: 3.899595
387 (array([22]),) False
 151000/500000: episode: 3775, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.125 [13.000, 43.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.204032, mean_absolute_error: 3.003594, mean_q: 3.894150
380 (array([22]),) False
 151040/500000: episode: 3776, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.750 [16.000, 48.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.202654, mean_absolute_error: 2.991375, mean_q: 3.885160
57 (array([37]),) False
 151080/500000: episode: 3777, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 33.825 [7.000, 60.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.229126, mean_absolute_error: 2.999708, mean_q: 3.893122
446 (array([22]),) False
 151120/500000: episode: 3778, duration: 32.234s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.850 [19.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.205006, mean_absolute_error: 2.998679, mean_q: 3.904336
614 (array([22]),) False
 151160/500000: episode: 3779, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.225 [3.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.200403, mean_absolute_error: 2.990123, mean_q: 3.890739
591 (array([22]),) False
 151200/500000: episode: 3780, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.700 [10.000, 22.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.211155, mean_absolute_error: 3.013355, mean_q: 3.908133
172 (array([12]),) False
 151240/500000: episode: 3781, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.175 [0.000, 54.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.208548, mean_absolute_error: 2.991276, mean_q: 3.897142
196 (array([22]),) False
 151280/500000: episode: 3782, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.175 [9.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.208173, mean_absolute_error: 3.014962, mean_q: 3.907985
635 (array([22]),) False
 151320/500000: episode: 3783, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.275 [7.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.208821, mean_absolute_error: 3.022769, mean_q: 3.912540
836 (array([22]),) False
 151360/500000: episode: 3784, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.325 [16.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.200636, mean_absolute_error: 2.996009, mean_q: 3.873983
577 (array([12]),) False
 151400/500000: episode: 3785, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.200 [12.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.212687, mean_absolute_error: 2.995039, mean_q: 3.880503
493 (array([22]),) False
 151440/500000: episode: 3786, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.125 [12.000, 48.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.189206, mean_absolute_error: 2.990434, mean_q: 3.871552
825 (array([22]),) False
 151480/500000: episode: 3787, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.950 [4.000, 51.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.207330, mean_absolute_error: 2.954408, mean_q: 3.838858
335 (array([22]),) False
 151520/500000: episode: 3788, duration: 32.113s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.150 [14.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.188097, mean_absolute_error: 2.976341, mean_q: 3.863555
161 (array([22]),) False
 151560/500000: episode: 3789, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 14.275 [11.000, 46.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.196541, mean_absolute_error: 2.983112, mean_q: 3.875033
638 (array([22]),) False
 151600/500000: episode: 3790, duration: 32.214s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.800 [10.000, 51.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.194596, mean_absolute_error: 2.998126, mean_q: 3.888448
659 (array([40]),) False
 151640/500000: episode: 3791, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.575 [4.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.213594, mean_absolute_error: 2.936697, mean_q: 3.820087
462 (array([12]),) False
 151680/500000: episode: 3792, duration: 32.160s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.850 [5.000, 56.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.194663, mean_absolute_error: 2.993013, mean_q: 3.884027
48 (array([12]),) False
 151720/500000: episode: 3793, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 37.075 [22.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.204682, mean_absolute_error: 2.949041, mean_q: 3.837121
748 (array([22]),) False
 151760/500000: episode: 3794, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.000 [3.000, 41.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.195940, mean_absolute_error: 2.962599, mean_q: 3.848502
813 (array([22]),) False
 151800/500000: episode: 3795, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 22.925 [12.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.215492, mean_absolute_error: 2.947219, mean_q: 3.831687
423 (array([22]),) False
 151840/500000: episode: 3796, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.175 [22.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.192504, mean_absolute_error: 2.977225, mean_q: 3.864172
685 (array([22]),) False
 151880/500000: episode: 3797, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.325 [9.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.196600, mean_absolute_error: 2.991503, mean_q: 3.893528
809 (array([48]),) False
 151920/500000: episode: 3798, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 37.525 [19.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.198508, mean_absolute_error: 3.041343, mean_q: 3.946585
695 (array([22]),) False
 151960/500000: episode: 3799, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.950 [5.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.213535, mean_absolute_error: 2.972205, mean_q: 3.871039
158 (array([22]),) False
 152000/500000: episode: 3800, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 19.500 [2.000, 32.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.200525, mean_absolute_error: 2.986808, mean_q: 3.890131
583 (array([22]),) False
 152040/500000: episode: 3801, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 16.150 [11.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.203959, mean_absolute_error: 3.024905, mean_q: 3.926940
511 (array([22]),) False
 152080/500000: episode: 3802, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.825 [8.000, 33.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.194391, mean_absolute_error: 2.997521, mean_q: 3.882364
704 (array([22]),) False
 152120/500000: episode: 3803, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 30.875 [5.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.200671, mean_absolute_error: 2.999003, mean_q: 3.901736
571 (array([48]),) False
 152160/500000: episode: 3804, duration: 32.257s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 31.975 [22.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.213184, mean_absolute_error: 2.991915, mean_q: 3.885101
389 (array([48]),) False
 152200/500000: episode: 3805, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.725 [2.000, 54.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.213378, mean_absolute_error: 2.995435, mean_q: 3.903598
778 (array([12]),) False
 152240/500000: episode: 3806, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 14.100 [4.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.199230, mean_absolute_error: 2.991657, mean_q: 3.894962
711 (array([22]),) False
 152280/500000: episode: 3807, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.100 [12.000, 44.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.197439, mean_absolute_error: 3.022413, mean_q: 3.930363
219 (array([36]),) False
 152320/500000: episode: 3808, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 20.875 [0.000, 45.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.215197, mean_absolute_error: 2.995851, mean_q: 3.902227
623 (array([37]),) False
 152360/500000: episode: 3809, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 40.875 [1.000, 48.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.204208, mean_absolute_error: 3.046848, mean_q: 3.950285
850 (array([12]),) False
 152400/500000: episode: 3810, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 35.000 [10.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.216425, mean_absolute_error: 3.004010, mean_q: 3.891484
60 (array([22]),) False
 152440/500000: episode: 3811, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 33.750 [12.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.216661, mean_absolute_error: 3.002485, mean_q: 3.891370
420 (array([22]),) False
 152480/500000: episode: 3812, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 39.325 [11.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.211950, mean_absolute_error: 2.990639, mean_q: 3.886907
590 (array([22]),) False
 152520/500000: episode: 3813, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.425 [22.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.206498, mean_absolute_error: 2.972286, mean_q: 3.864458
544 (array([22]),) False
 152560/500000: episode: 3814, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 25.150 [22.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.204753, mean_absolute_error: 3.024750, mean_q: 3.925431
688 (array([22]),) False
 152600/500000: episode: 3815, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.250 [4.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.206900, mean_absolute_error: 3.013499, mean_q: 3.913815
590 (array([22]),) False
 152640/500000: episode: 3816, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.925 [2.000, 39.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.193393, mean_absolute_error: 3.029260, mean_q: 3.940750
639 (array([22]),) False
 152680/500000: episode: 3817, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.025 [22.000, 23.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.183494, mean_absolute_error: 3.013124, mean_q: 3.908567
743 (array([48]),) False
 152720/500000: episode: 3818, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.475 [13.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.186904, mean_absolute_error: 3.017596, mean_q: 3.909926
562 (array([22]),) False
 152760/500000: episode: 3819, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.625 [2.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.214110, mean_absolute_error: 2.983837, mean_q: 3.882665
636 (array([12]),) False
 152800/500000: episode: 3820, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.050 [12.000, 51.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.204843, mean_absolute_error: 3.036516, mean_q: 3.937909
456 (array([22]),) False
 152840/500000: episode: 3821, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 33.425 [17.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.243181, mean_absolute_error: 3.065896, mean_q: 3.968849
828 (array([48]),) False
 152880/500000: episode: 3822, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.375 [12.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.211116, mean_absolute_error: 3.035047, mean_q: 3.932821
194 (array([44]),) False
 152920/500000: episode: 3823, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 40.250 [2.000, 51.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.207422, mean_absolute_error: 3.051812, mean_q: 3.959036
38 (array([22]),) False
 152960/500000: episode: 3824, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.000 [22.000, 58.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.201971, mean_absolute_error: 3.029884, mean_q: 3.932258
410 (array([22]),) False
 153000/500000: episode: 3825, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.425 [20.000, 41.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.221744, mean_absolute_error: 3.061515, mean_q: 3.954581
340 (array([12]),) False
 153040/500000: episode: 3826, duration: 32.176s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 19.750 [12.000, 52.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.204168, mean_absolute_error: 3.048524, mean_q: 3.948238
787 (array([3]),) False
 153080/500000: episode: 3827, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 22.925 [1.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.218961, mean_absolute_error: 3.066572, mean_q: 3.967432
734 (array([48]),) False
 153120/500000: episode: 3828, duration: 32.250s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 38.275 [12.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.205278, mean_absolute_error: 3.036627, mean_q: 3.937078
135 (array([22]),) False
 153160/500000: episode: 3829, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.325 [6.000, 53.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.210800, mean_absolute_error: 3.048516, mean_q: 3.946660
694 (array([22]),) False
 153200/500000: episode: 3830, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.425 [12.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.193029, mean_absolute_error: 3.089047, mean_q: 3.989568
733 (array([22]),) False
 153240/500000: episode: 3831, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.925 [7.000, 42.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.207732, mean_absolute_error: 3.046776, mean_q: 3.942806
485 (array([22]),) False
 153280/500000: episode: 3832, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.600 [2.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.204598, mean_absolute_error: 3.028985, mean_q: 3.919564
224 (array([12]),) False
 153320/500000: episode: 3833, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.875 [10.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.195370, mean_absolute_error: 3.077508, mean_q: 3.992348
602 (array([36]),) False
 153360/500000: episode: 3834, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 34.975 [8.000, 43.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.201595, mean_absolute_error: 3.080188, mean_q: 3.980813
683 (array([22]),) False
 153400/500000: episode: 3835, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.900 [16.000, 28.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.199171, mean_absolute_error: 3.102152, mean_q: 4.007308
513 (array([12]),) False
 153440/500000: episode: 3836, duration: 32.159s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 13.125 [12.000, 47.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.200350, mean_absolute_error: 3.056033, mean_q: 3.964395
69 (array([12]),) False
 153480/500000: episode: 3837, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 14.525 [12.000, 52.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.199688, mean_absolute_error: 3.033889, mean_q: 3.934921
806 (array([22]),) False
 153520/500000: episode: 3838, duration: 32.219s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.600 [22.000, 45.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.204899, mean_absolute_error: 3.093929, mean_q: 3.997146
281 (array([48]),) False
 153560/500000: episode: 3839, duration: 33.242s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 25.825 [6.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.212880, mean_absolute_error: 3.091469, mean_q: 4.005290
415 (array([22]),) False
 153600/500000: episode: 3840, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.000 [10.000, 57.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.233595, mean_absolute_error: 3.071141, mean_q: 3.989790
777 (array([48]),) False
 153640/500000: episode: 3841, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 16.625 [11.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.222536, mean_absolute_error: 3.076576, mean_q: 3.977638
683 (array([22]),) False
 153680/500000: episode: 3842, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.700 [9.000, 59.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.211314, mean_absolute_error: 3.083256, mean_q: 3.981295
110 (array([22]),) False
 153720/500000: episode: 3843, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.200 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.204082, mean_absolute_error: 3.123182, mean_q: 4.022170
274 (array([12]),) False
 153760/500000: episode: 3844, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 27.875 [2.000, 54.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.204971, mean_absolute_error: 3.108314, mean_q: 4.003398
582 (array([44]),) False
 153800/500000: episode: 3845, duration: 32.891s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.650 [22.000, 59.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.222735, mean_absolute_error: 3.100398, mean_q: 3.991530
301 (array([22]),) False
 153840/500000: episode: 3846, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 32.750 [22.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.196618, mean_absolute_error: 3.082001, mean_q: 3.976685
607 (array([12]),) False
 153880/500000: episode: 3847, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 36.950 [9.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.208562, mean_absolute_error: 3.097104, mean_q: 4.001217
635 (array([22]),) False
 153920/500000: episode: 3848, duration: 32.201s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.300 [5.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.200105, mean_absolute_error: 3.067771, mean_q: 3.959393
529 (array([3]),) False
 153960/500000: episode: 3849, duration: 32.985s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 7.850 [3.000, 51.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.215813, mean_absolute_error: 3.082498, mean_q: 3.979982
160 (array([12]),) False
 154000/500000: episode: 3850, duration: 32.102s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 20.050 [7.000, 44.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.219321, mean_absolute_error: 3.106709, mean_q: 4.000672
818 (array([48]),) False
 154040/500000: episode: 3851, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 22.800 [5.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.197782, mean_absolute_error: 3.000438, mean_q: 3.891865
735 (array([22]),) False
 154080/500000: episode: 3852, duration: 31.243s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.875 [5.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.206016, mean_absolute_error: 3.049136, mean_q: 3.947704
306 (array([22]),) False
 154120/500000: episode: 3853, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.225 [0.000, 26.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.209334, mean_absolute_error: 3.077445, mean_q: 3.977563
798 (array([18]),) False
 154160/500000: episode: 3854, duration: 30.878s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.700 [3.000, 44.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.215725, mean_absolute_error: 3.088560, mean_q: 3.986895
77 (array([22]),) False
 154200/500000: episode: 3855, duration: 30.926s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.525 [3.000, 48.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.224348, mean_absolute_error: 3.029190, mean_q: 3.920088
527 (array([58]),) False
 154240/500000: episode: 3856, duration: 30.819s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 56.050 [5.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.216732, mean_absolute_error: 3.070391, mean_q: 3.975724
354 (array([12]),) False
 154280/500000: episode: 3857, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 15.025 [12.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.213100, mean_absolute_error: 3.116641, mean_q: 4.024573
148 (array([22]),) False
 154320/500000: episode: 3858, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.925 [8.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.208076, mean_absolute_error: 3.114761, mean_q: 4.026444
707 (array([48]),) False
 154360/500000: episode: 3859, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.700 [20.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.209618, mean_absolute_error: 3.050315, mean_q: 3.937600
38 (array([22]),) False
 154400/500000: episode: 3860, duration: 30.071s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.475 [22.000, 41.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.209980, mean_absolute_error: 3.057042, mean_q: 3.980132
649 (array([22]),) False
 154440/500000: episode: 3861, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [8.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.205664, mean_absolute_error: 3.068237, mean_q: 3.982459
618 (array([12]),) False
 154480/500000: episode: 3862, duration: 30.017s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.675 [15.000, 47.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.208474, mean_absolute_error: 3.106478, mean_q: 4.037341
335 (array([22]),) False
 154520/500000: episode: 3863, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.175 [7.000, 51.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.199729, mean_absolute_error: 3.100760, mean_q: 4.023235
246 (array([22]),) False
 154560/500000: episode: 3864, duration: 30.144s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.350 [4.000, 39.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.213694, mean_absolute_error: 3.063238, mean_q: 3.986900
655 (array([22]),) False
 154600/500000: episode: 3865, duration: 31.091s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.300 [2.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.212575, mean_absolute_error: 3.000334, mean_q: 3.906251
150 (array([22]),) False
 154640/500000: episode: 3866, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.850 [12.000, 33.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.208357, mean_absolute_error: 3.081119, mean_q: 3.998145
841 (array([21]),) False
 154680/500000: episode: 3867, duration: 31.131s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.375 [14.000, 53.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.230567, mean_absolute_error: 3.106189, mean_q: 4.036684
617 (array([22]),) False
 154720/500000: episode: 3868, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.075 [10.000, 46.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.191774, mean_absolute_error: 3.079566, mean_q: 4.010365
207 (array([36]),) False
 154760/500000: episode: 3869, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 16.875 [0.000, 57.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.215470, mean_absolute_error: 3.123619, mean_q: 4.048784
269 (array([36]),) False
 154800/500000: episode: 3870, duration: 31.064s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 21.725 [1.000, 44.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.195684, mean_absolute_error: 3.088688, mean_q: 4.001508
597 (array([22]),) False
 154840/500000: episode: 3871, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.100 [5.000, 53.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.201750, mean_absolute_error: 3.104863, mean_q: 4.018187
667 (array([48]),) False
 154880/500000: episode: 3872, duration: 30.251s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.725 [7.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.201586, mean_absolute_error: 3.092241, mean_q: 4.014604
770 (array([22]),) False
 154920/500000: episode: 3873, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.950 [12.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.219031, mean_absolute_error: 3.070635, mean_q: 3.975625
13 (array([48]),) False
 154960/500000: episode: 3874, duration: 30.242s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.525 [8.000, 48.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.224107, mean_absolute_error: 3.127648, mean_q: 4.049644
621 (array([22]),) False
 155000/500000: episode: 3875, duration: 31.033s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.450 [7.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.225116, mean_absolute_error: 3.103207, mean_q: 4.010049
644 (array([12]),) False
 155040/500000: episode: 3876, duration: 30.268s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 28.375 [9.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.229155, mean_absolute_error: 3.097915, mean_q: 3.999250
22 (array([37]),) False
 155080/500000: episode: 3877, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.075 [8.000, 49.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.229218, mean_absolute_error: 3.127428, mean_q: 4.026216
738 (array([12]),) False
 155120/500000: episode: 3878, duration: 30.984s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 25.625 [12.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.210223, mean_absolute_error: 3.080887, mean_q: 3.978611
799 (array([36]),) False
 155160/500000: episode: 3879, duration: 31.076s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 41.700 [10.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.199271, mean_absolute_error: 3.037683, mean_q: 3.919577
601 (array([14]),) False
 155200/500000: episode: 3880, duration: 31.030s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 47.850 [42.000, 48.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.211068, mean_absolute_error: 3.093579, mean_q: 3.995906
551 (array([22]),) False
 155240/500000: episode: 3881, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 17.250 [7.000, 37.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.222592, mean_absolute_error: 3.093914, mean_q: 3.988345
780 (array([22]),) False
 155280/500000: episode: 3882, duration: 31.060s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.425 [8.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.209787, mean_absolute_error: 3.117101, mean_q: 4.021689
444 (array([22]),) False
 155320/500000: episode: 3883, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.750 [11.000, 55.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.198525, mean_absolute_error: 3.129947, mean_q: 4.032697
159 (array([48]),) False
 155360/500000: episode: 3884, duration: 30.167s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 32.725 [2.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.216659, mean_absolute_error: 3.072441, mean_q: 3.968686
346 (array([12]),) False
 155400/500000: episode: 3885, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 17.325 [6.000, 22.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.206677, mean_absolute_error: 3.100777, mean_q: 4.010341
431 (array([22]),) False
 155440/500000: episode: 3886, duration: 30.283s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.400 [5.000, 31.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.211156, mean_absolute_error: 3.088240, mean_q: 4.003015
265 (array([22]),) False
 155480/500000: episode: 3887, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.725 [3.000, 30.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.207049, mean_absolute_error: 3.043126, mean_q: 3.955807
306 (array([22]),) False
 155520/500000: episode: 3888, duration: 30.183s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.450 [18.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.219041, mean_absolute_error: 3.072318, mean_q: 3.975087
0 (array([48]),) False
 155560/500000: episode: 3889, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.475 [10.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.216626, mean_absolute_error: 3.047732, mean_q: 3.948815
451 (array([38]),) False
 155600/500000: episode: 3890, duration: 31.102s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 23.375 [22.000, 56.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.209046, mean_absolute_error: 3.018376, mean_q: 3.912731
783 (array([22]),) False
 155640/500000: episode: 3891, duration: 31.073s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.850 [0.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.191232, mean_absolute_error: 3.068360, mean_q: 3.957923
730 (array([54]),) False
 155680/500000: episode: 3892, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 35.775 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.208421, mean_absolute_error: 3.082080, mean_q: 3.975417
548 (array([22]),) False
 155720/500000: episode: 3893, duration: 31.023s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.675 [3.000, 58.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.201895, mean_absolute_error: 3.078434, mean_q: 3.974187
593 (array([37]),) False
 155760/500000: episode: 3894, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.350 [3.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.210184, mean_absolute_error: 3.043633, mean_q: 3.938732
101 (array([22]),) False
 155800/500000: episode: 3895, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.300 [8.000, 22.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.201354, mean_absolute_error: 3.052986, mean_q: 3.958027
351 (array([22]),) False
 155840/500000: episode: 3896, duration: 30.163s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.575 [13.000, 42.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.204778, mean_absolute_error: 3.025602, mean_q: 3.912497
533 (array([22]),) False
 155880/500000: episode: 3897, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.425 [19.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.210147, mean_absolute_error: 3.049484, mean_q: 3.937976
190 (array([3]),) False
 155920/500000: episode: 3898, duration: 30.124s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 6.125 [1.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.205326, mean_absolute_error: 3.049886, mean_q: 3.949380
362 (array([22]),) False
 155960/500000: episode: 3899, duration: 31.070s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.300 [5.000, 55.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.193329, mean_absolute_error: 3.116396, mean_q: 4.013568
855 (array([12]),) False
 156000/500000: episode: 3900, duration: 30.149s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 19.150 [12.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.207458, mean_absolute_error: 3.045444, mean_q: 3.945829
826 (array([22]),) False
 156040/500000: episode: 3901, duration: 31.043s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.975 [18.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.204489, mean_absolute_error: 3.020900, mean_q: 3.913322
643 (array([44]),) False
 156080/500000: episode: 3902, duration: 30.996s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 40.925 [8.000, 52.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.201394, mean_absolute_error: 3.031015, mean_q: 3.912784
187 (array([15]),) False
 156120/500000: episode: 3903, duration: 31.132s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 15.775 [3.000, 29.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.236136, mean_absolute_error: 3.049509, mean_q: 3.949862
736 (array([22]),) False
 156160/500000: episode: 3904, duration: 31.001s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 17.550 [3.000, 32.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.213609, mean_absolute_error: 3.030508, mean_q: 3.927624
101 (array([22]),) False
 156200/500000: episode: 3905, duration: 31.046s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.275 [11.000, 54.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.224077, mean_absolute_error: 3.102558, mean_q: 4.013187
350 (array([12]),) False
 156240/500000: episode: 3906, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 15.425 [12.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.213428, mean_absolute_error: 3.029096, mean_q: 3.927404
549 (array([22]),) False
 156280/500000: episode: 3907, duration: 30.994s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 24.700 [2.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.208029, mean_absolute_error: 3.016191, mean_q: 3.915040
793 (array([12]),) False
 156320/500000: episode: 3908, duration: 30.132s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 22.575 [3.000, 57.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.211528, mean_absolute_error: 3.042433, mean_q: 3.942645
658 (array([48]),) False
 156360/500000: episode: 3909, duration: 31.035s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.550 [12.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.200457, mean_absolute_error: 3.032121, mean_q: 3.934943
622 (array([36]),) False
 156400/500000: episode: 3910, duration: 30.100s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 34.875 [3.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.204153, mean_absolute_error: 3.020291, mean_q: 3.919968
166 (array([22]),) False
 156440/500000: episode: 3911, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 19.875 [4.000, 60.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.201767, mean_absolute_error: 3.041626, mean_q: 3.940527
808 (array([22]),) False
 156480/500000: episode: 3912, duration: 30.144s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.125 [3.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.200928, mean_absolute_error: 3.044208, mean_q: 3.942820
637 (array([12]),) False
 156520/500000: episode: 3913, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 19.675 [6.000, 27.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.190957, mean_absolute_error: 3.039811, mean_q: 3.938180
486 (array([22]),) False
 156560/500000: episode: 3914, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.875 [22.000, 52.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.211463, mean_absolute_error: 3.019381, mean_q: 3.919940
572 (array([58]),) False
 156600/500000: episode: 3915, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 55.175 [0.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.207905, mean_absolute_error: 3.024975, mean_q: 3.923894
325 (array([22]),) False
 156640/500000: episode: 3916, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.050 [12.000, 51.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.206765, mean_absolute_error: 3.022453, mean_q: 3.924707
738 (array([12]),) False
 156680/500000: episode: 3917, duration: 31.032s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 30.725 [12.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.210826, mean_absolute_error: 3.026834, mean_q: 3.924117
29 (array([22]),) False
 156720/500000: episode: 3918, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.525 [3.000, 51.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.220733, mean_absolute_error: 3.064897, mean_q: 3.968119
750 (array([22]),) False
 156760/500000: episode: 3919, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.100 [9.000, 59.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.199111, mean_absolute_error: 3.078959, mean_q: 3.981792
837 (array([48]),) False
 156800/500000: episode: 3920, duration: 30.074s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 47.900 [32.000, 60.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.211582, mean_absolute_error: 3.046087, mean_q: 3.947311
457 (array([38]),) False
 156840/500000: episode: 3921, duration: 31.037s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.700 [3.000, 53.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.209700, mean_absolute_error: 3.048110, mean_q: 3.933018
783 (array([22]),) False
 156880/500000: episode: 3922, duration: 30.092s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.625 [14.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.206700, mean_absolute_error: 3.037600, mean_q: 3.933514
255 (array([12]),) False
 156920/500000: episode: 3923, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 23.275 [1.000, 47.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.237002, mean_absolute_error: 3.050832, mean_q: 3.948259
599 (array([48]),) False
 156960/500000: episode: 3924, duration: 30.152s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 39.125 [3.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.205193, mean_absolute_error: 3.007502, mean_q: 3.910680
290 (array([22]),) False
 157000/500000: episode: 3925, duration: 31.096s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.375 [1.000, 52.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.220903, mean_absolute_error: 2.985551, mean_q: 3.878827
221 (array([22]),) False
 157040/500000: episode: 3926, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.700 [2.000, 44.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.212023, mean_absolute_error: 3.001105, mean_q: 3.892178
461 (array([22]),) False
 157080/500000: episode: 3927, duration: 31.096s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.200 [8.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.229461, mean_absolute_error: 3.022672, mean_q: 3.903667
860 (array([12]),) False
 157120/500000: episode: 3928, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 18.100 [5.000, 57.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.197593, mean_absolute_error: 3.048217, mean_q: 3.955162
391 (array([22]),) False
 157160/500000: episode: 3929, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 24.600 [22.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.199649, mean_absolute_error: 2.995998, mean_q: 3.884130
110 (array([22]),) False
 157200/500000: episode: 3930, duration: 31.051s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.450 [2.000, 50.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.208397, mean_absolute_error: 2.986237, mean_q: 3.871592
446 (array([22]),) False
 157240/500000: episode: 3931, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.325 [22.000, 45.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.192333, mean_absolute_error: 2.956122, mean_q: 3.834756
523 (array([22]),) False
 157280/500000: episode: 3932, duration: 30.198s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.975 [22.000, 52.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.200555, mean_absolute_error: 2.973113, mean_q: 3.861309
493 (array([22]),) False
 157320/500000: episode: 3933, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.875 [3.000, 59.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.193409, mean_absolute_error: 2.927189, mean_q: 3.809419
136 (array([12]),) False
 157360/500000: episode: 3934, duration: 30.230s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 23.500 [12.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.197849, mean_absolute_error: 2.972493, mean_q: 3.851584
714 (array([22]),) False
 157400/500000: episode: 3935, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 17.550 [1.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.210596, mean_absolute_error: 2.934378, mean_q: 3.817609
266 (array([12]),) False
 157440/500000: episode: 3936, duration: 30.222s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.450 [8.000, 44.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.222840, mean_absolute_error: 2.950241, mean_q: 3.824579
25 (array([48]),) False
 157480/500000: episode: 3937, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 33.950 [7.000, 59.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.200270, mean_absolute_error: 2.943404, mean_q: 3.815491
128 (array([22]),) False
 157520/500000: episode: 3938, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.750 [8.000, 36.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.198923, mean_absolute_error: 2.944419, mean_q: 3.825040
858 (array([12]),) False
 157560/500000: episode: 3939, duration: 31.085s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 16.125 [12.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.200903, mean_absolute_error: 2.975854, mean_q: 3.853940
115 (array([22]),) False
 157600/500000: episode: 3940, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.500 [2.000, 50.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.210418, mean_absolute_error: 2.945314, mean_q: 3.820839
403 (array([12]),) False
 157640/500000: episode: 3941, duration: 31.063s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.950 [6.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.203175, mean_absolute_error: 2.968885, mean_q: 3.860934
121 (array([22]),) False
 157680/500000: episode: 3942, duration: 31.040s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 19.275 [3.000, 34.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.198135, mean_absolute_error: 2.965677, mean_q: 3.843013
106 (array([22]),) False
 157720/500000: episode: 3943, duration: 31.041s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.100 [6.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.203089, mean_absolute_error: 2.982066, mean_q: 3.864907
129 (array([22]),) False
 157760/500000: episode: 3944, duration: 30.217s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.825 [12.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.195174, mean_absolute_error: 2.934273, mean_q: 3.810609
839 (array([22]),) False
 157800/500000: episode: 3945, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.025 [12.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.215466, mean_absolute_error: 2.989181, mean_q: 3.882842
399 (array([22]),) False
 157840/500000: episode: 3946, duration: 30.209s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 33.725 [12.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.210319, mean_absolute_error: 2.982726, mean_q: 3.870233
846 (array([48]),) False
 157880/500000: episode: 3947, duration: 31.070s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.725 [9.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.207014, mean_absolute_error: 2.932910, mean_q: 3.809874
762 (array([22]),) False
 157920/500000: episode: 3948, duration: 30.193s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.075 [2.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.190169, mean_absolute_error: 2.920058, mean_q: 3.788259
634 (array([57]),) False
 157960/500000: episode: 3949, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 23.800 [3.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.196810, mean_absolute_error: 2.994087, mean_q: 3.881219
17 (array([22]),) False
 158000/500000: episode: 3950, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.625 [7.000, 22.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.226060, mean_absolute_error: 2.919756, mean_q: 3.804689
411 (array([22]),) False
 158040/500000: episode: 3951, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.825 [0.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.186855, mean_absolute_error: 2.970213, mean_q: 3.845281
787 (array([3]),) False
 158080/500000: episode: 3952, duration: 31.017s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 22.350 [22.000, 36.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.206505, mean_absolute_error: 2.946291, mean_q: 3.826943
768 (array([22]),) False
 158120/500000: episode: 3953, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 21.400 [4.000, 47.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.200380, mean_absolute_error: 2.909570, mean_q: 3.781165
45 (array([22]),) False
 158160/500000: episode: 3954, duration: 31.079s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.600 [5.000, 41.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.200956, mean_absolute_error: 2.925162, mean_q: 3.804671
134 (array([58]),) False
 158200/500000: episode: 3955, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 45.725 [12.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.193588, mean_absolute_error: 2.938821, mean_q: 3.825244
862 (array([14]),) False
 158240/500000: episode: 3956, duration: 30.208s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 29.625 [3.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.203675, mean_absolute_error: 2.949577, mean_q: 3.836761
91 (array([48]),) False
 158280/500000: episode: 3957, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.950 [12.000, 52.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.200855, mean_absolute_error: 2.932345, mean_q: 3.815311
296 (array([22]),) False
 158320/500000: episode: 3958, duration: 30.246s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.125 [7.000, 54.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.202793, mean_absolute_error: 2.979417, mean_q: 3.870208
41 (array([12]),) False
 158360/500000: episode: 3959, duration: 31.047s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.475 [4.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.191855, mean_absolute_error: 2.930433, mean_q: 3.807891
281 (array([48]),) False
 158400/500000: episode: 3960, duration: 30.197s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 21.600 [12.000, 43.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.211801, mean_absolute_error: 2.985236, mean_q: 3.867255
118 (array([22]),) False
 158440/500000: episode: 3961, duration: 31.017s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.700 [3.000, 55.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.206124, mean_absolute_error: 2.970807, mean_q: 3.871079
177 (array([22]),) False
 158480/500000: episode: 3962, duration: 31.035s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.525 [12.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.200441, mean_absolute_error: 2.921590, mean_q: 3.814130
364 (array([14]),) False
 158520/500000: episode: 3963, duration: 30.987s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.100 [8.000, 53.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.204244, mean_absolute_error: 3.006012, mean_q: 3.885426
119 (array([45]),) False
 158560/500000: episode: 3964, duration: 31.090s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 18.925 [3.000, 49.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.209674, mean_absolute_error: 2.943137, mean_q: 3.819597
449 (array([22]),) False
 158600/500000: episode: 3965, duration: 31.044s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.575 [20.000, 35.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.206444, mean_absolute_error: 2.977775, mean_q: 3.858414
648 (array([22]),) False
 158640/500000: episode: 3966, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.625 [3.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.190673, mean_absolute_error: 2.925239, mean_q: 3.812579
499 (array([8]),) False
 158680/500000: episode: 3967, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 36.800 [14.000, 42.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.195952, mean_absolute_error: 2.985767, mean_q: 3.860345
270 (array([3]),) False
 158720/500000: episode: 3968, duration: 30.178s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 10.100 [3.000, 36.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.199591, mean_absolute_error: 2.960791, mean_q: 3.839035
598 (array([22]),) False
 158760/500000: episode: 3969, duration: 31.041s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.875 [0.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.208697, mean_absolute_error: 2.953205, mean_q: 3.850527
679 (array([44]),) False
 158800/500000: episode: 3970, duration: 30.089s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.425 [4.000, 60.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.207974, mean_absolute_error: 2.989916, mean_q: 3.885291
723 (array([48]),) False
 158840/500000: episode: 3971, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 18.625 [0.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.198322, mean_absolute_error: 2.991410, mean_q: 3.879406
394 (array([22]),) False
 158880/500000: episode: 3972, duration: 30.101s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.800 [14.000, 22.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.220004, mean_absolute_error: 2.990496, mean_q: 3.870698
121 (array([22]),) False
 158920/500000: episode: 3973, duration: 31.093s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 17.900 [7.000, 38.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.203351, mean_absolute_error: 2.955371, mean_q: 3.841892
203 (array([48]),) False
 158960/500000: episode: 3974, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.825 [39.000, 53.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.206611, mean_absolute_error: 2.939608, mean_q: 3.821787
664 (array([22]),) False
 159000/500000: episode: 3975, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 20.825 [12.000, 52.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.214022, mean_absolute_error: 2.936011, mean_q: 3.812380
491 (array([22]),) False
 159040/500000: episode: 3976, duration: 31.013s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.575 [22.000, 49.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.197270, mean_absolute_error: 2.973565, mean_q: 3.867314
554 (array([22]),) False
 159080/500000: episode: 3977, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 20.625 [3.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.200030, mean_absolute_error: 2.993085, mean_q: 3.873118
141 (array([44]),) False
 159120/500000: episode: 3978, duration: 31.014s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 33.350 [12.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.199388, mean_absolute_error: 2.958847, mean_q: 3.846810
403 (array([12]),) False
 159160/500000: episode: 3979, duration: 31.114s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.450 [3.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.188674, mean_absolute_error: 2.976681, mean_q: 3.870946
142 (array([12]),) False
 159200/500000: episode: 3980, duration: 30.069s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 20.750 [12.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.216077, mean_absolute_error: 2.938112, mean_q: 3.821835
560 (array([22]),) False
 159240/500000: episode: 3981, duration: 31.097s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.100 [11.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.193574, mean_absolute_error: 2.963355, mean_q: 3.864414
174 (array([33]),) False
 159280/500000: episode: 3982, duration: 30.130s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.275 [22.000, 56.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.220187, mean_absolute_error: 2.932653, mean_q: 3.812970
56 (array([12]),) False
 159320/500000: episode: 3983, duration: 31.070s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 42.025 [17.000, 48.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.196451, mean_absolute_error: 2.999817, mean_q: 3.893499
162 (array([22]),) False
 159360/500000: episode: 3984, duration: 30.177s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.450 [14.000, 55.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.202903, mean_absolute_error: 2.967746, mean_q: 3.865550
75 (array([22]),) False
 159400/500000: episode: 3985, duration: 31.060s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.125 [3.000, 56.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.206709, mean_absolute_error: 2.931953, mean_q: 3.814599
857 (array([22]),) False
 159440/500000: episode: 3986, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 33.475 [12.000, 57.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.202722, mean_absolute_error: 3.003883, mean_q: 3.899408
337 (array([22]),) False
 159480/500000: episode: 3987, duration: 31.022s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.775 [1.000, 54.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.198864, mean_absolute_error: 2.915808, mean_q: 3.797046
234 (array([22]),) False
 159520/500000: episode: 3988, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.350 [7.000, 34.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.204477, mean_absolute_error: 2.987537, mean_q: 3.880864
41 (array([12]),) False
 159560/500000: episode: 3989, duration: 31.022s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.975 [15.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.195818, mean_absolute_error: 2.936786, mean_q: 3.833111
797 (array([22]),) False
 159600/500000: episode: 3990, duration: 31.019s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.275 [0.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.193974, mean_absolute_error: 2.970529, mean_q: 3.856306
352 (array([22]),) False
 159640/500000: episode: 3991, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 19.550 [12.000, 46.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.218769, mean_absolute_error: 2.951807, mean_q: 3.838344
470 (array([22]),) False
 159680/500000: episode: 3992, duration: 30.194s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.825 [18.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.201955, mean_absolute_error: 2.964366, mean_q: 3.843044
856 (array([48]),) False
 159720/500000: episode: 3993, duration: 31.056s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 44.625 [2.000, 52.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.208587, mean_absolute_error: 2.980901, mean_q: 3.875661
834 (array([44]),) False
 159760/500000: episode: 3994, duration: 30.170s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 24.250 [3.000, 48.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.191099, mean_absolute_error: 2.932173, mean_q: 3.827702
29 (array([22]),) False
 159800/500000: episode: 3995, duration: 31.098s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.075 [20.000, 25.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.202378, mean_absolute_error: 2.966770, mean_q: 3.851709
670 (array([22]),) False
 159840/500000: episode: 3996, duration: 30.177s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 22.050 [3.000, 54.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.208008, mean_absolute_error: 2.904284, mean_q: 3.792889
5 (array([37]),) False
 159880/500000: episode: 3997, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.100 [7.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.199051, mean_absolute_error: 2.966255, mean_q: 3.840547
578 (array([22]),) False
 159920/500000: episode: 3998, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.375 [1.000, 46.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.204612, mean_absolute_error: 2.942829, mean_q: 3.813788
216 (array([22]),) False
 159960/500000: episode: 3999, duration: 31.111s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.325 [21.000, 36.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.204359, mean_absolute_error: 2.931758, mean_q: 3.798499
350 (array([12]),) False
 160000/500000: episode: 4000, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 14.825 [12.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.209618, mean_absolute_error: 2.973641, mean_q: 3.848417
17 (array([22]),) False
 160040/500000: episode: 4001, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.125 [7.000, 22.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.207757, mean_absolute_error: 2.933432, mean_q: 3.808273
383 (array([22]),) False
 160080/500000: episode: 4002, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.300 [9.000, 22.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.205251, mean_absolute_error: 2.977430, mean_q: 3.863690
91 (array([48]),) False
 160120/500000: episode: 4003, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 48.125 [48.000, 52.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.207744, mean_absolute_error: 2.949165, mean_q: 3.823638
721 (array([22]),) False
 160160/500000: episode: 4004, duration: 30.819s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.300 [22.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.198308, mean_absolute_error: 2.995959, mean_q: 3.871706
710 (array([12]),) False
 160200/500000: episode: 4005, duration: 31.163s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 12.500 [3.000, 49.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.198371, mean_absolute_error: 2.994191, mean_q: 3.861543
327 (array([22]),) False
 160240/500000: episode: 4006, duration: 30.480s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.550 [0.000, 53.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.205945, mean_absolute_error: 2.922361, mean_q: 3.789619
621 (array([22]),) False
 160280/500000: episode: 4007, duration: 31.137s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.925 [16.000, 52.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.211961, mean_absolute_error: 2.974431, mean_q: 3.841791
337 (array([22]),) False
 160320/500000: episode: 4008, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.325 [2.000, 54.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.215613, mean_absolute_error: 2.960830, mean_q: 3.825719
694 (array([22]),) False
 160360/500000: episode: 4009, duration: 31.370s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.625 [4.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.195484, mean_absolute_error: 2.959985, mean_q: 3.825641
659 (array([40]),) False
 160400/500000: episode: 4010, duration: 31.204s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.275 [5.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.202785, mean_absolute_error: 2.949049, mean_q: 3.823023
322 (array([12]),) False
 160440/500000: episode: 4011, duration: 31.243s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 14.300 [12.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.193923, mean_absolute_error: 2.937319, mean_q: 3.805519
159 (array([48]),) False
 160480/500000: episode: 4012, duration: 31.379s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.525 [3.000, 55.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.206881, mean_absolute_error: 2.917334, mean_q: 3.799783
734 (array([48]),) False
 160520/500000: episode: 4013, duration: 31.251s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 29.800 [6.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.195222, mean_absolute_error: 2.900096, mean_q: 3.768622
592 (array([22]),) False
 160560/500000: episode: 4014, duration: 31.184s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.650 [11.000, 48.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.196514, mean_absolute_error: 2.942873, mean_q: 3.809945
347 (array([22]),) False
 160600/500000: episode: 4015, duration: 30.892s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.650 [0.000, 33.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.192509, mean_absolute_error: 2.929756, mean_q: 3.802881
573 (array([22]),) False
 160640/500000: episode: 4016, duration: 30.074s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 26.350 [22.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.194331, mean_absolute_error: 2.920435, mean_q: 3.783257
465 (array([48]),) False
 160680/500000: episode: 4017, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.525 [9.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.200441, mean_absolute_error: 2.916856, mean_q: 3.785372
378 (array([22]),) False
 160720/500000: episode: 4018, duration: 30.148s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.325 [22.000, 50.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.205815, mean_absolute_error: 2.940157, mean_q: 3.823520
479 (array([22]),) False
 160760/500000: episode: 4019, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.250 [3.000, 56.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.191475, mean_absolute_error: 2.912126, mean_q: 3.789963
303 (array([22]),) False
 160800/500000: episode: 4020, duration: 30.085s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.199821, mean_absolute_error: 2.917917, mean_q: 3.796606
291 (array([22]),) False
 160840/500000: episode: 4021, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.875 [19.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.213490, mean_absolute_error: 2.872981, mean_q: 3.738920
125 (array([58]),) False
 160880/500000: episode: 4022, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 56.000 [18.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.193120, mean_absolute_error: 2.920917, mean_q: 3.782777
820 (array([48]),) False
 160920/500000: episode: 4023, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.725 [22.000, 55.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.193297, mean_absolute_error: 2.897024, mean_q: 3.770363
98 (array([12]),) False
 160960/500000: episode: 4024, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.425 [2.000, 32.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.193949, mean_absolute_error: 2.925196, mean_q: 3.799104
496 (array([48]),) False
 161000/500000: episode: 4025, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 47.100 [12.000, 48.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.186929, mean_absolute_error: 2.943444, mean_q: 3.826773
836 (array([22]),) False
 161040/500000: episode: 4026, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.275 [0.000, 36.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.207360, mean_absolute_error: 2.953502, mean_q: 3.840518
272 (array([12]),) False
 161080/500000: episode: 4027, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.550 [3.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.194088, mean_absolute_error: 2.972261, mean_q: 3.846991
665 (array([12]),) False
 161120/500000: episode: 4028, duration: 30.029s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 12.575 [11.000, 30.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.189432, mean_absolute_error: 2.923367, mean_q: 3.806898
199 (array([22]),) False
 161160/500000: episode: 4029, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.600 [11.000, 51.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.197193, mean_absolute_error: 2.965830, mean_q: 3.861107
394 (array([22]),) False
 161200/500000: episode: 4030, duration: 30.381s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.250 [11.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.200927, mean_absolute_error: 2.841691, mean_q: 3.714836
51 (array([22]),) False
 161240/500000: episode: 4031, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.475 [4.000, 46.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.202507, mean_absolute_error: 2.945545, mean_q: 3.827971
485 (array([22]),) False
 161280/500000: episode: 4032, duration: 30.021s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.500 [15.000, 42.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.185272, mean_absolute_error: 2.984700, mean_q: 3.859609
442 (array([22]),) False
 161320/500000: episode: 4033, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.500 [9.000, 49.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.195611, mean_absolute_error: 2.935829, mean_q: 3.816420
633 (array([22]),) False
 161360/500000: episode: 4034, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.525 [13.000, 58.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.202703, mean_absolute_error: 2.982781, mean_q: 3.881201
10 (array([3]),) False
 161400/500000: episode: 4035, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.425 [3.000, 57.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.192485, mean_absolute_error: 2.969694, mean_q: 3.857365
580 (array([22]),) False
 161440/500000: episode: 4036, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.125 [6.000, 55.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.216859, mean_absolute_error: 2.966061, mean_q: 3.843987
585 (array([48]),) False
 161480/500000: episode: 4037, duration: 30.897s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.400 [3.000, 24.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.198777, mean_absolute_error: 2.951775, mean_q: 3.845237
23 (array([48]),) False
 161520/500000: episode: 4038, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.175 [4.000, 54.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.199783, mean_absolute_error: 2.934820, mean_q: 3.819186
764 (array([48]),) False
 161560/500000: episode: 4039, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 27.350 [12.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.209027, mean_absolute_error: 2.976295, mean_q: 3.868863
548 (array([22]),) False
 161600/500000: episode: 4040, duration: 30.035s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.400 [9.000, 58.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.205436, mean_absolute_error: 2.980198, mean_q: 3.858055
272 (array([12]),) False
 161640/500000: episode: 4041, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.575 [10.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.191599, mean_absolute_error: 2.925000, mean_q: 3.798522
513 (array([12]),) False
 161680/500000: episode: 4042, duration: 30.030s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 13.725 [5.000, 48.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.200900, mean_absolute_error: 2.985005, mean_q: 3.860384
391 (array([22]),) False
 161720/500000: episode: 4043, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.950 [1.000, 41.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.201998, mean_absolute_error: 2.957251, mean_q: 3.825326
681 (array([12]),) False
 161760/500000: episode: 4044, duration: 30.113s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 23.300 [12.000, 54.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.209631, mean_absolute_error: 2.980451, mean_q: 3.857519
242 (array([22]),) False
 161800/500000: episode: 4045, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.875 [12.000, 52.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.198335, mean_absolute_error: 3.015801, mean_q: 3.883931
548 (array([22]),) False
 161840/500000: episode: 4046, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.750 [1.000, 56.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.183585, mean_absolute_error: 2.991594, mean_q: 3.870964
649 (array([22]),) False
 161880/500000: episode: 4047, duration: 30.959s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 20.625 [0.000, 22.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.190632, mean_absolute_error: 2.975873, mean_q: 3.845787
139 (array([48]),) False
 161920/500000: episode: 4048, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 18.150 [2.000, 55.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.198481, mean_absolute_error: 2.955496, mean_q: 3.824525
50 (array([22]),) False
 161960/500000: episode: 4049, duration: 30.846s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.575 [6.000, 60.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.203876, mean_absolute_error: 3.007261, mean_q: 3.873897
672 (array([44]),) False
 162000/500000: episode: 4050, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 43.475 [2.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.205268, mean_absolute_error: 2.959104, mean_q: 3.833087
558 (array([40]),) False
 162040/500000: episode: 4051, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 19.150 [12.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.194691, mean_absolute_error: 3.012656, mean_q: 3.902753
712 (array([22]),) False
 162080/500000: episode: 4052, duration: 30.086s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 19.200 [1.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.199567, mean_absolute_error: 3.056985, mean_q: 3.951006
50 (array([22]),) False
 162120/500000: episode: 4053, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.350 [2.000, 59.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.188431, mean_absolute_error: 2.952249, mean_q: 3.824032
465 (array([48]),) False
 162160/500000: episode: 4054, duration: 30.129s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 46.775 [22.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.197497, mean_absolute_error: 3.016447, mean_q: 3.891922
543 (array([12]),) False
 162200/500000: episode: 4055, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 13.850 [12.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.211780, mean_absolute_error: 3.003338, mean_q: 3.881036
108 (array([48]),) False
 162240/500000: episode: 4056, duration: 30.042s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 29.825 [7.000, 53.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.202755, mean_absolute_error: 3.009539, mean_q: 3.897794
689 (array([12]),) False
 162280/500000: episode: 4057, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 12.500 [7.000, 32.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.200978, mean_absolute_error: 2.989435, mean_q: 3.882294
139 (array([48]),) False
 162320/500000: episode: 4058, duration: 30.926s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 18.575 [5.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.194595, mean_absolute_error: 2.964951, mean_q: 3.854612
820 (array([48]),) False
 162360/500000: episode: 4059, duration: 31.310s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 25.275 [10.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.196134, mean_absolute_error: 2.952015, mean_q: 3.828351
482 (array([22]),) False
 162400/500000: episode: 4060, duration: 31.477s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.275 [22.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.208566, mean_absolute_error: 2.960838, mean_q: 3.848882
485 (array([22]),) False
 162440/500000: episode: 4061, duration: 31.517s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.525 [10.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.189290, mean_absolute_error: 2.945112, mean_q: 3.833912
744 (array([22]),) False
 162480/500000: episode: 4062, duration: 31.518s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 20.575 [0.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.194581, mean_absolute_error: 3.000153, mean_q: 3.890931
48 (array([12]),) False
 162520/500000: episode: 4063, duration: 31.477s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.025 [3.000, 24.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.212723, mean_absolute_error: 2.908023, mean_q: 3.778053
643 (array([44]),) False
 162560/500000: episode: 4064, duration: 31.075s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 39.575 [8.000, 55.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.211556, mean_absolute_error: 2.949691, mean_q: 3.824744
324 (array([12]),) False
 162600/500000: episode: 4065, duration: 31.497s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 15.575 [5.000, 50.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.194566, mean_absolute_error: 2.897602, mean_q: 3.764323
55 (array([22]),) False
 162640/500000: episode: 4066, duration: 31.118s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.825 [6.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.214190, mean_absolute_error: 2.956368, mean_q: 3.841822
248 (array([12]),) False
 162680/500000: episode: 4067, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 20.725 [1.000, 32.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.209909, mean_absolute_error: 2.914411, mean_q: 3.802818
191 (array([38]),) False
 162720/500000: episode: 4068, duration: 31.074s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 13.225 [1.000, 35.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.196392, mean_absolute_error: 2.917490, mean_q: 3.802984
232 (array([22]),) False
 162760/500000: episode: 4069, duration: 31.789s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.475 [3.000, 58.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.208263, mean_absolute_error: 2.912313, mean_q: 3.793498
326 (array([48]),) False
 162800/500000: episode: 4070, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 47.050 [12.000, 56.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.191930, mean_absolute_error: 2.927876, mean_q: 3.807157
372 (array([22]),) False
 162840/500000: episode: 4071, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.700 [22.000, 36.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.204696, mean_absolute_error: 2.885744, mean_q: 3.772992
460 (array([36]),) False
 162880/500000: episode: 4072, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 26.500 [22.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.196029, mean_absolute_error: 2.904357, mean_q: 3.789267
622 (array([36]),) False
 162920/500000: episode: 4073, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 35.000 [3.000, 55.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.211306, mean_absolute_error: 2.874343, mean_q: 3.761918
140 (array([12]),) False
 162960/500000: episode: 4074, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 46.375 [0.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.204309, mean_absolute_error: 2.885003, mean_q: 3.763719
174 (array([33]),) False
 163000/500000: episode: 4075, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.350 [0.000, 50.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.192506, mean_absolute_error: 2.930706, mean_q: 3.823727
815 (array([22]),) False
 163040/500000: episode: 4076, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.150 [3.000, 47.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.202966, mean_absolute_error: 2.928812, mean_q: 3.815612
68 (array([22]),) False
 163080/500000: episode: 4077, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.400 [8.000, 49.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.187074, mean_absolute_error: 2.903065, mean_q: 3.786704
256 (array([22]),) False
 163120/500000: episode: 4078, duration: 32.264s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.700 [3.000, 38.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.196147, mean_absolute_error: 2.863709, mean_q: 3.761482
310 (array([12]),) False
 163160/500000: episode: 4079, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 12.175 [12.000, 19.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.203945, mean_absolute_error: 2.882333, mean_q: 3.757926
528 (array([12]),) False
 163200/500000: episode: 4080, duration: 32.198s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 35.800 [0.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.195227, mean_absolute_error: 2.909947, mean_q: 3.789830
381 (array([22]),) False
 163240/500000: episode: 4081, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.275 [3.000, 48.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.208169, mean_absolute_error: 2.913239, mean_q: 3.794539
311 (array([22]),) False
 163280/500000: episode: 4082, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.500 [12.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.207115, mean_absolute_error: 2.964839, mean_q: 3.871017
779 (array([12]),) False
 163320/500000: episode: 4083, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 11.500 [2.000, 12.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.208628, mean_absolute_error: 2.964977, mean_q: 3.867391
535 (array([22]),) False
 163360/500000: episode: 4084, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.925 [5.000, 37.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.213886, mean_absolute_error: 2.958401, mean_q: 3.845351
117 (array([44]),) False
 163400/500000: episode: 4085, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.575 [3.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.200941, mean_absolute_error: 2.910640, mean_q: 3.791407
609 (array([22]),) False
 163440/500000: episode: 4086, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.425 [22.000, 44.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.212893, mean_absolute_error: 2.929200, mean_q: 3.810117
622 (array([36]),) False
 163480/500000: episode: 4087, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 34.450 [5.000, 49.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.190378, mean_absolute_error: 2.877301, mean_q: 3.751260
172 (array([12]),) False
 163520/500000: episode: 4088, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 14.350 [3.000, 52.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.203627, mean_absolute_error: 2.921593, mean_q: 3.794441
438 (array([22]),) False
 163560/500000: episode: 4089, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.100 [0.000, 56.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.195676, mean_absolute_error: 2.905869, mean_q: 3.780005
597 (array([22]),) False
 163600/500000: episode: 4090, duration: 32.248s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.725 [6.000, 36.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.196053, mean_absolute_error: 2.862538, mean_q: 3.734256
170 (array([44]),) False
 163640/500000: episode: 4091, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 44.125 [43.000, 50.000], mean observation: -0.171 [-1.000, 1.000], loss: 0.193289, mean_absolute_error: 2.890577, mean_q: 3.758598
796 (array([38]),) False
 163680/500000: episode: 4092, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.700 [7.000, 31.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.194412, mean_absolute_error: 2.897173, mean_q: 3.783698
585 (array([48]),) False
 163720/500000: episode: 4093, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 12.125 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.197072, mean_absolute_error: 2.852851, mean_q: 3.732996
710 (array([12]),) False
 163760/500000: episode: 4094, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 33.700 [0.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.208341, mean_absolute_error: 2.903534, mean_q: 3.785304
418 (array([22]),) False
 163800/500000: episode: 4095, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.425 [12.000, 50.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.191714, mean_absolute_error: 2.911343, mean_q: 3.787017
492 (array([22]),) False
 163840/500000: episode: 4096, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.925 [12.000, 48.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.203306, mean_absolute_error: 2.886807, mean_q: 3.764637
267 (array([22]),) False
 163880/500000: episode: 4097, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.000 [15.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.204861, mean_absolute_error: 2.812424, mean_q: 3.679933
59 (array([12]),) False
 163920/500000: episode: 4098, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.750 [14.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.191810, mean_absolute_error: 2.928023, mean_q: 3.809088
602 (array([36]),) False
 163960/500000: episode: 4099, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 35.450 [4.000, 53.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.198728, mean_absolute_error: 2.908982, mean_q: 3.794990
95 (array([22]),) False
 164000/500000: episode: 4100, duration: 32.214s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.075 [2.000, 48.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.188775, mean_absolute_error: 2.901402, mean_q: 3.773637
861 (array([22]),) False
 164040/500000: episode: 4101, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.925 [22.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.199031, mean_absolute_error: 2.896249, mean_q: 3.771780
415 (array([22]),) False
 164080/500000: episode: 4102, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.600 [22.000, 46.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.197314, mean_absolute_error: 2.914412, mean_q: 3.792431
827 (array([14]),) False
 164120/500000: episode: 4103, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 40.575 [19.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.198934, mean_absolute_error: 2.917520, mean_q: 3.778493
228 (array([44]),) False
 164160/500000: episode: 4104, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 17.150 [7.000, 44.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.183594, mean_absolute_error: 2.915810, mean_q: 3.777068
385 (array([30]),) False
 164200/500000: episode: 4105, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.850 [16.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.212018, mean_absolute_error: 2.925513, mean_q: 3.796378
356 (array([22]),) False
 164240/500000: episode: 4106, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.725 [22.000, 39.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.195814, mean_absolute_error: 2.930255, mean_q: 3.815368
352 (array([22]),) False
 164280/500000: episode: 4107, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.350 [20.000, 38.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.196946, mean_absolute_error: 2.890207, mean_q: 3.762299
755 (array([22]),) False
 164320/500000: episode: 4108, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [3.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.206440, mean_absolute_error: 2.906641, mean_q: 3.792324
777 (array([48]),) False
 164360/500000: episode: 4109, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 12.950 [5.000, 35.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.213450, mean_absolute_error: 2.935978, mean_q: 3.815020
265 (array([22]),) False
 164400/500000: episode: 4110, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.175 [8.000, 22.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.204077, mean_absolute_error: 2.844378, mean_q: 3.721137
249 (array([22]),) False
 164440/500000: episode: 4111, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.600 [1.000, 27.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.200658, mean_absolute_error: 2.950705, mean_q: 3.840123
846 (array([48]),) False
 164480/500000: episode: 4112, duration: 32.216s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 47.900 [34.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.204141, mean_absolute_error: 2.908473, mean_q: 3.786792
582 (array([44]),) False
 164520/500000: episode: 4113, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.425 [3.000, 56.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.196682, mean_absolute_error: 2.911686, mean_q: 3.788752
344 (array([22]),) False
 164560/500000: episode: 4114, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.300 [14.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.199944, mean_absolute_error: 2.924003, mean_q: 3.816105
518 (array([22]),) False
 164600/500000: episode: 4115, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.425 [12.000, 53.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.201595, mean_absolute_error: 2.931070, mean_q: 3.819176
204 (array([22]),) False
 164640/500000: episode: 4116, duration: 32.260s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 22.025 [12.000, 58.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.191242, mean_absolute_error: 2.902267, mean_q: 3.790080
46 (array([22]),) False
 164680/500000: episode: 4117, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.200 [1.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.184046, mean_absolute_error: 2.901505, mean_q: 3.790459
0 (array([48]),) False
 164720/500000: episode: 4118, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.325 [10.000, 46.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.215994, mean_absolute_error: 2.934074, mean_q: 3.823346
145 (array([19]),) False
 164760/500000: episode: 4119, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.000 [3.000, 44.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.207888, mean_absolute_error: 2.887503, mean_q: 3.765407
201 (array([22]),) False
 164800/500000: episode: 4120, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.100 [5.000, 55.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.203288, mean_absolute_error: 2.879024, mean_q: 3.749797
154 (array([44]),) False
 164840/500000: episode: 4121, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 19.450 [2.000, 46.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.211736, mean_absolute_error: 2.881431, mean_q: 3.757441
428 (array([22]),) False
 164880/500000: episode: 4122, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.425 [22.000, 49.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.193854, mean_absolute_error: 2.918535, mean_q: 3.787825
133 (array([22]),) False
 164920/500000: episode: 4123, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.350 [12.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.198313, mean_absolute_error: 2.899847, mean_q: 3.771147
233 (array([54]),) False
 164960/500000: episode: 4124, duration: 32.217s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.925 [22.000, 58.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.196006, mean_absolute_error: 2.940203, mean_q: 3.816275
639 (array([22]),) False
 165000/500000: episode: 4125, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.625 [8.000, 22.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.184906, mean_absolute_error: 2.967892, mean_q: 3.854226
295 (array([22]),) False
 165040/500000: episode: 4126, duration: 32.240s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.900 [11.000, 53.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.190380, mean_absolute_error: 2.947502, mean_q: 3.821869
105 (array([22]),) False
 165080/500000: episode: 4127, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.975 [22.000, 40.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.203119, mean_absolute_error: 2.937257, mean_q: 3.816372
411 (array([22]),) False
 165120/500000: episode: 4128, duration: 32.203s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.575 [15.000, 43.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.214744, mean_absolute_error: 2.949698, mean_q: 3.821094
318 (array([48]),) False
 165160/500000: episode: 4129, duration: 33.184s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 42.600 [12.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.222856, mean_absolute_error: 2.910337, mean_q: 3.783178
255 (array([12]),) False
 165200/500000: episode: 4130, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 25.525 [22.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.194827, mean_absolute_error: 2.896728, mean_q: 3.772285
710 (array([12]),) False
 165240/500000: episode: 4131, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 30.650 [12.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.225313, mean_absolute_error: 2.966679, mean_q: 3.855106
469 (array([22]),) False
 165280/500000: episode: 4132, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.725 [9.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.207979, mean_absolute_error: 2.953281, mean_q: 3.839032
57 (array([37]),) False
 165320/500000: episode: 4133, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 31.875 [10.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.197668, mean_absolute_error: 2.929122, mean_q: 3.815383
193 (array([36]),) False
 165360/500000: episode: 4134, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 28.375 [3.000, 57.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.202314, mean_absolute_error: 2.963123, mean_q: 3.858020
547 (array([21]),) False
 165400/500000: episode: 4135, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 22.725 [12.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.199547, mean_absolute_error: 2.963438, mean_q: 3.846753
297 (array([15]),) False
 165440/500000: episode: 4136, duration: 32.210s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.275 [3.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.201341, mean_absolute_error: 2.931786, mean_q: 3.821178
158 (array([22]),) False
 165480/500000: episode: 4137, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.250 [10.000, 49.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.208222, mean_absolute_error: 2.972193, mean_q: 3.871361
182 (array([54]),) False
 165520/500000: episode: 4138, duration: 32.265s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 28.125 [12.000, 58.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.201453, mean_absolute_error: 2.871578, mean_q: 3.765800
719 (array([22]),) False
 165560/500000: episode: 4139, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 15.225 [6.000, 39.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.209098, mean_absolute_error: 2.923970, mean_q: 3.810573
83 (array([22]),) False
 165600/500000: episode: 4140, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.850 [14.000, 40.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.189926, mean_absolute_error: 2.934421, mean_q: 3.804006
435 (array([22]),) False
 165640/500000: episode: 4141, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.225 [5.000, 51.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.217838, mean_absolute_error: 2.936228, mean_q: 3.818067
110 (array([22]),) False
 165680/500000: episode: 4142, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.300 [12.000, 44.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.209810, mean_absolute_error: 2.922611, mean_q: 3.796155
708 (array([40]),) False
 165720/500000: episode: 4143, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.075 [10.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.228165, mean_absolute_error: 2.919844, mean_q: 3.791073
344 (array([22]),) False
 165760/500000: episode: 4144, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.625 [13.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.220430, mean_absolute_error: 2.918504, mean_q: 3.789401
850 (array([12]),) False
 165800/500000: episode: 4145, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 27.700 [12.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.217775, mean_absolute_error: 2.943160, mean_q: 3.831303
164 (array([22]),) False
 165840/500000: episode: 4146, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.375 [9.000, 59.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.208439, mean_absolute_error: 2.907083, mean_q: 3.778116
234 (array([22]),) False
 165880/500000: episode: 4147, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.750 [17.000, 59.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.199552, mean_absolute_error: 2.954813, mean_q: 3.851353
283 (array([34]),) False
 165920/500000: episode: 4148, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 13.275 [3.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.200890, mean_absolute_error: 2.896856, mean_q: 3.788480
260 (array([22]),) False
 165960/500000: episode: 4149, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.450 [5.000, 57.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.227062, mean_absolute_error: 2.923343, mean_q: 3.819320
676 (array([40]),) False
 166000/500000: episode: 4150, duration: 32.245s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.700 [3.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.216898, mean_absolute_error: 2.859158, mean_q: 3.736113
461 (array([22]),) False
 166040/500000: episode: 4151, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.925 [5.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.196247, mean_absolute_error: 2.942485, mean_q: 3.834920
585 (array([48]),) False
 166080/500000: episode: 4152, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.475 [1.000, 22.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.220562, mean_absolute_error: 2.914210, mean_q: 3.806244
849 (array([3]),) False
 166120/500000: episode: 4153, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 14.250 [3.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.192928, mean_absolute_error: 2.916877, mean_q: 3.808786
135 (array([22]),) False
 166160/500000: episode: 4154, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.325 [12.000, 46.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.221588, mean_absolute_error: 2.905563, mean_q: 3.793354
339 (array([22]),) False
 166200/500000: episode: 4155, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.205026, mean_absolute_error: 2.904094, mean_q: 3.799017
81 (array([22]),) False
 166240/500000: episode: 4156, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.625 [14.000, 22.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.207665, mean_absolute_error: 2.906929, mean_q: 3.792748
263 (array([8]),) False
 166280/500000: episode: 4157, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 9.050 [8.000, 34.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.193431, mean_absolute_error: 2.909453, mean_q: 3.783836
530 (array([22]),) False
 166320/500000: episode: 4158, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.950 [19.000, 23.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.204843, mean_absolute_error: 2.882102, mean_q: 3.758241
819 (array([48]),) False
 166360/500000: episode: 4159, duration: 31.676s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 45.975 [3.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.207399, mean_absolute_error: 2.913848, mean_q: 3.806058
420 (array([22]),) False
 166400/500000: episode: 4160, duration: 31.127s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 37.775 [5.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.199519, mean_absolute_error: 2.923401, mean_q: 3.815092
743 (array([48]),) False
 166440/500000: episode: 4161, duration: 31.537s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.850 [18.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.202970, mean_absolute_error: 2.897758, mean_q: 3.786547
848 (array([44]),) False
 166480/500000: episode: 4162, duration: 31.106s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 41.850 [2.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.208908, mean_absolute_error: 2.909700, mean_q: 3.812220
550 (array([12]),) False
 166520/500000: episode: 4163, duration: 31.590s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 15.425 [12.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.204147, mean_absolute_error: 2.898537, mean_q: 3.800433
439 (array([12]),) False
 166560/500000: episode: 4164, duration: 31.110s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.600 [22.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.224265, mean_absolute_error: 2.900881, mean_q: 3.793994
219 (array([36]),) False
 166600/500000: episode: 4165, duration: 31.585s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 11.725 [1.000, 52.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.213303, mean_absolute_error: 2.878679, mean_q: 3.763987
848 (array([44]),) False
 166640/500000: episode: 4166, duration: 31.576s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 43.525 [10.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.195832, mean_absolute_error: 2.916840, mean_q: 3.807460
646 (array([44]),) False
 166680/500000: episode: 4167, duration: 31.512s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 29.275 [3.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.204608, mean_absolute_error: 2.883073, mean_q: 3.769993
323 (array([55]),) False
 166720/500000: episode: 4168, duration: 31.594s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.975 [12.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.197602, mean_absolute_error: 2.911252, mean_q: 3.810043
816 (array([4]),) False
 166760/500000: episode: 4169, duration: 31.771s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 55.500 [21.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.204817, mean_absolute_error: 2.890234, mean_q: 3.790486
641 (array([22]),) False
 166800/500000: episode: 4170, duration: 33.291s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.875 [4.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.212599, mean_absolute_error: 2.894701, mean_q: 3.784261
287 (array([48]),) False
 166840/500000: episode: 4171, duration: 33.270s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.700 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.193706, mean_absolute_error: 2.901143, mean_q: 3.795518
41 (array([12]),) False
 166880/500000: episode: 4172, duration: 32.338s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 23.750 [5.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.222866, mean_absolute_error: 2.921438, mean_q: 3.822044
331 (array([22]),) False
 166920/500000: episode: 4173, duration: 33.245s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.950 [4.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.190210, mean_absolute_error: 2.881689, mean_q: 3.777993
339 (array([22]),) False
 166960/500000: episode: 4174, duration: 32.426s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.925 [1.000, 46.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.201540, mean_absolute_error: 2.932819, mean_q: 3.827083
149 (array([8]),) False
 167000/500000: episode: 4175, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 8.425 [7.000, 21.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.197259, mean_absolute_error: 2.909118, mean_q: 3.788588
802 (array([22]),) False
 167040/500000: episode: 4176, duration: 32.321s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.200 [3.000, 28.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.208428, mean_absolute_error: 2.891783, mean_q: 3.764716
563 (array([22]),) False
 167080/500000: episode: 4177, duration: 33.301s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.325 [12.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.194194, mean_absolute_error: 2.957282, mean_q: 3.864412
783 (array([22]),) False
 167120/500000: episode: 4178, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.700 [2.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.209350, mean_absolute_error: 2.868788, mean_q: 3.746510
263 (array([8]),) False
 167160/500000: episode: 4179, duration: 33.324s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 9.000 [8.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.204603, mean_absolute_error: 2.916528, mean_q: 3.809641
302 (array([22]),) False
 167200/500000: episode: 4180, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.100 [1.000, 35.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.199941, mean_absolute_error: 2.934985, mean_q: 3.826854
314 (array([22]),) False
 167240/500000: episode: 4181, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.775 [12.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.208594, mean_absolute_error: 2.962671, mean_q: 3.863242
787 (array([3]),) False
 167280/500000: episode: 4182, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 24.900 [12.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.199954, mean_absolute_error: 2.933578, mean_q: 3.821788
273 (array([22]),) False
 167320/500000: episode: 4183, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 25.900 [7.000, 53.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.194929, mean_absolute_error: 2.923346, mean_q: 3.813405
288 (array([33]),) False
 167360/500000: episode: 4184, duration: 32.290s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.125 [16.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.200723, mean_absolute_error: 2.922584, mean_q: 3.807649
207 (array([36]),) False
 167400/500000: episode: 4185, duration: 33.277s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 27.675 [4.000, 59.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.205046, mean_absolute_error: 2.934502, mean_q: 3.812610
795 (array([3]),) False
 167440/500000: episode: 4186, duration: 32.400s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 3.775 [3.000, 20.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.207303, mean_absolute_error: 2.882114, mean_q: 3.754969
132 (array([22]),) False
 167480/500000: episode: 4187, duration: 33.243s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.150 [17.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.206802, mean_absolute_error: 2.849069, mean_q: 3.715064
275 (array([12]),) False
 167520/500000: episode: 4188, duration: 32.363s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 17.575 [3.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.201906, mean_absolute_error: 2.909129, mean_q: 3.784282
724 (array([58]),) False
 167560/500000: episode: 4189, duration: 33.363s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 55.125 [3.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.200411, mean_absolute_error: 2.907869, mean_q: 3.787236
298 (array([22]),) False
 167600/500000: episode: 4190, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.025 [5.000, 50.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.219472, mean_absolute_error: 2.917579, mean_q: 3.801081
627 (array([48]),) False
 167640/500000: episode: 4191, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.350 [10.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.213227, mean_absolute_error: 2.914300, mean_q: 3.779942
159 (array([48]),) False
 167680/500000: episode: 4192, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.450 [2.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.199589, mean_absolute_error: 2.947186, mean_q: 3.827299
725 (array([36]),) False
 167720/500000: episode: 4193, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 36.575 [36.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.204080, mean_absolute_error: 2.961418, mean_q: 3.857002
739 (array([22]),) False
 167760/500000: episode: 4194, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.475 [12.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.207253, mean_absolute_error: 2.985362, mean_q: 3.861734
221 (array([22]),) False
 167800/500000: episode: 4195, duration: 33.250s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.450 [6.000, 46.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.208266, mean_absolute_error: 2.920271, mean_q: 3.785429
569 (array([22]),) False
 167840/500000: episode: 4196, duration: 32.313s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 21.950 [2.000, 42.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.204496, mean_absolute_error: 2.938647, mean_q: 3.820489
466 (array([22]),) False
 167880/500000: episode: 4197, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.125 [5.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.211662, mean_absolute_error: 2.939307, mean_q: 3.806053
707 (array([48]),) False
 167920/500000: episode: 4198, duration: 32.342s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 47.025 [8.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.199554, mean_absolute_error: 2.915586, mean_q: 3.795151
259 (array([12]),) False
 167960/500000: episode: 4199, duration: 33.276s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 21.300 [8.000, 22.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.192660, mean_absolute_error: 2.928612, mean_q: 3.808881
188 (array([22]),) False
 168000/500000: episode: 4200, duration: 32.309s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.675 [5.000, 48.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.205582, mean_absolute_error: 2.964484, mean_q: 3.844307
546 (array([22]),) False
 168040/500000: episode: 4201, duration: 33.248s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 14.025 [3.000, 50.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.216321, mean_absolute_error: 2.956665, mean_q: 3.836794
276 (array([56]),) False
 168080/500000: episode: 4202, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.900 [3.000, 53.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.201295, mean_absolute_error: 2.931866, mean_q: 3.813742
796 (array([38]),) False
 168120/500000: episode: 4203, duration: 33.306s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.250 [0.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.211996, mean_absolute_error: 2.902503, mean_q: 3.769969
242 (array([22]),) False
 168160/500000: episode: 4204, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 20.975 [0.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.197817, mean_absolute_error: 2.900970, mean_q: 3.778828
206 (array([22]),) False
 168200/500000: episode: 4205, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.075 [12.000, 54.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.200684, mean_absolute_error: 2.945245, mean_q: 3.822701
356 (array([22]),) False
 168240/500000: episode: 4206, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 24.150 [22.000, 55.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.224082, mean_absolute_error: 2.977199, mean_q: 3.859726
684 (array([22]),) False
 168280/500000: episode: 4207, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.625 [21.000, 48.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.197102, mean_absolute_error: 2.900499, mean_q: 3.768882
837 (array([48]),) False
 168320/500000: episode: 4208, duration: 31.867s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 44.950 [1.000, 48.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.204367, mean_absolute_error: 2.900460, mean_q: 3.783818
313 (array([22]),) False
 168360/500000: episode: 4209, duration: 32.191s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.150 [2.000, 52.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.206961, mean_absolute_error: 2.912558, mean_q: 3.801495
794 (array([22]),) False
 168400/500000: episode: 4210, duration: 31.693s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.450 [0.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.191822, mean_absolute_error: 2.929420, mean_q: 3.809434
250 (array([22]),) False
 168440/500000: episode: 4211, duration: 32.553s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 21.900 [8.000, 48.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.219582, mean_absolute_error: 2.882479, mean_q: 3.753417
263 (array([8]),) False
 168480/500000: episode: 4212, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 10.175 [8.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.196959, mean_absolute_error: 2.918994, mean_q: 3.803781
323 (array([55]),) False
 168520/500000: episode: 4213, duration: 33.295s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 33.250 [11.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.221703, mean_absolute_error: 2.890595, mean_q: 3.759132
640 (array([22]),) False
 168560/500000: episode: 4214, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.250 [14.000, 42.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.194126, mean_absolute_error: 2.930667, mean_q: 3.806746
290 (array([22]),) False
 168600/500000: episode: 4215, duration: 33.333s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.400 [9.000, 53.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.203292, mean_absolute_error: 2.885186, mean_q: 3.768169
658 (array([48]),) False
 168640/500000: episode: 4216, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.525 [17.000, 55.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.201472, mean_absolute_error: 2.892757, mean_q: 3.775812
392 (array([40]),) False
 168680/500000: episode: 4217, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.575 [14.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.194995, mean_absolute_error: 2.882087, mean_q: 3.765972
851 (array([48]),) False
 168720/500000: episode: 4218, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 48.250 [48.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.205846, mean_absolute_error: 2.848812, mean_q: 3.727915
60 (array([22]),) False
 168760/500000: episode: 4219, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 27.700 [14.000, 54.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.198454, mean_absolute_error: 2.868174, mean_q: 3.743142
178 (array([38]),) False
 168800/500000: episode: 4220, duration: 32.265s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.825 [8.000, 53.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.189532, mean_absolute_error: 2.880075, mean_q: 3.769978
115 (array([22]),) False
 168840/500000: episode: 4221, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.475 [22.000, 51.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.193110, mean_absolute_error: 2.872651, mean_q: 3.755550
270 (array([3]),) False
 168880/500000: episode: 4222, duration: 32.334s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 10.550 [3.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.203385, mean_absolute_error: 2.861048, mean_q: 3.748976
693 (array([22]),) False
 168920/500000: episode: 4223, duration: 33.323s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.250 [4.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.213814, mean_absolute_error: 2.915979, mean_q: 3.802962
199 (array([22]),) False
 168960/500000: episode: 4224, duration: 32.376s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.675 [4.000, 56.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.197112, mean_absolute_error: 2.851890, mean_q: 3.740355
608 (array([36]),) False
 169000/500000: episode: 4225, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 13.400 [3.000, 41.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.213350, mean_absolute_error: 2.866984, mean_q: 3.756931
587 (array([14]),) False
 169040/500000: episode: 4226, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.175 [0.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.213218, mean_absolute_error: 2.889522, mean_q: 3.779338
483 (array([48]),) False
 169080/500000: episode: 4227, duration: 33.361s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 44.675 [8.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.211337, mean_absolute_error: 2.841198, mean_q: 3.730993
441 (array([22]),) False
 169120/500000: episode: 4228, duration: 33.243s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.350 [9.000, 41.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.202129, mean_absolute_error: 2.895490, mean_q: 3.780803
492 (array([22]),) False
 169160/500000: episode: 4229, duration: 33.214s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.000 [2.000, 56.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.188105, mean_absolute_error: 2.862904, mean_q: 3.743438
13 (array([48]),) False
 169200/500000: episode: 4230, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 25.500 [1.000, 48.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.184474, mean_absolute_error: 2.831029, mean_q: 3.719637
203 (array([48]),) False
 169240/500000: episode: 4231, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.100 [22.000, 48.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.212370, mean_absolute_error: 2.866836, mean_q: 3.737113
401 (array([12]),) False
 169280/500000: episode: 4232, duration: 32.315s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 26.650 [12.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.200469, mean_absolute_error: 2.893562, mean_q: 3.783577
824 (array([22]),) False
 169320/500000: episode: 4233, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.150 [22.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.207024, mean_absolute_error: 2.886237, mean_q: 3.771863
696 (array([36]),) False
 169360/500000: episode: 4234, duration: 32.366s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 35.975 [27.000, 44.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.200936, mean_absolute_error: 2.868453, mean_q: 3.748169
267 (array([22]),) False
 169400/500000: episode: 4235, duration: 32.328s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [15.000, 49.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.214326, mean_absolute_error: 2.898139, mean_q: 3.792001
737 (array([15]),) False
 169440/500000: episode: 4236, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.075 [12.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.205803, mean_absolute_error: 2.877705, mean_q: 3.756927
81 (array([22]),) False
 169480/500000: episode: 4237, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.225 [5.000, 60.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.199244, mean_absolute_error: 2.902692, mean_q: 3.791943
856 (array([48]),) False
 169520/500000: episode: 4238, duration: 33.295s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 47.925 [35.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.208482, mean_absolute_error: 2.873403, mean_q: 3.746179
221 (array([22]),) False
 169560/500000: episode: 4239, duration: 32.341s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.450 [12.000, 58.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.200677, mean_absolute_error: 2.916193, mean_q: 3.801353
85 (array([48]),) False
 169600/500000: episode: 4240, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 26.450 [5.000, 54.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.218718, mean_absolute_error: 2.885738, mean_q: 3.759438
469 (array([22]),) False
 169640/500000: episode: 4241, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.975 [5.000, 36.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.216162, mean_absolute_error: 2.878750, mean_q: 3.744774
474 (array([22]),) False
 169680/500000: episode: 4242, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.075 [12.000, 51.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.213222, mean_absolute_error: 2.901273, mean_q: 3.777643
425 (array([22]),) False
 169720/500000: episode: 4243, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.925 [22.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.193325, mean_absolute_error: 2.915565, mean_q: 3.786067
541 (array([57]),) False
 169760/500000: episode: 4244, duration: 33.253s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 46.025 [0.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.211821, mean_absolute_error: 2.910870, mean_q: 3.772085
554 (array([22]),) False
 169800/500000: episode: 4245, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 20.825 [12.000, 25.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.198236, mean_absolute_error: 2.895008, mean_q: 3.759489
635 (array([22]),) False
 169840/500000: episode: 4246, duration: 33.323s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 32.675 [4.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.204845, mean_absolute_error: 2.886796, mean_q: 3.748963
83 (array([22]),) False
 169880/500000: episode: 4247, duration: 32.365s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.075 [10.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.202627, mean_absolute_error: 2.865841, mean_q: 3.727225
491 (array([22]),) False
 169920/500000: episode: 4248, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.250 [19.000, 48.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.202065, mean_absolute_error: 2.847767, mean_q: 3.718058
698 (array([22]),) False
 169960/500000: episode: 4249, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.500 [12.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.205011, mean_absolute_error: 2.911180, mean_q: 3.784143
340 (array([12]),) False
 170000/500000: episode: 4250, duration: 33.277s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 19.700 [2.000, 44.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.200056, mean_absolute_error: 2.870881, mean_q: 3.753302
342 (array([12]),) False
 170040/500000: episode: 4251, duration: 32.348s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.575 [2.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.211130, mean_absolute_error: 2.871004, mean_q: 3.748088
525 (array([22]),) False
 170080/500000: episode: 4252, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.725 [7.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.197301, mean_absolute_error: 2.860463, mean_q: 3.738945
218 (array([22]),) False
 170120/500000: episode: 4253, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.150 [21.000, 52.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.205819, mean_absolute_error: 2.859466, mean_q: 3.738700
177 (array([22]),) False
 170160/500000: episode: 4254, duration: 33.323s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 18.375 [8.000, 56.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.211088, mean_absolute_error: 2.845646, mean_q: 3.722325
663 (array([22]),) False
 170200/500000: episode: 4255, duration: 32.385s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 20.100 [3.000, 56.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.195291, mean_absolute_error: 2.856964, mean_q: 3.734262
137 (array([22]),) False
 170240/500000: episode: 4256, duration: 33.298s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.325 [22.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.196325, mean_absolute_error: 2.860353, mean_q: 3.744426
779 (array([12]),) False
 170280/500000: episode: 4257, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 13.475 [2.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.207073, mean_absolute_error: 2.798199, mean_q: 3.669645
205 (array([22]),) False
 170320/500000: episode: 4258, duration: 33.294s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.875 [3.000, 42.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.202302, mean_absolute_error: 2.801617, mean_q: 3.670408
666 (array([22]),) False
 170360/500000: episode: 4259, duration: 32.457s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.550 [8.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.212415, mean_absolute_error: 2.809268, mean_q: 3.690581
580 (array([22]),) False
 170400/500000: episode: 4260, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.150 [8.000, 50.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.206853, mean_absolute_error: 2.865695, mean_q: 3.736894
323 (array([55]),) False
 170440/500000: episode: 4261, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 28.825 [9.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.210721, mean_absolute_error: 2.794325, mean_q: 3.666189
199 (array([22]),) False
 170480/500000: episode: 4262, duration: 33.347s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.850 [9.000, 60.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.195920, mean_absolute_error: 2.918410, mean_q: 3.781834
159 (array([48]),) False
 170520/500000: episode: 4263, duration: 32.281s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 32.050 [6.000, 60.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.185843, mean_absolute_error: 2.848024, mean_q: 3.710673
459 (array([22]),) False
 170560/500000: episode: 4264, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.725 [22.000, 53.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.208330, mean_absolute_error: 2.861902, mean_q: 3.738977
451 (array([38]),) False
 170600/500000: episode: 4265, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 22.925 [3.000, 50.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.204403, mean_absolute_error: 2.864323, mean_q: 3.735902
765 (array([48]),) False
 170640/500000: episode: 4266, duration: 33.282s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 46.775 [12.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.214728, mean_absolute_error: 2.879075, mean_q: 3.751995
248 (array([12]),) False
 170680/500000: episode: 4267, duration: 32.273s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 23.550 [8.000, 54.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.205195, mean_absolute_error: 2.849440, mean_q: 3.724935
443 (array([22]),) False
 170720/500000: episode: 4268, duration: 33.261s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.275 [22.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.207264, mean_absolute_error: 2.834176, mean_q: 3.696929
733 (array([22]),) False
 170760/500000: episode: 4269, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.925 [3.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.185292, mean_absolute_error: 2.849139, mean_q: 3.711356
479 (array([22]),) False
 170800/500000: episode: 4270, duration: 33.309s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.825 [0.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.196152, mean_absolute_error: 2.859765, mean_q: 3.731812
9 (array([14]),) False
 170840/500000: episode: 4271, duration: 32.389s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.925 [0.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.206604, mean_absolute_error: 2.852283, mean_q: 3.733632
152 (array([58]),) False
 170880/500000: episode: 4272, duration: 33.263s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 54.150 [3.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.204641, mean_absolute_error: 2.829651, mean_q: 3.697156
603 (array([58]),) False
 170920/500000: episode: 4273, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 53.750 [3.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.205687, mean_absolute_error: 2.824008, mean_q: 3.701552
609 (array([22]),) False
 170960/500000: episode: 4274, duration: 33.322s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.150 [17.000, 44.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.191768, mean_absolute_error: 2.815124, mean_q: 3.702735
39 (array([22]),) False
 171000/500000: episode: 4275, duration: 32.272s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.500 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.205097, mean_absolute_error: 2.807413, mean_q: 3.689263
591 (array([22]),) False
 171040/500000: episode: 4276, duration: 33.311s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.000 [22.000, 56.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.208816, mean_absolute_error: 2.878362, mean_q: 3.766621
661 (array([48]),) False
 171080/500000: episode: 4277, duration: 33.235s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.925 [20.000, 22.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.220636, mean_absolute_error: 2.793529, mean_q: 3.667660
173 (array([3]),) False
 171120/500000: episode: 4278, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 4.525 [3.000, 42.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.209583, mean_absolute_error: 2.808148, mean_q: 3.701941
185 (array([22]),) False
 171160/500000: episode: 4279, duration: 32.374s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.575 [22.000, 49.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.211707, mean_absolute_error: 2.741681, mean_q: 3.623414
480 (array([22]),) False
 171200/500000: episode: 4280, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.200 [3.000, 33.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.200501, mean_absolute_error: 2.799603, mean_q: 3.687418
785 (array([22]),) False
 171240/500000: episode: 4281, duration: 33.287s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.175 [8.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.199737, mean_absolute_error: 2.764892, mean_q: 3.647298
626 (array([22]),) False
 171280/500000: episode: 4282, duration: 33.287s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.425 [15.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.201424, mean_absolute_error: 2.818963, mean_q: 3.711319
430 (array([22]),) False
 171320/500000: episode: 4283, duration: 32.306s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 25.375 [11.000, 59.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.200309, mean_absolute_error: 2.835312, mean_q: 3.717271
239 (array([22]),) False
 171360/500000: episode: 4284, duration: 33.263s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.250 [1.000, 36.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.206585, mean_absolute_error: 2.832722, mean_q: 3.717526
220 (array([22]),) False
 171400/500000: episode: 4285, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 20.375 [0.000, 22.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.190327, mean_absolute_error: 2.823034, mean_q: 3.707088
382 (array([22]),) False
 171440/500000: episode: 4286, duration: 33.328s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.000 [3.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.203054, mean_absolute_error: 2.821513, mean_q: 3.709210
490 (array([12]),) False
 171480/500000: episode: 4287, duration: 32.349s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 13.900 [5.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.205001, mean_absolute_error: 2.825794, mean_q: 3.717219
45 (array([22]),) False
 171520/500000: episode: 4288, duration: 33.282s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.425 [7.000, 45.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.199379, mean_absolute_error: 2.838056, mean_q: 3.727822
580 (array([22]),) False
 171560/500000: episode: 4289, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.300 [22.000, 32.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.211584, mean_absolute_error: 2.774952, mean_q: 3.655014
848 (array([44]),) False
 171600/500000: episode: 4290, duration: 33.310s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 42.400 [17.000, 44.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.193064, mean_absolute_error: 2.801883, mean_q: 3.678481
155 (array([22]),) False
 171640/500000: episode: 4291, duration: 32.370s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.025 [10.000, 29.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.199232, mean_absolute_error: 2.777892, mean_q: 3.637558
7 (array([22]),) False
 171680/500000: episode: 4292, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.750 [2.000, 32.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.193926, mean_absolute_error: 2.829051, mean_q: 3.710636
58 (array([48]),) False
 171720/500000: episode: 4293, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 48.125 [48.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.189341, mean_absolute_error: 2.835199, mean_q: 3.714874
224 (array([12]),) False
 171760/500000: episode: 4294, duration: 33.297s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.650 [12.000, 54.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.199689, mean_absolute_error: 2.792625, mean_q: 3.682571
846 (array([48]),) False
 171800/500000: episode: 4295, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.450 [6.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.207341, mean_absolute_error: 2.803077, mean_q: 3.681229
321 (array([22]),) False
 171840/500000: episode: 4296, duration: 33.297s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.900 [12.000, 52.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.191382, mean_absolute_error: 2.760107, mean_q: 3.639413
851 (array([48]),) False
 171880/500000: episode: 4297, duration: 32.376s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 47.050 [2.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.198781, mean_absolute_error: 2.803524, mean_q: 3.698807
257 (array([22]),) False
 171920/500000: episode: 4298, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.900 [8.000, 28.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.206634, mean_absolute_error: 2.819893, mean_q: 3.712083
11 (array([22]),) False
 171960/500000: episode: 4299, duration: 32.312s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.550 [22.000, 41.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.208269, mean_absolute_error: 2.828010, mean_q: 3.723700
419 (array([40]),) False
 172000/500000: episode: 4300, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.375 [14.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.206479, mean_absolute_error: 2.804281, mean_q: 3.699323
318 (array([48]),) False
 172040/500000: episode: 4301, duration: 32.291s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 46.450 [3.000, 49.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.212339, mean_absolute_error: 2.797049, mean_q: 3.696271
381 (array([22]),) False
 172080/500000: episode: 4302, duration: 33.260s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.125 [9.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.197944, mean_absolute_error: 2.783890, mean_q: 3.672155
309 (array([22]),) False
 172120/500000: episode: 4303, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.175 [7.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.201778, mean_absolute_error: 2.814822, mean_q: 3.711592
304 (array([22]),) False
 172160/500000: episode: 4304, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 29.275 [7.000, 54.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.203696, mean_absolute_error: 2.802366, mean_q: 3.702744
611 (array([22]),) False
 172200/500000: episode: 4305, duration: 32.659s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 28.825 [4.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.203623, mean_absolute_error: 2.847312, mean_q: 3.742630
57 (array([37]),) False
 172240/500000: episode: 4306, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 26.575 [4.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.202863, mean_absolute_error: 2.840000, mean_q: 3.734771
432 (array([22]),) False
 172280/500000: episode: 4307, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.500 [14.000, 52.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.208463, mean_absolute_error: 2.812800, mean_q: 3.698376
449 (array([22]),) False
 172320/500000: episode: 4308, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.675 [2.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.194187, mean_absolute_error: 2.815255, mean_q: 3.709139
423 (array([22]),) False
 172360/500000: episode: 4309, duration: 32.261s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.425 [1.000, 22.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.211495, mean_absolute_error: 2.865351, mean_q: 3.759060
518 (array([22]),) False
 172400/500000: episode: 4310, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.350 [2.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.197530, mean_absolute_error: 2.890244, mean_q: 3.785050
198 (array([22]),) False
 172440/500000: episode: 4311, duration: 32.218s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 25.400 [12.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.196582, mean_absolute_error: 2.829870, mean_q: 3.728489
118 (array([22]),) False
 172480/500000: episode: 4312, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.075 [3.000, 26.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.200277, mean_absolute_error: 2.788267, mean_q: 3.682601
73 (array([22]),) False
 172520/500000: episode: 4313, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.650 [12.000, 54.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.196135, mean_absolute_error: 2.814399, mean_q: 3.700891
701 (array([48]),) False
 172560/500000: episode: 4314, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 44.950 [9.000, 56.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.186855, mean_absolute_error: 2.812402, mean_q: 3.716578
477 (array([22]),) False
 172600/500000: episode: 4315, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.050 [22.000, 44.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.200361, mean_absolute_error: 2.808641, mean_q: 3.720327
538 (array([12]),) False
 172640/500000: episode: 4316, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 21.825 [12.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.202901, mean_absolute_error: 2.813367, mean_q: 3.713518
46 (array([22]),) False
 172680/500000: episode: 4317, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.900 [22.000, 46.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.203986, mean_absolute_error: 2.837760, mean_q: 3.728273
238 (array([22]),) False
 172720/500000: episode: 4318, duration: 33.361s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 18.625 [12.000, 49.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.204704, mean_absolute_error: 2.851569, mean_q: 3.747094
627 (array([48]),) False
 172760/500000: episode: 4319, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 46.575 [18.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.202409, mean_absolute_error: 2.947676, mean_q: 3.857520
644 (array([12]),) False
 172800/500000: episode: 4320, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.375 [3.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.209893, mean_absolute_error: 2.877611, mean_q: 3.764961
730 (array([54]),) False
 172840/500000: episode: 4321, duration: 32.357s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 50.725 [5.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.206968, mean_absolute_error: 2.861428, mean_q: 3.751314
80 (array([42]),) False
 172880/500000: episode: 4322, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 44.725 [5.000, 59.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.214419, mean_absolute_error: 2.832843, mean_q: 3.709823
152 (array([58]),) False
 172920/500000: episode: 4323, duration: 32.245s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 56.475 [24.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.215162, mean_absolute_error: 2.947867, mean_q: 3.837828
415 (array([22]),) False
 172960/500000: episode: 4324, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.425 [0.000, 38.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.215936, mean_absolute_error: 2.901135, mean_q: 3.791515
119 (array([45]),) False
 173000/500000: episode: 4325, duration: 32.389s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 32.150 [3.000, 51.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.214381, mean_absolute_error: 2.862193, mean_q: 3.748271
528 (array([12]),) False
 173040/500000: episode: 4326, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 20.500 [10.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.228373, mean_absolute_error: 2.885948, mean_q: 3.765043
546 (array([22]),) False
 173080/500000: episode: 4327, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.850 [19.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.199565, mean_absolute_error: 2.864851, mean_q: 3.738171
347 (array([22]),) False
 173120/500000: episode: 4328, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 43.575 [29.000, 44.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.227527, mean_absolute_error: 2.845634, mean_q: 3.709922
244 (array([14]),) False
 173160/500000: episode: 4329, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 21.725 [12.000, 53.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.194671, mean_absolute_error: 2.830016, mean_q: 3.700473
520 (array([22]),) False
 173200/500000: episode: 4330, duration: 33.293s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 19.175 [5.000, 30.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.199156, mean_absolute_error: 2.866900, mean_q: 3.745108
643 (array([44]),) False
 173240/500000: episode: 4331, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 42.425 [8.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.196521, mean_absolute_error: 2.841053, mean_q: 3.723354
258 (array([22]),) False
 173280/500000: episode: 4332, duration: 33.254s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.625 [0.000, 56.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.188160, mean_absolute_error: 2.839880, mean_q: 3.722687
95 (array([22]),) False
 173320/500000: episode: 4333, duration: 32.338s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 27.250 [22.000, 50.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.181453, mean_absolute_error: 2.848536, mean_q: 3.727151
521 (array([22]),) False
 173360/500000: episode: 4334, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.325 [12.000, 55.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.204137, mean_absolute_error: 2.847697, mean_q: 3.722526
481 (array([22]),) False
 173400/500000: episode: 4335, duration: 32.316s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.050 [22.000, 42.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.212826, mean_absolute_error: 2.858036, mean_q: 3.737738
540 (array([22]),) False
 173440/500000: episode: 4336, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.875 [19.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.214716, mean_absolute_error: 2.834549, mean_q: 3.715203
609 (array([22]),) False
 173480/500000: episode: 4337, duration: 32.294s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.925 [19.000, 22.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.190869, mean_absolute_error: 2.812459, mean_q: 3.686314
861 (array([22]),) False
 173520/500000: episode: 4338, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 27.025 [13.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.211933, mean_absolute_error: 2.870533, mean_q: 3.757392
530 (array([22]),) False
 173560/500000: episode: 4339, duration: 33.257s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.825 [15.000, 22.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.224743, mean_absolute_error: 2.871912, mean_q: 3.756474
853 (array([22]),) False
 173600/500000: episode: 4340, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.275 [1.000, 49.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.202911, mean_absolute_error: 2.864616, mean_q: 3.749416
168 (array([22]),) False
 173640/500000: episode: 4341, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 14.750 [0.000, 45.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.196511, mean_absolute_error: 2.848336, mean_q: 3.721223
195 (array([22]),) False
 173680/500000: episode: 4342, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.425 [12.000, 42.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.202035, mean_absolute_error: 2.880280, mean_q: 3.757339
68 (array([22]),) False
 173720/500000: episode: 4343, duration: 33.246s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.525 [22.000, 53.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.194059, mean_absolute_error: 2.871454, mean_q: 3.763917
622 (array([36]),) False
 173760/500000: episode: 4344, duration: 33.298s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 35.050 [1.000, 52.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.209347, mean_absolute_error: 2.809503, mean_q: 3.695004
480 (array([22]),) False
 173800/500000: episode: 4345, duration: 32.421s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.150 [22.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.202701, mean_absolute_error: 2.830743, mean_q: 3.722630
233 (array([54]),) False
 173840/500000: episode: 4346, duration: 33.303s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 26.450 [4.000, 60.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.204280, mean_absolute_error: 2.832011, mean_q: 3.709328
165 (array([34]),) False
 173880/500000: episode: 4347, duration: 32.332s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 19.600 [3.000, 52.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.201460, mean_absolute_error: 2.793271, mean_q: 3.672950
88 (array([22]),) False
 173920/500000: episode: 4348, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.425 [2.000, 22.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.215051, mean_absolute_error: 2.827678, mean_q: 3.707413
385 (array([30]),) False
 173960/500000: episode: 4349, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.075 [8.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.199039, mean_absolute_error: 2.836034, mean_q: 3.725932
699 (array([22]),) False
 174000/500000: episode: 4350, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [0.000, 57.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.205527, mean_absolute_error: 2.780509, mean_q: 3.665654
657 (array([48]),) False
 174040/500000: episode: 4351, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 46.550 [5.000, 52.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.203134, mean_absolute_error: 2.846237, mean_q: 3.747032
53 (array([22]),) False
 174080/500000: episode: 4352, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.225 [22.000, 51.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.203855, mean_absolute_error: 2.838988, mean_q: 3.740980
276 (array([56]),) False
 174120/500000: episode: 4353, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.525 [3.000, 58.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.214134, mean_absolute_error: 2.841244, mean_q: 3.738260
457 (array([38]),) False
 174160/500000: episode: 4354, duration: 33.254s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.250 [1.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.218387, mean_absolute_error: 2.808357, mean_q: 3.703767
143 (array([12]),) False
 174200/500000: episode: 4355, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 17.600 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.203003, mean_absolute_error: 2.785618, mean_q: 3.664211
121 (array([22]),) False
 174240/500000: episode: 4356, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 18.150 [12.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.206864, mean_absolute_error: 2.830035, mean_q: 3.724718
488 (array([22]),) False
 174280/500000: episode: 4357, duration: 32.370s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.350 [1.000, 56.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.214088, mean_absolute_error: 2.838543, mean_q: 3.732880
566 (array([12]),) False
 174320/500000: episode: 4358, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 26.400 [19.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.203093, mean_absolute_error: 2.823123, mean_q: 3.722245
490 (array([12]),) False
 174360/500000: episode: 4359, duration: 32.377s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 14.250 [2.000, 53.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.196303, mean_absolute_error: 2.797941, mean_q: 3.681170
393 (array([22]),) False
 174400/500000: episode: 4360, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.825 [22.000, 39.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.217382, mean_absolute_error: 2.835763, mean_q: 3.741143
586 (array([12]),) False
 174440/500000: episode: 4361, duration: 32.326s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 18.700 [12.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.208596, mean_absolute_error: 2.780284, mean_q: 3.674926
304 (array([22]),) False
 174480/500000: episode: 4362, duration: 33.251s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 31.850 [12.000, 48.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.208360, mean_absolute_error: 2.787654, mean_q: 3.679827
833 (array([22]),) False
 174520/500000: episode: 4363, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.725 [10.000, 32.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.197510, mean_absolute_error: 2.827549, mean_q: 3.724688
631 (array([22]),) False
 174560/500000: episode: 4364, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.200 [22.000, 54.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.198214, mean_absolute_error: 2.870455, mean_q: 3.776578
136 (array([12]),) False
 174600/500000: episode: 4365, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 40.300 [12.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.188579, mean_absolute_error: 2.850780, mean_q: 3.755387
650 (array([22]),) False
 174640/500000: episode: 4366, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.400 [20.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.202901, mean_absolute_error: 2.830151, mean_q: 3.741093
598 (array([22]),) False
 174680/500000: episode: 4367, duration: 32.907s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 24.125 [7.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.196961, mean_absolute_error: 2.832810, mean_q: 3.745471
345 (array([22]),) False
 174720/500000: episode: 4368, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.125 [3.000, 52.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.215371, mean_absolute_error: 2.817529, mean_q: 3.724387
84 (array([22]),) False
 174760/500000: episode: 4369, duration: 32.387s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [22.000, 35.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.206144, mean_absolute_error: 2.785537, mean_q: 3.678978
693 (array([22]),) False
 174800/500000: episode: 4370, duration: 33.246s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.125 [18.000, 27.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.209998, mean_absolute_error: 2.841547, mean_q: 3.750891
267 (array([22]),) False
 174840/500000: episode: 4371, duration: 32.418s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.275 [0.000, 35.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.209100, mean_absolute_error: 2.827670, mean_q: 3.724487
628 (array([22]),) False
 174880/500000: episode: 4372, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.175 [22.000, 51.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.207904, mean_absolute_error: 2.806313, mean_q: 3.694089
410 (array([22]),) False
 174920/500000: episode: 4373, duration: 32.314s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.300 [2.000, 22.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.214519, mean_absolute_error: 2.866505, mean_q: 3.745974
813 (array([22]),) False
 174960/500000: episode: 4374, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 34.225 [10.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.196114, mean_absolute_error: 2.850329, mean_q: 3.725865
196 (array([22]),) False
 175000/500000: episode: 4375, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.800 [2.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.206184, mean_absolute_error: 2.835615, mean_q: 3.701601
754 (array([52]),) False
 175040/500000: episode: 4376, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.550 [1.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.197594, mean_absolute_error: 2.843808, mean_q: 3.727153
673 (array([3]),) False
 175080/500000: episode: 4377, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 6.000 [3.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.197460, mean_absolute_error: 2.877867, mean_q: 3.773142
328 (array([12]),) False
 175120/500000: episode: 4378, duration: 33.323s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 14.675 [10.000, 55.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.195236, mean_absolute_error: 2.881543, mean_q: 3.770512
181 (array([22]),) False
 175160/500000: episode: 4379, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.250 [4.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.189297, mean_absolute_error: 2.890257, mean_q: 3.786391
270 (array([3]),) False
 175200/500000: episode: 4380, duration: 33.284s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 9.100 [3.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.198669, mean_absolute_error: 2.850272, mean_q: 3.728791
371 (array([14]),) False
 175240/500000: episode: 4381, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.525 [4.000, 48.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.193512, mean_absolute_error: 2.820052, mean_q: 3.687713
320 (array([22]),) False
 175280/500000: episode: 4382, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.400 [12.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.197362, mean_absolute_error: 2.891898, mean_q: 3.771101
333 (array([12]),) False
 175320/500000: episode: 4383, duration: 32.297s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 18.025 [12.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.196300, mean_absolute_error: 2.883235, mean_q: 3.755365
318 (array([48]),) False
 175360/500000: episode: 4384, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 44.150 [8.000, 54.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.196869, mean_absolute_error: 2.889478, mean_q: 3.769527
197 (array([22]),) False
 175400/500000: episode: 4385, duration: 32.305s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.175 [4.000, 35.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.181806, mean_absolute_error: 2.873917, mean_q: 3.754117
367 (array([12]),) False
 175440/500000: episode: 4386, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 30.150 [2.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.195970, mean_absolute_error: 2.883355, mean_q: 3.753756
344 (array([22]),) False
 175480/500000: episode: 4387, duration: 33.259s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.825 [5.000, 44.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.197894, mean_absolute_error: 2.871537, mean_q: 3.743581
789 (array([22]),) False
 175520/500000: episode: 4388, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.775 [1.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.208058, mean_absolute_error: 2.864454, mean_q: 3.735824
238 (array([22]),) False
 175560/500000: episode: 4389, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.075 [9.000, 52.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.213381, mean_absolute_error: 2.853591, mean_q: 3.729731
792 (array([58]),) False
 175600/500000: episode: 4390, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 41.850 [3.000, 58.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.196603, mean_absolute_error: 2.827236, mean_q: 3.706677
518 (array([22]),) False
 175640/500000: episode: 4391, duration: 33.240s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.925 [22.000, 49.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.199044, mean_absolute_error: 2.845086, mean_q: 3.708287
534 (array([22]),) False
 175680/500000: episode: 4392, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.725 [22.000, 44.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.212316, mean_absolute_error: 2.810534, mean_q: 3.678564
755 (array([22]),) False
 175720/500000: episode: 4393, duration: 32.391s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.450 [22.000, 51.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.214356, mean_absolute_error: 2.854556, mean_q: 3.739609
631 (array([22]),) False
 175760/500000: episode: 4394, duration: 33.289s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.425 [6.000, 42.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.202555, mean_absolute_error: 2.837979, mean_q: 3.714623
545 (array([22]),) False
 175800/500000: episode: 4395, duration: 32.335s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.900 [4.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.201364, mean_absolute_error: 2.853180, mean_q: 3.740346
625 (array([22]),) False
 175840/500000: episode: 4396, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.625 [18.000, 51.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.208185, mean_absolute_error: 2.861106, mean_q: 3.742033
550 (array([12]),) False
 175880/500000: episode: 4397, duration: 32.375s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 13.500 [8.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.198293, mean_absolute_error: 2.841080, mean_q: 3.722689
382 (array([22]),) False
 175920/500000: episode: 4398, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.125 [22.000, 37.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.194004, mean_absolute_error: 2.852489, mean_q: 3.741971
672 (array([44]),) False
 175960/500000: episode: 4399, duration: 33.286s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 50.750 [9.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.203256, mean_absolute_error: 2.887815, mean_q: 3.783822
341 (array([22]),) False
 176000/500000: episode: 4400, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.800 [6.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.207804, mean_absolute_error: 2.873851, mean_q: 3.762979
128 (array([22]),) False
 176040/500000: episode: 4401, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.575 [20.000, 47.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.199237, mean_absolute_error: 2.906860, mean_q: 3.804408
424 (array([22]),) False
 176080/500000: episode: 4402, duration: 33.312s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.950 [22.000, 47.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.197520, mean_absolute_error: 2.885411, mean_q: 3.778408
465 (array([48]),) False
 176120/500000: episode: 4403, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 47.125 [13.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.208911, mean_absolute_error: 2.833464, mean_q: 3.723135
169 (array([22]),) False
 176160/500000: episode: 4404, duration: 33.169s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.000 [12.000, 44.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.195840, mean_absolute_error: 2.820686, mean_q: 3.702995
179 (array([18]),) False
 176200/500000: episode: 4405, duration: 32.304s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 25.450 [9.000, 59.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.206460, mean_absolute_error: 2.885970, mean_q: 3.781904
196 (array([22]),) False
 176240/500000: episode: 4406, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.900 [22.000, 43.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.189847, mean_absolute_error: 2.868538, mean_q: 3.768948
650 (array([22]),) False
 176280/500000: episode: 4407, duration: 32.350s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.850 [4.000, 47.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.198867, mean_absolute_error: 2.896530, mean_q: 3.798730
570 (array([47]),) False
 176320/500000: episode: 4408, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.000 [5.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.197897, mean_absolute_error: 2.891926, mean_q: 3.787280
750 (array([22]),) False
 176360/500000: episode: 4409, duration: 32.316s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.800 [5.000, 32.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.197559, mean_absolute_error: 2.882800, mean_q: 3.781599
475 (array([22]),) False
 176400/500000: episode: 4410, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 21.100 [9.000, 44.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.182180, mean_absolute_error: 2.798935, mean_q: 3.681802
828 (array([48]),) False
 176440/500000: episode: 4411, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 47.275 [29.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.195507, mean_absolute_error: 2.854751, mean_q: 3.741745
169 (array([22]),) False
 176480/500000: episode: 4412, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.600 [3.000, 44.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.194023, mean_absolute_error: 2.887635, mean_q: 3.771461
759 (array([48]),) False
 176520/500000: episode: 4413, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 45.775 [8.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.192342, mean_absolute_error: 2.880425, mean_q: 3.789515
196 (array([22]),) False
 176560/500000: episode: 4414, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.100 [0.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.205103, mean_absolute_error: 2.865437, mean_q: 3.759399
376 (array([22]),) False
 176600/500000: episode: 4415, duration: 33.202s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 44.800 [17.000, 48.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.204896, mean_absolute_error: 2.854773, mean_q: 3.746006
132 (array([22]),) False
 176640/500000: episode: 4416, duration: 33.257s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.575 [1.000, 37.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.191181, mean_absolute_error: 2.884037, mean_q: 3.772120
733 (array([22]),) False
 176680/500000: episode: 4417, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.197615, mean_absolute_error: 2.900541, mean_q: 3.785299
292 (array([22]),) False
 176720/500000: episode: 4418, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 25.675 [22.000, 32.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.199316, mean_absolute_error: 2.886764, mean_q: 3.774113
97 (array([22]),) False
 176760/500000: episode: 4419, duration: 32.378s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.225 [22.000, 46.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.201181, mean_absolute_error: 2.888956, mean_q: 3.782220
335 (array([22]),) False
 176800/500000: episode: 4420, duration: 33.254s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.500 [13.000, 36.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.198408, mean_absolute_error: 2.887075, mean_q: 3.780712
607 (array([12]),) False
 176840/500000: episode: 4421, duration: 32.263s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 25.725 [12.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.200753, mean_absolute_error: 2.891175, mean_q: 3.786913
179 (array([18]),) False
 176880/500000: episode: 4422, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 22.925 [4.000, 51.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.198671, mean_absolute_error: 2.865231, mean_q: 3.769804
636 (array([12]),) False
 176920/500000: episode: 4423, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 42.850 [1.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.210204, mean_absolute_error: 2.863153, mean_q: 3.764300
859 (array([22]),) False
 176960/500000: episode: 4424, duration: 33.276s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.650 [1.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.233686, mean_absolute_error: 2.846158, mean_q: 3.744384
475 (array([22]),) False
 177000/500000: episode: 4425, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.675 [12.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.198788, mean_absolute_error: 2.849330, mean_q: 3.756899
405 (array([22]),) False
 177040/500000: episode: 4426, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.425 [6.000, 54.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.201238, mean_absolute_error: 2.903661, mean_q: 3.805937
287 (array([48]),) False
 177080/500000: episode: 4427, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 31.425 [3.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.212958, mean_absolute_error: 2.920104, mean_q: 3.836372
856 (array([48]),) False
 177120/500000: episode: 4428, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.600 [16.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.188039, mean_absolute_error: 2.885482, mean_q: 3.793675
859 (array([22]),) False
 177160/500000: episode: 4429, duration: 32.374s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.175 [2.000, 52.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.213146, mean_absolute_error: 2.910681, mean_q: 3.809594
827 (array([14]),) False
 177200/500000: episode: 4430, duration: 33.278s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.675 [9.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.194698, mean_absolute_error: 2.897026, mean_q: 3.805311
164 (array([22]),) False
 177240/500000: episode: 4431, duration: 32.394s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.205153, mean_absolute_error: 2.850494, mean_q: 3.764108
529 (array([3]),) False
 177280/500000: episode: 4432, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 4.925 [3.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.194709, mean_absolute_error: 2.892364, mean_q: 3.810603
454 (array([12]),) False
 177320/500000: episode: 4433, duration: 32.332s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 44.050 [0.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.205287, mean_absolute_error: 2.884079, mean_q: 3.782016
858 (array([12]),) False
 177360/500000: episode: 4434, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 13.200 [12.000, 56.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.189117, mean_absolute_error: 2.926361, mean_q: 3.836047
177 (array([22]),) False
 177400/500000: episode: 4435, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.350 [2.000, 57.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.203630, mean_absolute_error: 2.879721, mean_q: 3.798663
481 (array([22]),) False
 177440/500000: episode: 4436, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.350 [5.000, 44.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.205737, mean_absolute_error: 2.911055, mean_q: 3.829051
95 (array([22]),) False
 177480/500000: episode: 4437, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.525 [5.000, 27.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.197198, mean_absolute_error: 2.891454, mean_q: 3.795560
687 (array([44]),) False
 177520/500000: episode: 4438, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 41.050 [14.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.207212, mean_absolute_error: 2.872765, mean_q: 3.776505
701 (array([48]),) False
 177560/500000: episode: 4439, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 44.675 [0.000, 58.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.191649, mean_absolute_error: 2.870647, mean_q: 3.771548
465 (array([48]),) False
 177600/500000: episode: 4440, duration: 33.278s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 47.950 [46.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.203064, mean_absolute_error: 2.880427, mean_q: 3.781532
306 (array([22]),) False
 177640/500000: episode: 4441, duration: 32.331s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [8.000, 44.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.204678, mean_absolute_error: 2.901434, mean_q: 3.798802
195 (array([22]),) False
 177680/500000: episode: 4442, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.350 [9.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.214207, mean_absolute_error: 2.913223, mean_q: 3.827621
303 (array([22]),) False
 177720/500000: episode: 4443, duration: 32.315s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.575 [4.000, 23.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.204906, mean_absolute_error: 2.886747, mean_q: 3.788719
570 (array([47]),) False
 177760/500000: episode: 4444, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.200 [7.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.204110, mean_absolute_error: 2.869143, mean_q: 3.774649
554 (array([22]),) False
 177800/500000: episode: 4445, duration: 32.299s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.550 [0.000, 51.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.217023, mean_absolute_error: 2.926051, mean_q: 3.844638
520 (array([22]),) False
 177840/500000: episode: 4446, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.300 [13.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.198541, mean_absolute_error: 2.899491, mean_q: 3.815647
71 (array([58]),) False
 177880/500000: episode: 4447, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 40.925 [7.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.207532, mean_absolute_error: 2.884108, mean_q: 3.793244
499 (array([8]),) False
 177920/500000: episode: 4448, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.700 [1.000, 49.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.207165, mean_absolute_error: 2.865925, mean_q: 3.770069
685 (array([22]),) False
 177960/500000: episode: 4449, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.675 [8.000, 40.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.215992, mean_absolute_error: 2.949636, mean_q: 3.855458
249 (array([22]),) False
 178000/500000: episode: 4450, duration: 33.264s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.200 [15.000, 52.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.216633, mean_absolute_error: 2.933963, mean_q: 3.838886
577 (array([12]),) False
 178040/500000: episode: 4451, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.025 [12.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.215845, mean_absolute_error: 2.984512, mean_q: 3.902921
769 (array([12]),) False
 178080/500000: episode: 4452, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 33.200 [12.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.199517, mean_absolute_error: 2.969782, mean_q: 3.892564
91 (array([48]),) False
 178120/500000: episode: 4453, duration: 32.369s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 47.225 [27.000, 48.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.202728, mean_absolute_error: 2.937272, mean_q: 3.851613
805 (array([22]),) False
 178160/500000: episode: 4454, duration: 33.302s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.975 [6.000, 57.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.200472, mean_absolute_error: 2.865273, mean_q: 3.777322
790 (array([48]),) False
 178200/500000: episode: 4455, duration: 32.282s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 46.900 [8.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.203520, mean_absolute_error: 2.980387, mean_q: 3.898005
123 (array([22]),) False
 178240/500000: episode: 4456, duration: 33.244s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.525 [1.000, 55.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.208313, mean_absolute_error: 2.884892, mean_q: 3.781785
549 (array([22]),) False
 178280/500000: episode: 4457, duration: 32.357s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.400 [6.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.201018, mean_absolute_error: 2.937703, mean_q: 3.837557
63 (array([18]),) False
 178320/500000: episode: 4458, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 18.150 [12.000, 42.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.206657, mean_absolute_error: 2.968510, mean_q: 3.873147
72 (array([12]),) False
 178360/500000: episode: 4459, duration: 33.231s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 17.025 [12.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.216387, mean_absolute_error: 2.952996, mean_q: 3.857950
718 (array([12]),) False
 178400/500000: episode: 4460, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 15.275 [6.000, 41.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.216536, mean_absolute_error: 2.929782, mean_q: 3.836535
483 (array([48]),) False
 178440/500000: episode: 4461, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 47.050 [12.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.239398, mean_absolute_error: 2.917201, mean_q: 3.816685
255 (array([12]),) False
 178480/500000: episode: 4462, duration: 33.349s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.400 [7.000, 45.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.197819, mean_absolute_error: 2.910957, mean_q: 3.823480
442 (array([22]),) False
 178520/500000: episode: 4463, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.550 [5.000, 31.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.201728, mean_absolute_error: 2.931743, mean_q: 3.835124
707 (array([48]),) False
 178560/500000: episode: 4464, duration: 33.257s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.100 [13.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.196669, mean_absolute_error: 2.929351, mean_q: 3.831825
405 (array([22]),) False
 178600/500000: episode: 4465, duration: 32.363s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.300 [0.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.200262, mean_absolute_error: 2.894585, mean_q: 3.782892
672 (array([44]),) False
 178640/500000: episode: 4466, duration: 33.254s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 48.725 [15.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.210626, mean_absolute_error: 2.868702, mean_q: 3.763397
171 (array([22]),) False
 178680/500000: episode: 4467, duration: 32.283s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.800 [22.000, 54.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.204471, mean_absolute_error: 2.947170, mean_q: 3.835092
492 (array([22]),) False
 178720/500000: episode: 4468, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.125 [4.000, 48.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.231776, mean_absolute_error: 2.938687, mean_q: 3.840095
226 (array([22]),) False
 178760/500000: episode: 4469, duration: 32.283s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.225 [2.000, 36.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.223041, mean_absolute_error: 2.939812, mean_q: 3.830455
104 (array([22]),) False
 178800/500000: episode: 4470, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.325 [17.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.205119, mean_absolute_error: 2.962343, mean_q: 3.858257
416 (array([22]),) False
 178840/500000: episode: 4471, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.075 [5.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.214786, mean_absolute_error: 2.943805, mean_q: 3.843205
112 (array([12]),) False
 178880/500000: episode: 4472, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 13.500 [4.000, 50.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.199841, mean_absolute_error: 2.912070, mean_q: 3.810899
838 (array([21]),) False
 178920/500000: episode: 4473, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 25.325 [7.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.203683, mean_absolute_error: 2.927543, mean_q: 3.827120
460 (array([36]),) False
 178960/500000: episode: 4474, duration: 33.334s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.525 [9.000, 44.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.204146, mean_absolute_error: 2.945594, mean_q: 3.853091
239 (array([22]),) False
 179000/500000: episode: 4475, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.275 [0.000, 39.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.210758, mean_absolute_error: 2.931868, mean_q: 3.830456
624 (array([48]),) False
 179040/500000: episode: 4476, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.200 [11.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.198954, mean_absolute_error: 2.919720, mean_q: 3.827713
556 (array([48]),) False
 179080/500000: episode: 4477, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.850 [0.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.224768, mean_absolute_error: 2.966609, mean_q: 3.883556
596 (array([22]),) False
 179120/500000: episode: 4478, duration: 33.289s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.525 [22.000, 53.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.203048, mean_absolute_error: 2.951131, mean_q: 3.867106
208 (array([22]),) False
 179160/500000: episode: 4479, duration: 32.333s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 23.875 [15.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.209453, mean_absolute_error: 2.928322, mean_q: 3.832317
208 (array([22]),) False
 179200/500000: episode: 4480, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 24.875 [22.000, 54.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.212061, mean_absolute_error: 2.947995, mean_q: 3.863963
122 (array([12]),) False
 179240/500000: episode: 4481, duration: 32.309s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 20.900 [2.000, 58.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.208303, mean_absolute_error: 2.967404, mean_q: 3.884547
75 (array([22]),) False
 179280/500000: episode: 4482, duration: 33.309s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.925 [1.000, 48.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.219370, mean_absolute_error: 2.879041, mean_q: 3.791313
772 (array([46]),) False
 179320/500000: episode: 4483, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 30.700 [8.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.207693, mean_absolute_error: 2.950134, mean_q: 3.865031
656 (array([48]),) False
 179360/500000: episode: 4484, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 44.175 [6.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.211792, mean_absolute_error: 2.984991, mean_q: 3.891552
19 (array([12]),) False
 179400/500000: episode: 4485, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.175 [7.000, 47.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.193644, mean_absolute_error: 2.907155, mean_q: 3.811065
353 (array([22]),) False
 179440/500000: episode: 4486, duration: 33.245s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.575 [12.000, 55.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.201144, mean_absolute_error: 2.941043, mean_q: 3.836944
391 (array([22]),) False
 179480/500000: episode: 4487, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [10.000, 55.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.188984, mean_absolute_error: 2.957197, mean_q: 3.853249
782 (array([22]),) False
 179520/500000: episode: 4488, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.000 [2.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.198433, mean_absolute_error: 2.994826, mean_q: 3.895564
332 (array([22]),) False
 179560/500000: episode: 4489, duration: 32.303s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 29.950 [3.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.210001, mean_absolute_error: 2.944742, mean_q: 3.848326
300 (array([22]),) False
 179600/500000: episode: 4490, duration: 33.288s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 19.775 [4.000, 37.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.199404, mean_absolute_error: 2.950506, mean_q: 3.856784
540 (array([22]),) False
 179640/500000: episode: 4491, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.600 [0.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.205271, mean_absolute_error: 2.961953, mean_q: 3.866486
105 (array([22]),) False
 179680/500000: episode: 4492, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.650 [5.000, 54.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.212532, mean_absolute_error: 2.946611, mean_q: 3.844400
62 (array([22]),) False
 179720/500000: episode: 4493, duration: 32.299s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.275 [15.000, 57.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.211193, mean_absolute_error: 2.940142, mean_q: 3.841529
739 (array([22]),) False
 179760/500000: episode: 4494, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 20.950 [4.000, 43.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.215947, mean_absolute_error: 2.969758, mean_q: 3.876213
782 (array([22]),) False
 179800/500000: episode: 4495, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.725 [7.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.191978, mean_absolute_error: 2.941563, mean_q: 3.861412
531 (array([22]),) False
 179840/500000: episode: 4496, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.375 [9.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.199647, mean_absolute_error: 2.937605, mean_q: 3.840427
558 (array([40]),) False
 179880/500000: episode: 4497, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 17.125 [12.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.226984, mean_absolute_error: 2.932183, mean_q: 3.843771
711 (array([22]),) False
 179920/500000: episode: 4498, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.225 [16.000, 37.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.194021, mean_absolute_error: 2.929975, mean_q: 3.843974
178 (array([38]),) False
 179960/500000: episode: 4499, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.700 [9.000, 40.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.197671, mean_absolute_error: 2.966342, mean_q: 3.869294
268 (array([22]),) False
 180000/500000: episode: 4500, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.775 [9.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.207386, mean_absolute_error: 2.982215, mean_q: 3.888134
136 (array([12]),) False
 180040/500000: episode: 4501, duration: 32.349s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 20.375 [1.000, 22.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.204831, mean_absolute_error: 3.012780, mean_q: 3.917700
356 (array([22]),) False
 180080/500000: episode: 4502, duration: 33.272s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.275 [3.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.191264, mean_absolute_error: 2.983542, mean_q: 3.883135
511 (array([22]),) False
 180120/500000: episode: 4503, duration: 32.245s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.825 [4.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.220758, mean_absolute_error: 2.990063, mean_q: 3.896263
702 (array([22]),) False
 180160/500000: episode: 4504, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.575 [4.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.211562, mean_absolute_error: 2.943804, mean_q: 3.845064
498 (array([12]),) False
 180200/500000: episode: 4505, duration: 32.284s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.375 [22.000, 46.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.198590, mean_absolute_error: 2.986188, mean_q: 3.891735
830 (array([22]),) False
 180240/500000: episode: 4506, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.550 [22.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.189775, mean_absolute_error: 2.963178, mean_q: 3.868889
360 (array([22]),) False
 180280/500000: episode: 4507, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 21.600 [2.000, 44.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.202425, mean_absolute_error: 2.924247, mean_q: 3.824513
566 (array([12]),) False
 180320/500000: episode: 4508, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 24.925 [12.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.205448, mean_absolute_error: 2.956198, mean_q: 3.872781
284 (array([12]),) False
 180360/500000: episode: 4509, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.925 [0.000, 58.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.205764, mean_absolute_error: 2.939874, mean_q: 3.860930
739 (array([22]),) False
 180400/500000: episode: 4510, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.475 [12.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.201405, mean_absolute_error: 2.921782, mean_q: 3.832281
386 (array([12]),) False
 180440/500000: episode: 4511, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.700 [16.000, 37.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.197916, mean_absolute_error: 2.964224, mean_q: 3.885646
13 (array([48]),) False
 180480/500000: episode: 4512, duration: 33.285s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 39.825 [4.000, 50.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.191228, mean_absolute_error: 2.988949, mean_q: 3.892818
687 (array([44]),) False
 180520/500000: episode: 4513, duration: 32.325s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 41.100 [4.000, 44.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.202003, mean_absolute_error: 2.978230, mean_q: 3.879503
398 (array([22]),) False
 180560/500000: episode: 4514, duration: 33.294s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.625 [0.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.199790, mean_absolute_error: 2.930436, mean_q: 3.833541
270 (array([3]),) False
 180600/500000: episode: 4515, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 10.150 [1.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.207887, mean_absolute_error: 2.941714, mean_q: 3.845240
157 (array([48]),) False
 180640/500000: episode: 4516, duration: 33.214s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 48.000 [48.000, 48.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.200631, mean_absolute_error: 2.976110, mean_q: 3.884525
188 (array([22]),) False
 180680/500000: episode: 4517, duration: 32.331s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.400 [7.000, 25.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.205840, mean_absolute_error: 2.959665, mean_q: 3.859887
639 (array([22]),) False
 180720/500000: episode: 4518, duration: 33.242s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.650 [22.000, 37.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.210809, mean_absolute_error: 3.007536, mean_q: 3.904292
176 (array([3]),) False
 180760/500000: episode: 4519, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 13.625 [12.000, 58.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.213598, mean_absolute_error: 2.970466, mean_q: 3.864745
325 (array([22]),) False
 180800/500000: episode: 4520, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.150 [17.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.207366, mean_absolute_error: 2.926430, mean_q: 3.818429
493 (array([22]),) False
 180840/500000: episode: 4521, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.575 [22.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.227458, mean_absolute_error: 2.908094, mean_q: 3.798678
495 (array([48]),) False
 180880/500000: episode: 4522, duration: 33.214s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.725 [1.000, 48.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.205869, mean_absolute_error: 2.880992, mean_q: 3.766716
461 (array([22]),) False
 180920/500000: episode: 4523, duration: 32.260s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.200 [9.000, 42.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.199066, mean_absolute_error: 2.947714, mean_q: 3.837868
431 (array([22]),) False
 180960/500000: episode: 4524, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.450 [22.000, 38.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.201242, mean_absolute_error: 2.898907, mean_q: 3.779809
850 (array([12]),) False
 181000/500000: episode: 4525, duration: 32.328s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 26.975 [8.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.199836, mean_absolute_error: 2.974647, mean_q: 3.870107
5 (array([37]),) False
 181040/500000: episode: 4526, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 57.600 [49.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.213676, mean_absolute_error: 2.961399, mean_q: 3.851122
841 (array([21]),) False
 181080/500000: episode: 4527, duration: 32.300s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.825 [0.000, 45.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.208308, mean_absolute_error: 2.972060, mean_q: 3.870814
722 (array([22]),) False
 181120/500000: episode: 4528, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.225 [20.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.194000, mean_absolute_error: 2.940326, mean_q: 3.841283
604 (array([40]),) False
 181160/500000: episode: 4529, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.300 [1.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.193142, mean_absolute_error: 2.928915, mean_q: 3.824368
724 (array([58]),) False
 181200/500000: episode: 4530, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 58.025 [58.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.210847, mean_absolute_error: 2.925051, mean_q: 3.817395
693 (array([22]),) False
 181240/500000: episode: 4531, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 20.950 [10.000, 22.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.213329, mean_absolute_error: 2.937432, mean_q: 3.840386
787 (array([3]),) False
 181280/500000: episode: 4532, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 21.425 [1.000, 43.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.223992, mean_absolute_error: 3.025889, mean_q: 3.932853
433 (array([22]),) False
 181320/500000: episode: 4533, duration: 33.392s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.525 [18.000, 49.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.211964, mean_absolute_error: 2.956701, mean_q: 3.861744
3 (array([48]),) False
 181360/500000: episode: 4534, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 22.675 [2.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.209072, mean_absolute_error: 2.924035, mean_q: 3.834251
74 (array([22]),) False
 181400/500000: episode: 4535, duration: 32.310s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.650 [10.000, 53.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.216571, mean_absolute_error: 2.997954, mean_q: 3.910219
541 (array([57]),) False
 181440/500000: episode: 4536, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 28.275 [1.000, 56.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.210861, mean_absolute_error: 3.001172, mean_q: 3.918900
641 (array([22]),) False
 181480/500000: episode: 4537, duration: 32.271s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.550 [9.000, 41.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.220716, mean_absolute_error: 2.895607, mean_q: 3.795319
759 (array([48]),) False
 181520/500000: episode: 4538, duration: 33.307s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 45.650 [10.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.197413, mean_absolute_error: 2.952588, mean_q: 3.863761
795 (array([3]),) False
 181560/500000: episode: 4539, duration: 32.298s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 8.125 [3.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.201053, mean_absolute_error: 2.935474, mean_q: 3.849948
604 (array([40]),) False
 181600/500000: episode: 4540, duration: 33.304s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.075 [12.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.211198, mean_absolute_error: 2.977037, mean_q: 3.881647
748 (array([22]),) False
 181640/500000: episode: 4541, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.200 [2.000, 49.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.213857, mean_absolute_error: 2.946248, mean_q: 3.850577
373 (array([22]),) False
 181680/500000: episode: 4542, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.950 [1.000, 37.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.219895, mean_absolute_error: 2.963089, mean_q: 3.860273
106 (array([22]),) False
 181720/500000: episode: 4543, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.100 [0.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.197293, mean_absolute_error: 3.025998, mean_q: 3.946055
593 (array([37]),) False
 181760/500000: episode: 4544, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.575 [6.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.198433, mean_absolute_error: 2.949784, mean_q: 3.849193
753 (array([22]),) False
 181800/500000: episode: 4545, duration: 33.261s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 23.475 [12.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.196416, mean_absolute_error: 3.017304, mean_q: 3.921463
456 (array([22]),) False
 181840/500000: episode: 4546, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 31.700 [2.000, 60.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.206218, mean_absolute_error: 3.028940, mean_q: 3.950969
644 (array([12]),) False
 181880/500000: episode: 4547, duration: 32.299s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 19.300 [6.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.201060, mean_absolute_error: 2.987910, mean_q: 3.890413
309 (array([22]),) False
 181920/500000: episode: 4548, duration: 33.277s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.850 [3.000, 28.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.204659, mean_absolute_error: 3.038588, mean_q: 3.955957
629 (array([22]),) False
 181960/500000: episode: 4549, duration: 32.326s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.525 [22.000, 49.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.226128, mean_absolute_error: 2.963402, mean_q: 3.855466
473 (array([22]),) False
 182000/500000: episode: 4550, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.400 [22.000, 58.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.199419, mean_absolute_error: 2.989358, mean_q: 3.888201
234 (array([22]),) False
 182040/500000: episode: 4551, duration: 32.321s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 20.725 [0.000, 22.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.210839, mean_absolute_error: 2.998448, mean_q: 3.899229
502 (array([22]),) False
 182080/500000: episode: 4552, duration: 33.297s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.300 [2.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.196380, mean_absolute_error: 2.982477, mean_q: 3.878939
708 (array([40]),) False
 182120/500000: episode: 4553, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.975 [6.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.223145, mean_absolute_error: 2.992351, mean_q: 3.879311
834 (array([44]),) False
 182160/500000: episode: 4554, duration: 33.265s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 33.625 [3.000, 48.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.205528, mean_absolute_error: 2.996608, mean_q: 3.884099
205 (array([22]),) False
 182200/500000: episode: 4555, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.500 [2.000, 22.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.198238, mean_absolute_error: 2.993618, mean_q: 3.896177
397 (array([22]),) False
 182240/500000: episode: 4556, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.750 [2.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.195483, mean_absolute_error: 2.975596, mean_q: 3.866348
188 (array([22]),) False
 182280/500000: episode: 4557, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.200 [22.000, 49.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.206996, mean_absolute_error: 2.965569, mean_q: 3.868978
599 (array([48]),) False
 182320/500000: episode: 4558, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 41.525 [22.000, 51.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.215535, mean_absolute_error: 2.938486, mean_q: 3.819410
246 (array([22]),) False
 182360/500000: episode: 4559, duration: 32.246s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.075 [1.000, 58.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.191945, mean_absolute_error: 2.937448, mean_q: 3.830411
853 (array([22]),) False
 182400/500000: episode: 4560, duration: 33.268s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.500 [22.000, 53.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.214701, mean_absolute_error: 2.955908, mean_q: 3.844902
567 (array([22]),) False
 182440/500000: episode: 4561, duration: 32.343s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 18.475 [1.000, 22.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.203941, mean_absolute_error: 2.968241, mean_q: 3.872482
265 (array([22]),) False
 182480/500000: episode: 4562, duration: 33.284s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 17.425 [2.000, 46.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.212196, mean_absolute_error: 2.972404, mean_q: 3.884912
162 (array([22]),) False
 182520/500000: episode: 4563, duration: 32.371s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.075 [4.000, 32.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.221020, mean_absolute_error: 2.919950, mean_q: 3.814032
169 (array([22]),) False
 182560/500000: episode: 4564, duration: 33.263s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.000 [16.000, 58.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.207638, mean_absolute_error: 2.980479, mean_q: 3.874779
439 (array([12]),) False
 182600/500000: episode: 4565, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.975 [2.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.239978, mean_absolute_error: 2.962509, mean_q: 3.865930
356 (array([22]),) False
 182640/500000: episode: 4566, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.000 [13.000, 27.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.213830, mean_absolute_error: 2.956085, mean_q: 3.859483
403 (array([12]),) False
 182680/500000: episode: 4567, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 29.200 [22.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.214063, mean_absolute_error: 2.951910, mean_q: 3.848308
850 (array([12]),) False
 182720/500000: episode: 4568, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 24.950 [12.000, 49.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.190779, mean_absolute_error: 2.949750, mean_q: 3.844336
277 (array([56]),) False
 182760/500000: episode: 4569, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 51.650 [12.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.197759, mean_absolute_error: 2.924401, mean_q: 3.809159
707 (array([48]),) False
 182800/500000: episode: 4570, duration: 33.253s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 43.675 [5.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.212441, mean_absolute_error: 2.990781, mean_q: 3.872897
76 (array([38]),) False
 182840/500000: episode: 4571, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 36.300 [3.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.207668, mean_absolute_error: 2.931332, mean_q: 3.820426
659 (array([40]),) False
 182880/500000: episode: 4572, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.375 [6.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.200979, mean_absolute_error: 2.945221, mean_q: 3.838223
572 (array([58]),) False
 182920/500000: episode: 4573, duration: 30.147s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 56.000 [15.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.208828, mean_absolute_error: 2.974136, mean_q: 3.869600
56 (array([12]),) False
 182960/500000: episode: 4574, duration: 31.106s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.875 [11.000, 44.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.199278, mean_absolute_error: 2.937100, mean_q: 3.833876
340 (array([12]),) False
 183000/500000: episode: 4575, duration: 30.144s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 18.125 [0.000, 39.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.196354, mean_absolute_error: 2.973894, mean_q: 3.878832
824 (array([22]),) False
 183040/500000: episode: 4576, duration: 31.056s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.675 [8.000, 23.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.206871, mean_absolute_error: 3.000465, mean_q: 3.909557
169 (array([22]),) False
 183080/500000: episode: 4577, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [7.000, 57.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.207612, mean_absolute_error: 2.922450, mean_q: 3.832764
424 (array([22]),) False
 183120/500000: episode: 4578, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.700 [12.000, 60.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.202970, mean_absolute_error: 2.940756, mean_q: 3.857838
664 (array([22]),) False
 183160/500000: episode: 4579, duration: 30.958s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.675 [7.000, 36.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.216126, mean_absolute_error: 2.978180, mean_q: 3.895109
122 (array([12]),) False
 183200/500000: episode: 4580, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 24.350 [12.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.213025, mean_absolute_error: 2.997533, mean_q: 3.919093
848 (array([44]),) False
 183240/500000: episode: 4581, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 42.350 [1.000, 54.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.209464, mean_absolute_error: 3.011180, mean_q: 3.929522
272 (array([12]),) False
 183280/500000: episode: 4582, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 21.925 [12.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.197299, mean_absolute_error: 3.009942, mean_q: 3.916387
434 (array([22]),) False
 183320/500000: episode: 4583, duration: 30.159s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.775 [3.000, 56.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.204241, mean_absolute_error: 2.973333, mean_q: 3.880978
47 (array([44]),) False
 183360/500000: episode: 4584, duration: 31.020s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 25.200 [8.000, 44.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.207940, mean_absolute_error: 3.010121, mean_q: 3.920315
19 (array([12]),) False
 183400/500000: episode: 4585, duration: 30.141s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.875 [21.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.213123, mean_absolute_error: 3.059382, mean_q: 3.983622
494 (array([48]),) False
 183440/500000: episode: 4586, duration: 31.039s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 43.550 [1.000, 48.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.222584, mean_absolute_error: 2.989245, mean_q: 3.907794
842 (array([22]),) False
 183480/500000: episode: 4587, duration: 30.205s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.900 [10.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.196713, mean_absolute_error: 3.025318, mean_q: 3.960648
430 (array([22]),) False
 183520/500000: episode: 4588, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.675 [9.000, 60.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.207606, mean_absolute_error: 3.034508, mean_q: 3.943799
51 (array([22]),) False
 183560/500000: episode: 4589, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.925 [0.000, 46.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.206217, mean_absolute_error: 3.026365, mean_q: 3.940265
667 (array([48]),) False
 183600/500000: episode: 4590, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 48.000 [48.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.215251, mean_absolute_error: 3.000485, mean_q: 3.914855
744 (array([22]),) False
 183640/500000: episode: 4591, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 26.725 [16.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.209222, mean_absolute_error: 3.044589, mean_q: 3.957442
131 (array([22]),) False
 183680/500000: episode: 4592, duration: 31.017s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 21.400 [1.000, 29.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.212426, mean_absolute_error: 3.018352, mean_q: 3.922712
712 (array([22]),) False
 183720/500000: episode: 4593, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.225 [14.000, 36.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.209850, mean_absolute_error: 2.996960, mean_q: 3.903953
727 (array([12]),) False
 183760/500000: episode: 4594, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 20.000 [4.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.211863, mean_absolute_error: 3.013282, mean_q: 3.933301
1 (array([22]),) False
 183800/500000: episode: 4595, duration: 30.148s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.650 [22.000, 52.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.211551, mean_absolute_error: 3.033551, mean_q: 3.947184
323 (array([55]),) False
 183840/500000: episode: 4596, duration: 30.987s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 32.300 [18.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.214278, mean_absolute_error: 3.009727, mean_q: 3.921847
517 (array([22]),) False
 183880/500000: episode: 4597, duration: 30.229s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.600 [3.000, 44.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.200423, mean_absolute_error: 3.025032, mean_q: 3.934905
797 (array([22]),) False
 183920/500000: episode: 4598, duration: 31.071s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.075 [13.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.217840, mean_absolute_error: 2.982088, mean_q: 3.903924
11 (array([22]),) False
 183960/500000: episode: 4599, duration: 30.195s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.550 [2.000, 60.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.221174, mean_absolute_error: 3.046783, mean_q: 3.973583
210 (array([58]),) False
 184000/500000: episode: 4600, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 50.375 [12.000, 58.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.196282, mean_absolute_error: 3.043913, mean_q: 3.955186
613 (array([22]),) False
 184040/500000: episode: 4601, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.525 [6.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.213656, mean_absolute_error: 3.024136, mean_q: 3.943588
100 (array([22]),) False
 184080/500000: episode: 4602, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.650 [0.000, 32.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.214607, mean_absolute_error: 3.035934, mean_q: 3.955487
69 (array([12]),) False
 184120/500000: episode: 4603, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 15.650 [12.000, 54.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.215615, mean_absolute_error: 3.085443, mean_q: 3.995631
672 (array([44]),) False
 184160/500000: episode: 4604, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 49.100 [6.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.220363, mean_absolute_error: 3.054799, mean_q: 3.971001
398 (array([22]),) False
 184200/500000: episode: 4605, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.300 [8.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.226910, mean_absolute_error: 3.073570, mean_q: 4.004321
583 (array([22]),) False
 184240/500000: episode: 4606, duration: 30.976s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 14.100 [11.000, 47.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.223708, mean_absolute_error: 3.076145, mean_q: 3.990062
376 (array([22]),) False
 184280/500000: episode: 4607, duration: 30.132s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 44.875 [1.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.221934, mean_absolute_error: 3.030489, mean_q: 3.950230
244 (array([14]),) False
 184320/500000: episode: 4608, duration: 31.018s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 18.550 [14.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.218801, mean_absolute_error: 3.033612, mean_q: 3.948318
340 (array([12]),) False
 184360/500000: episode: 4609, duration: 30.174s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 19.900 [3.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.206636, mean_absolute_error: 3.085190, mean_q: 3.990392
821 (array([22]),) False
 184400/500000: episode: 4610, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.975 [0.000, 53.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.230273, mean_absolute_error: 2.980247, mean_q: 3.892319
729 (array([22]),) False
 184440/500000: episode: 4611, duration: 30.177s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 29.575 [4.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.219873, mean_absolute_error: 3.086365, mean_q: 4.023407
587 (array([14]),) False
 184480/500000: episode: 4612, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 47.225 [19.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.223643, mean_absolute_error: 3.088264, mean_q: 4.010902
85 (array([48]),) False
 184520/500000: episode: 4613, duration: 30.948s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 24.050 [10.000, 49.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.208072, mean_absolute_error: 3.077275, mean_q: 4.003799
841 (array([21]),) False
 184560/500000: episode: 4614, duration: 31.047s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 36.050 [12.000, 52.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.222938, mean_absolute_error: 3.025018, mean_q: 3.929845
670 (array([22]),) False
 184600/500000: episode: 4615, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 31.425 [12.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.204637, mean_absolute_error: 3.002046, mean_q: 3.898793
276 (array([56]),) False
 184640/500000: episode: 4616, duration: 31.028s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 16.975 [2.000, 58.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.207268, mean_absolute_error: 3.040996, mean_q: 3.946491
712 (array([22]),) False
 184680/500000: episode: 4617, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.194153, mean_absolute_error: 3.033514, mean_q: 3.942216
3 (array([48]),) False
 184720/500000: episode: 4618, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 21.350 [4.000, 35.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.198437, mean_absolute_error: 3.067987, mean_q: 3.979419
795 (array([3]),) False
 184760/500000: episode: 4619, duration: 30.098s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 5.850 [0.000, 40.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.205086, mean_absolute_error: 3.012888, mean_q: 3.911068
75 (array([22]),) False
 184800/500000: episode: 4620, duration: 31.014s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.625 [0.000, 52.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.203709, mean_absolute_error: 3.065265, mean_q: 3.962665
719 (array([22]),) False
 184840/500000: episode: 4621, duration: 30.177s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 15.975 [12.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.212361, mean_absolute_error: 3.055607, mean_q: 3.954036
373 (array([22]),) False
 184880/500000: episode: 4622, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.075 [3.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.201816, mean_absolute_error: 3.068532, mean_q: 3.961541
658 (array([48]),) False
 184920/500000: episode: 4623, duration: 30.157s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.800 [14.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.219977, mean_absolute_error: 3.027766, mean_q: 3.926105
390 (array([22]),) False
 184960/500000: episode: 4624, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 24.150 [10.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.206278, mean_absolute_error: 3.024054, mean_q: 3.932292
234 (array([22]),) False
 185000/500000: episode: 4625, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.375 [8.000, 22.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.209928, mean_absolute_error: 2.994812, mean_q: 3.891634
827 (array([14]),) False
 185040/500000: episode: 4626, duration: 31.033s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 41.075 [0.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.220663, mean_absolute_error: 3.112643, mean_q: 4.023065
42 (array([22]),) False
 185080/500000: episode: 4627, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 20.800 [0.000, 36.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.218948, mean_absolute_error: 3.054024, mean_q: 3.962746
695 (array([22]),) False
 185120/500000: episode: 4628, duration: 31.067s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.375 [10.000, 56.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.221116, mean_absolute_error: 2.971873, mean_q: 3.866484
527 (array([58]),) False
 185160/500000: episode: 4629, duration: 31.015s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 56.200 [14.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.220916, mean_absolute_error: 3.063159, mean_q: 3.955431
269 (array([36]),) False
 185200/500000: episode: 4630, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 16.675 [1.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.195701, mean_absolute_error: 3.026267, mean_q: 3.923434
94 (array([44]),) False
 185240/500000: episode: 4631, duration: 30.158s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 40.125 [14.000, 60.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.219834, mean_absolute_error: 3.037665, mean_q: 3.929102
411 (array([22]),) False
 185280/500000: episode: 4632, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.675 [4.000, 46.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.212481, mean_absolute_error: 3.047149, mean_q: 3.951030
760 (array([22]),) False
 185320/500000: episode: 4633, duration: 30.189s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 39.000 [0.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.208304, mean_absolute_error: 3.026111, mean_q: 3.935303
80 (array([42]),) False
 185360/500000: episode: 4634, duration: 30.997s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 45.775 [11.000, 48.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.205997, mean_absolute_error: 3.045420, mean_q: 3.953723
839 (array([22]),) False
 185400/500000: episode: 4635, duration: 30.154s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 20.850 [0.000, 38.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.205554, mean_absolute_error: 2.998788, mean_q: 3.888905
826 (array([22]),) False
 185440/500000: episode: 4636, duration: 31.054s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 21.200 [6.000, 51.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.214302, mean_absolute_error: 3.006650, mean_q: 3.907601
179 (array([18]),) False
 185480/500000: episode: 4637, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.150 [12.000, 33.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.204566, mean_absolute_error: 3.042738, mean_q: 3.949189
178 (array([38]),) False
 185520/500000: episode: 4638, duration: 31.066s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 26.200 [21.000, 49.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.209089, mean_absolute_error: 3.021092, mean_q: 3.914124
61 (array([48]),) False
 185560/500000: episode: 4639, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 22.875 [22.000, 57.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.212754, mean_absolute_error: 3.009260, mean_q: 3.919572
484 (array([22]),) False
 185600/500000: episode: 4640, duration: 31.020s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.475 [19.000, 45.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.218999, mean_absolute_error: 3.077851, mean_q: 3.998388
66 (array([22]),) False
 185640/500000: episode: 4641, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.975 [19.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.216552, mean_absolute_error: 2.986596, mean_q: 3.886596
323 (array([55]),) False
 185680/500000: episode: 4642, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.850 [7.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.215744, mean_absolute_error: 3.014806, mean_q: 3.927883
803 (array([58]),) False
 185720/500000: episode: 4643, duration: 30.127s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 45.425 [2.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.241483, mean_absolute_error: 2.978628, mean_q: 3.888524
761 (array([3]),) False
 185760/500000: episode: 4644, duration: 31.024s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 5.400 [3.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.218857, mean_absolute_error: 3.017754, mean_q: 3.928400
511 (array([22]),) False
 185800/500000: episode: 4645, duration: 30.208s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.300 [9.000, 38.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.211771, mean_absolute_error: 2.968943, mean_q: 3.866562
28 (array([58]),) False
 185840/500000: episode: 4646, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.575 [3.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.205560, mean_absolute_error: 3.046283, mean_q: 3.963710
710 (array([12]),) False
 185880/500000: episode: 4647, duration: 30.143s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 19.575 [10.000, 53.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.206779, mean_absolute_error: 3.018275, mean_q: 3.945550
349 (array([48]),) False
 185920/500000: episode: 4648, duration: 31.050s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 16.625 [4.000, 22.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.211643, mean_absolute_error: 3.046415, mean_q: 3.977662
556 (array([48]),) False
 185960/500000: episode: 4649, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 44.100 [1.000, 51.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.221251, mean_absolute_error: 2.988689, mean_q: 3.902155
747 (array([22]),) False
 186000/500000: episode: 4650, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.725 [16.000, 52.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.213060, mean_absolute_error: 3.002134, mean_q: 3.916578
540 (array([22]),) False
 186040/500000: episode: 4651, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.150 [22.000, 54.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.217580, mean_absolute_error: 3.038709, mean_q: 3.944513
723 (array([48]),) False
 186080/500000: episode: 4652, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 30.000 [2.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.233083, mean_absolute_error: 3.048667, mean_q: 3.962968
756 (array([48]),) False
 186120/500000: episode: 4653, duration: 30.954s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 41.625 [20.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.194585, mean_absolute_error: 3.008612, mean_q: 3.921214
708 (array([40]),) False
 186160/500000: episode: 4654, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.175 [22.000, 47.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.204326, mean_absolute_error: 3.049197, mean_q: 3.963132
821 (array([22]),) False
 186200/500000: episode: 4655, duration: 30.188s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 20.475 [1.000, 37.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.235222, mean_absolute_error: 3.059533, mean_q: 3.979926
622 (array([36]),) False
 186240/500000: episode: 4656, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 36.300 [24.000, 48.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.236818, mean_absolute_error: 3.095119, mean_q: 4.014661
15 (array([22]),) False
 186280/500000: episode: 4657, duration: 30.219s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.425 [1.000, 52.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.203126, mean_absolute_error: 3.038274, mean_q: 3.937713
697 (array([22]),) False
 186320/500000: episode: 4658, duration: 31.065s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.325 [0.000, 22.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.202617, mean_absolute_error: 3.094564, mean_q: 4.009131
671 (array([57]),) False
 186360/500000: episode: 4659, duration: 30.216s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 40.475 [1.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.208404, mean_absolute_error: 3.044197, mean_q: 3.960934
263 (array([8]),) False
 186400/500000: episode: 4660, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 9.850 [8.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.216569, mean_absolute_error: 3.057823, mean_q: 3.975443
380 (array([22]),) False
 186440/500000: episode: 4661, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.075 [22.000, 58.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.229232, mean_absolute_error: 3.072037, mean_q: 3.984388
843 (array([3]),) False
 186480/500000: episode: 4662, duration: 31.054s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 53.650 [0.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.218341, mean_absolute_error: 3.088160, mean_q: 4.013770
761 (array([3]),) False
 186520/500000: episode: 4663, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 6.250 [3.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.214722, mean_absolute_error: 3.052545, mean_q: 3.979802
820 (array([48]),) False
 186560/500000: episode: 4664, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 21.075 [12.000, 52.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.219719, mean_absolute_error: 3.049976, mean_q: 3.974967
825 (array([22]),) False
 186600/500000: episode: 4665, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.950 [10.000, 39.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.219673, mean_absolute_error: 3.102262, mean_q: 4.034566
729 (array([22]),) False
 186640/500000: episode: 4666, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 25.725 [4.000, 55.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.212236, mean_absolute_error: 3.034083, mean_q: 3.955882
529 (array([3]),) False
 186680/500000: episode: 4667, duration: 30.145s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 4.875 [3.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.217072, mean_absolute_error: 3.069900, mean_q: 3.991865
652 (array([22]),) False
 186720/500000: episode: 4668, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.250 [3.000, 57.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.219025, mean_absolute_error: 3.038755, mean_q: 3.959845
344 (array([22]),) False
 186760/500000: episode: 4669, duration: 30.187s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.400 [22.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.233676, mean_absolute_error: 3.100363, mean_q: 4.019449
124 (array([48]),) False
 186800/500000: episode: 4670, duration: 31.065s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 48.150 [48.000, 54.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.211604, mean_absolute_error: 3.062158, mean_q: 3.993161
703 (array([3]),) False
 186840/500000: episode: 4671, duration: 30.225s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 4.325 [3.000, 43.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.213164, mean_absolute_error: 3.060044, mean_q: 3.976758
264 (array([12]),) False
 186880/500000: episode: 4672, duration: 31.079s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 19.025 [1.000, 53.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.215725, mean_absolute_error: 3.069384, mean_q: 3.989643
859 (array([22]),) False
 186920/500000: episode: 4673, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.250 [7.000, 47.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.204417, mean_absolute_error: 3.047707, mean_q: 3.968651
514 (array([54]),) False
 186960/500000: episode: 4674, duration: 31.056s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.975 [3.000, 25.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.213546, mean_absolute_error: 3.100107, mean_q: 4.030206
106 (array([22]),) False
 187000/500000: episode: 4675, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 20.775 [1.000, 39.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.225444, mean_absolute_error: 3.066150, mean_q: 3.995937
110 (array([22]),) False
 187040/500000: episode: 4676, duration: 31.041s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.625 [14.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.218747, mean_absolute_error: 3.017358, mean_q: 3.938809
490 (array([12]),) False
 187080/500000: episode: 4677, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 14.425 [12.000, 49.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.234962, mean_absolute_error: 3.090646, mean_q: 4.016665
654 (array([22]),) False
 187120/500000: episode: 4678, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.700 [20.000, 51.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.226414, mean_absolute_error: 3.084504, mean_q: 4.010504
26 (array([22]),) False
 187160/500000: episode: 4679, duration: 30.164s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.375 [3.000, 48.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.206620, mean_absolute_error: 3.067432, mean_q: 3.979768
799 (array([36]),) False
 187200/500000: episode: 4680, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 40.950 [3.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.215095, mean_absolute_error: 3.095265, mean_q: 4.017832
113 (array([22]),) False
 187240/500000: episode: 4681, duration: 30.157s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.050 [13.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.220926, mean_absolute_error: 3.052877, mean_q: 3.979551
71 (array([58]),) False
 187280/500000: episode: 4682, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 39.625 [1.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.225038, mean_absolute_error: 3.084030, mean_q: 4.022966
97 (array([22]),) False
 187320/500000: episode: 4683, duration: 30.129s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.650 [6.000, 24.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.230778, mean_absolute_error: 3.041680, mean_q: 3.972890
283 (array([34]),) False
 187360/500000: episode: 4684, duration: 31.042s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 20.300 [3.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.223362, mean_absolute_error: 3.137709, mean_q: 4.073273
595 (array([22]),) False
 187400/500000: episode: 4685, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.500 [19.000, 42.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.223899, mean_absolute_error: 3.072352, mean_q: 3.987810
771 (array([12]),) False
 187440/500000: episode: 4686, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 15.750 [12.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.226643, mean_absolute_error: 3.108767, mean_q: 4.030904
846 (array([48]),) False
 187480/500000: episode: 4687, duration: 30.970s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.275 [21.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.215276, mean_absolute_error: 3.111983, mean_q: 4.045313
239 (array([22]),) False
 187520/500000: episode: 4688, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.975 [12.000, 28.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.208928, mean_absolute_error: 3.067850, mean_q: 3.981570
44 (array([22]),) False
 187560/500000: episode: 4689, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.075 [21.000, 49.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.228027, mean_absolute_error: 3.095296, mean_q: 4.016877
39 (array([22]),) False
 187600/500000: episode: 4690, duration: 30.853s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.775 [10.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.223331, mean_absolute_error: 3.123549, mean_q: 4.047704
81 (array([22]),) False
 187640/500000: episode: 4691, duration: 30.057s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.500 [22.000, 54.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.225221, mean_absolute_error: 3.070063, mean_q: 3.996563
105 (array([22]),) False
 187680/500000: episode: 4692, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 23.325 [20.000, 48.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.217197, mean_absolute_error: 3.045738, mean_q: 3.972378
320 (array([22]),) False
 187720/500000: episode: 4693, duration: 30.044s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.150 [18.000, 51.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.226540, mean_absolute_error: 3.108575, mean_q: 4.035712
387 (array([22]),) False
 187760/500000: episode: 4694, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.900 [6.000, 56.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.220820, mean_absolute_error: 3.095135, mean_q: 4.016212
397 (array([22]),) False
 187800/500000: episode: 4695, duration: 30.024s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 24.550 [3.000, 56.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.219044, mean_absolute_error: 3.109891, mean_q: 4.048314
427 (array([22]),) False
 187840/500000: episode: 4696, duration: 31.001s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 21.950 [5.000, 47.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.224333, mean_absolute_error: 3.044717, mean_q: 3.969267
581 (array([22]),) False
 187880/500000: episode: 4697, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.550 [1.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.226549, mean_absolute_error: 3.046223, mean_q: 3.981350
751 (array([22]),) False
 187920/500000: episode: 4698, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 42.475 [22.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.218161, mean_absolute_error: 3.119464, mean_q: 4.062086
100 (array([22]),) False
 187960/500000: episode: 4699, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.925 [22.000, 53.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.221828, mean_absolute_error: 3.075454, mean_q: 4.016547
292 (array([22]),) False
 188000/500000: episode: 4700, duration: 30.829s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.150 [8.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.230243, mean_absolute_error: 3.073429, mean_q: 4.014491
504 (array([48]),) False
 188040/500000: episode: 4701, duration: 30.794s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 46.400 [15.000, 54.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.210647, mean_absolute_error: 3.115149, mean_q: 4.067767
750 (array([22]),) False
 188080/500000: episode: 4702, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.600 [2.000, 60.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.209034, mean_absolute_error: 3.106660, mean_q: 4.038938
381 (array([22]),) False
 188120/500000: episode: 4703, duration: 30.082s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.400 [21.000, 54.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.213107, mean_absolute_error: 3.118152, mean_q: 4.047633
289 (array([21]),) False
 188160/500000: episode: 4704, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 25.650 [1.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.228190, mean_absolute_error: 3.144577, mean_q: 4.067115
835 (array([50]),) False
 188200/500000: episode: 4705, duration: 30.037s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.450 [10.000, 52.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.225048, mean_absolute_error: 3.087164, mean_q: 3.986498
663 (array([22]),) False
 188240/500000: episode: 4706, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 17.450 [1.000, 50.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.233980, mean_absolute_error: 3.127791, mean_q: 4.034196
559 (array([59]),) False
 188280/500000: episode: 4707, duration: 30.110s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.700 [3.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.216919, mean_absolute_error: 3.154696, mean_q: 4.071747
327 (array([22]),) False
 188320/500000: episode: 4708, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.125 [0.000, 24.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.229605, mean_absolute_error: 3.173790, mean_q: 4.102843
795 (array([3]),) False
 188360/500000: episode: 4709, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 8.350 [3.000, 49.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.231431, mean_absolute_error: 3.106979, mean_q: 4.039954
237 (array([22]),) False
 188400/500000: episode: 4710, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.150 [7.000, 44.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.210589, mean_absolute_error: 3.139080, mean_q: 4.063653
390 (array([22]),) False
 188440/500000: episode: 4711, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 22.575 [13.000, 48.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.215028, mean_absolute_error: 3.143540, mean_q: 4.062242
208 (array([22]),) False
 188480/500000: episode: 4712, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 24.925 [12.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.232498, mean_absolute_error: 3.094486, mean_q: 4.006174
281 (array([48]),) False
 188520/500000: episode: 4713, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.600 [10.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.214060, mean_absolute_error: 3.080366, mean_q: 3.994504
838 (array([21]),) False
 188560/500000: episode: 4714, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 18.875 [3.000, 30.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.228566, mean_absolute_error: 3.145385, mean_q: 4.066607
80 (array([42]),) False
 188600/500000: episode: 4715, duration: 30.073s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 42.925 [0.000, 48.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.221025, mean_absolute_error: 3.131201, mean_q: 4.052068
386 (array([12]),) False
 188640/500000: episode: 4716, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.050 [0.000, 49.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.218084, mean_absolute_error: 3.100322, mean_q: 4.015670
307 (array([22]),) False
 188680/500000: episode: 4717, duration: 30.047s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.075 [0.000, 47.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.216922, mean_absolute_error: 3.075057, mean_q: 3.978528
822 (array([22]),) False
 188720/500000: episode: 4718, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.375 [10.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.218208, mean_absolute_error: 3.131105, mean_q: 4.030035
361 (array([22]),) False
 188760/500000: episode: 4719, duration: 30.059s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.100 [12.000, 36.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.204701, mean_absolute_error: 3.044873, mean_q: 3.940763
615 (array([36]),) False
 188800/500000: episode: 4720, duration: 30.958s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 33.750 [3.000, 44.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.224126, mean_absolute_error: 3.122635, mean_q: 4.039155
164 (array([22]),) False
 188840/500000: episode: 4721, duration: 30.903s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.825 [6.000, 52.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.239222, mean_absolute_error: 3.012836, mean_q: 3.922637
152 (array([58]),) False
 188880/500000: episode: 4722, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 52.750 [12.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.223419, mean_absolute_error: 3.118119, mean_q: 4.039304
110 (array([22]),) False
 188920/500000: episode: 4723, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.275 [8.000, 55.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.222815, mean_absolute_error: 3.081559, mean_q: 3.981776
21 (array([3]),) False
 188960/500000: episode: 4724, duration: 30.872s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 19.125 [0.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.230818, mean_absolute_error: 3.113193, mean_q: 4.027421
462 (array([12]),) False
 189000/500000: episode: 4725, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 31.150 [1.000, 48.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.234765, mean_absolute_error: 3.145171, mean_q: 4.065207
361 (array([22]),) False
 189040/500000: episode: 4726, duration: 30.959s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.625 [5.000, 55.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.207936, mean_absolute_error: 3.095177, mean_q: 4.017291
750 (array([22]),) False
 189080/500000: episode: 4727, duration: 29.936s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.250 [22.000, 54.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.214939, mean_absolute_error: 3.096020, mean_q: 4.004093
341 (array([22]),) False
 189120/500000: episode: 4728, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.250 [3.000, 46.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.218121, mean_absolute_error: 3.128099, mean_q: 4.041754
534 (array([22]),) False
 189160/500000: episode: 4729, duration: 30.115s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.200 [22.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.222547, mean_absolute_error: 3.090676, mean_q: 3.997505
196 (array([22]),) False
 189200/500000: episode: 4730, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.475 [13.000, 41.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.218257, mean_absolute_error: 3.068536, mean_q: 3.984775
588 (array([22]),) False
 189240/500000: episode: 4731, duration: 30.065s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.525 [6.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.217091, mean_absolute_error: 3.141690, mean_q: 4.055029
799 (array([36]),) False
 189280/500000: episode: 4732, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 42.775 [36.000, 51.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.226399, mean_absolute_error: 3.120828, mean_q: 4.040671
297 (array([15]),) False
 189320/500000: episode: 4733, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.225 [3.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.216067, mean_absolute_error: 3.091153, mean_q: 3.997599
23 (array([48]),) False
 189360/500000: episode: 4734, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.400 [13.000, 56.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.225000, mean_absolute_error: 3.066537, mean_q: 3.974419
711 (array([22]),) False
 189400/500000: episode: 4735, duration: 30.879s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.550 [9.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.221595, mean_absolute_error: 3.120906, mean_q: 4.051730
241 (array([22]),) False
 189440/500000: episode: 4736, duration: 30.844s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.875 [13.000, 54.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.209667, mean_absolute_error: 3.121887, mean_q: 4.051497
621 (array([22]),) False
 189480/500000: episode: 4737, duration: 30.848s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.825 [10.000, 27.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.209311, mean_absolute_error: 3.135871, mean_q: 4.067075
574 (array([8]),) False
 189520/500000: episode: 4738, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.100 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.257469, mean_absolute_error: 3.090071, mean_q: 4.009888
48 (array([12]),) False
 189560/500000: episode: 4739, duration: 30.010s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.150 [9.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.216346, mean_absolute_error: 3.130967, mean_q: 4.048745
377 (array([22]),) False
 189600/500000: episode: 4740, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.400 [8.000, 52.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.214567, mean_absolute_error: 3.178917, mean_q: 4.111009
727 (array([12]),) False
 189640/500000: episode: 4741, duration: 30.084s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 18.500 [12.000, 22.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.238573, mean_absolute_error: 3.139525, mean_q: 4.067089
492 (array([22]),) False
 189680/500000: episode: 4742, duration: 30.837s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.150 [6.000, 22.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.219609, mean_absolute_error: 3.103038, mean_q: 4.018506
712 (array([22]),) False
 189720/500000: episode: 4743, duration: 30.035s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.350 [7.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.232477, mean_absolute_error: 3.074629, mean_q: 3.990020
763 (array([48]),) False
 189760/500000: episode: 4744, duration: 30.976s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 47.525 [8.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.238996, mean_absolute_error: 3.124670, mean_q: 4.044754
147 (array([44]),) False
 189800/500000: episode: 4745, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 24.450 [2.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.213043, mean_absolute_error: 3.088508, mean_q: 4.012984
511 (array([22]),) False
 189840/500000: episode: 4746, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.000 [19.000, 53.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.223917, mean_absolute_error: 3.087717, mean_q: 3.991206
703 (array([3]),) False
 189880/500000: episode: 4747, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 2.975 [1.000, 4.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.240890, mean_absolute_error: 3.096293, mean_q: 4.004737
841 (array([21]),) False
 189920/500000: episode: 4748, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.950 [4.000, 51.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.222768, mean_absolute_error: 3.070965, mean_q: 3.992266
726 (array([12]),) False
 189960/500000: episode: 4749, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 16.475 [8.000, 26.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.213800, mean_absolute_error: 3.080447, mean_q: 3.992950
729 (array([22]),) False
 190000/500000: episode: 4750, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 26.450 [12.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.223582, mean_absolute_error: 3.074043, mean_q: 3.975776
512 (array([48]),) False
 190040/500000: episode: 4751, duration: 30.032s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 18.100 [6.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.208634, mean_absolute_error: 3.082695, mean_q: 3.985918
188 (array([22]),) False
 190080/500000: episode: 4752, duration: 30.897s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.350 [0.000, 43.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.211221, mean_absolute_error: 3.141766, mean_q: 4.048482
719 (array([22]),) False
 190120/500000: episode: 4753, duration: 30.018s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 16.950 [0.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.219889, mean_absolute_error: 3.130730, mean_q: 4.039267
217 (array([12]),) False
 190160/500000: episode: 4754, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.950 [0.000, 44.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.214075, mean_absolute_error: 3.157543, mean_q: 4.082446
119 (array([45]),) False
 190200/500000: episode: 4755, duration: 30.047s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 11.700 [6.000, 12.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.220334, mean_absolute_error: 3.059039, mean_q: 3.964022
741 (array([22]),) False
 190240/500000: episode: 4756, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 20.850 [1.000, 22.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.228793, mean_absolute_error: 3.137984, mean_q: 4.061004
531 (array([22]),) False
 190280/500000: episode: 4757, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.575 [7.000, 53.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.230469, mean_absolute_error: 3.111953, mean_q: 4.024640
257 (array([22]),) False
 190320/500000: episode: 4758, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.875 [3.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.210617, mean_absolute_error: 3.075772, mean_q: 3.993652
698 (array([22]),) False
 190360/500000: episode: 4759, duration: 30.822s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.750 [2.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.223506, mean_absolute_error: 3.094250, mean_q: 4.008077
528 (array([12]),) False
 190400/500000: episode: 4760, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 21.750 [3.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.240650, mean_absolute_error: 3.074519, mean_q: 3.992962
565 (array([12]),) False
 190440/500000: episode: 4761, duration: 30.871s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 23.175 [3.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.219629, mean_absolute_error: 3.093146, mean_q: 3.997099
282 (array([22]),) False
 190480/500000: episode: 4762, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.000 [4.000, 23.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.218458, mean_absolute_error: 3.054701, mean_q: 3.977836
499 (array([8]),) False
 190520/500000: episode: 4763, duration: 30.032s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 16.950 [3.000, 48.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.226828, mean_absolute_error: 3.135752, mean_q: 4.062333
193 (array([36]),) False
 190560/500000: episode: 4764, duration: 30.878s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 43.775 [35.000, 44.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.228251, mean_absolute_error: 3.099187, mean_q: 4.005079
194 (array([44]),) False
 190600/500000: episode: 4765, duration: 30.064s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 42.900 [14.000, 55.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.242177, mean_absolute_error: 3.143944, mean_q: 4.033458
56 (array([12]),) False
 190640/500000: episode: 4766, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 13.000 [3.000, 46.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.216069, mean_absolute_error: 3.083648, mean_q: 3.979457
674 (array([48]),) False
 190680/500000: episode: 4767, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 30.225 [2.000, 46.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.213375, mean_absolute_error: 3.094869, mean_q: 4.008584
117 (array([44]),) False
 190720/500000: episode: 4768, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.025 [3.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.231728, mean_absolute_error: 3.087427, mean_q: 3.987128
430 (array([22]),) False
 190760/500000: episode: 4769, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.650 [4.000, 47.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.235603, mean_absolute_error: 3.071402, mean_q: 3.982096
676 (array([40]),) False
 190800/500000: episode: 4770, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 37.300 [3.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.224665, mean_absolute_error: 3.095798, mean_q: 4.015398
668 (array([22]),) False
 190840/500000: episode: 4771, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 26.725 [5.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.226703, mean_absolute_error: 3.087488, mean_q: 4.008595
216 (array([22]),) False
 190880/500000: episode: 4772, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.600 [22.000, 46.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.202711, mean_absolute_error: 3.105809, mean_q: 4.028714
414 (array([48]),) False
 190920/500000: episode: 4773, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 32.925 [6.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.216865, mean_absolute_error: 3.070037, mean_q: 3.973014
810 (array([12]),) False
 190960/500000: episode: 4774, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.100 [5.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.214010, mean_absolute_error: 3.087754, mean_q: 3.997483
515 (array([22]),) False
 191000/500000: episode: 4775, duration: 30.048s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.227800, mean_absolute_error: 3.117826, mean_q: 4.032419
390 (array([22]),) False
 191040/500000: episode: 4776, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 28.175 [7.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.211378, mean_absolute_error: 3.075562, mean_q: 3.982933
413 (array([22]),) False
 191080/500000: episode: 4777, duration: 29.985s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.725 [14.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.223970, mean_absolute_error: 3.064276, mean_q: 3.963169
835 (array([50]),) False
 191120/500000: episode: 4778, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.125 [2.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.219601, mean_absolute_error: 3.043684, mean_q: 3.939743
661 (array([48]),) False
 191160/500000: episode: 4779, duration: 30.085s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.050 [9.000, 49.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.215474, mean_absolute_error: 3.038131, mean_q: 3.948860
690 (array([22]),) False
 191200/500000: episode: 4780, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.075 [1.000, 53.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.222232, mean_absolute_error: 3.105396, mean_q: 4.019130
514 (array([54]),) False
 191240/500000: episode: 4781, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.800 [12.000, 54.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.234370, mean_absolute_error: 3.043358, mean_q: 3.952722
608 (array([36]),) False
 191280/500000: episode: 4782, duration: 30.857s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 30.725 [9.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.218622, mean_absolute_error: 3.045362, mean_q: 3.960202
580 (array([22]),) False
 191320/500000: episode: 4783, duration: 30.817s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.600 [12.000, 40.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.214286, mean_absolute_error: 3.070947, mean_q: 3.965998
547 (array([21]),) False
 191360/500000: episode: 4784, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 17.625 [4.000, 25.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.239145, mean_absolute_error: 3.021548, mean_q: 3.905984
267 (array([22]),) False
 191400/500000: episode: 4785, duration: 30.849s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.125 [22.000, 27.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.218748, mean_absolute_error: 3.135316, mean_q: 4.035701
699 (array([22]),) False
 191440/500000: episode: 4786, duration: 30.881s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.525 [22.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.211954, mean_absolute_error: 3.069285, mean_q: 3.961003
128 (array([22]),) False
 191480/500000: episode: 4787, duration: 30.041s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.850 [8.000, 38.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.219629, mean_absolute_error: 3.119933, mean_q: 4.020445
861 (array([22]),) False
 191520/500000: episode: 4788, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.500 [10.000, 22.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.221523, mean_absolute_error: 3.100138, mean_q: 3.995238
528 (array([12]),) False
 191560/500000: episode: 4789, duration: 30.095s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 24.275 [0.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.208753, mean_absolute_error: 3.023682, mean_q: 3.926104
619 (array([3]),) False
 191600/500000: episode: 4790, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 14.825 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.210452, mean_absolute_error: 3.039913, mean_q: 3.942564
559 (array([59]),) False
 191640/500000: episode: 4791, duration: 30.009s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.150 [12.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.216108, mean_absolute_error: 3.126805, mean_q: 4.044985
597 (array([22]),) False
 191680/500000: episode: 4792, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.500 [5.000, 55.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.236462, mean_absolute_error: 3.072427, mean_q: 3.973184
796 (array([38]),) False
 191720/500000: episode: 4793, duration: 30.867s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 8.100 [3.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.229606, mean_absolute_error: 3.030071, mean_q: 3.927305
167 (array([22]),) False
 191760/500000: episode: 4794, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.825 [8.000, 31.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.214418, mean_absolute_error: 3.072898, mean_q: 3.992877
498 (array([12]),) False
 191800/500000: episode: 4795, duration: 30.879s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 28.525 [0.000, 48.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.219641, mean_absolute_error: 3.109506, mean_q: 4.037692
147 (array([44]),) False
 191840/500000: episode: 4796, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 23.725 [22.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.222065, mean_absolute_error: 3.051111, mean_q: 3.965574
48 (array([12]),) False
 191880/500000: episode: 4797, duration: 30.804s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 53.400 [13.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.225969, mean_absolute_error: 3.061978, mean_q: 3.966412
422 (array([48]),) False
 191920/500000: episode: 4798, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 37.350 [16.000, 54.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.230070, mean_absolute_error: 3.075788, mean_q: 3.980026
206 (array([22]),) False
 191960/500000: episode: 4799, duration: 30.007s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.500 [12.000, 54.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.211283, mean_absolute_error: 3.040910, mean_q: 3.936918
248 (array([12]),) False
 192000/500000: episode: 4800, duration: 30.925s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 21.925 [1.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.228262, mean_absolute_error: 3.101777, mean_q: 4.012120
487 (array([48]),) False
 192040/500000: episode: 4801, duration: 30.001s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 39.375 [22.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.221670, mean_absolute_error: 3.098577, mean_q: 3.999059
641 (array([22]),) False
 192080/500000: episode: 4802, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.200 [2.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.210138, mean_absolute_error: 3.060591, mean_q: 3.968796
461 (array([22]),) False
 192120/500000: episode: 4803, duration: 30.005s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.575 [7.000, 46.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.222060, mean_absolute_error: 3.092195, mean_q: 3.998170
827 (array([14]),) False
 192160/500000: episode: 4804, duration: 30.854s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 40.600 [22.000, 55.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.229831, mean_absolute_error: 3.073575, mean_q: 3.975665
48 (array([12]),) False
 192200/500000: episode: 4805, duration: 30.868s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 49.500 [9.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.208058, mean_absolute_error: 3.015232, mean_q: 3.914319
487 (array([48]),) False
 192240/500000: episode: 4806, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 37.275 [12.000, 48.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.234745, mean_absolute_error: 3.050802, mean_q: 3.954509
172 (array([12]),) False
 192280/500000: episode: 4807, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 19.075 [0.000, 60.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.217400, mean_absolute_error: 3.044916, mean_q: 3.949190
621 (array([22]),) False
 192320/500000: episode: 4808, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.175 [1.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.216385, mean_absolute_error: 3.062180, mean_q: 3.966274
693 (array([22]),) False
 192360/500000: episode: 4809, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.500 [9.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.240574, mean_absolute_error: 3.059587, mean_q: 3.969882
235 (array([14]),) False
 192400/500000: episode: 4810, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 28.000 [4.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.220612, mean_absolute_error: 3.067264, mean_q: 3.971621
177 (array([22]),) False
 192440/500000: episode: 4811, duration: 30.034s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 19.975 [8.000, 51.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.223150, mean_absolute_error: 3.077703, mean_q: 3.988832
88 (array([22]),) False
 192480/500000: episode: 4812, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.550 [11.000, 53.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.214699, mean_absolute_error: 3.111898, mean_q: 4.011527
380 (array([22]),) False
 192520/500000: episode: 4813, duration: 30.007s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.725 [1.000, 55.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.231461, mean_absolute_error: 3.045580, mean_q: 3.942903
204 (array([22]),) False
 192560/500000: episode: 4814, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.050 [10.000, 54.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.225703, mean_absolute_error: 3.090691, mean_q: 3.997038
533 (array([22]),) False
 192600/500000: episode: 4815, duration: 30.003s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.250 [7.000, 53.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.222497, mean_absolute_error: 3.145165, mean_q: 4.074025
838 (array([21]),) False
 192640/500000: episode: 4816, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.400 [1.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.222036, mean_absolute_error: 3.068689, mean_q: 3.974227
669 (array([15]),) False
 192680/500000: episode: 4817, duration: 30.810s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 34.250 [13.000, 55.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.222114, mean_absolute_error: 3.121546, mean_q: 4.047608
143 (array([12]),) False
 192720/500000: episode: 4818, duration: 30.813s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 18.275 [6.000, 43.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.241750, mean_absolute_error: 3.136096, mean_q: 4.066186
648 (array([22]),) False
 192760/500000: episode: 4819, duration: 30.847s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.223748, mean_absolute_error: 3.110826, mean_q: 4.036686
121 (array([22]),) False
 192800/500000: episode: 4820, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 17.650 [5.000, 52.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.223140, mean_absolute_error: 3.088651, mean_q: 4.015216
328 (array([12]),) False
 192840/500000: episode: 4821, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 15.575 [12.000, 46.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.210324, mean_absolute_error: 3.133808, mean_q: 4.054900
709 (array([41]),) False
 192880/500000: episode: 4822, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.950 [0.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.244463, mean_absolute_error: 3.061862, mean_q: 3.970123
755 (array([22]),) False
 192920/500000: episode: 4823, duration: 30.047s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.875 [12.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.223540, mean_absolute_error: 3.085584, mean_q: 4.004770
720 (array([22]),) False
 192960/500000: episode: 4824, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.575 [17.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.230324, mean_absolute_error: 3.131209, mean_q: 4.068862
338 (array([12]),) False
 193000/500000: episode: 4825, duration: 29.970s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 20.075 [2.000, 52.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.221855, mean_absolute_error: 3.070583, mean_q: 3.976720
529 (array([3]),) False
 193040/500000: episode: 4826, duration: 30.879s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 5.600 [3.000, 56.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.244201, mean_absolute_error: 3.064765, mean_q: 3.966236
279 (array([22]),) False
 193080/500000: episode: 4827, duration: 29.994s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 28.000 [21.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.218565, mean_absolute_error: 3.140517, mean_q: 4.046973
455 (array([22]),) False
 193120/500000: episode: 4828, duration: 30.873s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 44.050 [6.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.225577, mean_absolute_error: 3.074153, mean_q: 3.964222
239 (array([22]),) False
 193160/500000: episode: 4829, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.550 [4.000, 22.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.240173, mean_absolute_error: 3.132954, mean_q: 4.044775
496 (array([48]),) False
 193200/500000: episode: 4830, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 47.500 [26.000, 58.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.228720, mean_absolute_error: 3.054820, mean_q: 3.964277
572 (array([58]),) False
 193240/500000: episode: 4831, duration: 30.846s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 54.075 [1.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.228217, mean_absolute_error: 3.024752, mean_q: 3.917537
684 (array([22]),) False
 193280/500000: episode: 4832, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.550 [6.000, 60.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.233180, mean_absolute_error: 3.032371, mean_q: 3.917131
576 (array([58]),) False
 193320/500000: episode: 4833, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 55.650 [32.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.212286, mean_absolute_error: 3.012555, mean_q: 3.911501
369 (array([48]),) False
 193360/500000: episode: 4834, duration: 30.892s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 48.125 [48.000, 53.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.237380, mean_absolute_error: 3.119302, mean_q: 4.033990
695 (array([22]),) False
 193400/500000: episode: 4835, duration: 30.077s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.650 [22.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.214500, mean_absolute_error: 3.043222, mean_q: 3.950618
149 (array([8]),) False
 193440/500000: episode: 4836, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 10.550 [5.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.240174, mean_absolute_error: 3.015502, mean_q: 3.922889
546 (array([22]),) False
 193480/500000: episode: 4837, duration: 30.034s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.700 [5.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.226259, mean_absolute_error: 3.029221, mean_q: 3.943726
151 (array([22]),) False
 193520/500000: episode: 4838, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.975 [16.000, 54.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.240454, mean_absolute_error: 3.050459, mean_q: 3.960690
810 (array([12]),) False
 193560/500000: episode: 4839, duration: 30.044s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.825 [8.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.229522, mean_absolute_error: 3.056484, mean_q: 3.978872
58 (array([48]),) False
 193600/500000: episode: 4840, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.200 [2.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.237310, mean_absolute_error: 3.064149, mean_q: 3.968058
19 (array([12]),) False
 193640/500000: episode: 4841, duration: 30.856s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.400 [4.000, 59.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.243563, mean_absolute_error: 3.043140, mean_q: 3.939679
8 (array([22]),) False
 193680/500000: episode: 4842, duration: 30.903s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 28.150 [3.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.223872, mean_absolute_error: 3.067578, mean_q: 3.961413
855 (array([12]),) False
 193720/500000: episode: 4843, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 15.725 [12.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.231152, mean_absolute_error: 3.037217, mean_q: 3.937604
273 (array([22]),) False
 193760/500000: episode: 4844, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.625 [2.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.237597, mean_absolute_error: 3.033164, mean_q: 3.937132
495 (array([48]),) False
 193800/500000: episode: 4845, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.600 [38.000, 50.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.223348, mean_absolute_error: 3.031448, mean_q: 3.950125
610 (array([48]),) False
 193840/500000: episode: 4846, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.975 [1.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.217608, mean_absolute_error: 3.057088, mean_q: 3.991074
690 (array([22]),) False
 193880/500000: episode: 4847, duration: 30.009s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.900 [7.000, 46.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.221519, mean_absolute_error: 3.059892, mean_q: 3.973907
674 (array([48]),) False
 193920/500000: episode: 4848, duration: 30.888s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 26.825 [5.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.214310, mean_absolute_error: 3.055305, mean_q: 3.961355
586 (array([12]),) False
 193960/500000: episode: 4849, duration: 29.954s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 13.525 [11.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.214038, mean_absolute_error: 3.044768, mean_q: 3.936996
240 (array([22]),) False
 194000/500000: episode: 4850, duration: 30.844s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.150 [2.000, 52.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.218527, mean_absolute_error: 3.044195, mean_q: 3.929335
73 (array([22]),) False
 194040/500000: episode: 4851, duration: 30.068s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.300 [7.000, 22.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.217338, mean_absolute_error: 3.006476, mean_q: 3.887683
278 (array([48]),) False
 194080/500000: episode: 4852, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 38.250 [7.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.216848, mean_absolute_error: 3.059386, mean_q: 3.955890
573 (array([22]),) False
 194120/500000: episode: 4853, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 17.400 [3.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.223961, mean_absolute_error: 3.005856, mean_q: 3.905383
187 (array([15]),) False
 194160/500000: episode: 4854, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 23.550 [12.000, 58.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.225938, mean_absolute_error: 3.009943, mean_q: 3.905779
382 (array([22]),) False
 194200/500000: episode: 4855, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.850 [12.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.216747, mean_absolute_error: 3.053679, mean_q: 3.956776
798 (array([18]),) False
 194240/500000: episode: 4856, duration: 30.846s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.225 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.221975, mean_absolute_error: 3.069028, mean_q: 3.989101
620 (array([44]),) False
 194280/500000: episode: 4857, duration: 30.816s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 31.050 [10.000, 56.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.212916, mean_absolute_error: 3.075821, mean_q: 3.979245
351 (array([22]),) False
 194320/500000: episode: 4858, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 20.750 [3.000, 49.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.224927, mean_absolute_error: 3.042761, mean_q: 3.945580
99 (array([22]),) False
 194360/500000: episode: 4859, duration: 30.252s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [4.000, 53.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.217188, mean_absolute_error: 3.051065, mean_q: 3.944545
399 (array([22]),) False
 194400/500000: episode: 4860, duration: 31.279s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 32.125 [3.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.224084, mean_absolute_error: 3.025780, mean_q: 3.928907
757 (array([48]),) False
 194440/500000: episode: 4861, duration: 30.318s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 43.925 [0.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.223132, mean_absolute_error: 3.060475, mean_q: 3.967445
775 (array([58]),) False
 194480/500000: episode: 4862, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 55.750 [7.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.234624, mean_absolute_error: 3.049060, mean_q: 3.960256
29 (array([22]),) False
 194520/500000: episode: 4863, duration: 30.819s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.575 [0.000, 34.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.237751, mean_absolute_error: 3.037434, mean_q: 3.941389
87 (array([3]),) False
 194560/500000: episode: 4864, duration: 31.450s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 25.725 [3.000, 52.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.215943, mean_absolute_error: 3.053495, mean_q: 3.964785
498 (array([12]),) False
 194600/500000: episode: 4865, duration: 31.672s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 41.900 [7.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.220732, mean_absolute_error: 3.015360, mean_q: 3.917181
173 (array([3]),) False
 194640/500000: episode: 4866, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 4.900 [3.000, 44.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.212884, mean_absolute_error: 3.065010, mean_q: 3.971540
593 (array([37]),) False
 194680/500000: episode: 4867, duration: 30.853s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.800 [12.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.234690, mean_absolute_error: 3.015284, mean_q: 3.918174
678 (array([22]),) False
 194720/500000: episode: 4868, duration: 31.308s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.850 [22.000, 55.000], mean observation: -0.107 [-1.000, 1.000], loss: 0.220746, mean_absolute_error: 2.987990, mean_q: 3.885255
275 (array([12]),) False
 194760/500000: episode: 4869, duration: 31.407s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 18.400 [3.000, 56.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.208153, mean_absolute_error: 2.964213, mean_q: 3.870114
300 (array([22]),) False
 194800/500000: episode: 4870, duration: 31.180s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 25.675 [10.000, 49.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.237563, mean_absolute_error: 3.033314, mean_q: 3.940043
272 (array([12]),) False
 194840/500000: episode: 4871, duration: 30.407s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 15.250 [3.000, 37.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.234961, mean_absolute_error: 3.025955, mean_q: 3.930898
39 (array([22]),) False
 194880/500000: episode: 4872, duration: 31.226s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.400 [6.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.235620, mean_absolute_error: 3.043367, mean_q: 3.951040
275 (array([12]),) False
 194920/500000: episode: 4873, duration: 30.316s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 17.575 [3.000, 42.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.224015, mean_absolute_error: 2.934789, mean_q: 3.821800
174 (array([33]),) False
 194960/500000: episode: 4874, duration: 31.083s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.325 [12.000, 43.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.229214, mean_absolute_error: 2.966833, mean_q: 3.848748
172 (array([12]),) False
 195000/500000: episode: 4875, duration: 30.492s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 20.975 [12.000, 49.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.228125, mean_absolute_error: 2.990346, mean_q: 3.890112
13 (array([48]),) False
 195040/500000: episode: 4876, duration: 31.015s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 42.625 [19.000, 55.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.236908, mean_absolute_error: 3.004924, mean_q: 3.887466
377 (array([22]),) False
 195080/500000: episode: 4877, duration: 31.135s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.175 [14.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.218699, mean_absolute_error: 3.001313, mean_q: 3.904388
317 (array([12]),) False
 195120/500000: episode: 4878, duration: 31.115s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 31.075 [12.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.220885, mean_absolute_error: 3.042293, mean_q: 3.934209
680 (array([22]),) False
 195160/500000: episode: 4879, duration: 31.099s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.575 [15.000, 44.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.237743, mean_absolute_error: 3.016266, mean_q: 3.912043
677 (array([48]),) False
 195200/500000: episode: 4880, duration: 31.132s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.850 [1.000, 55.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.225157, mean_absolute_error: 3.000470, mean_q: 3.879979
362 (array([22]),) False
 195240/500000: episode: 4881, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.125 [11.000, 55.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.238765, mean_absolute_error: 3.015591, mean_q: 3.909433
14 (array([48]),) False
 195280/500000: episode: 4882, duration: 31.158s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 37.975 [19.000, 51.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.223557, mean_absolute_error: 2.982342, mean_q: 3.873890
370 (array([58]),) False
 195320/500000: episode: 4883, duration: 30.242s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.375 [0.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.230920, mean_absolute_error: 3.046015, mean_q: 3.945755
358 (array([22]),) False
 195360/500000: episode: 4884, duration: 31.113s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.850 [8.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.225805, mean_absolute_error: 3.000282, mean_q: 3.890408
138 (array([3]),) False
 195400/500000: episode: 4885, duration: 30.428s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 14.025 [3.000, 52.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.228169, mean_absolute_error: 3.034801, mean_q: 3.925831
648 (array([22]),) False
 195440/500000: episode: 4886, duration: 31.050s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.450 [2.000, 39.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.238732, mean_absolute_error: 3.046457, mean_q: 3.939711
18 (array([22]),) False
 195480/500000: episode: 4887, duration: 30.583s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.700 [22.000, 52.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.224288, mean_absolute_error: 3.005336, mean_q: 3.883077
78 (array([55]),) False
 195520/500000: episode: 4888, duration: 31.475s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.800 [13.000, 23.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.209636, mean_absolute_error: 2.980875, mean_q: 3.872079
795 (array([3]),) False
 195560/500000: episode: 4889, duration: 31.438s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 7.750 [3.000, 58.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.232879, mean_absolute_error: 3.034659, mean_q: 3.936113
718 (array([12]),) False
 195600/500000: episode: 4890, duration: 31.298s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 14.575 [12.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.225606, mean_absolute_error: 3.017601, mean_q: 3.923733
827 (array([14]),) False
 195640/500000: episode: 4891, duration: 31.106s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 41.850 [12.000, 55.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.208447, mean_absolute_error: 2.961053, mean_q: 3.854356
21 (array([3]),) False
 195680/500000: episode: 4892, duration: 31.352s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.625 [3.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.229369, mean_absolute_error: 2.997722, mean_q: 3.891936
563 (array([22]),) False
 195720/500000: episode: 4893, duration: 31.457s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.600 [12.000, 47.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.225485, mean_absolute_error: 3.019098, mean_q: 3.916135
493 (array([22]),) False
 195760/500000: episode: 4894, duration: 31.298s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.850 [7.000, 42.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.226044, mean_absolute_error: 3.055532, mean_q: 3.953278
826 (array([22]),) False
 195800/500000: episode: 4895, duration: 30.587s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.550 [12.000, 54.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.243048, mean_absolute_error: 3.027962, mean_q: 3.928258
700 (array([44]),) False
 195840/500000: episode: 4896, duration: 31.042s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 48.550 [18.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.216880, mean_absolute_error: 3.049395, mean_q: 3.957757
308 (array([22]),) False
 195880/500000: episode: 4897, duration: 30.045s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.025 [2.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.215960, mean_absolute_error: 3.040546, mean_q: 3.943490
768 (array([22]),) False
 195920/500000: episode: 4898, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.875 [22.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.216440, mean_absolute_error: 2.984957, mean_q: 3.890753
466 (array([22]),) False
 195960/500000: episode: 4899, duration: 30.130s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.350 [0.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.247342, mean_absolute_error: 2.992292, mean_q: 3.894403
303 (array([22]),) False
 196000/500000: episode: 4900, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.175 [11.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.224298, mean_absolute_error: 2.982332, mean_q: 3.890862
726 (array([12]),) False
 196040/500000: episode: 4901, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 14.750 [3.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.240473, mean_absolute_error: 3.016842, mean_q: 3.924544
430 (array([22]),) False
 196080/500000: episode: 4902, duration: 31.044s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.600 [22.000, 30.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.229869, mean_absolute_error: 3.010518, mean_q: 3.930338
490 (array([12]),) False
 196120/500000: episode: 4903, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 12.600 [0.000, 54.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.208936, mean_absolute_error: 3.049931, mean_q: 3.979271
805 (array([22]),) False
 196160/500000: episode: 4904, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.700 [22.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.222598, mean_absolute_error: 3.023797, mean_q: 3.930301
611 (array([22]),) False
 196200/500000: episode: 4905, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 39.400 [7.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.222388, mean_absolute_error: 3.043611, mean_q: 3.950763
0 (array([48]),) False
 196240/500000: episode: 4906, duration: 31.118s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.450 [0.000, 22.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.204970, mean_absolute_error: 3.010526, mean_q: 3.915708
666 (array([22]),) False
 196280/500000: episode: 4907, duration: 30.192s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 29.625 [10.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.216210, mean_absolute_error: 2.989141, mean_q: 3.898032
315 (array([12]),) False
 196320/500000: episode: 4908, duration: 31.108s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 26.150 [4.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.220137, mean_absolute_error: 3.013062, mean_q: 3.920977
591 (array([22]),) False
 196360/500000: episode: 4909, duration: 30.195s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.475 [12.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.217032, mean_absolute_error: 3.006217, mean_q: 3.915754
64 (array([12]),) False
 196400/500000: episode: 4910, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 18.775 [8.000, 44.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.207953, mean_absolute_error: 2.985154, mean_q: 3.886811
608 (array([36]),) False
 196440/500000: episode: 4911, duration: 30.140s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 34.625 [1.000, 37.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.229387, mean_absolute_error: 3.023203, mean_q: 3.932333
604 (array([40]),) False
 196480/500000: episode: 4912, duration: 31.103s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.650 [10.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.213108, mean_absolute_error: 2.976148, mean_q: 3.875944
703 (array([3]),) False
 196520/500000: episode: 4913, duration: 31.020s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 7.525 [3.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.221923, mean_absolute_error: 2.975953, mean_q: 3.861266
507 (array([44]),) False
 196560/500000: episode: 4914, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.300 [11.000, 48.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.234651, mean_absolute_error: 3.013034, mean_q: 3.926039
229 (array([48]),) False
 196600/500000: episode: 4915, duration: 31.095s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 25.275 [0.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.216953, mean_absolute_error: 2.956285, mean_q: 3.844690
469 (array([22]),) False
 196640/500000: episode: 4916, duration: 31.046s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.550 [16.000, 50.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.247421, mean_absolute_error: 3.021764, mean_q: 3.920480
316 (array([12]),) False
 196680/500000: episode: 4917, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 14.450 [12.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.218236, mean_absolute_error: 2.989866, mean_q: 3.896813
639 (array([22]),) False
 196720/500000: episode: 4918, duration: 31.119s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.050 [1.000, 38.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.244142, mean_absolute_error: 2.983454, mean_q: 3.891043
608 (array([36]),) False
 196760/500000: episode: 4919, duration: 30.247s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 35.600 [10.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.212061, mean_absolute_error: 3.005102, mean_q: 3.915170
65 (array([48]),) False
 196800/500000: episode: 4920, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 16.100 [0.000, 32.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.231667, mean_absolute_error: 2.966260, mean_q: 3.866013
809 (array([48]),) False
 196840/500000: episode: 4921, duration: 30.135s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 39.875 [9.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.224469, mean_absolute_error: 2.999420, mean_q: 3.914845
497 (array([33]),) False
 196880/500000: episode: 4922, duration: 31.078s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.700 [4.000, 53.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.208551, mean_absolute_error: 2.965238, mean_q: 3.863953
584 (array([36]),) False
 196920/500000: episode: 4923, duration: 30.156s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 4.025 [2.000, 27.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.208534, mean_absolute_error: 2.996343, mean_q: 3.903484
581 (array([22]),) False
 196960/500000: episode: 4924, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.825 [22.000, 55.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.219552, mean_absolute_error: 2.947356, mean_q: 3.839381
497 (array([33]),) False
 197000/500000: episode: 4925, duration: 31.101s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.275 [7.000, 54.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.211604, mean_absolute_error: 2.975687, mean_q: 3.891941
627 (array([48]),) False
 197040/500000: episode: 4926, duration: 31.076s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 44.775 [10.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.221323, mean_absolute_error: 2.973207, mean_q: 3.881402
126 (array([22]),) False
 197080/500000: episode: 4927, duration: 31.034s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 19.025 [12.000, 43.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.229478, mean_absolute_error: 2.958668, mean_q: 3.867851
373 (array([22]),) False
 197120/500000: episode: 4928, duration: 31.086s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.850 [2.000, 52.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.227233, mean_absolute_error: 2.962059, mean_q: 3.862578
41 (array([12]),) False
 197160/500000: episode: 4929, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.175 [22.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.216049, mean_absolute_error: 2.902804, mean_q: 3.801115
599 (array([48]),) False
 197200/500000: episode: 4930, duration: 31.118s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 40.325 [8.000, 48.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.226055, mean_absolute_error: 2.950974, mean_q: 3.857645
31 (array([48]),) False
 197240/500000: episode: 4931, duration: 30.388s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.125 [0.000, 59.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.221366, mean_absolute_error: 2.954785, mean_q: 3.861493
526 (array([22]),) False
 197280/500000: episode: 4932, duration: 31.082s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.025 [0.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.211059, mean_absolute_error: 3.007050, mean_q: 3.906539
743 (array([48]),) False
 197320/500000: episode: 4933, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 43.325 [5.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.240055, mean_absolute_error: 2.952964, mean_q: 3.857429
312 (array([12]),) False
 197360/500000: episode: 4934, duration: 30.871s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 49.375 [30.000, 55.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.217038, mean_absolute_error: 3.042409, mean_q: 3.968245
717 (array([22]),) False
 197400/500000: episode: 4935, duration: 30.200s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.275 [0.000, 35.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.218935, mean_absolute_error: 2.932296, mean_q: 3.832984
39 (array([22]),) False
 197440/500000: episode: 4936, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.625 [8.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.220140, mean_absolute_error: 2.972473, mean_q: 3.882168
14 (array([48]),) False
 197480/500000: episode: 4937, duration: 30.962s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 41.675 [22.000, 48.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.217409, mean_absolute_error: 2.970407, mean_q: 3.876113
440 (array([22]),) False
 197520/500000: episode: 4938, duration: 30.926s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.550 [2.000, 24.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.240444, mean_absolute_error: 2.996788, mean_q: 3.909577
97 (array([22]),) False
 197560/500000: episode: 4939, duration: 30.970s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.675 [8.000, 55.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.214804, mean_absolute_error: 3.019442, mean_q: 3.929137
837 (array([48]),) False
 197600/500000: episode: 4940, duration: 31.019s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 47.825 [41.000, 48.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.222610, mean_absolute_error: 2.964994, mean_q: 3.862875
604 (array([40]),) False
 197640/500000: episode: 4941, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 36.175 [12.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.221366, mean_absolute_error: 3.005922, mean_q: 3.913807
524 (array([22]),) False
 197680/500000: episode: 4942, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.300 [9.000, 52.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.229205, mean_absolute_error: 2.976866, mean_q: 3.886330
591 (array([22]),) False
 197720/500000: episode: 4943, duration: 30.366s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.175 [15.000, 47.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.241289, mean_absolute_error: 2.957784, mean_q: 3.856747
209 (array([8]),) False
 197760/500000: episode: 4944, duration: 31.175s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 30.650 [4.000, 54.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.227327, mean_absolute_error: 3.005394, mean_q: 3.903311
749 (array([22]),) False
 197800/500000: episode: 4945, duration: 30.435s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.625 [8.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.232288, mean_absolute_error: 3.022370, mean_q: 3.945210
796 (array([38]),) False
 197840/500000: episode: 4946, duration: 31.133s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 16.300 [4.000, 50.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.233684, mean_absolute_error: 2.937031, mean_q: 3.836775
533 (array([22]),) False
 197880/500000: episode: 4947, duration: 30.552s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.725 [12.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.213485, mean_absolute_error: 2.974278, mean_q: 3.883582
416 (array([22]),) False
 197920/500000: episode: 4948, duration: 31.465s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.250 [11.000, 50.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.221428, mean_absolute_error: 2.950044, mean_q: 3.857751
785 (array([22]),) False
 197960/500000: episode: 4949, duration: 31.313s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.400 [18.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.228772, mean_absolute_error: 2.938175, mean_q: 3.839868
636 (array([12]),) False
 198000/500000: episode: 4950, duration: 31.245s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 42.050 [12.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.221648, mean_absolute_error: 2.975951, mean_q: 3.886487
556 (array([48]),) False
 198040/500000: episode: 4951, duration: 31.472s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 47.550 [30.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.215764, mean_absolute_error: 2.950314, mean_q: 3.866052
256 (array([22]),) False
 198080/500000: episode: 4952, duration: 31.057s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.050 [3.000, 43.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.223312, mean_absolute_error: 2.970127, mean_q: 3.869008
374 (array([22]),) False
 198120/500000: episode: 4953, duration: 31.088s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.475 [6.000, 40.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.221314, mean_absolute_error: 2.945997, mean_q: 3.844220
583 (array([22]),) False
 198160/500000: episode: 4954, duration: 31.195s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 15.275 [1.000, 44.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.215154, mean_absolute_error: 2.958468, mean_q: 3.864703
680 (array([22]),) False
 198200/500000: episode: 4955, duration: 30.232s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.750 [1.000, 53.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.215306, mean_absolute_error: 2.939077, mean_q: 3.834998
450 (array([8]),) False
 198240/500000: episode: 4956, duration: 31.177s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 30.625 [0.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.244553, mean_absolute_error: 2.923461, mean_q: 3.819410
757 (array([48]),) False
 198280/500000: episode: 4957, duration: 30.311s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.450 [12.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.223008, mean_absolute_error: 2.924846, mean_q: 3.823931
31 (array([48]),) False
 198320/500000: episode: 4958, duration: 31.028s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.025 [4.000, 40.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.214762, mean_absolute_error: 2.948969, mean_q: 3.846572
178 (array([38]),) False
 198360/500000: episode: 4959, duration: 30.284s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.400 [6.000, 52.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.221048, mean_absolute_error: 2.978923, mean_q: 3.895141
121 (array([22]),) False
 198400/500000: episode: 4960, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 16.950 [12.000, 41.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.230780, mean_absolute_error: 3.012811, mean_q: 3.929822
522 (array([22]),) False
 198440/500000: episode: 4961, duration: 31.120s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.800 [8.000, 37.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.234499, mean_absolute_error: 2.977837, mean_q: 3.899665
426 (array([22]),) False
 198480/500000: episode: 4962, duration: 31.090s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.550 [16.000, 45.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.207157, mean_absolute_error: 2.999843, mean_q: 3.916135
839 (array([22]),) False
 198520/500000: episode: 4963, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.600 [10.000, 46.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.233821, mean_absolute_error: 2.978772, mean_q: 3.878874
358 (array([22]),) False
 198560/500000: episode: 4964, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.600 [9.000, 49.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.239764, mean_absolute_error: 2.982416, mean_q: 3.899973
474 (array([22]),) False
 198600/500000: episode: 4965, duration: 30.935s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.050 [5.000, 56.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.217311, mean_absolute_error: 2.951370, mean_q: 3.865257
234 (array([22]),) False
 198640/500000: episode: 4966, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.950 [6.000, 48.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.220711, mean_absolute_error: 2.995725, mean_q: 3.900179
119 (array([45]),) False
 198680/500000: episode: 4967, duration: 30.209s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 13.275 [3.000, 44.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.231531, mean_absolute_error: 3.028352, mean_q: 3.943882
768 (array([22]),) False
 198720/500000: episode: 4968, duration: 31.074s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.450 [0.000, 22.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.204963, mean_absolute_error: 2.926135, mean_q: 3.832909
274 (array([12]),) False
 198760/500000: episode: 4969, duration: 30.242s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 11.375 [3.000, 35.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.239870, mean_absolute_error: 3.003326, mean_q: 3.916554
827 (array([14]),) False
 198800/500000: episode: 4970, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 40.700 [12.000, 56.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.222951, mean_absolute_error: 2.959368, mean_q: 3.867292
584 (array([36]),) False
 198840/500000: episode: 4971, duration: 30.652s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 6.475 [3.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.214887, mean_absolute_error: 2.989906, mean_q: 3.914167
646 (array([44]),) False
 198880/500000: episode: 4972, duration: 31.554s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 29.450 [3.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.225929, mean_absolute_error: 2.964467, mean_q: 3.868299
67 (array([8]),) False
 198920/500000: episode: 4973, duration: 31.587s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 7.600 [3.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.237783, mean_absolute_error: 3.007088, mean_q: 3.931972
265 (array([22]),) False
 198960/500000: episode: 4974, duration: 31.567s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 22.225 [0.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.218370, mean_absolute_error: 2.915879, mean_q: 3.815872
87 (array([3]),) False
 199000/500000: episode: 4975, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 12.075 [0.000, 51.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.232649, mean_absolute_error: 2.973214, mean_q: 3.889248
340 (array([12]),) False
 199040/500000: episode: 4976, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 18.375 [7.000, 52.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.224802, mean_absolute_error: 3.025499, mean_q: 3.948197
440 (array([22]),) False
 199080/500000: episode: 4977, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.325 [0.000, 46.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.225464, mean_absolute_error: 2.959719, mean_q: 3.876223
545 (array([22]),) False
 199120/500000: episode: 4978, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.475 [2.000, 50.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.216723, mean_absolute_error: 3.018915, mean_q: 3.923131
162 (array([22]),) False
 199160/500000: episode: 4979, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.775 [5.000, 50.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.213947, mean_absolute_error: 2.974109, mean_q: 3.895854
577 (array([12]),) False
 199200/500000: episode: 4980, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 14.750 [6.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.211124, mean_absolute_error: 3.049088, mean_q: 3.969502
295 (array([22]),) False
 199240/500000: episode: 4981, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.300 [0.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.235420, mean_absolute_error: 2.982410, mean_q: 3.888957
470 (array([22]),) False
 199280/500000: episode: 4982, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.150 [3.000, 22.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.225631, mean_absolute_error: 2.969893, mean_q: 3.875710
344 (array([22]),) False
 199320/500000: episode: 4983, duration: 32.123s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.925 [8.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.213922, mean_absolute_error: 3.035599, mean_q: 3.959474
54 (array([8]),) False
 199360/500000: episode: 4984, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 21.550 [3.000, 60.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.232065, mean_absolute_error: 3.012443, mean_q: 3.928578
692 (array([22]),) False
 199400/500000: episode: 4985, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.700 [2.000, 44.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.225228, mean_absolute_error: 3.015122, mean_q: 3.942404
70 (array([22]),) False
 199440/500000: episode: 4986, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 46.650 [12.000, 53.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.224964, mean_absolute_error: 3.002972, mean_q: 3.923134
61 (array([48]),) False
 199480/500000: episode: 4987, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.550 [22.000, 36.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.227531, mean_absolute_error: 3.039388, mean_q: 3.960399
41 (array([12]),) False
 199520/500000: episode: 4988, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.219490, mean_absolute_error: 3.042387, mean_q: 3.961317
95 (array([22]),) False
 199560/500000: episode: 4989, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.775 [12.000, 55.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.233858, mean_absolute_error: 2.995097, mean_q: 3.903873
405 (array([22]),) False
 199600/500000: episode: 4990, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.325 [22.000, 35.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.216648, mean_absolute_error: 3.072550, mean_q: 3.992681
216 (array([22]),) False
 199640/500000: episode: 4991, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.450 [3.000, 45.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.223751, mean_absolute_error: 3.047225, mean_q: 3.970792
650 (array([22]),) False
 199680/500000: episode: 4992, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 24.275 [22.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.223232, mean_absolute_error: 3.047743, mean_q: 3.973202
438 (array([22]),) False
 199720/500000: episode: 4993, duration: 32.215s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.550 [17.000, 34.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.226494, mean_absolute_error: 3.042572, mean_q: 3.956224
414 (array([48]),) False
 199760/500000: episode: 4994, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 32.700 [1.000, 56.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.236252, mean_absolute_error: 2.983336, mean_q: 3.888904
795 (array([3]),) False
 199800/500000: episode: 4995, duration: 32.223s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 9.925 [3.000, 60.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.234494, mean_absolute_error: 3.028551, mean_q: 3.931450
759 (array([48]),) False
 199840/500000: episode: 4996, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 44.775 [16.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.232637, mean_absolute_error: 2.993719, mean_q: 3.901401
580 (array([22]),) False
 199880/500000: episode: 4997, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.700 [8.000, 47.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.229534, mean_absolute_error: 3.018859, mean_q: 3.935530
2 (array([12]),) False
 199920/500000: episode: 4998, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.125 [14.000, 47.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.218323, mean_absolute_error: 3.016698, mean_q: 3.914696
110 (array([22]),) False
 199960/500000: episode: 4999, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 21.850 [8.000, 45.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.231546, mean_absolute_error: 2.998102, mean_q: 3.897648
781 (array([8]),) False
 200000/500000: episode: 5000, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 31.100 [3.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.244660, mean_absolute_error: 2.966574, mean_q: 3.863710
6 (array([58]),) False
 200040/500000: episode: 5001, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.775 [9.000, 53.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.219208, mean_absolute_error: 3.038855, mean_q: 3.932511
700 (array([44]),) False
 200080/500000: episode: 5002, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 43.250 [3.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.233187, mean_absolute_error: 3.027286, mean_q: 3.922463
385 (array([30]),) False
 200120/500000: episode: 5003, duration: 32.238s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.100 [22.000, 37.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.224850, mean_absolute_error: 3.024138, mean_q: 3.913219
452 (array([22]),) False
 200160/500000: episode: 5004, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.150 [2.000, 60.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.219277, mean_absolute_error: 3.019198, mean_q: 3.917318
434 (array([22]),) False
 200200/500000: episode: 5005, duration: 32.228s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.229296, mean_absolute_error: 3.024372, mean_q: 3.910767
754 (array([52]),) False
 200240/500000: episode: 5006, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.250 [3.000, 51.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.245812, mean_absolute_error: 2.978180, mean_q: 3.859725
56 (array([12]),) False
 200280/500000: episode: 5007, duration: 32.284s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 12.825 [8.000, 50.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.233014, mean_absolute_error: 3.007973, mean_q: 3.890401
849 (array([3]),) False
 200320/500000: episode: 5008, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 50.500 [3.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.222059, mean_absolute_error: 3.014992, mean_q: 3.915119
224 (array([12]),) False
 200360/500000: episode: 5009, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.500 [2.000, 57.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.222022, mean_absolute_error: 2.999851, mean_q: 3.895055
654 (array([22]),) False
 200400/500000: episode: 5010, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.550 [9.000, 43.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.203873, mean_absolute_error: 3.030805, mean_q: 3.921172
835 (array([50]),) False
 200440/500000: episode: 5011, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.050 [3.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.246444, mean_absolute_error: 3.006974, mean_q: 3.904181
645 (array([48]),) False
 200480/500000: episode: 5012, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.050 [15.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.229234, mean_absolute_error: 2.958551, mean_q: 3.844000
857 (array([22]),) False
 200520/500000: episode: 5013, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 18.875 [5.000, 45.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.224693, mean_absolute_error: 2.937303, mean_q: 3.830424
264 (array([12]),) False
 200560/500000: episode: 5014, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.550 [8.000, 40.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.233130, mean_absolute_error: 2.942917, mean_q: 3.846828
590 (array([22]),) False
 200600/500000: episode: 5015, duration: 32.321s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.550 [1.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.228256, mean_absolute_error: 2.996506, mean_q: 3.911775
142 (array([12]),) False
 200640/500000: episode: 5016, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 13.100 [12.000, 46.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.212404, mean_absolute_error: 2.969973, mean_q: 3.881712
84 (array([22]),) False
 200680/500000: episode: 5017, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.700 [3.000, 48.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.223636, mean_absolute_error: 2.993310, mean_q: 3.906970
90 (array([22]),) False
 200720/500000: episode: 5018, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.100 [8.000, 45.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.236076, mean_absolute_error: 2.958079, mean_q: 3.859236
218 (array([22]),) False
 200760/500000: episode: 5019, duration: 32.153s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.925 [22.000, 57.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.232389, mean_absolute_error: 2.980912, mean_q: 3.888138
46 (array([22]),) False
 200800/500000: episode: 5020, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.875 [12.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.216116, mean_absolute_error: 2.952306, mean_q: 3.841577
666 (array([22]),) False
 200840/500000: episode: 5021, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 20.675 [4.000, 50.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.226055, mean_absolute_error: 3.026461, mean_q: 3.920192
582 (array([44]),) False
 200880/500000: episode: 5022, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 19.925 [12.000, 40.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.215400, mean_absolute_error: 2.967284, mean_q: 3.861153
666 (array([22]),) False
 200920/500000: episode: 5023, duration: 32.886s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.950 [0.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.235714, mean_absolute_error: 3.013833, mean_q: 3.906285
4 (array([22]),) False
 200960/500000: episode: 5024, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.900 [22.000, 55.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.221379, mean_absolute_error: 3.012395, mean_q: 3.915697
206 (array([22]),) False
 201000/500000: episode: 5025, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 21.750 [5.000, 54.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.227123, mean_absolute_error: 2.988685, mean_q: 3.882201
623 (array([37]),) False
 201040/500000: episode: 5026, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 25.425 [3.000, 36.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.223111, mean_absolute_error: 3.024168, mean_q: 3.934335
627 (array([48]),) False
 201080/500000: episode: 5027, duration: 32.302s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.000 [26.000, 48.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.231331, mean_absolute_error: 3.037209, mean_q: 3.941821
645 (array([48]),) False
 201120/500000: episode: 5028, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 47.250 [6.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.247533, mean_absolute_error: 3.015043, mean_q: 3.924933
315 (array([12]),) False
 201160/500000: episode: 5029, duration: 32.298s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 30.600 [12.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.234688, mean_absolute_error: 3.022991, mean_q: 3.923669
294 (array([22]),) False
 201200/500000: episode: 5030, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.800 [2.000, 41.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.216909, mean_absolute_error: 3.093676, mean_q: 4.014174
411 (array([22]),) False
 201240/500000: episode: 5031, duration: 32.273s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.675 [22.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.260271, mean_absolute_error: 3.038926, mean_q: 3.946644
539 (array([22]),) False
 201280/500000: episode: 5032, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 28.275 [3.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.254475, mean_absolute_error: 3.005729, mean_q: 3.917520
460 (array([36]),) False
 201320/500000: episode: 5033, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.775 [2.000, 44.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.227257, mean_absolute_error: 2.986133, mean_q: 3.900953
446 (array([22]),) False
 201360/500000: episode: 5034, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.025 [22.000, 43.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.231926, mean_absolute_error: 3.040940, mean_q: 3.946781
453 (array([22]),) False
 201400/500000: episode: 5035, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 22.250 [9.000, 46.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.227427, mean_absolute_error: 3.063653, mean_q: 3.977158
713 (array([37]),) False
 201440/500000: episode: 5036, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 15.700 [12.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.223903, mean_absolute_error: 3.021114, mean_q: 3.923027
730 (array([54]),) False
 201480/500000: episode: 5037, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 50.600 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.232460, mean_absolute_error: 3.012884, mean_q: 3.893881
190 (array([3]),) False
 201520/500000: episode: 5038, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 4.900 [3.000, 39.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.232314, mean_absolute_error: 3.009668, mean_q: 3.893822
211 (array([22]),) False
 201560/500000: episode: 5039, duration: 32.270s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.325 [9.000, 43.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.232074, mean_absolute_error: 3.014504, mean_q: 3.907185
496 (array([48]),) False
 201600/500000: episode: 5040, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 48.125 [47.000, 54.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.227387, mean_absolute_error: 3.058348, mean_q: 3.964625
180 (array([48]),) False
 201640/500000: episode: 5041, duration: 32.163s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 46.700 [2.000, 48.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.233343, mean_absolute_error: 3.079419, mean_q: 3.980443
190 (array([3]),) False
 201680/500000: episode: 5042, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 5.050 [3.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.217658, mean_absolute_error: 3.020680, mean_q: 3.909543
546 (array([22]),) False
 201720/500000: episode: 5043, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.850 [12.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.228631, mean_absolute_error: 3.055036, mean_q: 3.957348
274 (array([12]),) False
 201760/500000: episode: 5044, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 13.375 [0.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.248231, mean_absolute_error: 3.047829, mean_q: 3.952443
203 (array([48]),) False
 201800/500000: episode: 5045, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.500 [23.000, 48.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.224137, mean_absolute_error: 2.977000, mean_q: 3.874948
257 (array([22]),) False
 201840/500000: episode: 5046, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.625 [15.000, 49.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.262301, mean_absolute_error: 3.004606, mean_q: 3.906441
276 (array([56]),) False
 201880/500000: episode: 5047, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 11.225 [3.000, 34.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.223558, mean_absolute_error: 3.022734, mean_q: 3.928536
207 (array([36]),) False
 201920/500000: episode: 5048, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 19.675 [0.000, 54.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.241618, mean_absolute_error: 2.978408, mean_q: 3.880848
220 (array([22]),) False
 201960/500000: episode: 5049, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.625 [22.000, 56.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.264389, mean_absolute_error: 3.008298, mean_q: 3.906598
692 (array([22]),) False
 202000/500000: episode: 5050, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.200 [1.000, 40.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.239694, mean_absolute_error: 3.018287, mean_q: 3.928318
377 (array([22]),) False
 202040/500000: episode: 5051, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.300 [3.000, 47.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.225466, mean_absolute_error: 2.980046, mean_q: 3.884844
3 (array([48]),) False
 202080/500000: episode: 5052, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 24.100 [3.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.222547, mean_absolute_error: 2.983152, mean_q: 3.888939
392 (array([40]),) False
 202120/500000: episode: 5053, duration: 32.258s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 22.725 [9.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.232004, mean_absolute_error: 3.021734, mean_q: 3.930486
654 (array([22]),) False
 202160/500000: episode: 5054, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.625 [8.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.238700, mean_absolute_error: 3.013042, mean_q: 3.924084
556 (array([48]),) False
 202200/500000: episode: 5055, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.900 [1.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.219374, mean_absolute_error: 3.045515, mean_q: 3.958248
13 (array([48]),) False
 202240/500000: episode: 5056, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.425 [4.000, 56.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.216195, mean_absolute_error: 2.977631, mean_q: 3.881057
137 (array([22]),) False
 202280/500000: episode: 5057, duration: 31.785s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.700 [12.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.230493, mean_absolute_error: 3.031586, mean_q: 3.952229
103 (array([22]),) False
 202320/500000: episode: 5058, duration: 31.588s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 14.100 [1.000, 48.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.243923, mean_absolute_error: 3.009958, mean_q: 3.917087
146 (array([12]),) False
 202360/500000: episode: 5059, duration: 31.495s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 11.975 [3.000, 57.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.225384, mean_absolute_error: 2.989734, mean_q: 3.902060
533 (array([22]),) False
 202400/500000: episode: 5060, duration: 31.554s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.125 [6.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.219490, mean_absolute_error: 3.067271, mean_q: 3.987131
607 (array([12]),) False
 202440/500000: episode: 5061, duration: 31.573s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 27.350 [0.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.233425, mean_absolute_error: 2.976242, mean_q: 3.879179
542 (array([44]),) False
 202480/500000: episode: 5062, duration: 31.495s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 42.050 [6.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.245742, mean_absolute_error: 3.004599, mean_q: 3.908819
793 (array([12]),) False
 202520/500000: episode: 5063, duration: 31.122s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 14.775 [1.000, 49.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.244828, mean_absolute_error: 3.049489, mean_q: 3.963254
113 (array([22]),) False
 202560/500000: episode: 5064, duration: 31.493s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.850 [14.000, 52.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.236745, mean_absolute_error: 2.958327, mean_q: 3.868329
349 (array([48]),) False
 202600/500000: episode: 5065, duration: 31.032s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.875 [5.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.226349, mean_absolute_error: 2.987226, mean_q: 3.907098
181 (array([22]),) False
 202640/500000: episode: 5066, duration: 31.408s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.325 [11.000, 46.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.233938, mean_absolute_error: 2.966434, mean_q: 3.867034
771 (array([12]),) False
 202680/500000: episode: 5067, duration: 30.498s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 14.250 [12.000, 50.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.217907, mean_absolute_error: 3.047331, mean_q: 3.956275
663 (array([22]),) False
 202720/500000: episode: 5068, duration: 31.156s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 31.300 [0.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.239364, mean_absolute_error: 2.971237, mean_q: 3.885476
116 (array([22]),) False
 202760/500000: episode: 5069, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 16.575 [0.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.234493, mean_absolute_error: 2.977015, mean_q: 3.874334
322 (array([12]),) False
 202800/500000: episode: 5070, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 12.075 [1.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.230144, mean_absolute_error: 2.968055, mean_q: 3.864020
660 (array([2]),) False
 202840/500000: episode: 5071, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 26.900 [3.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.230367, mean_absolute_error: 2.951143, mean_q: 3.836079
550 (array([12]),) False
 202880/500000: episode: 5072, duration: 31.034s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 15.025 [6.000, 46.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.259386, mean_absolute_error: 2.975672, mean_q: 3.867434
686 (array([48]),) False
 202920/500000: episode: 5073, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 46.850 [11.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.233446, mean_absolute_error: 3.037580, mean_q: 3.938548
793 (array([12]),) False
 202960/500000: episode: 5074, duration: 31.063s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 13.950 [12.000, 42.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.221443, mean_absolute_error: 2.974510, mean_q: 3.875959
832 (array([22]),) False
 203000/500000: episode: 5075, duration: 30.138s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.475 [2.000, 22.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.243320, mean_absolute_error: 2.986734, mean_q: 3.891509
168 (array([22]),) False
 203040/500000: episode: 5076, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.525 [4.000, 50.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.228947, mean_absolute_error: 2.989638, mean_q: 3.890695
216 (array([22]),) False
 203080/500000: episode: 5077, duration: 30.150s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 24.250 [22.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.229985, mean_absolute_error: 3.013546, mean_q: 3.914766
235 (array([14]),) False
 203120/500000: episode: 5078, duration: 31.001s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.500 [12.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.246318, mean_absolute_error: 2.971030, mean_q: 3.877646
100 (array([22]),) False
 203160/500000: episode: 5079, duration: 30.187s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.700 [7.000, 50.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.252413, mean_absolute_error: 3.018826, mean_q: 3.936593
849 (array([3]),) False
 203200/500000: episode: 5080, duration: 31.092s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 43.125 [3.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.218452, mean_absolute_error: 3.020717, mean_q: 3.949343
76 (array([38]),) False
 203240/500000: episode: 5081, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 40.725 [12.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.232456, mean_absolute_error: 3.043136, mean_q: 3.951785
525 (array([22]),) False
 203280/500000: episode: 5082, duration: 31.078s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.950 [6.000, 35.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.253280, mean_absolute_error: 3.032624, mean_q: 3.940505
635 (array([22]),) False
 203320/500000: episode: 5083, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 24.700 [17.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.226304, mean_absolute_error: 3.009077, mean_q: 3.912308
322 (array([12]),) False
 203360/500000: episode: 5084, duration: 31.073s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 12.550 [12.000, 34.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.224288, mean_absolute_error: 2.982196, mean_q: 3.884401
662 (array([12]),) False
 203400/500000: episode: 5085, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 13.450 [12.000, 49.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.238210, mean_absolute_error: 2.995173, mean_q: 3.886747
622 (array([36]),) False
 203440/500000: episode: 5086, duration: 31.073s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 34.600 [5.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.218532, mean_absolute_error: 3.015707, mean_q: 3.922446
506 (array([8]),) False
 203480/500000: episode: 5087, duration: 30.257s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 8.725 [3.000, 58.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.237499, mean_absolute_error: 3.025394, mean_q: 3.935495
474 (array([22]),) False
 203520/500000: episode: 5088, duration: 31.067s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.625 [12.000, 38.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.227613, mean_absolute_error: 3.010149, mean_q: 3.913239
598 (array([22]),) False
 203560/500000: episode: 5089, duration: 30.583s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.050 [22.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.219364, mean_absolute_error: 3.002976, mean_q: 3.902513
539 (array([22]),) False
 203600/500000: episode: 5090, duration: 31.354s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.350 [3.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.235133, mean_absolute_error: 2.984756, mean_q: 3.888021
715 (array([22]),) False
 203640/500000: episode: 5091, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.375 [1.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.223040, mean_absolute_error: 2.980768, mean_q: 3.876956
320 (array([22]),) False
 203680/500000: episode: 5092, duration: 31.560s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.625 [13.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.233357, mean_absolute_error: 3.018706, mean_q: 3.909537
71 (array([58]),) False
 203720/500000: episode: 5093, duration: 31.483s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 50.625 [12.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.245273, mean_absolute_error: 2.985353, mean_q: 3.885356
50 (array([22]),) False
 203760/500000: episode: 5094, duration: 31.485s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.050 [12.000, 57.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.252986, mean_absolute_error: 3.007244, mean_q: 3.917723
615 (array([36]),) False
 203800/500000: episode: 5095, duration: 30.997s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 35.850 [11.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.231720, mean_absolute_error: 3.003424, mean_q: 3.922554
160 (array([12]),) False
 203840/500000: episode: 5096, duration: 31.312s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 16.250 [10.000, 57.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.230812, mean_absolute_error: 2.965311, mean_q: 3.878983
836 (array([22]),) False
 203880/500000: episode: 5097, duration: 31.202s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.250 [2.000, 22.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.256832, mean_absolute_error: 2.997617, mean_q: 3.924576
704 (array([22]),) False
 203920/500000: episode: 5098, duration: 31.156s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 26.975 [11.000, 50.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.244309, mean_absolute_error: 3.010171, mean_q: 3.943956
632 (array([22]),) False
 203960/500000: episode: 5099, duration: 30.060s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.925 [12.000, 29.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.260998, mean_absolute_error: 3.048171, mean_q: 3.982960
136 (array([12]),) False
 204000/500000: episode: 5100, duration: 31.353s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 9.325 [3.000, 44.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.226222, mean_absolute_error: 3.018302, mean_q: 3.937623
123 (array([22]),) False
 204040/500000: episode: 5101, duration: 30.407s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.975 [12.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.246576, mean_absolute_error: 2.973358, mean_q: 3.879234
126 (array([22]),) False
 204080/500000: episode: 5102, duration: 31.017s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.950 [12.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.238862, mean_absolute_error: 2.996328, mean_q: 3.902894
157 (array([48]),) False
 204120/500000: episode: 5103, duration: 30.158s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 44.525 [3.000, 55.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.234102, mean_absolute_error: 3.047666, mean_q: 3.967150
267 (array([22]),) False
 204160/500000: episode: 5104, duration: 31.341s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.400 [9.000, 57.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.237372, mean_absolute_error: 2.970346, mean_q: 3.878828
87 (array([3]),) False
 204200/500000: episode: 5105, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 5.925 [3.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.235889, mean_absolute_error: 3.005847, mean_q: 3.922877
820 (array([48]),) False
 204240/500000: episode: 5106, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 17.850 [12.000, 55.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.255008, mean_absolute_error: 3.065887, mean_q: 3.991239
108 (array([48]),) False
 204280/500000: episode: 5107, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 31.775 [12.000, 52.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.243097, mean_absolute_error: 3.063173, mean_q: 3.991419
256 (array([22]),) False
 204320/500000: episode: 5108, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.025 [22.000, 23.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.220935, mean_absolute_error: 2.965952, mean_q: 3.884403
522 (array([22]),) False
 204360/500000: episode: 5109, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.900 [3.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.242717, mean_absolute_error: 3.013319, mean_q: 3.940283
421 (array([22]),) False
 204400/500000: episode: 5110, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 30.450 [3.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.236925, mean_absolute_error: 3.010988, mean_q: 3.927864
1 (array([22]),) False
 204440/500000: episode: 5111, duration: 30.171s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.775 [6.000, 35.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.234381, mean_absolute_error: 3.017704, mean_q: 3.936617
57 (array([37]),) False
 204480/500000: episode: 5112, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 34.525 [12.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.248093, mean_absolute_error: 3.010165, mean_q: 3.920593
709 (array([41]),) False
 204520/500000: episode: 5113, duration: 30.158s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 15.425 [12.000, 42.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.242552, mean_absolute_error: 2.932942, mean_q: 3.838221
434 (array([22]),) False
 204560/500000: episode: 5114, duration: 30.976s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.350 [5.000, 59.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.240846, mean_absolute_error: 2.998269, mean_q: 3.906728
757 (array([48]),) False
 204600/500000: episode: 5115, duration: 30.186s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 42.025 [1.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.225519, mean_absolute_error: 2.955309, mean_q: 3.872570
207 (array([36]),) False
 204640/500000: episode: 5116, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.700 [12.000, 57.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.220571, mean_absolute_error: 3.020499, mean_q: 3.949152
456 (array([22]),) False
 204680/500000: episode: 5117, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 29.775 [2.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.243069, mean_absolute_error: 2.973168, mean_q: 3.890090
165 (array([34]),) False
 204720/500000: episode: 5118, duration: 31.072s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 24.050 [12.000, 60.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.248220, mean_absolute_error: 2.941420, mean_q: 3.847576
157 (array([48]),) False
 204760/500000: episode: 5119, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 48.050 [48.000, 50.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.248520, mean_absolute_error: 3.006037, mean_q: 3.927809
793 (array([12]),) False
 204800/500000: episode: 5120, duration: 31.112s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 15.250 [0.000, 51.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.266353, mean_absolute_error: 2.972581, mean_q: 3.888528
604 (array([40]),) False
 204840/500000: episode: 5121, duration: 31.004s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 32.475 [22.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.224029, mean_absolute_error: 3.050428, mean_q: 3.968708
568 (array([22]),) False
 204880/500000: episode: 5122, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.550 [12.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.258386, mean_absolute_error: 3.016704, mean_q: 3.923056
168 (array([22]),) False
 204920/500000: episode: 5123, duration: 30.242s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.600 [2.000, 56.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.229376, mean_absolute_error: 2.958986, mean_q: 3.852666
379 (array([22]),) False
 204960/500000: episode: 5124, duration: 31.122s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.350 [7.000, 49.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.233997, mean_absolute_error: 3.034886, mean_q: 3.940153
736 (array([22]),) False
 205000/500000: episode: 5125, duration: 30.137s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 23.125 [12.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.236260, mean_absolute_error: 2.989495, mean_q: 3.893060
328 (array([12]),) False
 205040/500000: episode: 5126, duration: 31.172s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 13.750 [6.000, 36.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.234665, mean_absolute_error: 2.998562, mean_q: 3.895635
494 (array([48]),) False
 205080/500000: episode: 5127, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 45.600 [14.000, 53.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.227060, mean_absolute_error: 2.962935, mean_q: 3.861475
548 (array([22]),) False
 205120/500000: episode: 5128, duration: 31.455s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 27.550 [0.000, 55.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.229727, mean_absolute_error: 2.986030, mean_q: 3.887571
505 (array([22]),) False
 205160/500000: episode: 5129, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.025 [22.000, 55.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.245819, mean_absolute_error: 3.013657, mean_q: 3.914466
68 (array([22]),) False
 205200/500000: episode: 5130, duration: 31.542s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.425 [2.000, 49.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.235057, mean_absolute_error: 3.045971, mean_q: 3.957275
803 (array([58]),) False
 205240/500000: episode: 5131, duration: 31.525s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 53.500 [3.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.240963, mean_absolute_error: 2.979253, mean_q: 3.881627
164 (array([22]),) False
 205280/500000: episode: 5132, duration: 31.498s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.675 [15.000, 56.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.238890, mean_absolute_error: 3.012835, mean_q: 3.911390
541 (array([57]),) False
 205320/500000: episode: 5133, duration: 31.269s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 36.200 [3.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.258633, mean_absolute_error: 2.948727, mean_q: 3.848923
487 (array([48]),) False
 205360/500000: episode: 5134, duration: 31.042s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 38.875 [6.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.242740, mean_absolute_error: 2.982359, mean_q: 3.867165
841 (array([21]),) False
 205400/500000: episode: 5135, duration: 30.513s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 39.350 [14.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.241500, mean_absolute_error: 3.106031, mean_q: 4.010587
91 (array([48]),) False
 205440/500000: episode: 5136, duration: 31.152s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 41.100 [12.000, 48.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.269225, mean_absolute_error: 2.972129, mean_q: 3.853031
24 (array([22]),) False
 205480/500000: episode: 5137, duration: 30.117s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.700 [13.000, 55.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.241007, mean_absolute_error: 3.034707, mean_q: 3.925395
198 (array([22]),) False
 205520/500000: episode: 5138, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 22.300 [12.000, 48.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.235754, mean_absolute_error: 3.075844, mean_q: 3.976451
776 (array([22]),) False
 205560/500000: episode: 5139, duration: 30.169s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.225 [22.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.268275, mean_absolute_error: 3.030697, mean_q: 3.936518
437 (array([12]),) False
 205600/500000: episode: 5140, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 24.825 [20.000, 51.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.223606, mean_absolute_error: 3.028552, mean_q: 3.934425
824 (array([22]),) False
 205640/500000: episode: 5141, duration: 31.067s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 20.575 [0.000, 22.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.234858, mean_absolute_error: 2.978401, mean_q: 3.851917
149 (array([8]),) False
 205680/500000: episode: 5142, duration: 31.041s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 9.850 [5.000, 45.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.234693, mean_absolute_error: 2.955858, mean_q: 3.833200
597 (array([22]),) False
 205720/500000: episode: 5143, duration: 31.066s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.050 [9.000, 47.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.225730, mean_absolute_error: 2.960360, mean_q: 3.853693
62 (array([22]),) False
 205760/500000: episode: 5144, duration: 31.051s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.850 [18.000, 56.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.230467, mean_absolute_error: 2.989975, mean_q: 3.895127
215 (array([22]),) False
 205800/500000: episode: 5145, duration: 30.959s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.825 [2.000, 37.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.248242, mean_absolute_error: 2.966759, mean_q: 3.846832
762 (array([22]),) False
 205840/500000: episode: 5146, duration: 31.063s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.025 [4.000, 50.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.219892, mean_absolute_error: 3.035188, mean_q: 3.921310
253 (array([44]),) False
 205880/500000: episode: 5147, duration: 30.171s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 34.675 [2.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.235197, mean_absolute_error: 3.012376, mean_q: 3.905012
190 (array([3]),) False
 205920/500000: episode: 5148, duration: 31.119s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 4.850 [3.000, 51.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.248020, mean_absolute_error: 3.058322, mean_q: 3.967133
554 (array([22]),) False
 205960/500000: episode: 5149, duration: 30.666s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.200 [3.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.242952, mean_absolute_error: 3.047979, mean_q: 3.943714
730 (array([54]),) False
 206000/500000: episode: 5150, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 51.400 [8.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.252132, mean_absolute_error: 3.000310, mean_q: 3.898383
832 (array([22]),) False
 206040/500000: episode: 5151, duration: 30.420s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.650 [1.000, 46.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.275082, mean_absolute_error: 2.978926, mean_q: 3.888964
806 (array([22]),) False
 206080/500000: episode: 5152, duration: 31.431s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.075 [22.000, 44.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.238305, mean_absolute_error: 2.962563, mean_q: 3.856465
157 (array([48]),) False
 206120/500000: episode: 5153, duration: 30.753s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 44.400 [2.000, 48.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.247083, mean_absolute_error: 3.032773, mean_q: 3.932411
292 (array([22]),) False
 206160/500000: episode: 5154, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.400 [12.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.264756, mean_absolute_error: 3.016936, mean_q: 3.912200
701 (array([48]),) False
 206200/500000: episode: 5155, duration: 31.433s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 46.550 [23.000, 56.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.228044, mean_absolute_error: 3.000371, mean_q: 3.902842
17 (array([22]),) False
 206240/500000: episode: 5156, duration: 31.123s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.700 [5.000, 40.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.230612, mean_absolute_error: 2.923621, mean_q: 3.796235
528 (array([12]),) False
 206280/500000: episode: 5157, duration: 31.312s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 23.175 [12.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.230817, mean_absolute_error: 3.007859, mean_q: 3.900935
680 (array([22]),) False
 206320/500000: episode: 5158, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.550 [2.000, 58.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.269987, mean_absolute_error: 2.971047, mean_q: 3.866727
480 (array([22]),) False
 206360/500000: episode: 5159, duration: 30.563s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.650 [0.000, 46.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.233543, mean_absolute_error: 3.009356, mean_q: 3.902054
816 (array([4]),) False
 206400/500000: episode: 5160, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 55.125 [18.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.222463, mean_absolute_error: 2.973733, mean_q: 3.873977
346 (array([12]),) False
 206440/500000: episode: 5161, duration: 30.037s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 22.350 [11.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.211596, mean_absolute_error: 2.994124, mean_q: 3.905095
173 (array([3]),) False
 206480/500000: episode: 5162, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 5.125 [3.000, 34.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.257228, mean_absolute_error: 2.951315, mean_q: 3.858819
222 (array([22]),) False
 206520/500000: episode: 5163, duration: 30.005s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.425 [20.000, 47.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.231306, mean_absolute_error: 2.930617, mean_q: 3.832359
800 (array([22]),) False
 206560/500000: episode: 5164, duration: 30.801s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.075 [0.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.262420, mean_absolute_error: 2.924707, mean_q: 3.819644
616 (array([22]),) False
 206600/500000: episode: 5165, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.025 [14.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.235279, mean_absolute_error: 2.971238, mean_q: 3.860621
786 (array([22]),) False
 206640/500000: episode: 5166, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.875 [0.000, 47.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.225523, mean_absolute_error: 2.961573, mean_q: 3.860501
628 (array([22]),) False
 206680/500000: episode: 5167, duration: 30.813s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.925 [22.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.226588, mean_absolute_error: 2.942428, mean_q: 3.839240
391 (array([22]),) False
 206720/500000: episode: 5168, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.750 [12.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.228501, mean_absolute_error: 2.957094, mean_q: 3.854644
198 (array([22]),) False
 206760/500000: episode: 5169, duration: 30.867s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.625 [2.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.247982, mean_absolute_error: 2.971634, mean_q: 3.869256
418 (array([22]),) False
 206800/500000: episode: 5170, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.875 [1.000, 44.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.226500, mean_absolute_error: 2.971244, mean_q: 3.877947
855 (array([12]),) False
 206840/500000: episode: 5171, duration: 30.226s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 16.400 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.251628, mean_absolute_error: 2.956326, mean_q: 3.862373
289 (array([21]),) False
 206880/500000: episode: 5172, duration: 31.343s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.800 [8.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.245589, mean_absolute_error: 2.999100, mean_q: 3.914970
34 (array([22]),) False
 206920/500000: episode: 5173, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.425 [6.000, 50.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.233523, mean_absolute_error: 2.967749, mean_q: 3.888591
362 (array([22]),) False
 206960/500000: episode: 5174, duration: 31.510s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.375 [22.000, 52.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.242173, mean_absolute_error: 2.940372, mean_q: 3.841847
604 (array([40]),) False
 207000/500000: episode: 5175, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 30.975 [11.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.252734, mean_absolute_error: 2.922742, mean_q: 3.812562
531 (array([22]),) False
 207040/500000: episode: 5176, duration: 31.455s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.875 [10.000, 49.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.267016, mean_absolute_error: 2.950573, mean_q: 3.852847
817 (array([12]),) False
 207080/500000: episode: 5177, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 21.400 [12.000, 53.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.245337, mean_absolute_error: 2.981850, mean_q: 3.896398
287 (array([48]),) False
 207120/500000: episode: 5178, duration: 31.549s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 23.775 [3.000, 51.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.261906, mean_absolute_error: 2.968388, mean_q: 3.880411
403 (array([12]),) False
 207160/500000: episode: 5179, duration: 31.556s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 29.125 [3.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.244938, mean_absolute_error: 2.960596, mean_q: 3.858701
692 (array([22]),) False
 207200/500000: episode: 5180, duration: 31.574s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 23.500 [4.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.271233, mean_absolute_error: 2.990944, mean_q: 3.910269
204 (array([22]),) False
 207240/500000: episode: 5181, duration: 31.504s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.275 [2.000, 46.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.273668, mean_absolute_error: 2.961481, mean_q: 3.866072
349 (array([48]),) False
 207280/500000: episode: 5182, duration: 31.508s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.450 [5.000, 38.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.255781, mean_absolute_error: 2.990370, mean_q: 3.891001
794 (array([22]),) False
 207320/500000: episode: 5183, duration: 31.318s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [11.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.247644, mean_absolute_error: 2.925219, mean_q: 3.806725
637 (array([12]),) False
 207360/500000: episode: 5184, duration: 33.279s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 17.500 [12.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.244788, mean_absolute_error: 2.945649, mean_q: 3.846977
723 (array([48]),) False
 207400/500000: episode: 5185, duration: 32.327s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.600 [5.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.249543, mean_absolute_error: 2.924175, mean_q: 3.819642
620 (array([44]),) False
 207440/500000: episode: 5186, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 37.525 [3.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.218610, mean_absolute_error: 2.973553, mean_q: 3.868688
761 (array([3]),) False
 207480/500000: episode: 5187, duration: 32.258s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 4.425 [3.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.255706, mean_absolute_error: 2.945245, mean_q: 3.834451
30 (array([22]),) False
 207520/500000: episode: 5188, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.225 [8.000, 44.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.223043, mean_absolute_error: 2.902442, mean_q: 3.793758
411 (array([22]),) False
 207560/500000: episode: 5189, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.075 [20.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.230097, mean_absolute_error: 2.915971, mean_q: 3.807292
143 (array([12]),) False
 207600/500000: episode: 5190, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.375 [2.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.261575, mean_absolute_error: 2.965094, mean_q: 3.869831
312 (array([12]),) False
 207640/500000: episode: 5191, duration: 33.169s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 36.625 [12.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.227212, mean_absolute_error: 2.964769, mean_q: 3.864857
652 (array([22]),) False
 207680/500000: episode: 5192, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.450 [0.000, 22.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.258361, mean_absolute_error: 2.871606, mean_q: 3.763507
187 (array([15]),) False
 207720/500000: episode: 5193, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 15.050 [3.000, 51.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.225808, mean_absolute_error: 2.984548, mean_q: 3.862640
423 (array([22]),) False
 207760/500000: episode: 5194, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.075 [15.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.231809, mean_absolute_error: 2.932810, mean_q: 3.818409
330 (array([38]),) False
 207800/500000: episode: 5195, duration: 32.344s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 18.075 [0.000, 45.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.256720, mean_absolute_error: 2.943803, mean_q: 3.832576
455 (array([22]),) False
 207840/500000: episode: 5196, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 42.450 [22.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.230337, mean_absolute_error: 2.970207, mean_q: 3.865572
700 (array([44]),) False
 207880/500000: episode: 5197, duration: 32.272s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 39.575 [3.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.235762, mean_absolute_error: 2.940458, mean_q: 3.840202
299 (array([12]),) False
 207920/500000: episode: 5198, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 29.400 [22.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.230853, mean_absolute_error: 2.981708, mean_q: 3.878339
782 (array([22]),) False
 207960/500000: episode: 5199, duration: 32.273s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 34.725 [21.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.226507, mean_absolute_error: 2.992365, mean_q: 3.903511
452 (array([22]),) False
 208000/500000: episode: 5200, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 21.625 [8.000, 22.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.226998, mean_absolute_error: 2.939316, mean_q: 3.837442
256 (array([22]),) False
 208040/500000: episode: 5201, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.475 [4.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.250561, mean_absolute_error: 2.960352, mean_q: 3.859187
215 (array([22]),) False
 208080/500000: episode: 5202, duration: 33.242s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.150 [5.000, 60.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.238884, mean_absolute_error: 2.960214, mean_q: 3.873140
413 (array([22]),) False
 208120/500000: episode: 5203, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 22.275 [11.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.241414, mean_absolute_error: 2.971616, mean_q: 3.881643
231 (array([22]),) False
 208160/500000: episode: 5204, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.925 [22.000, 49.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.238939, mean_absolute_error: 3.010460, mean_q: 3.910329
853 (array([22]),) False
 208200/500000: episode: 5205, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.825 [11.000, 44.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.242580, mean_absolute_error: 3.019082, mean_q: 3.921481
396 (array([48]),) False
 208240/500000: episode: 5206, duration: 33.268s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 43.775 [6.000, 55.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.241817, mean_absolute_error: 2.969644, mean_q: 3.859056
564 (array([22]),) False
 208280/500000: episode: 5207, duration: 32.289s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.400 [22.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.232799, mean_absolute_error: 2.951747, mean_q: 3.840175
66 (array([22]),) False
 208320/500000: episode: 5208, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.900 [5.000, 42.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.233596, mean_absolute_error: 2.972473, mean_q: 3.860147
751 (array([22]),) False
 208360/500000: episode: 5209, duration: 32.305s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 34.575 [5.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.225504, mean_absolute_error: 2.893928, mean_q: 3.777286
743 (array([48]),) False
 208400/500000: episode: 5210, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 48.525 [48.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.239837, mean_absolute_error: 3.014943, mean_q: 3.914485
285 (array([58]),) False
 208440/500000: episode: 5211, duration: 32.351s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 32.475 [1.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.243210, mean_absolute_error: 3.010567, mean_q: 3.905830
844 (array([48]),) False
 208480/500000: episode: 5212, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 31.025 [12.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.255195, mean_absolute_error: 2.960868, mean_q: 3.853849
752 (array([3]),) False
 208520/500000: episode: 5213, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 6.750 [3.000, 37.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.225625, mean_absolute_error: 2.942058, mean_q: 3.822867
163 (array([44]),) False
 208560/500000: episode: 5214, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 29.850 [11.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.247575, mean_absolute_error: 2.958297, mean_q: 3.850953
379 (array([22]),) False
 208600/500000: episode: 5215, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.050 [5.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.260406, mean_absolute_error: 2.972909, mean_q: 3.854659
575 (array([44]),) False
 208640/500000: episode: 5216, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 36.400 [11.000, 45.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.221551, mean_absolute_error: 2.935195, mean_q: 3.829041
57 (array([37]),) False
 208680/500000: episode: 5217, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 29.775 [12.000, 50.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.226405, mean_absolute_error: 2.988104, mean_q: 3.881983
681 (array([12]),) False
 208720/500000: episode: 5218, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 15.275 [4.000, 54.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.215081, mean_absolute_error: 2.925509, mean_q: 3.810045
393 (array([22]),) False
 208760/500000: episode: 5219, duration: 32.329s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.650 [7.000, 36.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.218802, mean_absolute_error: 2.984922, mean_q: 3.888772
852 (array([44]),) False
 208800/500000: episode: 5220, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 42.450 [19.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.240409, mean_absolute_error: 2.929408, mean_q: 3.825092
274 (array([12]),) False
 208840/500000: episode: 5221, duration: 32.281s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 17.450 [3.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.246745, mean_absolute_error: 2.928091, mean_q: 3.835500
237 (array([22]),) False
 208880/500000: episode: 5222, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 20.750 [3.000, 22.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.226691, mean_absolute_error: 2.982668, mean_q: 3.891278
60 (array([22]),) False
 208920/500000: episode: 5223, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 34.775 [5.000, 50.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.227410, mean_absolute_error: 2.937524, mean_q: 3.833478
679 (array([44]),) False
 208960/500000: episode: 5224, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.500 [12.000, 48.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.242948, mean_absolute_error: 2.900222, mean_q: 3.790410
236 (array([22]),) False
 209000/500000: episode: 5225, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.375 [6.000, 42.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.266970, mean_absolute_error: 2.941458, mean_q: 3.828220
207 (array([36]),) False
 209040/500000: episode: 5226, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 22.725 [10.000, 47.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.228232, mean_absolute_error: 2.946342, mean_q: 3.844281
854 (array([12]),) False
 209080/500000: episode: 5227, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 42.475 [11.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.224828, mean_absolute_error: 2.987822, mean_q: 3.890910
236 (array([22]),) False
 209120/500000: episode: 5228, duration: 33.251s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.175 [2.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.244929, mean_absolute_error: 2.959723, mean_q: 3.870273
63 (array([18]),) False
 209160/500000: episode: 5229, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.425 [10.000, 45.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.247796, mean_absolute_error: 2.897014, mean_q: 3.797101
127 (array([22]),) False
 209200/500000: episode: 5230, duration: 33.283s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.625 [5.000, 24.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.232905, mean_absolute_error: 2.894928, mean_q: 3.800688
632 (array([22]),) False
 209240/500000: episode: 5231, duration: 32.338s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.525 [22.000, 51.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.227129, mean_absolute_error: 2.970735, mean_q: 3.870144
456 (array([22]),) False
 209280/500000: episode: 5232, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.050 [3.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.227358, mean_absolute_error: 3.022458, mean_q: 3.922843
346 (array([12]),) False
 209320/500000: episode: 5233, duration: 32.232s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 24.675 [12.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.264954, mean_absolute_error: 2.954576, mean_q: 3.862703
861 (array([22]),) False
 209360/500000: episode: 5234, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.975 [11.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.229499, mean_absolute_error: 2.913930, mean_q: 3.807824
607 (array([12]),) False
 209400/500000: episode: 5235, duration: 32.232s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 27.150 [1.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.254139, mean_absolute_error: 2.945753, mean_q: 3.854262
349 (array([48]),) False
 209440/500000: episode: 5236, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.775 [2.000, 37.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.238018, mean_absolute_error: 2.972508, mean_q: 3.891830
417 (array([12]),) False
 209480/500000: episode: 5237, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.850 [0.000, 40.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.244711, mean_absolute_error: 2.979669, mean_q: 3.878840
244 (array([14]),) False
 209520/500000: episode: 5238, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 16.850 [14.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.239152, mean_absolute_error: 2.934769, mean_q: 3.833213
831 (array([3]),) False
 209560/500000: episode: 5239, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 16.075 [1.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.235692, mean_absolute_error: 2.945260, mean_q: 3.837786
403 (array([12]),) False
 209600/500000: episode: 5240, duration: 33.202s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 28.300 [3.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.236275, mean_absolute_error: 2.962244, mean_q: 3.863922
594 (array([48]),) False
 209640/500000: episode: 5241, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.225 [1.000, 52.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.240544, mean_absolute_error: 2.914893, mean_q: 3.817714
680 (array([22]),) False
 209680/500000: episode: 5242, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.650 [7.000, 51.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.267858, mean_absolute_error: 2.888010, mean_q: 3.781161
557 (array([22]),) False
 209720/500000: episode: 5243, duration: 32.297s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.600 [2.000, 39.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.273951, mean_absolute_error: 2.973693, mean_q: 3.890848
529 (array([3]),) False
 209760/500000: episode: 5244, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 5.150 [3.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.255110, mean_absolute_error: 3.005556, mean_q: 3.909918
464 (array([22]),) False
 209800/500000: episode: 5245, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.375 [8.000, 47.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.245064, mean_absolute_error: 2.986588, mean_q: 3.887441
747 (array([22]),) False
 209840/500000: episode: 5246, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.775 [11.000, 31.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.236608, mean_absolute_error: 2.978554, mean_q: 3.875465
682 (array([22]),) False
 209880/500000: episode: 5247, duration: 32.282s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.825 [11.000, 52.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.245213, mean_absolute_error: 2.978056, mean_q: 3.872981
586 (array([12]),) False
 209920/500000: episode: 5248, duration: 33.202s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 17.375 [12.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.214063, mean_absolute_error: 2.949728, mean_q: 3.850976
623 (array([37]),) False
 209960/500000: episode: 5249, duration: 33.200s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 22.950 [1.000, 59.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.244057, mean_absolute_error: 2.904911, mean_q: 3.784613
309 (array([22]),) False
 210000/500000: episode: 5250, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.750 [2.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.255756, mean_absolute_error: 2.970529, mean_q: 3.860575
862 (array([14]),) False
 210040/500000: episode: 5251, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 39.450 [5.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.230134, mean_absolute_error: 2.935415, mean_q: 3.815893
204 (array([22]),) False
 210080/500000: episode: 5252, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 21.925 [1.000, 54.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.221393, mean_absolute_error: 2.964279, mean_q: 3.861296
757 (array([48]),) False
 210120/500000: episode: 5253, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 44.950 [12.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.231101, mean_absolute_error: 2.967695, mean_q: 3.878396
701 (array([48]),) False
 210160/500000: episode: 5254, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 46.300 [21.000, 48.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.235866, mean_absolute_error: 2.974979, mean_q: 3.886207
654 (array([22]),) False
 210200/500000: episode: 5255, duration: 32.168s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.125 [22.000, 50.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.253315, mean_absolute_error: 3.020442, mean_q: 3.919164
88 (array([22]),) False
 210240/500000: episode: 5256, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.525 [9.000, 22.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.226048, mean_absolute_error: 2.919507, mean_q: 3.823221
138 (array([3]),) False
 210280/500000: episode: 5257, duration: 32.350s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 14.475 [3.000, 44.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.233841, mean_absolute_error: 2.929742, mean_q: 3.825845
54 (array([8]),) False
 210320/500000: episode: 5258, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 27.875 [8.000, 36.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.229699, mean_absolute_error: 2.929429, mean_q: 3.821453
378 (array([22]),) False
 210360/500000: episode: 5259, duration: 32.313s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.300 [1.000, 43.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.239744, mean_absolute_error: 2.963943, mean_q: 3.856810
772 (array([46]),) False
 210400/500000: episode: 5260, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 35.325 [12.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.235402, mean_absolute_error: 2.941554, mean_q: 3.827934
296 (array([22]),) False
 210440/500000: episode: 5261, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.625 [18.000, 52.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.226673, mean_absolute_error: 3.000180, mean_q: 3.895570
356 (array([22]),) False
 210480/500000: episode: 5262, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.475 [12.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.229442, mean_absolute_error: 2.931707, mean_q: 3.815835
736 (array([22]),) False
 210520/500000: episode: 5263, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 19.150 [3.000, 22.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.247697, mean_absolute_error: 2.967887, mean_q: 3.856957
729 (array([22]),) False
 210560/500000: episode: 5264, duration: 33.284s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 36.625 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.265585, mean_absolute_error: 3.015965, mean_q: 3.909463
214 (array([22]),) False
 210600/500000: episode: 5265, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.075 [8.000, 35.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.237907, mean_absolute_error: 3.013444, mean_q: 3.900783
461 (array([22]),) False
 210640/500000: episode: 5266, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.250 [10.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.239377, mean_absolute_error: 2.952883, mean_q: 3.828665
253 (array([44]),) False
 210680/500000: episode: 5267, duration: 32.268s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 41.775 [5.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.213214, mean_absolute_error: 2.954848, mean_q: 3.845955
659 (array([40]),) False
 210720/500000: episode: 5268, duration: 33.249s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 20.550 [2.000, 22.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.239808, mean_absolute_error: 2.939381, mean_q: 3.831796
268 (array([22]),) False
 210760/500000: episode: 5269, duration: 32.223s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.075 [0.000, 52.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.255624, mean_absolute_error: 2.924819, mean_q: 3.820380
355 (array([22]),) False
 210800/500000: episode: 5270, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 16.625 [7.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.253715, mean_absolute_error: 2.994203, mean_q: 3.902817
164 (array([22]),) False
 210840/500000: episode: 5271, duration: 32.298s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.075 [5.000, 56.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.252224, mean_absolute_error: 2.891683, mean_q: 3.780543
22 (array([37]),) False
 210880/500000: episode: 5272, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 29.325 [4.000, 55.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.233726, mean_absolute_error: 2.927714, mean_q: 3.833692
778 (array([12]),) False
 210920/500000: episode: 5273, duration: 33.224s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 21.700 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.237524, mean_absolute_error: 2.937980, mean_q: 3.839794
540 (array([22]),) False
 210960/500000: episode: 5274, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 27.075 [20.000, 56.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.234422, mean_absolute_error: 2.946082, mean_q: 3.847938
47 (array([44]),) False
 211000/500000: episode: 5275, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 24.125 [0.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.257142, mean_absolute_error: 2.991636, mean_q: 3.896662
357 (array([22]),) False
 211040/500000: episode: 5276, duration: 33.275s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 32.375 [9.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.265788, mean_absolute_error: 2.956843, mean_q: 3.855281
538 (array([12]),) False
 211080/500000: episode: 5277, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 35.700 [3.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.220151, mean_absolute_error: 2.933109, mean_q: 3.819127
794 (array([22]),) False
 211120/500000: episode: 5278, duration: 33.276s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.425 [6.000, 26.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.236807, mean_absolute_error: 2.922370, mean_q: 3.822359
562 (array([22]),) False
 211160/500000: episode: 5279, duration: 32.346s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.975 [0.000, 49.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.233044, mean_absolute_error: 2.960732, mean_q: 3.868168
292 (array([22]),) False
 211200/500000: episode: 5280, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.725 [1.000, 50.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.239585, mean_absolute_error: 2.946310, mean_q: 3.848406
650 (array([22]),) False
 211240/500000: episode: 5281, duration: 32.227s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.575 [1.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.248445, mean_absolute_error: 2.923644, mean_q: 3.819115
372 (array([22]),) False
 211280/500000: episode: 5282, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.400 [6.000, 56.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.249581, mean_absolute_error: 2.972928, mean_q: 3.875841
638 (array([22]),) False
 211320/500000: episode: 5283, duration: 32.292s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.250 [3.000, 55.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.232397, mean_absolute_error: 2.928799, mean_q: 3.815437
246 (array([22]),) False
 211360/500000: episode: 5284, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.650 [10.000, 41.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.236441, mean_absolute_error: 2.952504, mean_q: 3.845695
690 (array([22]),) False
 211400/500000: episode: 5285, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.400 [18.000, 42.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.218057, mean_absolute_error: 2.959854, mean_q: 3.847216
359 (array([22]),) False
 211440/500000: episode: 5286, duration: 33.184s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.200 [20.000, 52.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.233352, mean_absolute_error: 2.944045, mean_q: 3.813068
789 (array([22]),) False
 211480/500000: episode: 5287, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.850 [16.000, 22.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.236955, mean_absolute_error: 3.012754, mean_q: 3.909638
659 (array([40]),) False
 211520/500000: episode: 5288, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 24.800 [11.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.222483, mean_absolute_error: 2.962698, mean_q: 3.849596
570 (array([47]),) False
 211560/500000: episode: 5289, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.325 [9.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.237333, mean_absolute_error: 2.988962, mean_q: 3.887728
274 (array([12]),) False
 211600/500000: episode: 5290, duration: 33.281s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 15.700 [0.000, 44.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.235671, mean_absolute_error: 2.958622, mean_q: 3.858647
793 (array([12]),) False
 211640/500000: episode: 5291, duration: 32.313s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 13.500 [12.000, 55.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.245485, mean_absolute_error: 2.955181, mean_q: 3.848361
842 (array([22]),) False
 211680/500000: episode: 5292, duration: 33.222s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.250 [6.000, 40.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.228958, mean_absolute_error: 2.998990, mean_q: 3.906127
727 (array([12]),) False
 211720/500000: episode: 5293, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 12.350 [3.000, 29.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.232498, mean_absolute_error: 2.960175, mean_q: 3.857111
64 (array([12]),) False
 211760/500000: episode: 5294, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 22.650 [12.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.250968, mean_absolute_error: 2.966076, mean_q: 3.862882
532 (array([25]),) False
 211800/500000: episode: 5295, duration: 32.324s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.950 [0.000, 50.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.246562, mean_absolute_error: 2.939103, mean_q: 3.832757
616 (array([22]),) False
 211840/500000: episode: 5296, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.800 [4.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.214751, mean_absolute_error: 3.026809, mean_q: 3.944404
342 (array([12]),) False
 211880/500000: episode: 5297, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 23.025 [3.000, 36.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.266018, mean_absolute_error: 2.993495, mean_q: 3.896795
753 (array([22]),) False
 211920/500000: episode: 5298, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 21.875 [3.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.233401, mean_absolute_error: 2.934862, mean_q: 3.843703
184 (array([12]),) False
 211960/500000: episode: 5299, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 23.925 [12.000, 57.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.228858, mean_absolute_error: 2.945661, mean_q: 3.844490
250 (array([22]),) False
 212000/500000: episode: 5300, duration: 33.235s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 27.750 [7.000, 58.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.252275, mean_absolute_error: 2.934928, mean_q: 3.833677
585 (array([48]),) False
 212040/500000: episode: 5301, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.525 [4.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.252627, mean_absolute_error: 2.990311, mean_q: 3.894117
115 (array([22]),) False
 212080/500000: episode: 5302, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.250 [4.000, 45.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.210125, mean_absolute_error: 3.018626, mean_q: 3.932887
634 (array([57]),) False
 212120/500000: episode: 5303, duration: 32.268s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 22.350 [1.000, 57.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.246921, mean_absolute_error: 2.945475, mean_q: 3.861329
491 (array([22]),) False
 212160/500000: episode: 5304, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.600 [22.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.231749, mean_absolute_error: 2.996854, mean_q: 3.906944
564 (array([22]),) False
 212200/500000: episode: 5305, duration: 32.322s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 20.725 [3.000, 24.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.237192, mean_absolute_error: 2.925306, mean_q: 3.836128
376 (array([22]),) False
 212240/500000: episode: 5306, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 42.400 [9.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.230462, mean_absolute_error: 2.961154, mean_q: 3.887501
543 (array([12]),) False
 212280/500000: episode: 5307, duration: 32.288s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 12.600 [2.000, 33.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.222952, mean_absolute_error: 2.962569, mean_q: 3.861656
340 (array([12]),) False
 212320/500000: episode: 5308, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 19.225 [1.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.237088, mean_absolute_error: 2.932677, mean_q: 3.824280
760 (array([22]),) False
 212360/500000: episode: 5309, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 34.475 [2.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.242438, mean_absolute_error: 2.952953, mean_q: 3.839305
571 (array([48]),) False
 212400/500000: episode: 5310, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 19.425 [2.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.250206, mean_absolute_error: 2.965832, mean_q: 3.868021
579 (array([58]),) False
 212440/500000: episode: 5311, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 51.850 [4.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.225458, mean_absolute_error: 2.977320, mean_q: 3.871693
830 (array([22]),) False
 212480/500000: episode: 5312, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.850 [2.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.217724, mean_absolute_error: 3.023047, mean_q: 3.927335
499 (array([8]),) False
 212520/500000: episode: 5313, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 12.050 [8.000, 56.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.237457, mean_absolute_error: 2.921665, mean_q: 3.813700
689 (array([12]),) False
 212560/500000: episode: 5314, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 17.300 [12.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.248575, mean_absolute_error: 2.987534, mean_q: 3.893182
194 (array([44]),) False
 212600/500000: episode: 5315, duration: 32.377s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 42.875 [22.000, 49.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.229312, mean_absolute_error: 2.989991, mean_q: 3.891464
515 (array([22]),) False
 212640/500000: episode: 5316, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.227163, mean_absolute_error: 3.023123, mean_q: 3.927471
701 (array([48]),) False
 212680/500000: episode: 5317, duration: 32.266s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 46.225 [4.000, 50.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.225050, mean_absolute_error: 2.987447, mean_q: 3.883801
55 (array([22]),) False
 212720/500000: episode: 5318, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.225 [4.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.227028, mean_absolute_error: 2.980716, mean_q: 3.876160
13 (array([48]),) False
 212760/500000: episode: 5319, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.575 [6.000, 54.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.243736, mean_absolute_error: 2.940731, mean_q: 3.837420
269 (array([36]),) False
 212800/500000: episode: 5320, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 26.650 [3.000, 44.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.223011, mean_absolute_error: 3.017761, mean_q: 3.912338
209 (array([8]),) False
 212840/500000: episode: 5321, duration: 32.941s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 26.950 [8.000, 43.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.268366, mean_absolute_error: 2.949950, mean_q: 3.843256
679 (array([44]),) False
 212880/500000: episode: 5322, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.050 [3.000, 60.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.268908, mean_absolute_error: 2.988784, mean_q: 3.880114
264 (array([12]),) False
 212920/500000: episode: 5323, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 20.750 [12.000, 34.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.243631, mean_absolute_error: 3.038858, mean_q: 3.941689
670 (array([22]),) False
 212960/500000: episode: 5324, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.950 [3.000, 55.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.224180, mean_absolute_error: 3.006303, mean_q: 3.900469
207 (array([36]),) False
 213000/500000: episode: 5325, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 23.675 [5.000, 60.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.219805, mean_absolute_error: 2.964887, mean_q: 3.865035
738 (array([12]),) False
 213040/500000: episode: 5326, duration: 32.909s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 41.050 [3.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.219818, mean_absolute_error: 3.006422, mean_q: 3.897624
263 (array([8]),) False
 213080/500000: episode: 5327, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 9.975 [8.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.247263, mean_absolute_error: 2.974885, mean_q: 3.868645
326 (array([48]),) False
 213120/500000: episode: 5328, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 34.850 [12.000, 58.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.211668, mean_absolute_error: 2.991153, mean_q: 3.878701
801 (array([58]),) False
 213160/500000: episode: 5329, duration: 32.329s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 14.100 [3.000, 49.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.248802, mean_absolute_error: 2.962495, mean_q: 3.848782
802 (array([22]),) False
 213200/500000: episode: 5330, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.800 [3.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.232452, mean_absolute_error: 2.929759, mean_q: 3.804818
97 (array([22]),) False
 213240/500000: episode: 5331, duration: 32.351s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.525 [22.000, 50.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.230650, mean_absolute_error: 3.019221, mean_q: 3.913023
809 (array([48]),) False
 213280/500000: episode: 5332, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 26.375 [3.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.226720, mean_absolute_error: 2.925496, mean_q: 3.798465
232 (array([22]),) False
 213320/500000: episode: 5333, duration: 32.288s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.075 [18.000, 49.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.224753, mean_absolute_error: 2.985801, mean_q: 3.873538
704 (array([22]),) False
 213360/500000: episode: 5334, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.875 [10.000, 49.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.238380, mean_absolute_error: 2.978167, mean_q: 3.864131
441 (array([22]),) False
 213400/500000: episode: 5335, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 21.150 [5.000, 22.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.229147, mean_absolute_error: 2.926677, mean_q: 3.810191
707 (array([48]),) False
 213440/500000: episode: 5336, duration: 33.257s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.075 [2.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.217670, mean_absolute_error: 2.894478, mean_q: 3.784538
362 (array([22]),) False
 213480/500000: episode: 5337, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.450 [20.000, 56.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.233373, mean_absolute_error: 2.993121, mean_q: 3.886904
117 (array([44]),) False
 213520/500000: episode: 5338, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 13.325 [0.000, 46.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.249976, mean_absolute_error: 2.952965, mean_q: 3.840712
423 (array([22]),) False
 213560/500000: episode: 5339, duration: 33.155s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.725 [10.000, 38.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.242693, mean_absolute_error: 2.949618, mean_q: 3.843539
532 (array([25]),) False
 213600/500000: episode: 5340, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 23.200 [12.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.237733, mean_absolute_error: 2.994101, mean_q: 3.900867
296 (array([22]),) False
 213640/500000: episode: 5341, duration: 32.353s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.025 [3.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.206557, mean_absolute_error: 2.974586, mean_q: 3.872573
698 (array([22]),) False
 213680/500000: episode: 5342, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 24.525 [2.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.237567, mean_absolute_error: 3.025932, mean_q: 3.922584
436 (array([22]),) False
 213720/500000: episode: 5343, duration: 32.322s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.950 [22.000, 60.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.217034, mean_absolute_error: 2.954981, mean_q: 3.854882
449 (array([22]),) False
 213760/500000: episode: 5344, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.350 [2.000, 54.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.229041, mean_absolute_error: 2.919241, mean_q: 3.807008
54 (array([8]),) False
 213800/500000: episode: 5345, duration: 32.258s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 19.025 [8.000, 54.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.271526, mean_absolute_error: 2.997895, mean_q: 3.897777
4 (array([22]),) False
 213840/500000: episode: 5346, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 24.350 [3.000, 52.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.225396, mean_absolute_error: 2.955621, mean_q: 3.851411
791 (array([54]),) False
 213880/500000: episode: 5347, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 16.350 [3.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.249283, mean_absolute_error: 2.980774, mean_q: 3.879857
608 (array([36]),) False
 213920/500000: episode: 5348, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 36.175 [25.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.239680, mean_absolute_error: 2.959445, mean_q: 3.851891
645 (array([48]),) False
 213960/500000: episode: 5349, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 47.775 [25.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.248937, mean_absolute_error: 2.998020, mean_q: 3.884732
404 (array([12]),) False
 214000/500000: episode: 5350, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 20.350 [3.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.233118, mean_absolute_error: 2.994589, mean_q: 3.889571
533 (array([22]),) False
 214040/500000: episode: 5351, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.000 [18.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.233963, mean_absolute_error: 2.946455, mean_q: 3.837265
747 (array([22]),) False
 214080/500000: episode: 5352, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.100 [2.000, 33.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.271022, mean_absolute_error: 2.946755, mean_q: 3.830957
251 (array([3]),) False
 214120/500000: episode: 5353, duration: 32.287s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 6.525 [3.000, 46.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.262640, mean_absolute_error: 2.994210, mean_q: 3.887380
826 (array([22]),) False
 214160/500000: episode: 5354, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.125 [7.000, 55.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.237944, mean_absolute_error: 2.958486, mean_q: 3.859017
191 (array([38]),) False
 214200/500000: episode: 5355, duration: 32.214s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 21.600 [3.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.213113, mean_absolute_error: 3.022681, mean_q: 3.925366
380 (array([22]),) False
 214240/500000: episode: 5356, duration: 33.204s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.725 [5.000, 50.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.240163, mean_absolute_error: 2.937668, mean_q: 3.812721
775 (array([58]),) False
 214280/500000: episode: 5357, duration: 32.279s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 53.600 [10.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.221568, mean_absolute_error: 2.936073, mean_q: 3.818605
537 (array([22]),) False
 214320/500000: episode: 5358, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.975 [3.000, 36.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.238546, mean_absolute_error: 2.946420, mean_q: 3.816379
581 (array([22]),) False
 214360/500000: episode: 5359, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.200 [2.000, 53.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.233830, mean_absolute_error: 2.975760, mean_q: 3.851518
361 (array([22]),) False
 214400/500000: episode: 5360, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 22.575 [12.000, 46.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.218458, mean_absolute_error: 2.913371, mean_q: 3.785210
694 (array([22]),) False
 214440/500000: episode: 5361, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.825 [8.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.244714, mean_absolute_error: 2.910680, mean_q: 3.790648
415 (array([22]),) False
 214480/500000: episode: 5362, duration: 33.236s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.275 [2.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.241509, mean_absolute_error: 2.962954, mean_q: 3.848960
519 (array([58]),) False
 214520/500000: episode: 5363, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 53.250 [2.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.244669, mean_absolute_error: 3.012223, mean_q: 3.903205
319 (array([33]),) False
 214560/500000: episode: 5364, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 20.775 [3.000, 23.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.243926, mean_absolute_error: 2.968679, mean_q: 3.845048
490 (array([12]),) False
 214600/500000: episode: 5365, duration: 32.226s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 12.675 [12.000, 36.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.238727, mean_absolute_error: 2.941753, mean_q: 3.813480
41 (array([12]),) False
 214640/500000: episode: 5366, duration: 33.241s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 22.200 [8.000, 44.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.236837, mean_absolute_error: 2.990411, mean_q: 3.866313
460 (array([36]),) False
 214680/500000: episode: 5367, duration: 32.279s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.775 [9.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.242508, mean_absolute_error: 2.950234, mean_q: 3.831664
510 (array([22]),) False
 214720/500000: episode: 5368, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 20.600 [2.000, 55.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.223253, mean_absolute_error: 2.963624, mean_q: 3.851135
555 (array([22]),) False
 214760/500000: episode: 5369, duration: 32.338s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 21.025 [0.000, 50.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.238491, mean_absolute_error: 2.988059, mean_q: 3.887777
780 (array([22]),) False
 214800/500000: episode: 5370, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.625 [22.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.267100, mean_absolute_error: 2.962457, mean_q: 3.843074
768 (array([22]),) False
 214840/500000: episode: 5371, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.775 [22.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.232148, mean_absolute_error: 2.938624, mean_q: 3.822629
787 (array([3]),) False
 214880/500000: episode: 5372, duration: 33.257s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 19.200 [3.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.234768, mean_absolute_error: 2.927631, mean_q: 3.810773
491 (array([22]),) False
 214920/500000: episode: 5373, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 24.900 [22.000, 56.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.236647, mean_absolute_error: 2.938732, mean_q: 3.823724
387 (array([22]),) False
 214960/500000: episode: 5374, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.350 [22.000, 36.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.233471, mean_absolute_error: 2.997403, mean_q: 3.897027
734 (array([48]),) False
 215000/500000: episode: 5375, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 37.225 [12.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.240262, mean_absolute_error: 2.921673, mean_q: 3.795260
843 (array([3]),) False
 215040/500000: episode: 5376, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 41.175 [3.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.241568, mean_absolute_error: 2.971961, mean_q: 3.873333
617 (array([22]),) False
 215080/500000: episode: 5377, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 26.300 [5.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.240535, mean_absolute_error: 2.988617, mean_q: 3.880468
454 (array([12]),) False
 215120/500000: episode: 5378, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 27.525 [10.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.221871, mean_absolute_error: 3.003829, mean_q: 3.909524
479 (array([22]),) False
 215160/500000: episode: 5379, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.375 [15.000, 52.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.231663, mean_absolute_error: 2.966290, mean_q: 3.853846
132 (array([22]),) False
 215200/500000: episode: 5380, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.950 [22.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.218449, mean_absolute_error: 2.970719, mean_q: 3.869949
588 (array([22]),) False
 215240/500000: episode: 5381, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.925 [13.000, 36.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.214340, mean_absolute_error: 2.958976, mean_q: 3.855049
285 (array([58]),) False
 215280/500000: episode: 5382, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 35.825 [3.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.259937, mean_absolute_error: 2.946674, mean_q: 3.833997
386 (array([12]),) False
 215320/500000: episode: 5383, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.975 [3.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.230476, mean_absolute_error: 2.949085, mean_q: 3.829591
16 (array([22]),) False
 215360/500000: episode: 5384, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.425 [22.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.244262, mean_absolute_error: 2.955101, mean_q: 3.838561
109 (array([48]),) False
 215400/500000: episode: 5385, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 25.225 [14.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.221931, mean_absolute_error: 2.963172, mean_q: 3.839436
143 (array([12]),) False
 215440/500000: episode: 5386, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 19.700 [3.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.230187, mean_absolute_error: 2.954003, mean_q: 3.841959
708 (array([40]),) False
 215480/500000: episode: 5387, duration: 32.203s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.575 [7.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.225369, mean_absolute_error: 2.943182, mean_q: 3.818282
159 (array([48]),) False
 215520/500000: episode: 5388, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.175 [3.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.220584, mean_absolute_error: 2.937249, mean_q: 3.819672
327 (array([22]),) False
 215560/500000: episode: 5389, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.500 [4.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.248206, mean_absolute_error: 2.932051, mean_q: 3.814614
729 (array([22]),) False
 215600/500000: episode: 5390, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 32.550 [3.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.215119, mean_absolute_error: 2.933328, mean_q: 3.823489
115 (array([22]),) False
 215640/500000: episode: 5391, duration: 32.329s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.725 [13.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.229526, mean_absolute_error: 2.871194, mean_q: 3.749458
622 (array([36]),) False
 215680/500000: episode: 5392, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 35.525 [19.000, 36.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.232516, mean_absolute_error: 2.945050, mean_q: 3.830284
84 (array([22]),) False
 215720/500000: episode: 5393, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.200 [2.000, 50.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.241643, mean_absolute_error: 2.954425, mean_q: 3.827515
427 (array([22]),) False
 215760/500000: episode: 5394, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 23.050 [8.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.219285, mean_absolute_error: 2.897082, mean_q: 3.765359
643 (array([44]),) False
 215800/500000: episode: 5395, duration: 32.246s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 40.550 [4.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.238829, mean_absolute_error: 2.962993, mean_q: 3.846591
194 (array([44]),) False
 215840/500000: episode: 5396, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 41.225 [6.000, 53.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.220154, mean_absolute_error: 2.935528, mean_q: 3.813305
220 (array([22]),) False
 215880/500000: episode: 5397, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.925 [8.000, 33.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.213560, mean_absolute_error: 2.943281, mean_q: 3.822199
813 (array([22]),) False
 215920/500000: episode: 5398, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.725 [12.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.244354, mean_absolute_error: 2.948245, mean_q: 3.839943
193 (array([36]),) False
 215960/500000: episode: 5399, duration: 32.264s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 25.300 [3.000, 60.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.242375, mean_absolute_error: 2.877514, mean_q: 3.759984
803 (array([58]),) False
 216000/500000: episode: 5400, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 49.075 [2.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.226686, mean_absolute_error: 2.933840, mean_q: 3.828378
451 (array([38]),) False
 216040/500000: episode: 5401, duration: 32.800s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 22.600 [3.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.222774, mean_absolute_error: 2.919767, mean_q: 3.812838
439 (array([12]),) False
 216080/500000: episode: 5402, duration: 31.209s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 23.950 [5.000, 48.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.229877, mean_absolute_error: 2.959303, mean_q: 3.854288
550 (array([12]),) False
 216120/500000: episode: 5403, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 14.950 [2.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.223167, mean_absolute_error: 3.006051, mean_q: 3.907311
525 (array([22]),) False
 216160/500000: episode: 5404, duration: 31.196s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.575 [4.000, 36.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.226730, mean_absolute_error: 3.009333, mean_q: 3.904600
73 (array([22]),) False
 216200/500000: episode: 5405, duration: 31.532s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.775 [9.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.217931, mean_absolute_error: 3.000850, mean_q: 3.901872
19 (array([12]),) False
 216240/500000: episode: 5406, duration: 31.613s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.100 [22.000, 26.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.224062, mean_absolute_error: 2.983868, mean_q: 3.866528
293 (array([22]),) False
 216280/500000: episode: 5407, duration: 30.859s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.650 [22.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.235862, mean_absolute_error: 2.948531, mean_q: 3.837527
363 (array([36]),) False
 216320/500000: episode: 5408, duration: 31.369s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 26.250 [12.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.229418, mean_absolute_error: 2.963202, mean_q: 3.852186
817 (array([12]),) False
 216360/500000: episode: 5409, duration: 31.991s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 12.875 [10.000, 49.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.227640, mean_absolute_error: 2.960510, mean_q: 3.846879
128 (array([22]),) False
 216400/500000: episode: 5410, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.000 [4.000, 40.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.230541, mean_absolute_error: 2.938198, mean_q: 3.814473
595 (array([22]),) False
 216440/500000: episode: 5411, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.600 [3.000, 43.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.227638, mean_absolute_error: 2.943122, mean_q: 3.817104
402 (array([22]),) False
 216480/500000: episode: 5412, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.925 [12.000, 29.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.217639, mean_absolute_error: 2.973944, mean_q: 3.866582
774 (array([57]),) False
 216520/500000: episode: 5413, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 17.100 [6.000, 50.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.218032, mean_absolute_error: 3.007299, mean_q: 3.902444
794 (array([22]),) False
 216560/500000: episode: 5414, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.575 [9.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.220347, mean_absolute_error: 2.936986, mean_q: 3.820603
228 (array([44]),) False
 216600/500000: episode: 5415, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 19.700 [3.000, 43.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.243937, mean_absolute_error: 2.882488, mean_q: 3.764051
606 (array([22]),) False
 216640/500000: episode: 5416, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.950 [16.000, 36.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.234058, mean_absolute_error: 2.960115, mean_q: 3.846940
327 (array([22]),) False
 216680/500000: episode: 5417, duration: 32.226s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.350 [7.000, 41.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.246048, mean_absolute_error: 2.940677, mean_q: 3.828518
236 (array([22]),) False
 216720/500000: episode: 5418, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.225 [22.000, 31.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.225764, mean_absolute_error: 2.951956, mean_q: 3.858173
382 (array([22]),) False
 216760/500000: episode: 5419, duration: 32.200s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.600 [5.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.249619, mean_absolute_error: 2.974090, mean_q: 3.893647
373 (array([22]),) False
 216800/500000: episode: 5420, duration: 31.456s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [20.000, 48.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.234725, mean_absolute_error: 3.011070, mean_q: 3.919190
477 (array([22]),) False
 216840/500000: episode: 5421, duration: 30.161s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.525 [22.000, 43.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.243799, mean_absolute_error: 3.043358, mean_q: 3.959075
227 (array([22]),) False
 216880/500000: episode: 5422, duration: 31.018s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 25.150 [11.000, 58.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.223206, mean_absolute_error: 2.955684, mean_q: 3.865180
407 (array([22]),) False
 216920/500000: episode: 5423, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.825 [18.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.229228, mean_absolute_error: 2.987538, mean_q: 3.902140
853 (array([22]),) False
 216960/500000: episode: 5424, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.525 [4.000, 38.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.243941, mean_absolute_error: 2.957424, mean_q: 3.864780
162 (array([22]),) False
 217000/500000: episode: 5425, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.700 [22.000, 57.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.226437, mean_absolute_error: 2.897989, mean_q: 3.799520
325 (array([22]),) False
 217040/500000: episode: 5426, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.825 [18.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.220676, mean_absolute_error: 2.907723, mean_q: 3.801278
291 (array([22]),) False
 217080/500000: episode: 5427, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.500 [0.000, 45.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.217998, mean_absolute_error: 3.055324, mean_q: 3.965308
492 (array([22]),) False
 217120/500000: episode: 5428, duration: 31.077s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.233002, mean_absolute_error: 3.019372, mean_q: 3.930116
554 (array([22]),) False
 217160/500000: episode: 5429, duration: 30.203s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 24.125 [5.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.229358, mean_absolute_error: 3.017291, mean_q: 3.927363
675 (array([22]),) False
 217200/500000: episode: 5430, duration: 30.848s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.675 [18.000, 53.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.215903, mean_absolute_error: 2.991899, mean_q: 3.893931
760 (array([22]),) False
 217240/500000: episode: 5431, duration: 29.989s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 37.650 [6.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.219286, mean_absolute_error: 2.955739, mean_q: 3.848247
552 (array([22]),) False
 217280/500000: episode: 5432, duration: 30.668s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.925 [4.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.235487, mean_absolute_error: 3.035651, mean_q: 3.943104
452 (array([22]),) False
 217320/500000: episode: 5433, duration: 29.901s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.275 [13.000, 48.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.236211, mean_absolute_error: 2.944871, mean_q: 3.832602
178 (array([38]),) False
 217360/500000: episode: 5434, duration: 30.285s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.050 [14.000, 32.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.246868, mean_absolute_error: 2.966998, mean_q: 3.858552
801 (array([58]),) False
 217400/500000: episode: 5435, duration: 30.224s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 17.600 [3.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.243314, mean_absolute_error: 3.045272, mean_q: 3.944175
202 (array([22]),) False
 217440/500000: episode: 5436, duration: 30.554s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.575 [22.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.233388, mean_absolute_error: 2.945399, mean_q: 3.845508
607 (array([12]),) False
 217480/500000: episode: 5437, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 23.900 [3.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.254115, mean_absolute_error: 3.009135, mean_q: 3.913059
503 (array([3]),) False
 217520/500000: episode: 5438, duration: 31.097s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 7.525 [0.000, 48.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.252539, mean_absolute_error: 2.998972, mean_q: 3.905998
508 (array([22]),) False
 217560/500000: episode: 5439, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 26.825 [1.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.222377, mean_absolute_error: 3.037027, mean_q: 3.941427
480 (array([22]),) False
 217600/500000: episode: 5440, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.125 [13.000, 34.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.225174, mean_absolute_error: 3.018503, mean_q: 3.922414
578 (array([22]),) False
 217640/500000: episode: 5441, duration: 30.125s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 16.950 [12.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.218765, mean_absolute_error: 2.959170, mean_q: 3.854882
690 (array([22]),) False
 217680/500000: episode: 5442, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.650 [8.000, 53.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.224847, mean_absolute_error: 3.039359, mean_q: 3.945798
216 (array([22]),) False
 217720/500000: episode: 5443, duration: 30.126s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.000 [0.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.228718, mean_absolute_error: 3.030632, mean_q: 3.932862
234 (array([22]),) False
 217760/500000: episode: 5444, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 21.425 [0.000, 30.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.216719, mean_absolute_error: 2.989296, mean_q: 3.894643
24 (array([22]),) False
 217800/500000: episode: 5445, duration: 30.122s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.150 [2.000, 55.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.226916, mean_absolute_error: 3.034268, mean_q: 3.944454
315 (array([12]),) False
 217840/500000: episode: 5446, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 19.550 [1.000, 37.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.237091, mean_absolute_error: 3.033837, mean_q: 3.952227
141 (array([44]),) False
 217880/500000: episode: 5447, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.650 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.229865, mean_absolute_error: 3.029824, mean_q: 3.941128
27 (array([22]),) False
 217920/500000: episode: 5448, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.800 [10.000, 56.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.232256, mean_absolute_error: 3.048447, mean_q: 3.968346
389 (array([48]),) False
 217960/500000: episode: 5449, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 43.775 [0.000, 55.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.252652, mean_absolute_error: 3.015553, mean_q: 3.931033
698 (array([22]),) False
 218000/500000: episode: 5450, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.200 [12.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.245348, mean_absolute_error: 3.020879, mean_q: 3.932015
716 (array([48]),) False
 218040/500000: episode: 5451, duration: 30.873s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 14.275 [5.000, 34.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.239613, mean_absolute_error: 3.038074, mean_q: 3.939155
660 (array([2]),) False
 218080/500000: episode: 5452, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 12.450 [3.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.236361, mean_absolute_error: 3.040366, mean_q: 3.934531
784 (array([22]),) False
 218120/500000: episode: 5453, duration: 30.155s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 20.400 [3.000, 44.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.236993, mean_absolute_error: 3.043446, mean_q: 3.946619
238 (array([22]),) False
 218160/500000: episode: 5454, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 23.475 [1.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.223937, mean_absolute_error: 2.988961, mean_q: 3.883710
852 (array([44]),) False
 218200/500000: episode: 5455, duration: 30.081s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 25.325 [3.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.224954, mean_absolute_error: 3.043919, mean_q: 3.950139
282 (array([22]),) False
 218240/500000: episode: 5456, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.675 [6.000, 57.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.231704, mean_absolute_error: 3.019481, mean_q: 3.915554
361 (array([22]),) False
 218280/500000: episode: 5457, duration: 30.114s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.200 [12.000, 36.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.223177, mean_absolute_error: 3.024997, mean_q: 3.927663
402 (array([22]),) False
 218320/500000: episode: 5458, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 21.900 [18.000, 22.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.230444, mean_absolute_error: 2.974589, mean_q: 3.851799
707 (array([48]),) False
 218360/500000: episode: 5459, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 47.300 [20.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.249159, mean_absolute_error: 2.977217, mean_q: 3.862259
513 (array([12]),) False
 218400/500000: episode: 5460, duration: 31.001s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 13.250 [8.000, 39.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.238421, mean_absolute_error: 3.030643, mean_q: 3.923679
152 (array([58]),) False
 218440/500000: episode: 5461, duration: 30.948s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 54.350 [10.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.244866, mean_absolute_error: 2.941291, mean_q: 3.819622
752 (array([3]),) False
 218480/500000: episode: 5462, duration: 31.072s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 7.325 [3.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.230226, mean_absolute_error: 3.039194, mean_q: 3.934100
618 (array([12]),) False
 218520/500000: episode: 5463, duration: 30.065s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 22.400 [12.000, 46.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.229695, mean_absolute_error: 2.997342, mean_q: 3.889656
388 (array([22]),) False
 218560/500000: episode: 5464, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.200 [22.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.215276, mean_absolute_error: 3.008392, mean_q: 3.903964
500 (array([22]),) False
 218600/500000: episode: 5465, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 12.600 [3.000, 48.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.217472, mean_absolute_error: 3.000484, mean_q: 3.890144
202 (array([22]),) False
 218640/500000: episode: 5466, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.675 [9.000, 22.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.256725, mean_absolute_error: 3.013578, mean_q: 3.902922
400 (array([22]),) False
 218680/500000: episode: 5467, duration: 30.051s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.075 [0.000, 51.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.208043, mean_absolute_error: 3.022057, mean_q: 3.928471
331 (array([22]),) False
 218720/500000: episode: 5468, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.725 [7.000, 53.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.233060, mean_absolute_error: 3.025304, mean_q: 3.925385
220 (array([22]),) False
 218760/500000: episode: 5469, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.350 [7.000, 55.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.242872, mean_absolute_error: 3.015424, mean_q: 3.912206
607 (array([12]),) False
 218800/500000: episode: 5470, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 29.675 [3.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.226116, mean_absolute_error: 2.966895, mean_q: 3.873742
70 (array([22]),) False
 218840/500000: episode: 5471, duration: 30.037s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 47.225 [14.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.240178, mean_absolute_error: 2.971167, mean_q: 3.870875
247 (array([14]),) False
 218880/500000: episode: 5472, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 30.300 [6.000, 56.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.255697, mean_absolute_error: 3.014418, mean_q: 3.916743
756 (array([48]),) False
 218920/500000: episode: 5473, duration: 31.048s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 40.825 [2.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.244350, mean_absolute_error: 3.032514, mean_q: 3.934417
479 (array([22]),) False
 218960/500000: episode: 5474, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.025 [22.000, 23.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.257403, mean_absolute_error: 2.928743, mean_q: 3.822509
812 (array([22]),) False
 219000/500000: episode: 5475, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 41.325 [12.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.232396, mean_absolute_error: 2.994391, mean_q: 3.905151
268 (array([22]),) False
 219040/500000: episode: 5476, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 25.200 [14.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.233480, mean_absolute_error: 3.025820, mean_q: 3.928049
539 (array([22]),) False
 219080/500000: episode: 5477, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.150 [3.000, 54.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.237148, mean_absolute_error: 3.007857, mean_q: 3.921977
796 (array([38]),) False
 219120/500000: episode: 5478, duration: 30.948s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 24.000 [22.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.240921, mean_absolute_error: 2.987382, mean_q: 3.888662
807 (array([22]),) False
 219160/500000: episode: 5479, duration: 30.057s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.275 [3.000, 53.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.253186, mean_absolute_error: 3.041472, mean_q: 3.959879
189 (array([12]),) False
 219200/500000: episode: 5480, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 21.325 [12.000, 46.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.246530, mean_absolute_error: 3.021423, mean_q: 3.928061
283 (array([34]),) False
 219240/500000: episode: 5481, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 16.825 [1.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.221166, mean_absolute_error: 2.987672, mean_q: 3.893735
312 (array([12]),) False
 219280/500000: episode: 5482, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 12.825 [12.000, 28.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.232137, mean_absolute_error: 2.982854, mean_q: 3.883827
845 (array([22]),) False
 219320/500000: episode: 5483, duration: 30.008s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.150 [22.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.228051, mean_absolute_error: 3.035707, mean_q: 3.947515
822 (array([22]),) False
 219360/500000: episode: 5484, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.225 [22.000, 30.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.244699, mean_absolute_error: 2.966914, mean_q: 3.868096
216 (array([22]),) False
 219400/500000: episode: 5485, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.575 [9.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.220806, mean_absolute_error: 2.990091, mean_q: 3.890383
432 (array([22]),) False
 219440/500000: episode: 5486, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.225 [3.000, 28.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.228893, mean_absolute_error: 2.973146, mean_q: 3.877409
617 (array([22]),) False
 219480/500000: episode: 5487, duration: 29.999s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.425 [11.000, 41.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.230071, mean_absolute_error: 3.046473, mean_q: 3.967379
378 (array([22]),) False
 219520/500000: episode: 5488, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.800 [3.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.211297, mean_absolute_error: 2.996972, mean_q: 3.905586
553 (array([22]),) False
 219560/500000: episode: 5489, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 20.975 [12.000, 43.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.227563, mean_absolute_error: 3.010138, mean_q: 3.925442
179 (array([18]),) False
 219600/500000: episode: 5490, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 23.275 [12.000, 58.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.248636, mean_absolute_error: 2.971583, mean_q: 3.874823
262 (array([22]),) False
 219640/500000: episode: 5491, duration: 30.006s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 24.600 [9.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.231944, mean_absolute_error: 2.963636, mean_q: 3.860181
263 (array([8]),) False
 219680/500000: episode: 5492, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 9.350 [8.000, 39.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.211411, mean_absolute_error: 2.907912, mean_q: 3.801182
611 (array([22]),) False
 219720/500000: episode: 5493, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 37.500 [3.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.222615, mean_absolute_error: 2.985071, mean_q: 3.876852
562 (array([22]),) False
 219760/500000: episode: 5494, duration: 31.001s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.050 [5.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.226407, mean_absolute_error: 3.002986, mean_q: 3.896997
633 (array([22]),) False
 219800/500000: episode: 5495, duration: 30.035s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.175 [18.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.238256, mean_absolute_error: 2.986146, mean_q: 3.879215
145 (array([19]),) False
 219840/500000: episode: 5496, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 16.125 [3.000, 44.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.225507, mean_absolute_error: 2.999341, mean_q: 3.900482
338 (array([12]),) False
 219880/500000: episode: 5497, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 12.275 [3.000, 47.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.225169, mean_absolute_error: 3.001621, mean_q: 3.899616
845 (array([22]),) False
 219920/500000: episode: 5498, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.875 [1.000, 55.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.223222, mean_absolute_error: 3.013448, mean_q: 3.906845
133 (array([22]),) False
 219960/500000: episode: 5499, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.650 [15.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.228877, mean_absolute_error: 2.979709, mean_q: 3.874873
650 (array([22]),) False
 220000/500000: episode: 5500, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.200 [22.000, 30.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.247486, mean_absolute_error: 3.006711, mean_q: 3.898911
389 (array([48]),) False
 220040/500000: episode: 5501, duration: 30.878s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 47.650 [34.000, 48.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.224040, mean_absolute_error: 3.018231, mean_q: 3.923557
715 (array([22]),) False
 220080/500000: episode: 5502, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.775 [0.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.225290, mean_absolute_error: 2.971282, mean_q: 3.870995
50 (array([22]),) False
 220120/500000: episode: 5503, duration: 29.956s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.900 [22.000, 47.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.223629, mean_absolute_error: 3.021470, mean_q: 3.922391
184 (array([12]),) False
 220160/500000: episode: 5504, duration: 30.786s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.600 [12.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.242131, mean_absolute_error: 2.946325, mean_q: 3.830437
818 (array([48]),) False
 220200/500000: episode: 5505, duration: 30.873s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 41.725 [9.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.230923, mean_absolute_error: 2.943599, mean_q: 3.840137
288 (array([33]),) False
 220240/500000: episode: 5506, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.200 [5.000, 41.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.231616, mean_absolute_error: 2.978626, mean_q: 3.876054
582 (array([44]),) False
 220280/500000: episode: 5507, duration: 30.023s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 31.900 [2.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.223296, mean_absolute_error: 3.007520, mean_q: 3.904994
449 (array([22]),) False
 220320/500000: episode: 5508, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.550 [7.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.246635, mean_absolute_error: 2.985336, mean_q: 3.888098
734 (array([48]),) False
 220360/500000: episode: 5509, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 33.400 [12.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.221094, mean_absolute_error: 2.978182, mean_q: 3.871908
686 (array([48]),) False
 220400/500000: episode: 5510, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.325 [5.000, 53.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.231161, mean_absolute_error: 2.989803, mean_q: 3.890816
465 (array([48]),) False
 220440/500000: episode: 5511, duration: 30.011s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 45.875 [3.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.236603, mean_absolute_error: 2.958751, mean_q: 3.862108
301 (array([22]),) False
 220480/500000: episode: 5512, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 26.750 [18.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.236771, mean_absolute_error: 2.952747, mean_q: 3.852142
659 (array([40]),) False
 220520/500000: episode: 5513, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.243723, mean_absolute_error: 2.989064, mean_q: 3.871809
477 (array([22]),) False
 220560/500000: episode: 5514, duration: 31.006s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.025 [6.000, 44.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.234164, mean_absolute_error: 2.948864, mean_q: 3.845772
334 (array([48]),) False
 220600/500000: episode: 5515, duration: 30.050s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.375 [8.000, 51.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.242349, mean_absolute_error: 2.976179, mean_q: 3.865032
167 (array([22]),) False
 220640/500000: episode: 5516, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.500 [2.000, 37.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.232339, mean_absolute_error: 2.941254, mean_q: 3.820057
220 (array([22]),) False
 220680/500000: episode: 5517, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.925 [5.000, 57.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.229534, mean_absolute_error: 2.954781, mean_q: 3.861017
58 (array([48]),) False
 220720/500000: episode: 5518, duration: 31.044s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 45.475 [10.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.221282, mean_absolute_error: 2.990680, mean_q: 3.894212
443 (array([22]),) False
 220760/500000: episode: 5519, duration: 30.007s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.375 [8.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.227999, mean_absolute_error: 2.942015, mean_q: 3.835735
5 (array([37]),) False
 220800/500000: episode: 5520, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.600 [16.000, 47.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.222354, mean_absolute_error: 3.005101, mean_q: 3.905289
113 (array([22]),) False
 220840/500000: episode: 5521, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.300 [7.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.226305, mean_absolute_error: 2.965362, mean_q: 3.865255
860 (array([12]),) False
 220880/500000: episode: 5522, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 16.050 [12.000, 44.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.221322, mean_absolute_error: 2.931994, mean_q: 3.828790
81 (array([22]),) False
 220920/500000: episode: 5523, duration: 30.036s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.375 [3.000, 46.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.222902, mean_absolute_error: 2.974925, mean_q: 3.867880
323 (array([55]),) False
 220960/500000: episode: 5524, duration: 30.991s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 30.850 [1.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.233023, mean_absolute_error: 2.976021, mean_q: 3.877898
424 (array([22]),) False
 221000/500000: episode: 5525, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.900 [3.000, 48.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.214396, mean_absolute_error: 2.921230, mean_q: 3.817375
409 (array([22]),) False
 221040/500000: episode: 5526, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.300 [2.000, 35.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.231327, mean_absolute_error: 3.000621, mean_q: 3.910038
463 (array([22]),) False
 221080/500000: episode: 5527, duration: 30.084s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.475 [14.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.246153, mean_absolute_error: 2.986156, mean_q: 3.890147
113 (array([22]),) False
 221120/500000: episode: 5528, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.275 [2.000, 22.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.250060, mean_absolute_error: 3.028842, mean_q: 3.944835
457 (array([38]),) False
 221160/500000: episode: 5529, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.400 [3.000, 37.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.221949, mean_absolute_error: 2.906863, mean_q: 3.809530
753 (array([22]),) False
 221200/500000: episode: 5530, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 18.000 [3.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.219680, mean_absolute_error: 2.976840, mean_q: 3.902608
644 (array([12]),) False
 221240/500000: episode: 5531, duration: 29.990s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 20.100 [2.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.218470, mean_absolute_error: 2.944434, mean_q: 3.848257
637 (array([12]),) False
 221280/500000: episode: 5532, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 16.700 [0.000, 55.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.215862, mean_absolute_error: 2.925671, mean_q: 3.820433
222 (array([22]),) False
 221320/500000: episode: 5533, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 21.475 [12.000, 59.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.225293, mean_absolute_error: 2.962398, mean_q: 3.865537
367 (array([12]),) False
 221360/500000: episode: 5534, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 17.700 [1.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.236797, mean_absolute_error: 2.937222, mean_q: 3.833459
805 (array([22]),) False
 221400/500000: episode: 5535, duration: 30.055s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.125 [22.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.227381, mean_absolute_error: 2.962257, mean_q: 3.855145
763 (array([48]),) False
 221440/500000: episode: 5536, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 45.325 [3.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.230167, mean_absolute_error: 2.886508, mean_q: 3.777507
125 (array([58]),) False
 221480/500000: episode: 5537, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 53.800 [0.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.229350, mean_absolute_error: 2.913201, mean_q: 3.808680
286 (array([22]),) False
 221520/500000: episode: 5538, duration: 30.797s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 25.300 [16.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.207573, mean_absolute_error: 2.885796, mean_q: 3.765303
801 (array([58]),) False
 221560/500000: episode: 5539, duration: 29.825s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 13.900 [3.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.239221, mean_absolute_error: 2.956174, mean_q: 3.838300
501 (array([12]),) False
 221600/500000: episode: 5540, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.450 [1.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.209430, mean_absolute_error: 2.946409, mean_q: 3.832857
643 (array([44]),) False
 221640/500000: episode: 5541, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 36.625 [3.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.221112, mean_absolute_error: 2.984545, mean_q: 3.876708
679 (array([44]),) False
 221680/500000: episode: 5542, duration: 30.780s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 25.000 [12.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.239129, mean_absolute_error: 2.937145, mean_q: 3.835976
531 (array([22]),) False
 221720/500000: episode: 5543, duration: 29.919s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.800 [5.000, 39.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.237688, mean_absolute_error: 2.898938, mean_q: 3.794994
312 (array([12]),) False
 221760/500000: episode: 5544, duration: 30.772s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 13.850 [12.000, 46.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.224011, mean_absolute_error: 2.878068, mean_q: 3.775819
150 (array([22]),) False
 221800/500000: episode: 5545, duration: 30.759s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 19.800 [3.000, 45.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.225631, mean_absolute_error: 2.948252, mean_q: 3.835260
264 (array([12]),) False
 221840/500000: episode: 5546, duration: 30.822s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.400 [14.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.240766, mean_absolute_error: 2.939501, mean_q: 3.818532
758 (array([38]),) False
 221880/500000: episode: 5547, duration: 29.881s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 29.200 [3.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.231833, mean_absolute_error: 2.960261, mean_q: 3.850340
461 (array([22]),) False
 221920/500000: episode: 5548, duration: 30.752s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 25.700 [22.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.240151, mean_absolute_error: 2.954995, mean_q: 3.828274
173 (array([3]),) False
 221960/500000: episode: 5549, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 4.050 [1.000, 26.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.218616, mean_absolute_error: 2.938668, mean_q: 3.809402
217 (array([12]),) False
 222000/500000: episode: 5550, duration: 30.674s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 20.250 [2.000, 59.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.230222, mean_absolute_error: 2.935112, mean_q: 3.810129
370 (array([58]),) False
 222040/500000: episode: 5551, duration: 29.894s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.675 [3.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.234632, mean_absolute_error: 2.954874, mean_q: 3.846156
654 (array([22]),) False
 222080/500000: episode: 5552, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.750 [17.000, 41.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.225709, mean_absolute_error: 2.910857, mean_q: 3.802373
814 (array([22]),) False
 222120/500000: episode: 5553, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.900 [1.000, 48.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.219992, mean_absolute_error: 2.949425, mean_q: 3.844905
834 (array([44]),) False
 222160/500000: episode: 5554, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 19.400 [3.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.248766, mean_absolute_error: 2.963222, mean_q: 3.867987
741 (array([22]),) False
 222200/500000: episode: 5555, duration: 29.880s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 26.325 [12.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.229353, mean_absolute_error: 2.909966, mean_q: 3.802235
81 (array([22]),) False
 222240/500000: episode: 5556, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.275 [7.000, 22.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.232499, mean_absolute_error: 2.916446, mean_q: 3.816512
688 (array([22]),) False
 222280/500000: episode: 5557, duration: 30.777s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 25.725 [6.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.227831, mean_absolute_error: 2.962585, mean_q: 3.854694
737 (array([15]),) False
 222320/500000: episode: 5558, duration: 30.829s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 30.825 [3.000, 50.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.211583, mean_absolute_error: 2.984790, mean_q: 3.875909
346 (array([12]),) False
 222360/500000: episode: 5559, duration: 29.892s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 20.950 [0.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.216166, mean_absolute_error: 2.977536, mean_q: 3.862457
474 (array([22]),) False
 222400/500000: episode: 5560, duration: 30.748s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.225 [8.000, 49.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.238834, mean_absolute_error: 2.960038, mean_q: 3.846516
387 (array([22]),) False
 222440/500000: episode: 5561, duration: 30.777s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.150 [15.000, 35.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.245976, mean_absolute_error: 2.961421, mean_q: 3.849127
217 (array([12]),) False
 222480/500000: episode: 5562, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 20.625 [12.000, 51.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.234250, mean_absolute_error: 2.942243, mean_q: 3.832714
829 (array([21]),) False
 222520/500000: episode: 5563, duration: 29.868s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 22.875 [3.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.221331, mean_absolute_error: 2.961077, mean_q: 3.851820
437 (array([12]),) False
 222560/500000: episode: 5564, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 25.150 [8.000, 59.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.220794, mean_absolute_error: 3.006255, mean_q: 3.887125
75 (array([22]),) False
 222600/500000: episode: 5565, duration: 30.772s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.750 [10.000, 39.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.228133, mean_absolute_error: 2.977863, mean_q: 3.849447
126 (array([22]),) False
 222640/500000: episode: 5566, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.475 [22.000, 41.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.225984, mean_absolute_error: 2.932050, mean_q: 3.817012
442 (array([22]),) False
 222680/500000: episode: 5567, duration: 29.880s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.250 [0.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.237956, mean_absolute_error: 2.944570, mean_q: 3.829081
67 (array([8]),) False
 222720/500000: episode: 5568, duration: 30.818s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 8.900 [8.000, 27.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.221419, mean_absolute_error: 2.908546, mean_q: 3.782740
332 (array([22]),) False
 222760/500000: episode: 5569, duration: 30.804s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 46.875 [12.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.226719, mean_absolute_error: 2.970363, mean_q: 3.866339
724 (array([58]),) False
 222800/500000: episode: 5570, duration: 30.853s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 56.600 [3.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.236522, mean_absolute_error: 2.908102, mean_q: 3.784724
565 (array([12]),) False
 222840/500000: episode: 5571, duration: 29.861s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 18.425 [11.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.225079, mean_absolute_error: 2.893887, mean_q: 3.760535
418 (array([22]),) False
 222880/500000: episode: 5572, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.150 [6.000, 44.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.221029, mean_absolute_error: 2.912423, mean_q: 3.794204
414 (array([48]),) False
 222920/500000: episode: 5573, duration: 30.714s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 34.650 [10.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.235940, mean_absolute_error: 2.898510, mean_q: 3.757638
219 (array([36]),) False
 222960/500000: episode: 5574, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 15.400 [8.000, 44.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.220479, mean_absolute_error: 2.922329, mean_q: 3.795288
851 (array([48]),) False
 223000/500000: episode: 5575, duration: 29.916s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 44.300 [5.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.240625, mean_absolute_error: 2.965435, mean_q: 3.843138
227 (array([22]),) False
 223040/500000: episode: 5576, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.650 [16.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.222077, mean_absolute_error: 2.934263, mean_q: 3.820174
736 (array([22]),) False
 223080/500000: episode: 5577, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.075 [2.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.224068, mean_absolute_error: 2.956101, mean_q: 3.834291
729 (array([22]),) False
 223120/500000: episode: 5578, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 36.175 [0.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.224922, mean_absolute_error: 2.997652, mean_q: 3.889756
182 (array([54]),) False
 223160/500000: episode: 5579, duration: 29.848s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 47.725 [35.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.241308, mean_absolute_error: 2.917246, mean_q: 3.783946
348 (array([22]),) False
 223200/500000: episode: 5580, duration: 30.801s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.825 [19.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.249614, mean_absolute_error: 2.965265, mean_q: 3.860357
836 (array([22]),) False
 223240/500000: episode: 5581, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.223098, mean_absolute_error: 2.946141, mean_q: 3.834357
857 (array([22]),) False
 223280/500000: episode: 5582, duration: 30.826s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.225 [12.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.209742, mean_absolute_error: 2.888945, mean_q: 3.777584
677 (array([48]),) False
 223320/500000: episode: 5583, duration: 29.831s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 44.500 [12.000, 48.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.210884, mean_absolute_error: 2.930138, mean_q: 3.820693
822 (array([22]),) False
 223360/500000: episode: 5584, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.575 [3.000, 45.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.239378, mean_absolute_error: 3.009584, mean_q: 3.909710
575 (array([44]),) False
 223400/500000: episode: 5585, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 37.525 [8.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.225459, mean_absolute_error: 3.024905, mean_q: 3.914353
489 (array([22]),) False
 223440/500000: episode: 5586, duration: 30.827s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.900 [21.000, 41.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.207949, mean_absolute_error: 2.959170, mean_q: 3.851429
366 (array([22]),) False
 223480/500000: episode: 5587, duration: 29.871s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 34.825 [3.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.212480, mean_absolute_error: 2.971395, mean_q: 3.851330
470 (array([22]),) False
 223520/500000: episode: 5588, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 22.550 [0.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.230949, mean_absolute_error: 2.995895, mean_q: 3.882632
588 (array([22]),) False
 223560/500000: episode: 5589, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 22.975 [11.000, 41.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.234483, mean_absolute_error: 3.021285, mean_q: 3.907189
427 (array([22]),) False
 223600/500000: episode: 5590, duration: 30.804s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 23.350 [22.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.238787, mean_absolute_error: 2.985426, mean_q: 3.863243
550 (array([12]),) False
 223640/500000: episode: 5591, duration: 29.885s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 15.200 [12.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.222012, mean_absolute_error: 2.986646, mean_q: 3.873877
688 (array([22]),) False
 223680/500000: episode: 5592, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.375 [12.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.231806, mean_absolute_error: 2.940162, mean_q: 3.820678
517 (array([22]),) False
 223720/500000: episode: 5593, duration: 30.698s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.325 [6.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.242376, mean_absolute_error: 3.018905, mean_q: 3.925656
765 (array([48]),) False
 223760/500000: episode: 5594, duration: 30.772s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 26.050 [1.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.236138, mean_absolute_error: 2.909669, mean_q: 3.804633
5 (array([37]),) False
 223800/500000: episode: 5595, duration: 29.929s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 21.975 [5.000, 46.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.216343, mean_absolute_error: 2.940291, mean_q: 3.833138
298 (array([22]),) False
 223840/500000: episode: 5596, duration: 30.753s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 20.550 [1.000, 22.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.239281, mean_absolute_error: 2.934272, mean_q: 3.824724
300 (array([22]),) False
 223880/500000: episode: 5597, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 19.750 [14.000, 28.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.228618, mean_absolute_error: 2.927403, mean_q: 3.822797
501 (array([12]),) False
 223920/500000: episode: 5598, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.925 [5.000, 49.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.238257, mean_absolute_error: 2.974441, mean_q: 3.866793
388 (array([22]),) False
 223960/500000: episode: 5599, duration: 29.908s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.125 [22.000, 49.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.228858, mean_absolute_error: 2.995123, mean_q: 3.884376
196 (array([22]),) False
 224000/500000: episode: 5600, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.075 [15.000, 51.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.252171, mean_absolute_error: 2.932700, mean_q: 3.821070
116 (array([22]),) False
 224040/500000: episode: 5601, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 14.475 [0.000, 47.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.223176, mean_absolute_error: 2.987803, mean_q: 3.884721
351 (array([22]),) False
 224080/500000: episode: 5602, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.025 [22.000, 23.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.239521, mean_absolute_error: 3.009410, mean_q: 3.922704
434 (array([22]),) False
 224120/500000: episode: 5603, duration: 29.904s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.450 [11.000, 50.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.245589, mean_absolute_error: 2.900643, mean_q: 3.788535
528 (array([12]),) False
 224160/500000: episode: 5604, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 18.225 [5.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.261612, mean_absolute_error: 2.958570, mean_q: 3.860113
320 (array([22]),) False
 224200/500000: episode: 5605, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.450 [5.000, 27.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.233454, mean_absolute_error: 2.927651, mean_q: 3.819628
451 (array([38]),) False
 224240/500000: episode: 5606, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 22.400 [14.000, 46.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.217367, mean_absolute_error: 2.933371, mean_q: 3.834232
309 (array([22]),) False
 224280/500000: episode: 5607, duration: 29.888s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.025 [7.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.213294, mean_absolute_error: 2.958021, mean_q: 3.863906
366 (array([22]),) False
 224320/500000: episode: 5608, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 22.950 [7.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.233447, mean_absolute_error: 3.014240, mean_q: 3.921018
199 (array([22]),) False
 224360/500000: episode: 5609, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.575 [12.000, 55.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.233545, mean_absolute_error: 2.976984, mean_q: 3.872352
28 (array([58]),) False
 224400/500000: episode: 5610, duration: 30.783s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 29.075 [3.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.232976, mean_absolute_error: 2.921577, mean_q: 3.817513
320 (array([22]),) False
 224440/500000: episode: 5611, duration: 29.893s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.675 [12.000, 46.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.230206, mean_absolute_error: 2.918791, mean_q: 3.808019
167 (array([22]),) False
 224480/500000: episode: 5612, duration: 30.830s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.350 [2.000, 43.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.223442, mean_absolute_error: 2.917514, mean_q: 3.809180
187 (array([15]),) False
 224520/500000: episode: 5613, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 12.875 [6.000, 53.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.229649, mean_absolute_error: 2.948817, mean_q: 3.852266
283 (array([34]),) False
 224560/500000: episode: 5614, duration: 30.806s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 20.875 [3.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.229643, mean_absolute_error: 2.985997, mean_q: 3.894070
232 (array([22]),) False
 224600/500000: episode: 5615, duration: 29.870s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 20.725 [0.000, 29.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.237288, mean_absolute_error: 2.940819, mean_q: 3.839741
78 (array([55]),) False
 224640/500000: episode: 5616, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 25.100 [22.000, 60.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.208096, mean_absolute_error: 2.955349, mean_q: 3.862652
427 (array([22]),) False
 224680/500000: episode: 5617, duration: 30.705s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 22.475 [7.000, 40.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.234004, mean_absolute_error: 2.922645, mean_q: 3.812033
329 (array([12]),) False
 224720/500000: episode: 5618, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 18.400 [0.000, 22.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.231731, mean_absolute_error: 2.898489, mean_q: 3.787668
463 (array([22]),) False
 224760/500000: episode: 5619, duration: 29.859s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.325 [3.000, 40.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.238071, mean_absolute_error: 2.907087, mean_q: 3.782332
275 (array([12]),) False
 224800/500000: episode: 5620, duration: 30.776s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 21.425 [12.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.220749, mean_absolute_error: 2.994072, mean_q: 3.889333
94 (array([44]),) False
 224840/500000: episode: 5621, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 43.400 [20.000, 44.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.244044, mean_absolute_error: 2.930596, mean_q: 3.793995
420 (array([22]),) False
 224880/500000: episode: 5622, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 29.650 [12.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.222985, mean_absolute_error: 3.018483, mean_q: 3.893698
122 (array([12]),) False
 224920/500000: episode: 5623, duration: 29.880s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.000, 1.000], mean action: 19.975 [3.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.234915, mean_absolute_error: 2.975122, mean_q: 3.841889
603 (array([58]),) False
 224960/500000: episode: 5624, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 55.050 [12.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.227300, mean_absolute_error: 2.977463, mean_q: 3.852185
807 (array([22]),) False
 225000/500000: episode: 5625, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.875 [6.000, 51.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.222597, mean_absolute_error: 2.934222, mean_q: 3.811811
553 (array([22]),) False
 225040/500000: episode: 5626, duration: 30.830s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 19.750 [4.000, 50.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.226036, mean_absolute_error: 2.895845, mean_q: 3.774469
4 (array([22]),) False
 225080/500000: episode: 5627, duration: 29.885s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 21.875 [7.000, 36.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.232378, mean_absolute_error: 2.967139, mean_q: 3.845531
177 (array([22]),) False
 225120/500000: episode: 5628, duration: 30.772s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 20.475 [3.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.232595, mean_absolute_error: 2.973484, mean_q: 3.858936
83 (array([22]),) False
 225160/500000: episode: 5629, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.200 [6.000, 44.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.243034, mean_absolute_error: 2.914726, mean_q: 3.788947
621 (array([22]),) False
 225200/500000: episode: 5630, duration: 30.800s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.475 [19.000, 44.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.238193, mean_absolute_error: 3.012905, mean_q: 3.905928
486 (array([22]),) False
 225240/500000: episode: 5631, duration: 29.886s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.950 [17.000, 25.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.239387, mean_absolute_error: 2.952978, mean_q: 3.830653
345 (array([22]),) False
 225280/500000: episode: 5632, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.300 [12.000, 34.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.227964, mean_absolute_error: 2.955104, mean_q: 3.824897
0 (array([48]),) False
 225320/500000: episode: 5633, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 23.050 [22.000, 44.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.221635, mean_absolute_error: 2.934388, mean_q: 3.814972
600 (array([48]),) False
 225360/500000: episode: 5634, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 38.900 [11.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.227946, mean_absolute_error: 2.924218, mean_q: 3.798980
659 (array([40]),) False
 225400/500000: episode: 5635, duration: 29.918s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 23.550 [0.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.233341, mean_absolute_error: 2.951761, mean_q: 3.818466
710 (array([12]),) False
 225440/500000: episode: 5636, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 28.600 [12.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.234405, mean_absolute_error: 2.938272, mean_q: 3.820641
643 (array([44]),) False
 225480/500000: episode: 5637, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 42.400 [22.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.243470, mean_absolute_error: 2.964106, mean_q: 3.851007
367 (array([12]),) False
 225520/500000: episode: 5638, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 16.150 [5.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.219992, mean_absolute_error: 3.028067, mean_q: 3.913481
762 (array([22]),) False
 225560/500000: episode: 5639, duration: 29.964s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.450 [9.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.219011, mean_absolute_error: 2.929723, mean_q: 3.816012
227 (array([22]),) False
 225600/500000: episode: 5640, duration: 30.819s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.075 [7.000, 40.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.230758, mean_absolute_error: 2.903193, mean_q: 3.788773
183 (array([22]),) False
 225640/500000: episode: 5641, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 20.500 [12.000, 22.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.228377, mean_absolute_error: 2.980272, mean_q: 3.869071
240 (array([22]),) False
 225680/500000: episode: 5642, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 22.325 [14.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.231171, mean_absolute_error: 3.012830, mean_q: 3.918375
701 (array([48]),) False
 225720/500000: episode: 5643, duration: 29.925s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 46.325 [3.000, 48.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.220453, mean_absolute_error: 2.945482, mean_q: 3.842326
445 (array([22]),) False
 225760/500000: episode: 5644, duration: 30.695s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 21.900 [1.000, 48.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.230130, mean_absolute_error: 3.004713, mean_q: 3.907854
112 (array([12]),) False
 225800/500000: episode: 5645, duration: 30.732s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 13.125 [4.000, 39.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.241936, mean_absolute_error: 2.921832, mean_q: 3.800828
408 (array([12]),) False
 225840/500000: episode: 5646, duration: 30.828s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 23.300 [9.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.220893, mean_absolute_error: 2.969603, mean_q: 3.869380
139 (array([48]),) False
 225880/500000: episode: 5647, duration: 29.904s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 15.550 [7.000, 22.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.238868, mean_absolute_error: 2.940021, mean_q: 3.820391
832 (array([22]),) False
 225920/500000: episode: 5648, duration: 30.745s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.175 [8.000, 54.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.245314, mean_absolute_error: 2.921136, mean_q: 3.790253
531 (array([22]),) False
 225960/500000: episode: 5649, duration: 30.776s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.000 [12.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.231425, mean_absolute_error: 2.935944, mean_q: 3.806768
382 (array([22]),) False
 226000/500000: episode: 5650, duration: 30.840s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.525 [6.000, 50.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.224176, mean_absolute_error: 2.910556, mean_q: 3.799666
281 (array([48]),) False
 226040/500000: episode: 5651, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 17.025 [3.000, 46.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.223480, mean_absolute_error: 2.942808, mean_q: 3.829079
345 (array([22]),) False
 226080/500000: episode: 5652, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 20.875 [9.000, 22.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.235786, mean_absolute_error: 2.936460, mean_q: 3.811609
800 (array([22]),) False
 226120/500000: episode: 5653, duration: 29.917s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.575 [11.000, 39.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.221674, mean_absolute_error: 2.986262, mean_q: 3.869484
189 (array([12]),) False
 226160/500000: episode: 5654, duration: 30.801s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 15.050 [8.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.250587, mean_absolute_error: 2.893454, mean_q: 3.766305
166 (array([22]),) False
 226200/500000: episode: 5655, duration: 29.991s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 25.225 [7.000, 60.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.222420, mean_absolute_error: 2.934688, mean_q: 3.819620
281 (array([48]),) False
 226240/500000: episode: 5656, duration: 30.800s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 14.725 [4.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.221850, mean_absolute_error: 2.902372, mean_q: 3.768850
548 (array([22]),) False
 226280/500000: episode: 5657, duration: 29.920s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 23.475 [7.000, 53.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.232975, mean_absolute_error: 2.939528, mean_q: 3.818670
170 (array([44]),) False
 226320/500000: episode: 5658, duration: 30.759s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 40.150 [2.000, 44.000], mean observation: -0.171 [-1.000, 1.000], loss: 0.235715, mean_absolute_error: 2.957580, mean_q: 3.836225
586 (array([12]),) False
 226360/500000: episode: 5659, duration: 30.817s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 13.200 [1.000, 36.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.227841, mean_absolute_error: 2.950838, mean_q: 3.827669
219 (array([36]),) False
 226400/500000: episode: 5660, duration: 30.838s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 12.850 [1.000, 45.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.228605, mean_absolute_error: 2.928155, mean_q: 3.805960
592 (array([22]),) False
 226440/500000: episode: 5661, duration: 30.838s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.875 [0.000, 54.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.219566, mean_absolute_error: 2.948448, mean_q: 3.828283
103 (array([22]),) False
 226480/500000: episode: 5662, duration: 30.843s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 23.250 [2.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.231998, mean_absolute_error: 2.944268, mean_q: 3.830534
648 (array([22]),) False
 226520/500000: episode: 5663, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.825 [8.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.225966, mean_absolute_error: 2.985109, mean_q: 3.877707
104 (array([22]),) False
 226560/500000: episode: 5664, duration: 30.845s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 20.975 [4.000, 49.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.229677, mean_absolute_error: 2.958223, mean_q: 3.833899
271 (array([18]),) False
 226600/500000: episode: 5665, duration: 29.984s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 21.350 [9.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.232246, mean_absolute_error: 2.939727, mean_q: 3.831289
624 (array([48]),) False
 226640/500000: episode: 5666, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 26.475 [12.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.216436, mean_absolute_error: 2.924118, mean_q: 3.818828
632 (array([22]),) False
 226680/500000: episode: 5667, duration: 29.967s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.575 [7.000, 28.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.238723, mean_absolute_error: 2.911320, mean_q: 3.794324
25 (array([48]),) False
 226720/500000: episode: 5668, duration: 30.705s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 25.275 [14.000, 50.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.218306, mean_absolute_error: 2.912608, mean_q: 3.785042
28 (array([58]),) False
 226760/500000: episode: 5669, duration: 29.980s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 31.700 [3.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.234685, mean_absolute_error: 2.989611, mean_q: 3.880780
294 (array([22]),) False
 226800/500000: episode: 5670, duration: 30.734s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.375 [3.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.227313, mean_absolute_error: 2.930975, mean_q: 3.816507
52 (array([22]),) False
 226840/500000: episode: 5671, duration: 30.786s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.850 [16.000, 44.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.228040, mean_absolute_error: 2.973438, mean_q: 3.856599
742 (array([33]),) False
 226880/500000: episode: 5672, duration: 30.756s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 36.250 [31.000, 46.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.230923, mean_absolute_error: 2.936708, mean_q: 3.817701
802 (array([22]),) False
 226920/500000: episode: 5673, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 22.275 [3.000, 46.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.266995, mean_absolute_error: 2.903203, mean_q: 3.765305
203 (array([48]),) False
 226960/500000: episode: 5674, duration: 30.821s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 47.550 [16.000, 60.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.233071, mean_absolute_error: 2.936326, mean_q: 3.808909
431 (array([22]),) False
 227000/500000: episode: 5675, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.425 [14.000, 55.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.229566, mean_absolute_error: 2.995806, mean_q: 3.871213
129 (array([22]),) False
 227040/500000: episode: 5676, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 22.375 [7.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.243018, mean_absolute_error: 2.915313, mean_q: 3.784766
451 (array([38]),) False
 227080/500000: episode: 5677, duration: 29.934s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 22.175 [0.000, 44.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.222385, mean_absolute_error: 2.929984, mean_q: 3.812248
804 (array([3]),) False
 227120/500000: episode: 5678, duration: 30.840s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 6.125 [3.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.223783, mean_absolute_error: 2.957428, mean_q: 3.840111
492 (array([22]),) False
 227160/500000: episode: 5679, duration: 29.883s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 21.575 [2.000, 48.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.240943, mean_absolute_error: 2.925468, mean_q: 3.800574
676 (array([40]),) False
 227200/500000: episode: 5680, duration: 30.841s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 20.750 [0.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.260704, mean_absolute_error: 2.959726, mean_q: 3.837056
718 (array([12]),) False
 227240/500000: episode: 5681, duration: 29.950s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 16.500 [6.000, 49.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.225892, mean_absolute_error: 2.955567, mean_q: 3.829812
581 (array([22]),) False
 227280/500000: episode: 5682, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.875 [22.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.232314, mean_absolute_error: 3.009312, mean_q: 3.881124
452 (array([22]),) False
 227320/500000: episode: 5683, duration: 30.850s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 22.325 [22.000, 35.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.235981, mean_absolute_error: 2.954386, mean_q: 3.812506
64 (array([12]),) False
 227360/500000: episode: 5684, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 16.000, mean reward: 0.400 [0.000, 1.000], mean action: 19.925 [0.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.234137, mean_absolute_error: 2.969442, mean_q: 3.837946
524 (array([22]),) False
 227400/500000: episode: 5685, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.700 [1.000, 36.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.239852, mean_absolute_error: 2.939037, mean_q: 3.822087
716 (array([48]),) False
 227440/500000: episode: 5686, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 24.475 [7.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.219332, mean_absolute_error: 2.901793, mean_q: 3.769297
115 (array([22]),) False
 227480/500000: episode: 5687, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.550 [9.000, 34.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.225489, mean_absolute_error: 2.884205, mean_q: 3.743502
684 (array([22]),) False
 227520/500000: episode: 5688, duration: 30.814s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.175 [8.000, 43.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.226103, mean_absolute_error: 2.971826, mean_q: 3.846141
855 (array([12]),) False
 227560/500000: episode: 5689, duration: 30.001s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 17.150 [0.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.219477, mean_absolute_error: 2.900749, mean_q: 3.767162
698 (array([22]),) False
 227600/500000: episode: 5690, duration: 30.837s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 24.100 [22.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.227199, mean_absolute_error: 2.921980, mean_q: 3.793279
570 (array([47]),) False
 227640/500000: episode: 5691, duration: 29.957s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 25.525 [12.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.239513, mean_absolute_error: 2.899510, mean_q: 3.768911
201 (array([22]),) False
 227680/500000: episode: 5692, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 21.500 [0.000, 37.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.235500, mean_absolute_error: 2.914511, mean_q: 3.779464
363 (array([36]),) False
 227720/500000: episode: 5693, duration: 29.982s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 25.925 [5.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.235660, mean_absolute_error: 2.965174, mean_q: 3.850562
801 (array([58]),) False
 227760/500000: episode: 5694, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 6.000, mean reward: 0.150 [0.000, 1.000], mean action: 20.075 [3.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.223054, mean_absolute_error: 2.982354, mean_q: 3.863673
666 (array([22]),) False
 227800/500000: episode: 5695, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.050 [6.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.223616, mean_absolute_error: 2.916982, mean_q: 3.796953
238 (array([22]),) False
 227840/500000: episode: 5696, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 22.525 [13.000, 42.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.219536, mean_absolute_error: 2.920443, mean_q: 3.794853
239 (array([22]),) False
 227880/500000: episode: 5697, duration: 30.799s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.475 [4.000, 22.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.232606, mean_absolute_error: 2.901702, mean_q: 3.781449
283 (array([34]),) False
 227920/500000: episode: 5698, duration: 30.846s, episode steps: 40, steps per second: 1, episode reward: 7.000, mean reward: 0.175 [0.000, 1.000], mean action: 18.125 [3.000, 51.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.222902, mean_absolute_error: 2.925683, mean_q: 3.800684
757 (array([48]),) False
 227960/500000: episode: 5699, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 45.275 [1.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.236770, mean_absolute_error: 2.944744, mean_q: 3.823000
514 (array([54]),) False
 228000/500000: episode: 5700, duration: 30.831s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 18.700 [12.000, 51.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.241667, mean_absolute_error: 2.892557, mean_q: 3.771976
391 (array([22]),) False
 228040/500000: episode: 5701, duration: 30.006s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.275 [13.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.243314, mean_absolute_error: 2.919490, mean_q: 3.798730
632 (array([22]),) False
 228080/500000: episode: 5702, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.550 [2.000, 53.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.243018, mean_absolute_error: 2.951909, mean_q: 3.832790
719 (array([22]),) False
 228120/500000: episode: 5703, duration: 29.952s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 17.625 [2.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.214079, mean_absolute_error: 2.945296, mean_q: 3.836758
43 (array([12]),) False
 228160/500000: episode: 5704, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 21.950 [6.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.250621, mean_absolute_error: 2.952907, mean_q: 3.830807
862 (array([14]),) False
 228200/500000: episode: 5705, duration: 29.934s, episode steps: 40, steps per second: 1, episode reward: 28.000, mean reward: 0.700 [0.000, 1.000], mean action: 27.575 [10.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.220748, mean_absolute_error: 2.921062, mean_q: 3.790437
612 (array([22]),) False
 228240/500000: episode: 5706, duration: 30.822s, episode steps: 40, steps per second: 1, episode reward: 10.000, mean reward: 0.250 [0.000, 1.000], mean action: 35.275 [12.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.230970, mean_absolute_error: 2.912715, mean_q: 3.775690
549 (array([22]),) False
 228280/500000: episode: 5707, duration: 30.681s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 20.550 [0.000, 37.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.244004, mean_absolute_error: 2.998042, mean_q: 3.886903
673 (array([3]),) False
 228320/500000: episode: 5708, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 7.025 [0.000, 44.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.228044, mean_absolute_error: 2.914237, mean_q: 3.788094
745 (array([22]),) False
 228360/500000: episode: 5709, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 23.900 [3.000, 53.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.226193, mean_absolute_error: 2.963199, mean_q: 3.851046
520 (array([22]),) False
 228400/500000: episode: 5710, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 21.950 [12.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.236688, mean_absolute_error: 2.906195, mean_q: 3.783939
822 (array([22]),) False
 228440/500000: episode: 5711, duration: 30.630s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.925 [19.000, 22.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.221280, mean_absolute_error: 3.015775, mean_q: 3.900974
497 (array([33]),) False
 228480/500000: episode: 5712, duration: 30.844s, episode steps: 40, steps per second: 1, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 27.875 [3.000, 50.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.217234, mean_absolute_error: 2.935449, mean_q: 3.807826
780 (array([22]),) False
 228520/500000: episode: 5713, duration: 30.011s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.900 [20.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.232612, mean_absolute_error: 2.916529, mean_q: 3.792004
788 (array([3]),) False
 228560/500000: episode: 5714, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 3.000, mean reward: 0.075 [0.000, 1.000], mean action: 49.625 [3.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.224830, mean_absolute_error: 2.912765, mean_q: 3.789512
171 (array([22]),) False
 228600/500000: episode: 5715, duration: 29.940s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.150 [12.000, 45.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.227400, mean_absolute_error: 2.955935, mean_q: 3.833661
102 (array([22]),) False
 228640/500000: episode: 5716, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 24.650 [12.000, 53.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.214253, mean_absolute_error: 2.939523, mean_q: 3.817366
83 (array([22]),) False
 228680/500000: episode: 5717, duration: 29.947s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 21.350 [12.000, 49.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.226089, mean_absolute_error: 2.898395, mean_q: 3.766731
594 (array([48]),) False
 228720/500000: episode: 5718, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.250 [19.000, 52.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.241482, mean_absolute_error: 2.908565, mean_q: 3.779298
149 (array([8]),) False
 228760/500000: episode: 5719, duration: 30.842s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 11.525 [5.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.227514, mean_absolute_error: 2.950119, mean_q: 3.831506
108 (array([48]),) False
 228800/500000: episode: 5720, duration: 30.756s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 27.875 [12.000, 48.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.236448, mean_absolute_error: 2.952040, mean_q: 3.831722
234 (array([22]),) False
 228840/500000: episode: 5721, duration: 30.775s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 20.625 [0.000, 42.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.216164, mean_absolute_error: 2.944797, mean_q: 3.819454
828 (array([48]),) False
 228880/500000: episode: 5722, duration: 30.813s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 47.800 [40.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.226410, mean_absolute_error: 2.993333, mean_q: 3.871981
422 (array([48]),) False
 228920/500000: episode: 5723, duration: 30.810s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.950 [6.000, 48.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.248711, mean_absolute_error: 2.956776, mean_q: 3.823605
711 (array([22]),) False
 228960/500000: episode: 5724, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.550 [1.000, 44.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.234518, mean_absolute_error: 2.945797, mean_q: 3.814246
643 (array([44]),) False
 229000/500000: episode: 5725, duration: 30.026s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 37.200 [0.000, 44.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.230158, mean_absolute_error: 2.916160, mean_q: 3.781792
515 (array([22]),) False
 229040/500000: episode: 5726, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.425 [14.000, 57.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.235474, mean_absolute_error: 2.986212, mean_q: 3.859866
772 (array([46]),) False
 229080/500000: episode: 5727, duration: 29.976s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 43.475 [8.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.227343, mean_absolute_error: 2.925336, mean_q: 3.793198
547 (array([21]),) False
 229120/500000: episode: 5728, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 15.150 [12.000, 36.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.221841, mean_absolute_error: 2.909910, mean_q: 3.787840
861 (array([22]),) False
 229160/500000: episode: 5729, duration: 29.963s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 27.450 [13.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.223803, mean_absolute_error: 2.904476, mean_q: 3.773119
488 (array([22]),) False
 229200/500000: episode: 5730, duration: 30.685s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.250 [3.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.239050, mean_absolute_error: 2.935347, mean_q: 3.814056
716 (array([48]),) False
 229240/500000: episode: 5731, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 13.000, mean reward: 0.325 [0.000, 1.000], mean action: 31.150 [11.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.223752, mean_absolute_error: 2.919732, mean_q: 3.802471
246 (array([22]),) False
 229280/500000: episode: 5732, duration: 30.814s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.225 [2.000, 48.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.225779, mean_absolute_error: 2.964444, mean_q: 3.851167
861 (array([22]),) False
 229320/500000: episode: 5733, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 27.000, mean reward: 0.675 [0.000, 1.000], mean action: 28.725 [2.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.222820, mean_absolute_error: 2.954484, mean_q: 3.834182
650 (array([22]),) False
 229360/500000: episode: 5734, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 21.925 [16.000, 30.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.222347, mean_absolute_error: 2.959968, mean_q: 3.836557
827 (array([14]),) False
 229400/500000: episode: 5735, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 26.550 [0.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.213930, mean_absolute_error: 2.975187, mean_q: 3.858384
552 (array([22]),) False
 229440/500000: episode: 5736, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.950 [12.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.222331, mean_absolute_error: 2.909797, mean_q: 3.782977
370 (array([58]),) False
 229480/500000: episode: 5737, duration: 29.944s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 29.650 [3.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.238353, mean_absolute_error: 2.922749, mean_q: 3.800180
681 (array([12]),) False
 229520/500000: episode: 5738, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 17.300 [12.000, 51.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.218429, mean_absolute_error: 2.916340, mean_q: 3.784229
766 (array([12]),) False
 229560/500000: episode: 5739, duration: 29.958s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.425 [2.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.215605, mean_absolute_error: 2.939390, mean_q: 3.811858
858 (array([12]),) False
 229600/500000: episode: 5740, duration: 30.826s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 20.450 [1.000, 45.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.227704, mean_absolute_error: 2.934424, mean_q: 3.813597
429 (array([22]),) False
 229640/500000: episode: 5741, duration: 29.942s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.425 [13.000, 48.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.221371, mean_absolute_error: 2.958153, mean_q: 3.856334
787 (array([3]),) False
 229680/500000: episode: 5742, duration: 30.853s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 19.250 [3.000, 38.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.230634, mean_absolute_error: 2.893368, mean_q: 3.767783
216 (array([22]),) False
 229720/500000: episode: 5743, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.350 [12.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.230412, mean_absolute_error: 2.951159, mean_q: 3.835750
352 (array([22]),) False
 229760/500000: episode: 5744, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 24.025 [1.000, 56.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.238350, mean_absolute_error: 2.927569, mean_q: 3.820283
127 (array([22]),) False
 229800/500000: episode: 5745, duration: 30.812s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.227137, mean_absolute_error: 2.928082, mean_q: 3.815552
236 (array([22]),) False
 229840/500000: episode: 5746, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 23.350 [22.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.224118, mean_absolute_error: 2.946406, mean_q: 3.826822
803 (array([58]),) False
 229880/500000: episode: 5747, duration: 30.804s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 34.375 [3.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.233572, mean_absolute_error: 2.956066, mean_q: 3.847683
588 (array([22]),) False
 229920/500000: episode: 5748, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.150 [6.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.234823, mean_absolute_error: 2.880116, mean_q: 3.764095
46 (array([22]),) False
 229960/500000: episode: 5749, duration: 29.934s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 20.975 [0.000, 26.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.218986, mean_absolute_error: 2.968418, mean_q: 3.864780
815 (array([22]),) False
 230000/500000: episode: 5750, duration: 30.883s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 22.200 [0.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.229304, mean_absolute_error: 2.931604, mean_q: 3.813106
252 (array([22]),) False
 230040/500000: episode: 5751, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.700 [22.000, 46.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.248474, mean_absolute_error: 2.938665, mean_q: 3.826212
225 (array([48]),) False
 230080/500000: episode: 5752, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 11.000, mean reward: 0.275 [0.000, 1.000], mean action: 15.975 [3.000, 47.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.240547, mean_absolute_error: 2.930012, mean_q: 3.816299
23 (array([48]),) False
 230120/500000: episode: 5753, duration: 30.563s, episode steps: 40, steps per second: 1, episode reward: 20.000, mean reward: 0.500 [0.000, 1.000], mean action: 24.300 [19.000, 52.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.224717, mean_absolute_error: 2.924247, mean_q: 3.806155
407 (array([22]),) False
 230160/500000: episode: 5754, duration: 31.083s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.975 [16.000, 46.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.230067, mean_absolute_error: 2.928384, mean_q: 3.816074
107 (array([22]),) False
 230200/500000: episode: 5755, duration: 32.314s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 22.925 [19.000, 45.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.224329, mean_absolute_error: 2.905360, mean_q: 3.781297
495 (array([48]),) False
 230240/500000: episode: 5756, duration: 32.935s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.625 [13.000, 48.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.227806, mean_absolute_error: 2.964031, mean_q: 3.850048
389 (array([48]),) False
 230280/500000: episode: 5757, duration: 32.933s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 45.425 [7.000, 51.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.237006, mean_absolute_error: 2.907846, mean_q: 3.784119
416 (array([22]),) False
 230320/500000: episode: 5758, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 23.150 [2.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.241984, mean_absolute_error: 2.932847, mean_q: 3.813134
303 (array([22]),) False
 230360/500000: episode: 5759, duration: 32.781s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.725 [22.000, 53.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.226788, mean_absolute_error: 2.958031, mean_q: 3.849910
315 (array([12]),) False
 230400/500000: episode: 5760, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 13.850 [6.000, 22.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.222797, mean_absolute_error: 2.958390, mean_q: 3.842983
262 (array([22]),) False
 230440/500000: episode: 5761, duration: 31.997s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 23.100 [16.000, 51.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.238182, mean_absolute_error: 2.922884, mean_q: 3.800055
81 (array([22]),) False
 230480/500000: episode: 5762, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.575 [7.000, 49.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.241957, mean_absolute_error: 2.939176, mean_q: 3.822671
417 (array([12]),) False
 230520/500000: episode: 5763, duration: 32.029s, episode steps: 40, steps per second: 1, episode reward: 5.000, mean reward: 0.125 [0.000, 1.000], mean action: 21.500 [8.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.244771, mean_absolute_error: 2.991259, mean_q: 3.885205
182 (array([54]),) False
 230560/500000: episode: 5764, duration: 32.999s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 53.500 [12.000, 58.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.230639, mean_absolute_error: 2.982604, mean_q: 3.866046
751 (array([22]),) False
 230600/500000: episode: 5765, duration: 31.992s, episode steps: 40, steps per second: 1, episode reward: 19.000, mean reward: 0.475 [0.000, 1.000], mean action: 31.175 [12.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.248710, mean_absolute_error: 2.960361, mean_q: 3.844500
550 (array([12]),) False
 230640/500000: episode: 5766, duration: 32.863s, episode steps: 40, steps per second: 1, episode reward: 23.000, mean reward: 0.575 [0.000, 1.000], mean action: 16.875 [0.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.251002, mean_absolute_error: 2.942622, mean_q: 3.823703
212 (array([36]),) False
 230680/500000: episode: 5767, duration: 32.908s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 19.250 [9.000, 34.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.251522, mean_absolute_error: 2.927670, mean_q: 3.813648
192 (array([22]),) False
 230720/500000: episode: 5768, duration: 32.955s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 13.650 [12.000, 48.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.230898, mean_absolute_error: 2.894129, mean_q: 3.771469
299 (array([12]),) False
 230760/500000: episode: 5769, duration: 32.819s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 26.050 [3.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.235593, mean_absolute_error: 2.995041, mean_q: 3.900113
644 (array([12]),) False
 230800/500000: episode: 5770, duration: 33.355s, episode steps: 40, steps per second: 1, episode reward: 14.000, mean reward: 0.350 [0.000, 1.000], mean action: 18.575 [12.000, 43.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.232002, mean_absolute_error: 2.979909, mean_q: 3.879693
563 (array([22]),) False
 230840/500000: episode: 5771, duration: 32.361s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.325 [22.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.238233, mean_absolute_error: 2.920463, mean_q: 3.800220
136 (array([12]),) False
 230880/500000: episode: 5772, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 4.000, mean reward: 0.100 [0.000, 1.000], mean action: 22.200 [12.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.231585, mean_absolute_error: 2.929846, mean_q: 3.814803
191 (array([38]),) False
 230920/500000: episode: 5773, duration: 29.993s, episode steps: 40, steps per second: 1, episode reward: 8.000, mean reward: 0.200 [0.000, 1.000], mean action: 19.400 [11.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.228836, mean_absolute_error: 2.926136, mean_q: 3.800443
256 (array([22]),) False
 230960/500000: episode: 5774, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 22.025 [22.000, 23.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.223100, mean_absolute_error: 2.960140, mean_q: 3.845736
39 (array([22]),) False
 231000/500000: episode: 5775, duration: 29.952s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 22.425 [3.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.225425, mean_absolute_error: 2.924283, mean_q: 3.805039
628 (array([22]),) False
 231040/500000: episode: 5776, duration: 31.139s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 23.725 [5.000, 56.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.237759, mean_absolute_error: 2.948612, mean_q: 3.815506
774 (array([57]),) False
 231080/500000: episode: 5777, duration: 30.549s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 40.500 [11.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.238487, mean_absolute_error: 2.938335, mean_q: 3.797382
190 (array([3]),) False
 231120/500000: episode: 5778, duration: 31.414s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 5.975 [3.000, 47.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.228992, mean_absolute_error: 2.938566, mean_q: 3.819216
168 (array([22]),) False
 231160/500000: episode: 5779, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.850 [16.000, 22.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.232578, mean_absolute_error: 2.953676, mean_q: 3.835406
278 (array([48]),) False
 231200/500000: episode: 5780, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 36.450 [10.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.231743, mean_absolute_error: 2.915319, mean_q: 3.795223
625 (array([22]),) False
 231240/500000: episode: 5781, duration: 31.076s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 23.700 [5.000, 50.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.231940, mean_absolute_error: 2.980390, mean_q: 3.851261
58 (array([48]),) False
 231280/500000: episode: 5782, duration: 31.142s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 46.350 [7.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.224035, mean_absolute_error: 2.958498, mean_q: 3.827931
337 (array([22]),) False
 231320/500000: episode: 5783, duration: 31.117s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.075 [5.000, 42.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.237411, mean_absolute_error: 2.940886, mean_q: 3.815000
100 (array([22]),) False
 231360/500000: episode: 5784, duration: 31.109s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.300 [10.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.226011, mean_absolute_error: 3.000795, mean_q: 3.896021
231 (array([22]),) False
 231400/500000: episode: 5785, duration: 30.593s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.825 [6.000, 46.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.235561, mean_absolute_error: 2.964655, mean_q: 3.848789
138 (array([3]),) False
 231440/500000: episode: 5786, duration: 31.317s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 10.500 [3.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.237410, mean_absolute_error: 2.949326, mean_q: 3.836579
668 (array([22]),) False
 231480/500000: episode: 5787, duration: 30.667s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 22.450 [4.000, 49.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.228063, mean_absolute_error: 2.939480, mean_q: 3.834964
296 (array([22]),) False
 231520/500000: episode: 5788, duration: 31.102s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.000, 1.000], mean action: 23.025 [6.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.226390, mean_absolute_error: 2.907314, mean_q: 3.786291
200 (array([22]),) False
 231560/500000: episode: 5789, duration: 30.588s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 18.975 [3.000, 52.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.236965, mean_absolute_error: 2.949753, mean_q: 3.839517
247 (array([14]),) False
 231600/500000: episode: 5790, duration: 31.220s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 20.250 [6.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.245885, mean_absolute_error: 2.986146, mean_q: 3.878041
270 (array([3]),) False
 231640/500000: episode: 5791, duration: 31.545s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 9.250 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.232747, mean_absolute_error: 2.920120, mean_q: 3.792744
751 (array([22]),) False
 231680/500000: episode: 5792, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 28.050 [3.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.224304, mean_absolute_error: 2.950083, mean_q: 3.846764
781 (array([8]),) False
 231720/500000: episode: 5793, duration: 31.060s, episode steps: 40, steps per second: 1, episode reward: 15.000, mean reward: 0.375 [0.000, 1.000], mean action: 16.725 [3.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.227627, mean_absolute_error: 2.990642, mean_q: 3.885870
571 (array([48]),) False
 231760/500000: episode: 5794, duration: 30.997s, episode steps: 40, steps per second: 1, episode reward: 22.000, mean reward: 0.550 [0.000, 1.000], mean action: 26.075 [19.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.220940, mean_absolute_error: 2.941601, mean_q: 3.835817
361 (array([22]),) False
 231800/500000: episode: 5795, duration: 31.212s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 20.700 [12.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.230254, mean_absolute_error: 2.931789, mean_q: 3.816258
40 (array([22]),) False
 231840/500000: episode: 5796, duration: 31.093s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.350 [20.000, 53.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.229953, mean_absolute_error: 2.944623, mean_q: 3.826328
32 (array([48]),) False
 231880/500000: episode: 5797, duration: 30.253s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 35.000 [22.000, 48.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.228057, mean_absolute_error: 3.012242, mean_q: 3.918642
179 (array([18]),) False
 231920/500000: episode: 5798, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 21.000, mean reward: 0.525 [0.000, 1.000], mean action: 21.575 [1.000, 57.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.255251, mean_absolute_error: 2.909639, mean_q: 3.794964
283 (array([34]),) False
 231960/500000: episode: 5799, duration: 30.574s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 17.600 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.252440, mean_absolute_error: 2.917185, mean_q: 3.801006
248 (array([12]),) False
 232000/500000: episode: 5800, duration: 31.211s, episode steps: 40, steps per second: 1, episode reward: 9.000, mean reward: 0.225 [0.000, 1.000], mean action: 22.850 [5.000, 53.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.256395, mean_absolute_error: 2.938799, mean_q: 3.830440
12 (array([22]),) False
 232040/500000: episode: 5801, duration: 30.240s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.025 [16.000, 57.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.220640, mean_absolute_error: 2.973342, mean_q: 3.857430
130 (array([22]),) False
 232080/500000: episode: 5802, duration: 31.445s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 21.750 [12.000, 22.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.250301, mean_absolute_error: 2.988696, mean_q: 3.870589
212 (array([36]),) False
 232120/500000: episode: 5803, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 2.000, mean reward: 0.050 [0.000, 1.000], mean action: 27.650 [8.000, 52.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.233118, mean_absolute_error: 2.969517, mean_q: 3.853861
629 (array([22]),) False
 232160/500000: episode: 5804, duration: 31.328s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 32.175 [0.000, 54.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.222361, mean_absolute_error: 2.951179, mean_q: 3.831274
145 (array([19]),) False
 232200/500000: episode: 5805, duration: 31.575s, episode steps: 40, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 20.950 [3.000, 52.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.249784, mean_absolute_error: 2.957914, mean_q: 3.836794
529 (array([3]),) False
 232240/500000: episode: 5806, duration: 31.447s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 5.725 [3.000, 46.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.225223, mean_absolute_error: 2.856287, mean_q: 3.727188
702 (array([22]),) False
 232280/500000: episode: 5807, duration: 31.201s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 22.475 [17.000, 46.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.217634, mean_absolute_error: 2.997082, mean_q: 3.901851
73 (array([22]),) False
 232320/500000: episode: 5808, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 24.875 [22.000, 54.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.230101, mean_absolute_error: 2.985722, mean_q: 3.875081
87 (array([3]),) False
 232360/500000: episode: 5809, duration: 30.284s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 6.275 [2.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.240007, mean_absolute_error: 2.951132, mean_q: 3.833743
235 (array([14]),) False
 232400/500000: episode: 5810, duration: 32.510s, episode steps: 40, steps per second: 1, episode reward: 18.000, mean reward: 0.450 [0.000, 1.000], mean action: 24.925 [14.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.239343, mean_absolute_error: 2.938135, mean_q: 3.812505
530 (array([22]),) False
 232440/500000: episode: 5811, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.825 [19.000, 42.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.219929, mean_absolute_error: 2.975935, mean_q: 3.854362
239 (array([22]),) False
 232480/500000: episode: 5812, duration: 32.390s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 21.775 [1.000, 38.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.243138, mean_absolute_error: 2.926461, mean_q: 3.798734
485 (array([22]),) False
 232520/500000: episode: 5813, duration: 30.297s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.000 [6.000, 50.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.230112, mean_absolute_error: 2.968329, mean_q: 3.837013
608 (array([36]),) False
 232560/500000: episode: 5814, duration: 31.328s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.000, 1.000], mean action: 33.400 [0.000, 36.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.234548, mean_absolute_error: 2.961538, mean_q: 3.840033
262 (array([22]),) False
 232600/500000: episode: 5815, duration: 31.466s, episode steps: 40, steps per second: 1, episode reward: 12.000, mean reward: 0.300 [0.000, 1.000], mean action: 23.100 [7.000, 47.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.246062, mean_absolute_error: 2.957787, mean_q: 3.838283
813 (array([22]),) False
 232640/500000: episode: 5816, duration: 31.370s, episode steps: 40, steps per second: 1, episode reward: 32.000, mean reward: 0.800 [0.000, 1.000], mean action: 20.925 [8.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.243634, mean_absolute_error: 3.043031, mean_q: 3.936359
368 (array([22]),) False
 232680/500000: episode: 5817, duration: 31.621s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 22.975 [12.000, 43.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.233482, mean_absolute_error: 2.956409, mean_q: 3.837673
852 (array([44]),) False
 232720/500000: episode: 5818, duration: 32.358s, episode steps: 40, steps per second: 1, episode reward: 25.000, mean reward: 0.625 [0.000, 1.000], mean action: 36.175 [0.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.236178, mean_absolute_error: 2.940981, mean_q: 3.814536
313 (array([22]),) False
 232760/500000: episode: 5819, duration: 31.572s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 23.550 [14.000, 51.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.246513, mean_absolute_error: 2.962457, mean_q: 3.837534
115 (array([22]),) False
 232800/500000: episode: 5820, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 36.000, mean reward: 0.900 [0.000, 1.000], mean action: 22.675 [3.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.238583, mean_absolute_error: 2.942686, mean_q: 3.810920
294 (array([22]),) False
 232840/500000: episode: 5821, duration: 31.189s, episode steps: 40, steps per second: 1, episode reward: 39.000, mean reward: 0.975 [0.000, 1.000], mean action: 21.500 [2.000, 22.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.224186, mean_absolute_error: 2.996463, mean_q: 3.865864
752 (array([3]),) False
 232880/500000: episode: 5822, duration: 32.429s, episode steps: 40, steps per second: 1, episode reward: 38.000, mean reward: 0.950 [0.000, 1.000], mean action: 4.650 [3.000, 47.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.217501, mean_absolute_error: 2.940752, mean_q: 3.802209
185 (array([22]),) False
 232920/500000: episode: 5823, duration: 31.356s, episode steps: 40, steps per second: 1, episode reward: 24.000, mean reward: 0.600 [0.000, 1.000], mean action: 24.025 [8.000, 57.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.230519, mean_absolute_error: 2.985976, mean_q: 3.846179
651 (array([22]),) False
 232960/500000: episode: 5824, duration: 31.387s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 22.900 [16.000, 52.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.231921, mean_absolute_error: 2.958457, mean_q: 3.817861
639 (array([22]),) False
 233000/500000: episode: 5825, duration: 32.103s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 23.150 [7.000, 55.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.244624, mean_absolute_error: 3.015546, mean_q: 3.888913
513 (array([12]),) False
 233040/500000: episode: 5826, duration: 32.241s, episode steps: 40, steps per second: 1, episode reward: 29.000, mean reward: 0.725 [0.000, 1.000], mean action: 13.775 [11.000, 42.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.225854, mean_absolute_error: 2.946781, mean_q: 3.804006
135 (array([22]),) False
 233080/500000: episode: 5827, duration: 31.684s, episode steps: 40, steps per second: 1, episode reward: 35.000, mean reward: 0.875 [0.000, 1.000], mean action: 23.350 [16.000, 45.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.226820, mean_absolute_error: 3.025462, mean_q: 3.905318
537 (array([22]),) False
 233120/500000: episode: 5828, duration: 32.672s, episode steps: 40, steps per second: 1, episode reward: 33.000, mean reward: 0.825 [0.000, 1.000], mean action: 24.250 [0.000, 54.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.224232, mean_absolute_error: 2.974148, mean_q: 3.851051
718 (array([12]),) False
 233160/500000: episode: 5829, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 31.000, mean reward: 0.775 [0.000, 1.000], mean action: 13.550 [12.000, 44.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.228030, mean_absolute_error: 3.007170, mean_q: 3.882977
520 (array([22]),) False
 233200/500000: episode: 5830, duration: 32.206s, episode steps: 40, steps per second: 1, episode reward: 26.000, mean reward: 0.650 [0.000, 1.000], mean action: 23.000 [5.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.217476, mean_absolute_error: 2.978345, mean_q: 3.864356