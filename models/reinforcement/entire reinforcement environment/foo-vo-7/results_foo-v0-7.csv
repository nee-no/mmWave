703 (array([3]),) False
   1040/500000: episode: 26, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 27.424, mean reward: 0.686 [0.113, 1.000], mean action: 16.550 [1.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 24.637875, mean_absolute_error: 1.695263, mean_q: 7.693492
480 (array([22]),) False
   1080/500000: episode: 27, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 29.158, mean reward: 0.729 [0.072, 1.000], mean action: 28.125 [6.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 8.973722, mean_absolute_error: 1.413123, mean_q: 6.490710
216 (array([22]),) False
   1120/500000: episode: 28, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 26.025, mean reward: 0.651 [0.000, 1.000], mean action: 24.825 [1.000, 56.000], mean observation: -0.183 [-1.000, 1.000], loss: 3.002772, mean_absolute_error: 1.535161, mean_q: 5.353691
363 (array([36]),) False
   1160/500000: episode: 29, duration: 30.800s, episode steps: 40, steps per second: 1, episode reward: 22.051, mean reward: 0.551 [0.000, 1.000], mean action: 27.025 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 1.196168, mean_absolute_error: 1.585213, mean_q: 4.339433
572 (array([58]),) False
   1200/500000: episode: 30, duration: 30.828s, episode steps: 40, steps per second: 1, episode reward: 20.371, mean reward: 0.509 [0.092, 1.000], mean action: 37.525 [3.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.674866, mean_absolute_error: 1.548409, mean_q: 3.786909
532 (array([25]),) False
   1240/500000: episode: 31, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 21.522, mean reward: 0.538 [0.000, 1.000], mean action: 30.150 [2.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.424962, mean_absolute_error: 1.456491, mean_q: 3.337513
94 (array([44]),) False
   1280/500000: episode: 32, duration: 30.765s, episode steps: 40, steps per second: 1, episode reward: 27.408, mean reward: 0.685 [0.085, 1.000], mean action: 36.050 [0.000, 58.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.340746, mean_absolute_error: 1.471313, mean_q: 3.208589
283 (array([34]),) False
   1320/500000: episode: 33, duration: 30.797s, episode steps: 40, steps per second: 1, episode reward: 16.154, mean reward: 0.404 [0.025, 0.979], mean action: 21.075 [0.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.290507, mean_absolute_error: 1.456994, mean_q: 3.030364
679 (array([44]),) False
   1360/500000: episode: 34, duration: 29.834s, episode steps: 40, steps per second: 1, episode reward: 25.038, mean reward: 0.626 [0.000, 1.000], mean action: 21.650 [0.000, 51.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.229238, mean_absolute_error: 1.473574, mean_q: 2.917369
545 (array([22]),) False
   1400/500000: episode: 35, duration: 30.726s, episode steps: 40, steps per second: 1, episode reward: 26.887, mean reward: 0.672 [0.035, 1.000], mean action: 23.700 [2.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.203320, mean_absolute_error: 1.446566, mean_q: 2.797899
852 (array([44]),) False
   1440/500000: episode: 36, duration: 30.889s, episode steps: 40, steps per second: 1, episode reward: 29.998, mean reward: 0.750 [0.165, 0.900], mean action: 20.475 [0.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.174577, mean_absolute_error: 1.425347, mean_q: 2.697209
774 (array([57]),) False
   1480/500000: episode: 37, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 25.470, mean reward: 0.637 [0.282, 0.875], mean action: 22.550 [3.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.154278, mean_absolute_error: 1.429733, mean_q: 2.653028
151 (array([22]),) False
   1520/500000: episode: 38, duration: 29.740s, episode steps: 40, steps per second: 1, episode reward: 29.470, mean reward: 0.737 [0.164, 0.960], mean action: 21.575 [4.000, 58.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.150378, mean_absolute_error: 1.413901, mean_q: 2.583560
493 (array([22]),) False
   1560/500000: episode: 39, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 26.292, mean reward: 0.657 [0.134, 0.974], mean action: 21.900 [2.000, 59.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.136622, mean_absolute_error: 1.407135, mean_q: 2.538752
296 (array([22]),) False
   1600/500000: episode: 40, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 20.944, mean reward: 0.524 [0.053, 1.000], mean action: 25.750 [0.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.123377, mean_absolute_error: 1.422042, mean_q: 2.525632
611 (array([22]),) False
   1640/500000: episode: 41, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 28.505, mean reward: 0.713 [0.098, 1.000], mean action: 19.300 [2.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.123371, mean_absolute_error: 1.405824, mean_q: 2.467531
784 (array([22]),) False
   1680/500000: episode: 42, duration: 29.799s, episode steps: 40, steps per second: 1, episode reward: 31.237, mean reward: 0.781 [0.141, 0.966], mean action: 19.550 [8.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.110276, mean_absolute_error: 1.413994, mean_q: 2.454877
194 (array([44]),) False
   1720/500000: episode: 43, duration: 30.717s, episode steps: 40, steps per second: 1, episode reward: 23.467, mean reward: 0.587 [0.000, 1.000], mean action: 19.950 [3.000, 54.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.110707, mean_absolute_error: 1.404040, mean_q: 2.417094
779 (array([12]),) False
   1760/500000: episode: 44, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 27.031, mean reward: 0.676 [0.000, 1.000], mean action: 24.500 [1.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.108491, mean_absolute_error: 1.413595, mean_q: 2.408958
311 (array([22]),) False
   1800/500000: episode: 45, duration: 30.821s, episode steps: 40, steps per second: 1, episode reward: 28.555, mean reward: 0.714 [0.044, 1.000], mean action: 21.875 [5.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.103349, mean_absolute_error: 1.429899, mean_q: 2.411871
700 (array([44]),) False
   1840/500000: episode: 46, duration: 29.767s, episode steps: 40, steps per second: 1, episode reward: 27.574, mean reward: 0.689 [0.000, 1.000], mean action: 23.425 [4.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.096930, mean_absolute_error: 1.446241, mean_q: 2.416019
566 (array([12]),) False
   1880/500000: episode: 47, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 27.502, mean reward: 0.688 [0.118, 1.000], mean action: 18.950 [0.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.092641, mean_absolute_error: 1.443400, mean_q: 2.399593
588 (array([22]),) False
   1920/500000: episode: 48, duration: 30.726s, episode steps: 40, steps per second: 1, episode reward: 25.984, mean reward: 0.650 [0.020, 0.908], mean action: 21.350 [3.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.093850, mean_absolute_error: 1.453302, mean_q: 2.398245
183 (array([22]),) False
   1960/500000: episode: 49, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 18.395, mean reward: 0.460 [0.035, 1.000], mean action: 21.575 [0.000, 59.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.089547, mean_absolute_error: 1.464577, mean_q: 2.400129
268 (array([22]),) False
   2000/500000: episode: 50, duration: 29.908s, episode steps: 40, steps per second: 1, episode reward: 28.303, mean reward: 0.708 [0.005, 1.000], mean action: 23.925 [1.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.089087, mean_absolute_error: 1.501520, mean_q: 2.429378
568 (array([22]),) False
   2040/500000: episode: 51, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 26.621, mean reward: 0.666 [0.000, 0.960], mean action: 18.375 [2.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.088439, mean_absolute_error: 1.480491, mean_q: 2.380735
738 (array([12]),) False
   2080/500000: episode: 52, duration: 30.746s, episode steps: 40, steps per second: 1, episode reward: 33.908, mean reward: 0.848 [0.100, 1.000], mean action: 14.925 [6.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.085930, mean_absolute_error: 1.501601, mean_q: 2.407306
697 (array([22]),) False
   2120/500000: episode: 53, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 28.362, mean reward: 0.709 [0.000, 0.968], mean action: 20.425 [0.000, 54.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.083244, mean_absolute_error: 1.518709, mean_q: 2.420387
493 (array([22]),) False
   2160/500000: episode: 54, duration: 29.761s, episode steps: 40, steps per second: 1, episode reward: 28.947, mean reward: 0.724 [0.080, 0.971], mean action: 22.400 [3.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.087622, mean_absolute_error: 1.552445, mean_q: 2.444103
232 (array([22]),) False
   2200/500000: episode: 55, duration: 30.802s, episode steps: 40, steps per second: 1, episode reward: 26.131, mean reward: 0.653 [0.000, 1.000], mean action: 21.525 [0.000, 58.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.085999, mean_absolute_error: 1.565279, mean_q: 2.439837
122 (array([12]),) False
   2240/500000: episode: 56, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 25.805, mean reward: 0.645 [0.017, 1.000], mean action: 19.500 [2.000, 59.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.083011, mean_absolute_error: 1.600633, mean_q: 2.482198
332 (array([22]),) False
   2280/500000: episode: 57, duration: 30.756s, episode steps: 40, steps per second: 1, episode reward: 28.710, mean reward: 0.718 [0.202, 0.987], mean action: 18.800 [0.000, 59.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.083110, mean_absolute_error: 1.627795, mean_q: 2.501600
826 (array([22]),) False
   2320/500000: episode: 58, duration: 29.844s, episode steps: 40, steps per second: 1, episode reward: 21.553, mean reward: 0.539 [0.000, 1.000], mean action: 22.700 [2.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.080634, mean_absolute_error: 1.635389, mean_q: 2.503767
429 (array([22]),) False
   2360/500000: episode: 59, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 26.473, mean reward: 0.662 [0.003, 0.969], mean action: 22.675 [4.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.078380, mean_absolute_error: 1.651613, mean_q: 2.517938
7 (array([22]),) False
   2400/500000: episode: 60, duration: 30.631s, episode steps: 40, steps per second: 1, episode reward: 28.765, mean reward: 0.719 [0.000, 0.915], mean action: 17.725 [6.000, 57.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.080819, mean_absolute_error: 1.678859, mean_q: 2.540561
357 (array([22]),) False
   2440/500000: episode: 61, duration: 30.863s, episode steps: 40, steps per second: 1, episode reward: 22.429, mean reward: 0.561 [0.000, 0.957], mean action: 18.600 [0.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.082638, mean_absolute_error: 1.694628, mean_q: 2.553659
686 (array([48]),) False
   2480/500000: episode: 62, duration: 29.836s, episode steps: 40, steps per second: 1, episode reward: 27.676, mean reward: 0.692 [0.006, 1.000], mean action: 20.300 [0.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.083504, mean_absolute_error: 1.713586, mean_q: 2.567526
111 (array([22]),) False
   2520/500000: episode: 63, duration: 30.697s, episode steps: 40, steps per second: 1, episode reward: 26.199, mean reward: 0.655 [0.089, 1.000], mean action: 19.250 [0.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.082199, mean_absolute_error: 1.729532, mean_q: 2.577552
582 (array([44]),) False
   2560/500000: episode: 64, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 27.478, mean reward: 0.687 [0.000, 0.981], mean action: 21.675 [5.000, 54.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.075966, mean_absolute_error: 1.754084, mean_q: 2.596965
517 (array([22]),) False
   2600/500000: episode: 65, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 29.212, mean reward: 0.730 [0.169, 0.841], mean action: 18.000 [3.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.083930, mean_absolute_error: 1.771482, mean_q: 2.608396
701 (array([48]),) False
   2640/500000: episode: 66, duration: 29.961s, episode steps: 40, steps per second: 1, episode reward: 27.236, mean reward: 0.681 [0.011, 1.000], mean action: 16.800 [0.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.078843, mean_absolute_error: 1.802969, mean_q: 2.644848
574 (array([8]),) False
   2680/500000: episode: 67, duration: 30.700s, episode steps: 40, steps per second: 1, episode reward: 24.208, mean reward: 0.605 [0.164, 1.000], mean action: 18.800 [0.000, 51.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.079204, mean_absolute_error: 1.823439, mean_q: 2.659306
39 (array([22]),) False
   2720/500000: episode: 68, duration: 29.943s, episode steps: 40, steps per second: 1, episode reward: 23.697, mean reward: 0.592 [0.040, 1.000], mean action: 23.800 [0.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.082618, mean_absolute_error: 1.858414, mean_q: 2.689958
805 (array([22]),) False
   2760/500000: episode: 69, duration: 30.759s, episode steps: 40, steps per second: 1, episode reward: 29.125, mean reward: 0.728 [0.047, 0.992], mean action: 19.225 [4.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.085915, mean_absolute_error: 1.876275, mean_q: 2.706500
675 (array([22]),) False
   2800/500000: episode: 70, duration: 30.020s, episode steps: 40, steps per second: 1, episode reward: 21.176, mean reward: 0.529 [0.103, 0.771], mean action: 18.900 [4.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.084314, mean_absolute_error: 1.904723, mean_q: 2.736840
2 (array([12]),) False
   2840/500000: episode: 71, duration: 30.765s, episode steps: 40, steps per second: 1, episode reward: 28.223, mean reward: 0.706 [0.088, 1.000], mean action: 20.825 [3.000, 60.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.086282, mean_absolute_error: 1.923858, mean_q: 2.745624
348 (array([22]),) False
   2880/500000: episode: 72, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 26.452, mean reward: 0.661 [0.000, 1.000], mean action: 20.475 [4.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.081365, mean_absolute_error: 1.945967, mean_q: 2.774775
470 (array([22]),) False
   2920/500000: episode: 73, duration: 30.664s, episode steps: 40, steps per second: 1, episode reward: 28.150, mean reward: 0.704 [0.129, 1.000], mean action: 21.475 [1.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.085021, mean_absolute_error: 1.951946, mean_q: 2.778851
132 (array([22]),) False
   2960/500000: episode: 74, duration: 29.983s, episode steps: 40, steps per second: 1, episode reward: 25.021, mean reward: 0.626 [0.000, 0.896], mean action: 21.350 [1.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.088043, mean_absolute_error: 1.963901, mean_q: 2.797973
416 (array([22]),) False
   3000/500000: episode: 75, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 28.884, mean reward: 0.722 [0.121, 0.965], mean action: 20.950 [1.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.089461, mean_absolute_error: 1.999320, mean_q: 2.826614
113 (array([22]),) False
   3040/500000: episode: 76, duration: 30.753s, episode steps: 40, steps per second: 1, episode reward: 27.321, mean reward: 0.683 [0.147, 1.000], mean action: 23.625 [3.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.092378, mean_absolute_error: 2.037196, mean_q: 2.858928
519 (array([58]),) False
   3080/500000: episode: 77, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 16.183, mean reward: 0.405 [0.003, 0.669], mean action: 19.175 [0.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.087982, mean_absolute_error: 2.059103, mean_q: 2.879441
79 (array([22]),) False
   3120/500000: episode: 78, duration: 30.033s, episode steps: 40, steps per second: 1, episode reward: 29.643, mean reward: 0.741 [0.074, 0.974], mean action: 18.350 [3.000, 50.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.089713, mean_absolute_error: 2.074594, mean_q: 2.897828
156 (array([22]),) False
   3160/500000: episode: 79, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 23.062, mean reward: 0.577 [0.029, 1.000], mean action: 20.075 [1.000, 59.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.094416, mean_absolute_error: 2.087639, mean_q: 2.904129
282 (array([22]),) False
   3200/500000: episode: 80, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 28.383, mean reward: 0.710 [0.234, 0.936], mean action: 22.125 [6.000, 58.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.099004, mean_absolute_error: 2.109453, mean_q: 2.934655
853 (array([22]),) False
   3240/500000: episode: 81, duration: 30.741s, episode steps: 40, steps per second: 1, episode reward: 27.735, mean reward: 0.693 [0.054, 0.866], mean action: 23.225 [3.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.090599, mean_absolute_error: 2.153454, mean_q: 2.979677
564 (array([22]),) False
   3280/500000: episode: 82, duration: 30.025s, episode steps: 40, steps per second: 1, episode reward: 29.918, mean reward: 0.748 [0.000, 0.935], mean action: 19.025 [10.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.093223, mean_absolute_error: 2.182412, mean_q: 2.996633
210 (array([58]),) False
   3320/500000: episode: 83, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 13.192, mean reward: 0.330 [0.024, 1.000], mean action: 20.725 [0.000, 60.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.096503, mean_absolute_error: 2.188259, mean_q: 3.012703
781 (array([8]),) False
   3360/500000: episode: 84, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 20.933, mean reward: 0.523 [0.244, 0.990], mean action: 24.300 [2.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.100054, mean_absolute_error: 2.217942, mean_q: 3.032553
367 (array([12]),) False
   3400/500000: episode: 85, duration: 30.794s, episode steps: 40, steps per second: 1, episode reward: 26.484, mean reward: 0.662 [0.058, 1.000], mean action: 20.425 [3.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.106565, mean_absolute_error: 2.222320, mean_q: 3.025603
597 (array([22]),) False
   3440/500000: episode: 86, duration: 29.987s, episode steps: 40, steps per second: 1, episode reward: 26.768, mean reward: 0.669 [0.000, 0.892], mean action: 20.650 [9.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.096196, mean_absolute_error: 2.254619, mean_q: 3.063209
294 (array([22]),) False
   3480/500000: episode: 87, duration: 30.815s, episode steps: 40, steps per second: 1, episode reward: 27.499, mean reward: 0.687 [0.176, 0.965], mean action: 22.950 [0.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.096702, mean_absolute_error: 2.288560, mean_q: 3.094307
658 (array([48]),) False
   3520/500000: episode: 88, duration: 30.722s, episode steps: 40, steps per second: 1, episode reward: 26.554, mean reward: 0.664 [0.028, 1.000], mean action: 21.650 [0.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.096283, mean_absolute_error: 2.312765, mean_q: 3.128819
576 (array([58]),) False
   3560/500000: episode: 89, duration: 30.691s, episode steps: 40, steps per second: 1, episode reward: 17.728, mean reward: 0.443 [0.162, 0.894], mean action: 16.200 [1.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.108147, mean_absolute_error: 2.326560, mean_q: 3.134235
133 (array([22]),) False
   3600/500000: episode: 90, duration: 30.006s, episode steps: 40, steps per second: 1, episode reward: 27.953, mean reward: 0.699 [0.060, 0.866], mean action: 16.800 [3.000, 49.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.101197, mean_absolute_error: 2.360665, mean_q: 3.165454
92 (array([22]),) False
   3640/500000: episode: 91, duration: 30.700s, episode steps: 40, steps per second: 1, episode reward: 29.439, mean reward: 0.736 [0.148, 1.000], mean action: 19.275 [11.000, 57.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.104812, mean_absolute_error: 2.377967, mean_q: 3.191902
827 (array([14]),) False
   3680/500000: episode: 92, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 29.462, mean reward: 0.737 [0.000, 1.000], mean action: 23.025 [0.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.107534, mean_absolute_error: 2.409667, mean_q: 3.228017
775 (array([58]),) False
   3720/500000: episode: 93, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 7.617, mean reward: 0.190 [0.000, 0.909], mean action: 17.750 [4.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.113486, mean_absolute_error: 2.432173, mean_q: 3.243107
137 (array([22]),) False
   3760/500000: episode: 94, duration: 29.974s, episode steps: 40, steps per second: 1, episode reward: 25.991, mean reward: 0.650 [0.046, 0.926], mean action: 22.950 [7.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.114054, mean_absolute_error: 2.466652, mean_q: 3.283065
160 (array([12]),) False
   3800/500000: episode: 95, duration: 30.827s, episode steps: 40, steps per second: 1, episode reward: 25.596, mean reward: 0.640 [0.000, 1.000], mean action: 24.325 [1.000, 60.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.107923, mean_absolute_error: 2.477634, mean_q: 3.292656
605 (array([22]),) False
   3840/500000: episode: 96, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 28.005, mean reward: 0.700 [0.209, 1.000], mean action: 19.500 [1.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.107707, mean_absolute_error: 2.494111, mean_q: 3.298571
9 (array([14]),) False
   3880/500000: episode: 97, duration: 30.787s, episode steps: 40, steps per second: 1, episode reward: 29.443, mean reward: 0.736 [0.000, 0.989], mean action: 20.150 [0.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.120652, mean_absolute_error: 2.503244, mean_q: 3.323777
838 (array([21]),) False
   3920/500000: episode: 98, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 25.603, mean reward: 0.640 [0.000, 0.947], mean action: 21.150 [1.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.109983, mean_absolute_error: 2.537598, mean_q: 3.351227
380 (array([22]),) False
   3960/500000: episode: 99, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 26.307, mean reward: 0.658 [0.069, 0.909], mean action: 21.150 [1.000, 57.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.100402, mean_absolute_error: 2.575647, mean_q: 3.383158
125 (array([58]),) False
   4000/500000: episode: 100, duration: 30.762s, episode steps: 40, steps per second: 1, episode reward: 6.089, mean reward: 0.152 [0.000, 0.734], mean action: 17.650 [0.000, 52.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.107580, mean_absolute_error: 2.588638, mean_q: 3.399843
34 (array([22]),) False
   4040/500000: episode: 101, duration: 30.745s, episode steps: 40, steps per second: 1, episode reward: 27.682, mean reward: 0.692 [0.007, 1.000], mean action: 19.975 [0.000, 54.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.117122, mean_absolute_error: 2.602315, mean_q: 3.422533
593 (array([37]),) False
   4080/500000: episode: 102, duration: 30.018s, episode steps: 40, steps per second: 1, episode reward: 29.929, mean reward: 0.748 [0.000, 1.000], mean action: 17.950 [1.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.123883, mean_absolute_error: 2.616359, mean_q: 3.432972
789 (array([22]),) False
   4120/500000: episode: 103, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 27.022, mean reward: 0.676 [0.008, 0.969], mean action: 23.050 [0.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.122166, mean_absolute_error: 2.650817, mean_q: 3.463882
659 (array([40]),) False
   4160/500000: episode: 104, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 24.006, mean reward: 0.600 [0.081, 1.000], mean action: 21.775 [0.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.117699, mean_absolute_error: 2.683311, mean_q: 3.501291
708 (array([40]),) False
   4200/500000: episode: 105, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 24.187, mean reward: 0.605 [0.343, 0.936], mean action: 21.400 [7.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.122754, mean_absolute_error: 2.693961, mean_q: 3.513319
707 (array([48]),) False
   4240/500000: episode: 106, duration: 30.027s, episode steps: 40, steps per second: 1, episode reward: 24.235, mean reward: 0.606 [0.000, 0.943], mean action: 20.900 [0.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.115677, mean_absolute_error: 2.726293, mean_q: 3.545978
135 (array([22]),) False
   4280/500000: episode: 107, duration: 30.734s, episode steps: 40, steps per second: 1, episode reward: 29.085, mean reward: 0.727 [0.130, 0.945], mean action: 21.425 [0.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.123602, mean_absolute_error: 2.746124, mean_q: 3.562426
468 (array([22]),) False
   4320/500000: episode: 108, duration: 30.785s, episode steps: 40, steps per second: 1, episode reward: 31.749, mean reward: 0.794 [0.288, 0.977], mean action: 20.100 [8.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.127194, mean_absolute_error: 2.769153, mean_q: 3.591341
257 (array([22]),) False
   4360/500000: episode: 109, duration: 30.856s, episode steps: 40, steps per second: 1, episode reward: 27.624, mean reward: 0.691 [0.144, 1.000], mean action: 20.625 [5.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.136275, mean_absolute_error: 2.788954, mean_q: 3.613466
852 (array([44]),) False
   4400/500000: episode: 110, duration: 30.009s, episode steps: 40, steps per second: 1, episode reward: 30.153, mean reward: 0.754 [0.066, 0.900], mean action: 18.300 [0.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.122902, mean_absolute_error: 2.803055, mean_q: 3.626212
789 (array([22]),) False
   4440/500000: episode: 111, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 28.024, mean reward: 0.701 [0.031, 0.969], mean action: 18.750 [2.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.134103, mean_absolute_error: 2.821634, mean_q: 3.650254
439 (array([12]),) False
   4480/500000: episode: 112, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 31.136, mean reward: 0.778 [0.062, 1.000], mean action: 20.825 [1.000, 52.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.145972, mean_absolute_error: 2.832483, mean_q: 3.656753
719 (array([22]),) False
   4520/500000: episode: 113, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 27.967, mean reward: 0.699 [0.044, 1.000], mean action: 20.925 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.128535, mean_absolute_error: 2.885532, mean_q: 3.717786
273 (array([22]),) False
   4560/500000: episode: 114, duration: 29.974s, episode steps: 40, steps per second: 1, episode reward: 27.145, mean reward: 0.679 [0.000, 0.948], mean action: 15.575 [2.000, 47.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.130699, mean_absolute_error: 2.933560, mean_q: 3.773220
81 (array([22]),) False
   4600/500000: episode: 115, duration: 30.701s, episode steps: 40, steps per second: 1, episode reward: 27.136, mean reward: 0.678 [0.133, 0.812], mean action: 18.550 [0.000, 60.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.141305, mean_absolute_error: 2.946043, mean_q: 3.769803
320 (array([22]),) False
   4640/500000: episode: 116, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 26.033, mean reward: 0.651 [0.000, 1.000], mean action: 17.125 [4.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.138091, mean_absolute_error: 2.957609, mean_q: 3.789600
531 (array([22]),) False
   4680/500000: episode: 117, duration: 30.819s, episode steps: 40, steps per second: 1, episode reward: 29.810, mean reward: 0.745 [0.000, 0.945], mean action: 22.525 [11.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.150742, mean_absolute_error: 2.965824, mean_q: 3.801114
455 (array([22]),) False
   4720/500000: episode: 118, duration: 29.985s, episode steps: 40, steps per second: 1, episode reward: 21.967, mean reward: 0.549 [0.094, 0.858], mean action: 17.125 [2.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.147435, mean_absolute_error: 2.991696, mean_q: 3.822468
364 (array([14]),) False
   4760/500000: episode: 119, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 30.860, mean reward: 0.771 [0.000, 1.000], mean action: 22.500 [4.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.143964, mean_absolute_error: 2.992080, mean_q: 3.838969
664 (array([22]),) False
   4800/500000: episode: 120, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 27.547, mean reward: 0.689 [0.015, 0.997], mean action: 16.075 [0.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.126955, mean_absolute_error: 3.045736, mean_q: 3.880499
840 (array([12]),) False
   4840/500000: episode: 121, duration: 30.828s, episode steps: 40, steps per second: 1, episode reward: 28.085, mean reward: 0.702 [0.000, 1.000], mean action: 20.425 [3.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.143614, mean_absolute_error: 3.055321, mean_q: 3.885508
221 (array([22]),) False
   4880/500000: episode: 122, duration: 29.975s, episode steps: 40, steps per second: 1, episode reward: 27.348, mean reward: 0.684 [0.153, 0.931], mean action: 25.200 [4.000, 58.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.143719, mean_absolute_error: 3.064760, mean_q: 3.907694
257 (array([22]),) False
   4920/500000: episode: 123, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 27.545, mean reward: 0.689 [0.147, 1.000], mean action: 18.775 [5.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.140616, mean_absolute_error: 3.103117, mean_q: 3.935442
419 (array([40]),) False
   4960/500000: episode: 124, duration: 30.652s, episode steps: 40, steps per second: 1, episode reward: 24.065, mean reward: 0.602 [0.000, 1.000], mean action: 21.475 [2.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.144707, mean_absolute_error: 3.121286, mean_q: 3.958909
63 (array([18]),) False
   5000/500000: episode: 125, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 33.278, mean reward: 0.832 [0.262, 1.000], mean action: 22.875 [7.000, 54.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.142163, mean_absolute_error: 3.168185, mean_q: 4.010953
822 (array([22]),) False
   5040/500000: episode: 126, duration: 30.001s, episode steps: 40, steps per second: 1, episode reward: 21.880, mean reward: 0.547 [0.058, 0.918], mean action: 18.475 [0.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.164622, mean_absolute_error: 3.171960, mean_q: 4.003194
564 (array([22]),) False
   5080/500000: episode: 127, duration: 30.814s, episode steps: 40, steps per second: 1, episode reward: 28.316, mean reward: 0.708 [0.139, 0.933], mean action: 18.325 [0.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.151092, mean_absolute_error: 3.189440, mean_q: 4.019705
644 (array([12]),) False
   5120/500000: episode: 128, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 31.642, mean reward: 0.791 [0.152, 1.000], mean action: 20.575 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.153313, mean_absolute_error: 3.208844, mean_q: 4.033488
29 (array([22]),) False
   5160/500000: episode: 129, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 27.169, mean reward: 0.679 [0.001, 1.000], mean action: 17.700 [0.000, 58.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.148328, mean_absolute_error: 3.239277, mean_q: 4.076138
187 (array([15]),) False
   5200/500000: episode: 130, duration: 30.024s, episode steps: 40, steps per second: 1, episode reward: 30.255, mean reward: 0.756 [0.086, 1.000], mean action: 21.400 [0.000, 59.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.157584, mean_absolute_error: 3.253052, mean_q: 4.092706
578 (array([22]),) False
   5240/500000: episode: 131, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 30.188, mean reward: 0.755 [0.078, 0.998], mean action: 20.775 [0.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.155632, mean_absolute_error: 3.279781, mean_q: 4.110999
846 (array([48]),) False
   5280/500000: episode: 132, duration: 30.721s, episode steps: 40, steps per second: 1, episode reward: 28.861, mean reward: 0.722 [0.028, 0.931], mean action: 22.525 [9.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.144343, mean_absolute_error: 3.296880, mean_q: 4.134599
50 (array([22]),) False
   5320/500000: episode: 133, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 27.180, mean reward: 0.679 [0.110, 1.000], mean action: 21.550 [1.000, 56.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.170952, mean_absolute_error: 3.306522, mean_q: 4.151021
366 (array([22]),) False
   5360/500000: episode: 134, duration: 29.984s, episode steps: 40, steps per second: 1, episode reward: 28.989, mean reward: 0.725 [0.130, 0.883], mean action: 19.975 [1.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.159352, mean_absolute_error: 3.351151, mean_q: 4.191158
116 (array([22]),) False
   5400/500000: episode: 135, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 29.083, mean reward: 0.727 [0.008, 1.000], mean action: 20.325 [0.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.168352, mean_absolute_error: 3.347839, mean_q: 4.180616
622 (array([36]),) False
   5440/500000: episode: 136, duration: 30.712s, episode steps: 40, steps per second: 1, episode reward: 15.381, mean reward: 0.385 [0.193, 0.980], mean action: 19.975 [6.000, 56.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.175480, mean_absolute_error: 3.354716, mean_q: 4.196069
275 (array([12]),) False
   5480/500000: episode: 137, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 28.138, mean reward: 0.703 [0.013, 1.000], mean action: 18.875 [0.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.149090, mean_absolute_error: 3.390302, mean_q: 4.224972
159 (array([48]),) False
   5520/500000: episode: 138, duration: 29.988s, episode steps: 40, steps per second: 1, episode reward: 23.512, mean reward: 0.588 [0.105, 0.992], mean action: 22.325 [1.000, 59.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.181176, mean_absolute_error: 3.380085, mean_q: 4.224515
710 (array([12]),) False
   5560/500000: episode: 139, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 29.760, mean reward: 0.744 [0.035, 1.000], mean action: 22.925 [3.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.160368, mean_absolute_error: 3.414593, mean_q: 4.262149
81 (array([22]),) False
   5600/500000: episode: 140, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 23.853, mean reward: 0.596 [0.038, 0.814], mean action: 17.750 [3.000, 54.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.167584, mean_absolute_error: 3.441483, mean_q: 4.298848
256 (array([22]),) False
   5640/500000: episode: 141, duration: 30.816s, episode steps: 40, steps per second: 1, episode reward: 18.863, mean reward: 0.472 [0.040, 0.847], mean action: 21.775 [0.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.176399, mean_absolute_error: 3.446659, mean_q: 4.289195
288 (array([33]),) False
   5680/500000: episode: 142, duration: 29.983s, episode steps: 40, steps per second: 1, episode reward: 16.447, mean reward: 0.411 [0.047, 0.805], mean action: 21.600 [0.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.164042, mean_absolute_error: 3.487572, mean_q: 4.334279
381 (array([22]),) False
   5720/500000: episode: 143, duration: 30.757s, episode steps: 40, steps per second: 1, episode reward: 26.494, mean reward: 0.662 [0.063, 1.000], mean action: 21.925 [0.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.172718, mean_absolute_error: 3.499683, mean_q: 4.347650
726 (array([12]),) False
   5760/500000: episode: 144, duration: 30.690s, episode steps: 40, steps per second: 1, episode reward: 30.428, mean reward: 0.761 [0.185, 1.000], mean action: 20.775 [4.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.189533, mean_absolute_error: 3.513897, mean_q: 4.363343
82 (array([22]),) False
   5800/500000: episode: 145, duration: 30.758s, episode steps: 40, steps per second: 1, episode reward: 23.780, mean reward: 0.595 [0.005, 0.916], mean action: 21.400 [1.000, 60.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.165675, mean_absolute_error: 3.540360, mean_q: 4.379290
335 (array([22]),) False
   5840/500000: episode: 146, duration: 30.001s, episode steps: 40, steps per second: 1, episode reward: 25.346, mean reward: 0.634 [0.134, 1.000], mean action: 18.175 [2.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.196445, mean_absolute_error: 3.529468, mean_q: 4.398063
549 (array([22]),) False
   5880/500000: episode: 147, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 22.253, mean reward: 0.556 [0.034, 0.935], mean action: 18.175 [3.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.173658, mean_absolute_error: 3.580254, mean_q: 4.416708
309 (array([22]),) False
   5920/500000: episode: 148, duration: 30.822s, episode steps: 40, steps per second: 1, episode reward: 25.961, mean reward: 0.649 [0.104, 1.000], mean action: 22.625 [0.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.174854, mean_absolute_error: 3.581760, mean_q: 4.421416
861 (array([22]),) False
   5960/500000: episode: 149, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 25.733, mean reward: 0.643 [0.024, 1.000], mean action: 23.425 [6.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.202205, mean_absolute_error: 3.600953, mean_q: 4.439892
130 (array([22]),) False
   6000/500000: episode: 150, duration: 29.992s, episode steps: 40, steps per second: 1, episode reward: 29.393, mean reward: 0.735 [0.010, 1.000], mean action: 21.500 [3.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.184411, mean_absolute_error: 3.662830, mean_q: 4.490738
388 (array([22]),) False
   6040/500000: episode: 151, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 28.531, mean reward: 0.713 [0.029, 0.971], mean action: 22.325 [8.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.191946, mean_absolute_error: 3.630280, mean_q: 4.468965
250 (array([22]),) False
   6080/500000: episode: 152, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 25.287, mean reward: 0.632 [0.000, 0.854], mean action: 21.750 [1.000, 60.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.207882, mean_absolute_error: 3.685572, mean_q: 4.502131
501 (array([12]),) False
   6120/500000: episode: 153, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 25.443, mean reward: 0.636 [0.000, 1.000], mean action: 24.350 [6.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.193773, mean_absolute_error: 3.671771, mean_q: 4.526502
382 (array([22]),) False
   6160/500000: episode: 154, duration: 29.988s, episode steps: 40, steps per second: 1, episode reward: 21.820, mean reward: 0.545 [0.028, 1.000], mean action: 19.875 [0.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.199426, mean_absolute_error: 3.711074, mean_q: 4.525424
304 (array([22]),) False
   6200/500000: episode: 155, duration: 30.838s, episode steps: 40, steps per second: 1, episode reward: 30.805, mean reward: 0.770 [0.116, 1.000], mean action: 16.725 [1.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.193892, mean_absolute_error: 3.742255, mean_q: 4.574133
504 (array([48]),) False
   6240/500000: episode: 156, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 15.014, mean reward: 0.375 [0.000, 1.000], mean action: 24.800 [2.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.191617, mean_absolute_error: 3.760380, mean_q: 4.604051
215 (array([22]),) False
   6280/500000: episode: 157, duration: 30.781s, episode steps: 40, steps per second: 1, episode reward: 24.114, mean reward: 0.603 [0.154, 1.000], mean action: 18.675 [0.000, 60.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.216858, mean_absolute_error: 3.795906, mean_q: 4.618903
494 (array([48]),) False
   6320/500000: episode: 158, duration: 29.968s, episode steps: 40, steps per second: 1, episode reward: 24.293, mean reward: 0.607 [0.014, 1.000], mean action: 23.475 [5.000, 57.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.200366, mean_absolute_error: 3.805932, mean_q: 4.648794
178 (array([38]),) False
   6360/500000: episode: 159, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 25.494, mean reward: 0.637 [0.000, 1.000], mean action: 19.100 [3.000, 54.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.199715, mean_absolute_error: 3.843174, mean_q: 4.691171
128 (array([22]),) False
   6400/500000: episode: 160, duration: 30.741s, episode steps: 40, steps per second: 1, episode reward: 21.509, mean reward: 0.538 [0.127, 1.000], mean action: 20.200 [3.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.206764, mean_absolute_error: 3.853751, mean_q: 4.715078
486 (array([22]),) False
   6440/500000: episode: 161, duration: 30.773s, episode steps: 40, steps per second: 1, episode reward: 29.347, mean reward: 0.734 [0.010, 1.000], mean action: 20.575 [6.000, 58.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.206401, mean_absolute_error: 3.885445, mean_q: 4.753066
635 (array([22]),) False
   6480/500000: episode: 162, duration: 29.926s, episode steps: 40, steps per second: 1, episode reward: 27.478, mean reward: 0.687 [0.157, 1.000], mean action: 20.375 [2.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.206973, mean_absolute_error: 3.908213, mean_q: 4.744935
455 (array([22]),) False
   6520/500000: episode: 163, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 19.614, mean reward: 0.490 [0.070, 0.742], mean action: 24.000 [3.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.209345, mean_absolute_error: 3.940405, mean_q: 4.781217
155 (array([22]),) False
   6560/500000: episode: 164, duration: 30.695s, episode steps: 40, steps per second: 1, episode reward: 25.576, mean reward: 0.639 [0.000, 1.000], mean action: 19.175 [0.000, 51.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.216076, mean_absolute_error: 3.982669, mean_q: 4.841647
567 (array([22]),) False
   6600/500000: episode: 165, duration: 30.742s, episode steps: 40, steps per second: 1, episode reward: 21.369, mean reward: 0.534 [0.000, 0.845], mean action: 21.300 [12.000, 57.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.237474, mean_absolute_error: 3.957963, mean_q: 4.812544
586 (array([12]),) False
   6640/500000: episode: 166, duration: 30.014s, episode steps: 40, steps per second: 1, episode reward: 27.076, mean reward: 0.677 [0.028, 1.000], mean action: 18.500 [1.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.208391, mean_absolute_error: 4.022712, mean_q: 4.880792
642 (array([22]),) False
   6680/500000: episode: 167, duration: 30.817s, episode steps: 40, steps per second: 1, episode reward: 19.779, mean reward: 0.494 [0.000, 1.000], mean action: 23.775 [0.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.208900, mean_absolute_error: 4.045681, mean_q: 4.893506
200 (array([22]),) False
   6720/500000: episode: 168, duration: 30.746s, episode steps: 40, steps per second: 1, episode reward: 23.905, mean reward: 0.598 [0.069, 1.000], mean action: 22.900 [0.000, 56.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.231190, mean_absolute_error: 4.050712, mean_q: 4.905530
508 (array([22]),) False
   6760/500000: episode: 169, duration: 30.845s, episode steps: 40, steps per second: 1, episode reward: 26.416, mean reward: 0.660 [0.124, 1.000], mean action: 20.600 [2.000, 57.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.200508, mean_absolute_error: 4.090161, mean_q: 4.956662
753 (array([22]),) False
   6800/500000: episode: 170, duration: 29.996s, episode steps: 40, steps per second: 1, episode reward: 28.995, mean reward: 0.725 [0.000, 1.000], mean action: 21.275 [2.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.210423, mean_absolute_error: 4.120502, mean_q: 4.976535
819 (array([48]),) False
   6840/500000: episode: 171, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 20.153, mean reward: 0.504 [0.060, 0.693], mean action: 18.000 [3.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.208841, mean_absolute_error: 4.157439, mean_q: 5.016759
763 (array([48]),) False
   6880/500000: episode: 172, duration: 30.717s, episode steps: 40, steps per second: 1, episode reward: 23.258, mean reward: 0.581 [0.054, 0.864], mean action: 20.225 [5.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.219128, mean_absolute_error: 4.170703, mean_q: 5.039721
47 (array([44]),) False
   6920/500000: episode: 173, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 33.004, mean reward: 0.825 [0.145, 1.000], mean action: 19.850 [4.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.224657, mean_absolute_error: 4.197506, mean_q: 5.050220
435 (array([22]),) False
   6960/500000: episode: 174, duration: 29.898s, episode steps: 40, steps per second: 1, episode reward: 29.721, mean reward: 0.743 [0.057, 0.936], mean action: 18.525 [6.000, 55.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.245245, mean_absolute_error: 4.231076, mean_q: 5.084304
218 (array([22]),) False
   7000/500000: episode: 175, duration: 30.715s, episode steps: 40, steps per second: 1, episode reward: 26.548, mean reward: 0.664 [0.065, 1.000], mean action: 21.225 [1.000, 59.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.202787, mean_absolute_error: 4.259200, mean_q: 5.144744
732 (array([12]),) False
   7040/500000: episode: 176, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 28.156, mean reward: 0.704 [0.123, 1.000], mean action: 21.925 [4.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.238064, mean_absolute_error: 4.262065, mean_q: 5.148203
18 (array([22]),) False
   7080/500000: episode: 177, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 25.867, mean reward: 0.647 [0.245, 0.869], mean action: 19.675 [1.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.254621, mean_absolute_error: 4.288913, mean_q: 5.163945
281 (array([48]),) False
   7120/500000: episode: 178, duration: 29.997s, episode steps: 40, steps per second: 1, episode reward: 29.478, mean reward: 0.737 [0.000, 1.000], mean action: 16.850 [1.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.234567, mean_absolute_error: 4.327710, mean_q: 5.185045
52 (array([22]),) False
   7160/500000: episode: 179, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 27.898, mean reward: 0.697 [0.000, 1.000], mean action: 18.000 [1.000, 55.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.239086, mean_absolute_error: 4.350072, mean_q: 5.206144
549 (array([22]),) False
   7200/500000: episode: 180, duration: 30.752s, episode steps: 40, steps per second: 1, episode reward: 22.562, mean reward: 0.564 [0.064, 1.000], mean action: 18.050 [11.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.238422, mean_absolute_error: 4.378152, mean_q: 5.259073
107 (array([22]),) False
   7240/500000: episode: 181, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 25.104, mean reward: 0.628 [0.000, 0.901], mean action: 20.125 [2.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.223795, mean_absolute_error: 4.381810, mean_q: 5.276330
357 (array([22]),) False
   7280/500000: episode: 182, duration: 29.952s, episode steps: 40, steps per second: 1, episode reward: 25.874, mean reward: 0.647 [0.036, 1.000], mean action: 32.225 [12.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.235525, mean_absolute_error: 4.426541, mean_q: 5.306503
838 (array([21]),) False
   7320/500000: episode: 183, duration: 30.705s, episode steps: 40, steps per second: 1, episode reward: 27.378, mean reward: 0.684 [0.047, 1.000], mean action: 20.900 [2.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.254215, mean_absolute_error: 4.437223, mean_q: 5.308469
449 (array([22]),) False
   7360/500000: episode: 184, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 24.290, mean reward: 0.607 [0.031, 0.913], mean action: 22.125 [1.000, 60.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.265361, mean_absolute_error: 4.460515, mean_q: 5.334867
225 (array([48]),) False
   7400/500000: episode: 185, duration: 30.691s, episode steps: 40, steps per second: 1, episode reward: 27.687, mean reward: 0.692 [0.000, 1.000], mean action: 21.475 [0.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.275384, mean_absolute_error: 4.459708, mean_q: 5.372721
178 (array([38]),) False
   7440/500000: episode: 186, duration: 29.996s, episode steps: 40, steps per second: 1, episode reward: 26.178, mean reward: 0.654 [0.191, 0.992], mean action: 19.250 [1.000, 51.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.295446, mean_absolute_error: 4.484354, mean_q: 5.366390
241 (array([22]),) False
   7480/500000: episode: 187, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 23.786, mean reward: 0.595 [0.051, 0.796], mean action: 21.950 [1.000, 60.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.290786, mean_absolute_error: 4.550035, mean_q: 5.443996
383 (array([22]),) False
   7520/500000: episode: 188, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 27.984, mean reward: 0.700 [0.030, 0.966], mean action: 21.300 [8.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.297602, mean_absolute_error: 4.551522, mean_q: 5.447079
112 (array([12]),) False
   7560/500000: episode: 189, duration: 30.765s, episode steps: 40, steps per second: 1, episode reward: 29.456, mean reward: 0.736 [0.000, 1.000], mean action: 21.150 [5.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.290967, mean_absolute_error: 4.598269, mean_q: 5.504202
418 (array([22]),) False
   7600/500000: episode: 190, duration: 29.956s, episode steps: 40, steps per second: 1, episode reward: 26.978, mean reward: 0.674 [0.153, 1.000], mean action: 18.650 [1.000, 56.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.288742, mean_absolute_error: 4.639482, mean_q: 5.532307
411 (array([22]),) False
   7640/500000: episode: 191, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 24.701, mean reward: 0.618 [0.088, 0.861], mean action: 20.750 [5.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.263214, mean_absolute_error: 4.689607, mean_q: 5.575648
95 (array([22]),) False
   7680/500000: episode: 192, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 23.343, mean reward: 0.584 [0.211, 0.809], mean action: 22.150 [4.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.279865, mean_absolute_error: 4.697141, mean_q: 5.574646
102 (array([22]),) False
   7720/500000: episode: 193, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 27.468, mean reward: 0.687 [0.069, 1.000], mean action: 19.225 [5.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.296410, mean_absolute_error: 4.691603, mean_q: 5.579012
421 (array([22]),) False
   7760/500000: episode: 194, duration: 30.013s, episode steps: 40, steps per second: 1, episode reward: 20.555, mean reward: 0.514 [0.000, 0.957], mean action: 23.825 [9.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.261455, mean_absolute_error: 4.732120, mean_q: 5.615495
617 (array([22]),) False
   7800/500000: episode: 195, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 29.520, mean reward: 0.738 [0.000, 1.000], mean action: 18.575 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.304512, mean_absolute_error: 4.740796, mean_q: 5.631208
61 (array([48]),) False
   7840/500000: episode: 196, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 30.462, mean reward: 0.762 [0.019, 1.000], mean action: 41.025 [8.000, 59.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.315930, mean_absolute_error: 4.761883, mean_q: 5.662257
809 (array([48]),) False
   7880/500000: episode: 197, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 20.973, mean reward: 0.524 [0.033, 0.914], mean action: 19.625 [8.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.302881, mean_absolute_error: 4.776926, mean_q: 5.673287
482 (array([22]),) False
   7920/500000: episode: 198, duration: 29.978s, episode steps: 40, steps per second: 1, episode reward: 29.890, mean reward: 0.747 [0.099, 1.000], mean action: 19.750 [7.000, 58.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.283582, mean_absolute_error: 4.830695, mean_q: 5.742568
739 (array([22]),) False
   7960/500000: episode: 199, duration: 30.832s, episode steps: 40, steps per second: 1, episode reward: 30.057, mean reward: 0.751 [0.000, 1.000], mean action: 18.725 [0.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.294814, mean_absolute_error: 4.842847, mean_q: 5.736327
652 (array([22]),) False
   8000/500000: episode: 200, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 26.023, mean reward: 0.651 [0.191, 1.000], mean action: 20.100 [1.000, 47.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.308728, mean_absolute_error: 4.840733, mean_q: 5.756182
535 (array([22]),) False
   8040/500000: episode: 201, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 25.928, mean reward: 0.648 [0.086, 0.893], mean action: 25.425 [4.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.303143, mean_absolute_error: 4.875616, mean_q: 5.753971
732 (array([12]),) False
   8080/500000: episode: 202, duration: 29.926s, episode steps: 40, steps per second: 1, episode reward: 26.513, mean reward: 0.663 [0.000, 1.000], mean action: 21.925 [0.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.318695, mean_absolute_error: 4.889636, mean_q: 5.775774
854 (array([12]),) False
   8120/500000: episode: 203, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 30.480, mean reward: 0.762 [0.365, 1.000], mean action: 20.625 [11.000, 55.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.336811, mean_absolute_error: 4.911320, mean_q: 5.806067
172 (array([12]),) False
   8160/500000: episode: 204, duration: 30.671s, episode steps: 40, steps per second: 1, episode reward: 31.580, mean reward: 0.789 [0.086, 1.000], mean action: 18.925 [5.000, 54.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.288728, mean_absolute_error: 4.925893, mean_q: 5.828696
646 (array([44]),) False
   8200/500000: episode: 205, duration: 30.787s, episode steps: 40, steps per second: 1, episode reward: 9.866, mean reward: 0.247 [0.000, 0.968], mean action: 27.350 [1.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.318951, mean_absolute_error: 4.954093, mean_q: 5.858447
258 (array([22]),) False
   8240/500000: episode: 206, duration: 29.967s, episode steps: 40, steps per second: 1, episode reward: 26.832, mean reward: 0.671 [0.000, 0.971], mean action: 19.825 [0.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.355321, mean_absolute_error: 4.951037, mean_q: 5.827796
804 (array([3]),) False
   8280/500000: episode: 207, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 14.805, mean reward: 0.370 [0.000, 0.859], mean action: 23.875 [4.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.326979, mean_absolute_error: 4.988008, mean_q: 5.880083
788 (array([3]),) False
   8320/500000: episode: 208, duration: 30.812s, episode steps: 40, steps per second: 1, episode reward: 15.907, mean reward: 0.398 [0.076, 0.857], mean action: 22.450 [2.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.336184, mean_absolute_error: 5.003125, mean_q: 5.910463
327 (array([22]),) False
   8360/500000: episode: 209, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 22.726, mean reward: 0.568 [0.000, 1.000], mean action: 22.775 [0.000, 53.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.295010, mean_absolute_error: 5.060985, mean_q: 5.959867
411 (array([22]),) False
   8400/500000: episode: 210, duration: 29.935s, episode steps: 40, steps per second: 1, episode reward: 23.041, mean reward: 0.576 [0.121, 0.929], mean action: 23.800 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.306607, mean_absolute_error: 5.087308, mean_q: 5.948937
567 (array([22]),) False
   8440/500000: episode: 211, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 21.962, mean reward: 0.549 [0.106, 1.000], mean action: 21.150 [10.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.313312, mean_absolute_error: 5.106557, mean_q: 6.011272
846 (array([48]),) False
   8480/500000: episode: 212, duration: 30.646s, episode steps: 40, steps per second: 1, episode reward: 28.542, mean reward: 0.714 [0.038, 0.974], mean action: 20.725 [2.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.361906, mean_absolute_error: 5.150340, mean_q: 6.030432
318 (array([48]),) False
   8520/500000: episode: 213, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 28.937, mean reward: 0.723 [0.121, 1.000], mean action: 19.725 [0.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.366900, mean_absolute_error: 5.131000, mean_q: 6.042799
31 (array([48]),) False
   8560/500000: episode: 214, duration: 29.986s, episode steps: 40, steps per second: 1, episode reward: 23.141, mean reward: 0.579 [0.157, 0.751], mean action: 21.350 [4.000, 60.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.332687, mean_absolute_error: 5.176934, mean_q: 6.111557
503 (array([3]),) False
   8600/500000: episode: 215, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 19.073, mean reward: 0.477 [0.159, 1.000], mean action: 18.050 [0.000, 58.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.366564, mean_absolute_error: 5.208449, mean_q: 6.114902
42 (array([22]),) False
   8640/500000: episode: 216, duration: 30.702s, episode steps: 40, steps per second: 1, episode reward: 27.290, mean reward: 0.682 [0.035, 1.000], mean action: 24.275 [2.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.325397, mean_absolute_error: 5.255187, mean_q: 6.170102
178 (array([38]),) False
   8680/500000: episode: 217, duration: 30.780s, episode steps: 40, steps per second: 1, episode reward: 26.298, mean reward: 0.657 [0.192, 1.000], mean action: 20.250 [7.000, 60.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.362404, mean_absolute_error: 5.267666, mean_q: 6.183316
163 (array([44]),) False
   8720/500000: episode: 218, duration: 29.991s, episode steps: 40, steps per second: 1, episode reward: 35.683, mean reward: 0.892 [0.199, 0.999], mean action: 23.650 [2.000, 57.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.385807, mean_absolute_error: 5.233386, mean_q: 6.180483
749 (array([22]),) False
   8760/500000: episode: 219, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 31.189, mean reward: 0.780 [0.122, 0.976], mean action: 18.575 [2.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.388302, mean_absolute_error: 5.274163, mean_q: 6.181563
216 (array([22]),) False
   8800/500000: episode: 220, duration: 30.759s, episode steps: 40, steps per second: 1, episode reward: 17.926, mean reward: 0.448 [0.000, 0.593], mean action: 20.100 [8.000, 57.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.417527, mean_absolute_error: 5.307935, mean_q: 6.241496
509 (array([22]),) False
   8840/500000: episode: 221, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 25.997, mean reward: 0.650 [0.046, 0.964], mean action: 21.500 [1.000, 54.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.402036, mean_absolute_error: 5.292473, mean_q: 6.226248
196 (array([22]),) False
   8880/500000: episode: 222, duration: 29.931s, episode steps: 40, steps per second: 1, episode reward: 28.714, mean reward: 0.718 [0.119, 1.000], mean action: 17.750 [0.000, 56.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.375694, mean_absolute_error: 5.335029, mean_q: 6.283347
792 (array([58]),) False
   8920/500000: episode: 223, duration: 30.776s, episode steps: 40, steps per second: 1, episode reward: 10.510, mean reward: 0.263 [0.000, 0.926], mean action: 21.350 [1.000, 57.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.379745, mean_absolute_error: 5.359238, mean_q: 6.268867
639 (array([22]),) False
   8960/500000: episode: 224, duration: 30.814s, episode steps: 40, steps per second: 1, episode reward: 23.484, mean reward: 0.587 [0.112, 0.816], mean action: 24.225 [6.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.352137, mean_absolute_error: 5.412605, mean_q: 6.322160
730 (array([54]),) False
   9000/500000: episode: 225, duration: 30.710s, episode steps: 40, steps per second: 1, episode reward: 22.125, mean reward: 0.553 [0.000, 1.000], mean action: 35.125 [2.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.395814, mean_absolute_error: 5.408091, mean_q: 6.311753
807 (array([22]),) False
   9040/500000: episode: 226, duration: 29.942s, episode steps: 40, steps per second: 1, episode reward: 32.376, mean reward: 0.809 [0.141, 1.000], mean action: 17.025 [5.000, 51.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.354541, mean_absolute_error: 5.460636, mean_q: 6.366163
348 (array([22]),) False
   9080/500000: episode: 227, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 30.811, mean reward: 0.770 [0.049, 1.000], mean action: 20.250 [2.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.401321, mean_absolute_error: 5.448142, mean_q: 6.402675
523 (array([22]),) False
   9120/500000: episode: 228, duration: 30.725s, episode steps: 40, steps per second: 1, episode reward: 25.738, mean reward: 0.643 [0.048, 0.960], mean action: 23.750 [4.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.323625, mean_absolute_error: 5.531222, mean_q: 6.475601
441 (array([22]),) False
   9160/500000: episode: 229, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 26.798, mean reward: 0.670 [0.083, 0.917], mean action: 21.100 [0.000, 59.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.410218, mean_absolute_error: 5.546488, mean_q: 6.476143
65 (array([48]),) False
   9200/500000: episode: 230, duration: 30.016s, episode steps: 40, steps per second: 1, episode reward: 25.492, mean reward: 0.637 [0.058, 1.000], mean action: 23.600 [3.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.388185, mean_absolute_error: 5.545127, mean_q: 6.499357
589 (array([22]),) False
   9240/500000: episode: 231, duration: 30.800s, episode steps: 40, steps per second: 1, episode reward: 24.595, mean reward: 0.615 [0.000, 1.000], mean action: 22.550 [3.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.390475, mean_absolute_error: 5.571889, mean_q: 6.541353
494 (array([48]),) False
   9280/500000: episode: 232, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 27.592, mean reward: 0.690 [0.034, 0.825], mean action: 19.625 [6.000, 57.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.412917, mean_absolute_error: 5.606120, mean_q: 6.555978
453 (array([22]),) False
   9320/500000: episode: 233, duration: 30.847s, episode steps: 40, steps per second: 1, episode reward: 27.749, mean reward: 0.694 [0.050, 1.000], mean action: 18.525 [0.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.410721, mean_absolute_error: 5.609910, mean_q: 6.583610
588 (array([22]),) False
   9360/500000: episode: 234, duration: 29.946s, episode steps: 40, steps per second: 1, episode reward: 24.793, mean reward: 0.620 [0.039, 1.000], mean action: 24.075 [4.000, 56.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.407067, mean_absolute_error: 5.651578, mean_q: 6.602617
336 (array([12]),) False
   9400/500000: episode: 235, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 28.082, mean reward: 0.702 [0.040, 1.000], mean action: 19.000 [1.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.447763, mean_absolute_error: 5.614990, mean_q: 6.550345
329 (array([12]),) False
   9440/500000: episode: 236, duration: 30.720s, episode steps: 40, steps per second: 1, episode reward: 32.344, mean reward: 0.809 [0.142, 1.000], mean action: 17.100 [1.000, 47.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.347689, mean_absolute_error: 5.699660, mean_q: 6.621521
145 (array([19]),) False
   9480/500000: episode: 237, duration: 30.785s, episode steps: 40, steps per second: 1, episode reward: 21.619, mean reward: 0.540 [0.187, 1.000], mean action: 30.775 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.446618, mean_absolute_error: 5.681474, mean_q: 6.654626
379 (array([22]),) False
   9520/500000: episode: 238, duration: 29.975s, episode steps: 40, steps per second: 1, episode reward: 27.035, mean reward: 0.676 [0.081, 1.000], mean action: 24.850 [5.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.480797, mean_absolute_error: 5.690492, mean_q: 6.620117
5 (array([37]),) False
   9560/500000: episode: 239, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 30.609, mean reward: 0.765 [0.000, 0.985], mean action: 22.900 [0.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.381911, mean_absolute_error: 5.744605, mean_q: 6.665343
773 (array([22]),) False
   9600/500000: episode: 240, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 26.352, mean reward: 0.659 [0.147, 0.779], mean action: 15.775 [3.000, 44.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.451519, mean_absolute_error: 5.730695, mean_q: 6.697256
343 (array([22]),) False
   9640/500000: episode: 241, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 29.897, mean reward: 0.747 [0.102, 0.954], mean action: 17.475 [8.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.408042, mean_absolute_error: 5.775848, mean_q: 6.740654
657 (array([48]),) False
   9680/500000: episode: 242, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 27.585, mean reward: 0.690 [0.013, 1.000], mean action: 26.525 [0.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.391216, mean_absolute_error: 5.795787, mean_q: 6.746821
184 (array([12]),) False
   9720/500000: episode: 243, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 24.445, mean reward: 0.611 [0.000, 1.000], mean action: 20.500 [0.000, 49.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.414310, mean_absolute_error: 5.833114, mean_q: 6.783301
824 (array([22]),) False
   9760/500000: episode: 244, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 29.546, mean reward: 0.739 [0.165, 0.915], mean action: 19.300 [2.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.368591, mean_absolute_error: 5.839915, mean_q: 6.773831
122 (array([12]),) False
   9800/500000: episode: 245, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 29.405, mean reward: 0.735 [0.064, 1.000], mean action: 22.600 [8.000, 53.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.388359, mean_absolute_error: 5.870547, mean_q: 6.815903
115 (array([22]),) False
   9840/500000: episode: 246, duration: 29.974s, episode steps: 40, steps per second: 1, episode reward: 29.248, mean reward: 0.731 [0.160, 1.000], mean action: 22.675 [4.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.407370, mean_absolute_error: 5.856488, mean_q: 6.827127
115 (array([22]),) False
   9880/500000: episode: 247, duration: 30.824s, episode steps: 40, steps per second: 1, episode reward: 29.622, mean reward: 0.741 [0.250, 1.000], mean action: 24.775 [12.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.425321, mean_absolute_error: 5.918764, mean_q: 6.883397
651 (array([22]),) False
   9920/500000: episode: 248, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 27.318, mean reward: 0.683 [0.044, 1.000], mean action: 26.400 [0.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.393868, mean_absolute_error: 5.951518, mean_q: 6.927722
67 (array([8]),) False
   9960/500000: episode: 249, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 19.377, mean reward: 0.484 [0.342, 0.843], mean action: 29.475 [2.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.487438, mean_absolute_error: 5.951600, mean_q: 6.935661
130 (array([22]),) False
  10000/500000: episode: 250, duration: 30.001s, episode steps: 40, steps per second: 1, episode reward: 30.271, mean reward: 0.757 [0.060, 1.000], mean action: 21.850 [0.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.446133, mean_absolute_error: 5.984069, mean_q: 6.949954
468 (array([22]),) False
  10040/500000: episode: 251, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 31.249, mean reward: 0.781 [0.181, 0.997], mean action: 20.975 [2.000, 59.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.432731, mean_absolute_error: 6.033357, mean_q: 6.995375
124 (array([48]),) False
  10080/500000: episode: 252, duration: 30.779s, episode steps: 40, steps per second: 1, episode reward: 30.336, mean reward: 0.758 [0.016, 1.000], mean action: 37.175 [4.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.488256, mean_absolute_error: 6.031873, mean_q: 7.009748
503 (array([3]),) False
  10120/500000: episode: 253, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 15.997, mean reward: 0.400 [0.094, 0.782], mean action: 24.400 [2.000, 59.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.483919, mean_absolute_error: 6.014409, mean_q: 6.997960
153 (array([44]),) False
  10160/500000: episode: 254, duration: 29.928s, episode steps: 40, steps per second: 1, episode reward: 28.342, mean reward: 0.709 [0.167, 1.000], mean action: 25.150 [5.000, 52.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.485692, mean_absolute_error: 6.049100, mean_q: 7.012527
244 (array([14]),) False
  10200/500000: episode: 255, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 30.337, mean reward: 0.758 [0.000, 1.000], mean action: 23.250 [0.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.443856, mean_absolute_error: 6.075481, mean_q: 7.066360
652 (array([22]),) False
  10240/500000: episode: 256, duration: 30.732s, episode steps: 40, steps per second: 1, episode reward: 26.994, mean reward: 0.675 [0.191, 0.833], mean action: 20.000 [0.000, 57.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.453082, mean_absolute_error: 6.126117, mean_q: 7.091872
525 (array([22]),) False
  10280/500000: episode: 257, duration: 30.759s, episode steps: 40, steps per second: 1, episode reward: 27.991, mean reward: 0.700 [0.017, 1.000], mean action: 19.775 [2.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.496128, mean_absolute_error: 6.088309, mean_q: 7.100957
681 (array([12]),) False
  10320/500000: episode: 258, duration: 30.012s, episode steps: 40, steps per second: 1, episode reward: 28.802, mean reward: 0.720 [0.005, 1.000], mean action: 22.475 [1.000, 59.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.438602, mean_absolute_error: 6.158485, mean_q: 7.163916
319 (array([33]),) False
  10360/500000: episode: 259, duration: 30.819s, episode steps: 40, steps per second: 1, episode reward: 17.941, mean reward: 0.449 [0.000, 0.955], mean action: 17.650 [1.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.474984, mean_absolute_error: 6.164895, mean_q: 7.166098
503 (array([3]),) False
  10400/500000: episode: 260, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 16.027, mean reward: 0.401 [0.160, 1.000], mean action: 19.825 [0.000, 59.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.459102, mean_absolute_error: 6.178173, mean_q: 7.189158
403 (array([12]),) False
  10440/500000: episode: 261, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 27.639, mean reward: 0.691 [0.005, 1.000], mean action: 23.675 [4.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.480454, mean_absolute_error: 6.235556, mean_q: 7.248034
509 (array([22]),) False
  10480/500000: episode: 262, duration: 29.938s, episode steps: 40, steps per second: 1, episode reward: 31.033, mean reward: 0.776 [0.165, 0.964], mean action: 19.400 [2.000, 48.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.497600, mean_absolute_error: 6.251962, mean_q: 7.214611
816 (array([4]),) False
  10520/500000: episode: 263, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 19.203, mean reward: 0.480 [0.000, 0.695], mean action: 32.325 [11.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.558962, mean_absolute_error: 6.223330, mean_q: 7.274845
440 (array([22]),) False
  10560/500000: episode: 264, duration: 30.680s, episode steps: 40, steps per second: 1, episode reward: 29.524, mean reward: 0.738 [0.173, 1.000], mean action: 21.400 [2.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.479499, mean_absolute_error: 6.273422, mean_q: 7.263529
741 (array([22]),) False
  10600/500000: episode: 265, duration: 30.847s, episode steps: 40, steps per second: 1, episode reward: 29.745, mean reward: 0.744 [0.020, 1.000], mean action: 20.850 [1.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.473698, mean_absolute_error: 6.244256, mean_q: 7.244567
754 (array([52]),) False
  10640/500000: episode: 266, duration: 30.030s, episode steps: 40, steps per second: 1, episode reward: 27.520, mean reward: 0.688 [0.000, 0.986], mean action: 19.325 [0.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.451224, mean_absolute_error: 6.283150, mean_q: 7.279450
409 (array([22]),) False
  10680/500000: episode: 267, duration: 30.702s, episode steps: 40, steps per second: 1, episode reward: 33.750, mean reward: 0.844 [0.057, 0.995], mean action: 17.625 [8.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.494427, mean_absolute_error: 6.274991, mean_q: 7.248179
486 (array([22]),) False
  10720/500000: episode: 268, duration: 30.756s, episode steps: 40, steps per second: 1, episode reward: 30.154, mean reward: 0.754 [0.112, 0.897], mean action: 14.025 [0.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.465726, mean_absolute_error: 6.263664, mean_q: 7.266383
448 (array([12]),) False
  10760/500000: episode: 269, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 29.870, mean reward: 0.747 [0.110, 1.000], mean action: 21.950 [4.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.442393, mean_absolute_error: 6.317901, mean_q: 7.324722
419 (array([40]),) False
  10800/500000: episode: 270, duration: 29.882s, episode steps: 40, steps per second: 1, episode reward: 24.650, mean reward: 0.616 [0.160, 1.000], mean action: 19.525 [1.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.448594, mean_absolute_error: 6.309278, mean_q: 7.330903
379 (array([22]),) False
  10840/500000: episode: 271, duration: 30.676s, episode steps: 40, steps per second: 1, episode reward: 27.037, mean reward: 0.676 [0.104, 1.000], mean action: 27.525 [0.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.571058, mean_absolute_error: 6.267409, mean_q: 7.277151
485 (array([22]),) False
  10880/500000: episode: 272, duration: 30.781s, episode steps: 40, steps per second: 1, episode reward: 28.413, mean reward: 0.710 [0.000, 1.000], mean action: 19.275 [1.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.497388, mean_absolute_error: 6.350904, mean_q: 7.322043
802 (array([22]),) False
  10920/500000: episode: 273, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 23.539, mean reward: 0.588 [0.088, 1.000], mean action: 21.600 [4.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.510250, mean_absolute_error: 6.331891, mean_q: 7.318730
465 (array([48]),) False
  10960/500000: episode: 274, duration: 29.920s, episode steps: 40, steps per second: 1, episode reward: 27.849, mean reward: 0.696 [0.048, 0.999], mean action: 21.650 [3.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.563973, mean_absolute_error: 6.339871, mean_q: 7.356073
150 (array([22]),) False
  11000/500000: episode: 275, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 30.800, mean reward: 0.770 [0.229, 1.000], mean action: 17.300 [1.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.482931, mean_absolute_error: 6.371668, mean_q: 7.396559
281 (array([48]),) False
  11040/500000: episode: 276, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 28.421, mean reward: 0.711 [0.123, 1.000], mean action: 23.825 [6.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.482285, mean_absolute_error: 6.409054, mean_q: 7.439929
40 (array([22]),) False
  11080/500000: episode: 277, duration: 30.801s, episode steps: 40, steps per second: 1, episode reward: 28.964, mean reward: 0.724 [0.102, 1.000], mean action: 18.925 [1.000, 52.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.480048, mean_absolute_error: 6.420403, mean_q: 7.469618
72 (array([12]),) False
  11120/500000: episode: 278, duration: 29.892s, episode steps: 40, steps per second: 1, episode reward: 32.823, mean reward: 0.821 [0.000, 1.000], mean action: 19.500 [5.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.477246, mean_absolute_error: 6.469872, mean_q: 7.520358
352 (array([22]),) False
  11160/500000: episode: 279, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 29.902, mean reward: 0.748 [0.091, 0.954], mean action: 18.275 [0.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.561030, mean_absolute_error: 6.450162, mean_q: 7.467565
384 (array([22]),) False
  11200/500000: episode: 280, duration: 30.674s, episode steps: 40, steps per second: 1, episode reward: 29.903, mean reward: 0.748 [0.059, 1.000], mean action: 20.900 [2.000, 53.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.515500, mean_absolute_error: 6.513410, mean_q: 7.551456
481 (array([22]),) False
  11240/500000: episode: 281, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 25.337, mean reward: 0.633 [0.000, 1.000], mean action: 22.775 [0.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.478938, mean_absolute_error: 6.522227, mean_q: 7.555898
18 (array([22]),) False
  11280/500000: episode: 282, duration: 29.982s, episode steps: 40, steps per second: 1, episode reward: 28.285, mean reward: 0.707 [0.000, 1.000], mean action: 21.875 [3.000, 53.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.517375, mean_absolute_error: 6.525551, mean_q: 7.560638
279 (array([22]),) False
  11320/500000: episode: 283, duration: 30.733s, episode steps: 40, steps per second: 1, episode reward: 23.768, mean reward: 0.594 [0.124, 0.964], mean action: 20.325 [0.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.539846, mean_absolute_error: 6.519180, mean_q: 7.567155
456 (array([22]),) False
  11360/500000: episode: 284, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 28.728, mean reward: 0.718 [0.035, 1.000], mean action: 23.475 [6.000, 60.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.479506, mean_absolute_error: 6.565152, mean_q: 7.589797
278 (array([48]),) False
  11400/500000: episode: 285, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 22.343, mean reward: 0.559 [0.072, 0.916], mean action: 18.375 [2.000, 47.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.624239, mean_absolute_error: 6.542499, mean_q: 7.576682
854 (array([12]),) False
  11440/500000: episode: 286, duration: 29.996s, episode steps: 40, steps per second: 1, episode reward: 29.238, mean reward: 0.731 [0.000, 1.000], mean action: 16.425 [1.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.522121, mean_absolute_error: 6.545477, mean_q: 7.583827
292 (array([22]),) False
  11480/500000: episode: 287, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 30.373, mean reward: 0.759 [0.280, 0.869], mean action: 16.000 [12.000, 43.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.482526, mean_absolute_error: 6.596099, mean_q: 7.601416
248 (array([12]),) False
  11520/500000: episode: 288, duration: 30.695s, episode steps: 40, steps per second: 1, episode reward: 31.185, mean reward: 0.780 [0.107, 1.000], mean action: 16.800 [4.000, 50.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.488752, mean_absolute_error: 6.627913, mean_q: 7.632432
356 (array([22]),) False
  11560/500000: episode: 289, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 23.446, mean reward: 0.586 [0.092, 0.845], mean action: 21.200 [1.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.499631, mean_absolute_error: 6.636333, mean_q: 7.659200
580 (array([22]),) False
  11600/500000: episode: 290, duration: 29.920s, episode steps: 40, steps per second: 1, episode reward: 30.328, mean reward: 0.758 [0.000, 0.917], mean action: 17.150 [1.000, 50.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.593937, mean_absolute_error: 6.618216, mean_q: 7.621565
9 (array([14]),) False
  11640/500000: episode: 291, duration: 30.757s, episode steps: 40, steps per second: 1, episode reward: 30.687, mean reward: 0.767 [0.000, 1.000], mean action: 28.500 [8.000, 53.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.578457, mean_absolute_error: 6.627299, mean_q: 7.659869
453 (array([22]),) False
  11680/500000: episode: 292, duration: 30.742s, episode steps: 40, steps per second: 1, episode reward: 29.838, mean reward: 0.746 [0.066, 1.000], mean action: 17.875 [0.000, 52.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.563783, mean_absolute_error: 6.639513, mean_q: 7.675224
1 (array([22]),) False
  11720/500000: episode: 293, duration: 30.806s, episode steps: 40, steps per second: 1, episode reward: 24.924, mean reward: 0.623 [0.021, 1.000], mean action: 25.250 [1.000, 60.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.555125, mean_absolute_error: 6.672699, mean_q: 7.716971
200 (array([22]),) False
  11760/500000: episode: 294, duration: 29.961s, episode steps: 40, steps per second: 1, episode reward: 24.105, mean reward: 0.603 [0.147, 1.000], mean action: 21.500 [2.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.496530, mean_absolute_error: 6.691765, mean_q: 7.745677
609 (array([22]),) False
  11800/500000: episode: 295, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 29.811, mean reward: 0.745 [0.000, 1.000], mean action: 23.625 [0.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.491506, mean_absolute_error: 6.688526, mean_q: 7.762371
286 (array([22]),) False
  11840/500000: episode: 296, duration: 30.705s, episode steps: 40, steps per second: 1, episode reward: 24.784, mean reward: 0.620 [0.155, 0.921], mean action: 19.525 [0.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.569089, mean_absolute_error: 6.679712, mean_q: 7.733342
343 (array([22]),) False
  11880/500000: episode: 297, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 29.215, mean reward: 0.730 [0.000, 0.954], mean action: 18.550 [2.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.554146, mean_absolute_error: 6.705721, mean_q: 7.767478
662 (array([12]),) False
  11920/500000: episode: 298, duration: 30.046s, episode steps: 40, steps per second: 1, episode reward: 32.062, mean reward: 0.802 [0.179, 1.000], mean action: 20.350 [7.000, 59.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.534441, mean_absolute_error: 6.724937, mean_q: 7.780391
224 (array([12]),) False
  11960/500000: episode: 299, duration: 30.695s, episode steps: 40, steps per second: 1, episode reward: 28.614, mean reward: 0.715 [0.102, 1.000], mean action: 22.800 [1.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.542864, mean_absolute_error: 6.711276, mean_q: 7.746394
178 (array([38]),) False
  12000/500000: episode: 300, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 26.042, mean reward: 0.651 [0.120, 0.992], mean action: 22.450 [7.000, 60.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.508469, mean_absolute_error: 6.749114, mean_q: 7.786654
80 (array([42]),) False
  12040/500000: episode: 301, duration: 30.745s, episode steps: 40, steps per second: 1, episode reward: 28.843, mean reward: 0.721 [0.000, 1.000], mean action: 17.375 [3.000, 55.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.521727, mean_absolute_error: 6.749989, mean_q: 7.768233
717 (array([22]),) False
  12080/500000: episode: 302, duration: 29.969s, episode steps: 40, steps per second: 1, episode reward: 27.486, mean reward: 0.687 [0.000, 0.939], mean action: 20.400 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.560629, mean_absolute_error: 6.758203, mean_q: 7.795298
673 (array([3]),) False
  12120/500000: episode: 303, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 14.726, mean reward: 0.368 [0.031, 0.928], mean action: 22.825 [9.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.553513, mean_absolute_error: 6.748116, mean_q: 7.781758
608 (array([36]),) False
  12160/500000: episode: 304, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 25.402, mean reward: 0.635 [0.006, 1.000], mean action: 26.175 [3.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.607348, mean_absolute_error: 6.755851, mean_q: 7.804489
256 (array([22]),) False
  12200/500000: episode: 305, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 27.322, mean reward: 0.683 [0.122, 1.000], mean action: 20.200 [4.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.569962, mean_absolute_error: 6.785726, mean_q: 7.862504
657 (array([48]),) False
  12240/500000: episode: 306, duration: 29.979s, episode steps: 40, steps per second: 1, episode reward: 28.717, mean reward: 0.718 [0.046, 1.000], mean action: 42.150 [8.000, 51.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.541945, mean_absolute_error: 6.823222, mean_q: 7.899339
12 (array([22]),) False
  12280/500000: episode: 307, duration: 30.705s, episode steps: 40, steps per second: 1, episode reward: 32.020, mean reward: 0.800 [0.058, 1.000], mean action: 26.000 [11.000, 58.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.567346, mean_absolute_error: 6.843014, mean_q: 7.915341
792 (array([58]),) False
  12320/500000: episode: 308, duration: 30.710s, episode steps: 40, steps per second: 1, episode reward: 12.479, mean reward: 0.312 [0.000, 0.862], mean action: 41.650 [2.000, 57.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.597724, mean_absolute_error: 6.795557, mean_q: 7.887900
156 (array([22]),) False
  12360/500000: episode: 309, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 22.890, mean reward: 0.572 [0.047, 1.000], mean action: 25.575 [2.000, 60.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.613851, mean_absolute_error: 6.831792, mean_q: 7.899858
442 (array([22]),) False
  12400/500000: episode: 310, duration: 29.889s, episode steps: 40, steps per second: 1, episode reward: 27.729, mean reward: 0.693 [0.060, 1.000], mean action: 23.850 [4.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.521124, mean_absolute_error: 6.864326, mean_q: 7.923981
675 (array([22]),) False
  12440/500000: episode: 311, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 19.618, mean reward: 0.490 [0.072, 0.771], mean action: 23.450 [0.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.530142, mean_absolute_error: 6.874890, mean_q: 7.913209
181 (array([22]),) False
  12480/500000: episode: 312, duration: 30.711s, episode steps: 40, steps per second: 1, episode reward: 20.142, mean reward: 0.504 [0.009, 1.000], mean action: 21.450 [2.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.594547, mean_absolute_error: 6.860535, mean_q: 7.886119
96 (array([22]),) False
  12520/500000: episode: 313, duration: 30.812s, episode steps: 40, steps per second: 1, episode reward: 26.516, mean reward: 0.663 [0.053, 1.000], mean action: 22.000 [2.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.526445, mean_absolute_error: 6.869346, mean_q: 7.942436
611 (array([22]),) False
  12560/500000: episode: 314, duration: 29.970s, episode steps: 40, steps per second: 1, episode reward: 30.247, mean reward: 0.756 [0.054, 1.000], mean action: 28.275 [1.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.533481, mean_absolute_error: 6.888353, mean_q: 7.926975
570 (array([47]),) False
  12600/500000: episode: 315, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 25.566, mean reward: 0.639 [0.103, 0.956], mean action: 18.875 [1.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.542484, mean_absolute_error: 6.872716, mean_q: 7.926234
339 (array([22]),) False
  12640/500000: episode: 316, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 28.399, mean reward: 0.710 [0.062, 1.000], mean action: 19.250 [0.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.563185, mean_absolute_error: 6.880319, mean_q: 7.915047
73 (array([22]),) False
  12680/500000: episode: 317, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 32.437, mean reward: 0.811 [0.070, 0.982], mean action: 20.800 [7.000, 60.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.619820, mean_absolute_error: 6.866707, mean_q: 7.903568
29 (array([22]),) False
  12720/500000: episode: 318, duration: 29.958s, episode steps: 40, steps per second: 1, episode reward: 31.364, mean reward: 0.784 [0.168, 1.000], mean action: 18.875 [2.000, 57.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.548398, mean_absolute_error: 6.873366, mean_q: 7.959903
772 (array([46]),) False
  12760/500000: episode: 319, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 21.565, mean reward: 0.539 [0.153, 0.905], mean action: 20.850 [1.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.571766, mean_absolute_error: 6.916752, mean_q: 7.952186
782 (array([22]),) False
  12800/500000: episode: 320, duration: 30.762s, episode steps: 40, steps per second: 1, episode reward: 19.323, mean reward: 0.483 [0.179, 0.863], mean action: 34.925 [0.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.659955, mean_absolute_error: 6.862841, mean_q: 7.923629
63 (array([18]),) False
  12840/500000: episode: 321, duration: 30.825s, episode steps: 40, steps per second: 1, episode reward: 33.570, mean reward: 0.839 [0.075, 1.000], mean action: 21.775 [6.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.589353, mean_absolute_error: 6.854391, mean_q: 7.922693
243 (array([12]),) False
  12880/500000: episode: 322, duration: 29.924s, episode steps: 40, steps per second: 1, episode reward: 28.493, mean reward: 0.712 [0.177, 1.000], mean action: 22.600 [1.000, 58.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.607219, mean_absolute_error: 6.855340, mean_q: 7.917018
681 (array([12]),) False
  12920/500000: episode: 323, duration: 30.710s, episode steps: 40, steps per second: 1, episode reward: 32.216, mean reward: 0.805 [0.109, 1.000], mean action: 20.025 [8.000, 54.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.578546, mean_absolute_error: 6.897501, mean_q: 7.962965
37 (array([48]),) False
  12960/500000: episode: 324, duration: 30.690s, episode steps: 40, steps per second: 1, episode reward: 30.613, mean reward: 0.765 [0.122, 1.000], mean action: 25.500 [2.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.577138, mean_absolute_error: 6.891576, mean_q: 7.963879
128 (array([22]),) False
  13000/500000: episode: 325, duration: 30.840s, episode steps: 40, steps per second: 1, episode reward: 20.832, mean reward: 0.521 [0.067, 0.708], mean action: 19.800 [5.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.637812, mean_absolute_error: 6.898033, mean_q: 7.949566
363 (array([36]),) False
  13040/500000: episode: 326, duration: 29.909s, episode steps: 40, steps per second: 1, episode reward: 20.412, mean reward: 0.510 [0.000, 0.853], mean action: 18.150 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.633184, mean_absolute_error: 6.918906, mean_q: 7.961121
227 (array([22]),) False
  13080/500000: episode: 327, duration: 30.722s, episode steps: 40, steps per second: 1, episode reward: 15.177, mean reward: 0.379 [0.046, 0.617], mean action: 21.075 [0.000, 59.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.555041, mean_absolute_error: 6.904268, mean_q: 7.990388
798 (array([18]),) False
  13120/500000: episode: 328, duration: 30.699s, episode steps: 40, steps per second: 1, episode reward: 28.005, mean reward: 0.700 [0.027, 1.000], mean action: 19.575 [0.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.576213, mean_absolute_error: 6.939111, mean_q: 8.020735
249 (array([22]),) False
  13160/500000: episode: 329, duration: 30.783s, episode steps: 40, steps per second: 1, episode reward: 32.493, mean reward: 0.812 [0.000, 1.000], mean action: 18.425 [8.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.580425, mean_absolute_error: 6.926596, mean_q: 7.994919
652 (array([22]),) False
  13200/500000: episode: 330, duration: 29.950s, episode steps: 40, steps per second: 1, episode reward: 24.895, mean reward: 0.622 [0.000, 0.833], mean action: 19.250 [2.000, 56.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.651229, mean_absolute_error: 6.950835, mean_q: 7.998046
743 (array([48]),) False
  13240/500000: episode: 331, duration: 30.700s, episode steps: 40, steps per second: 1, episode reward: 24.549, mean reward: 0.614 [0.048, 0.982], mean action: 27.875 [0.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.531366, mean_absolute_error: 6.959291, mean_q: 8.042811
186 (array([22]),) False
  13280/500000: episode: 332, duration: 30.721s, episode steps: 40, steps per second: 1, episode reward: 29.379, mean reward: 0.734 [0.182, 0.879], mean action: 16.125 [6.000, 55.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.556457, mean_absolute_error: 6.938507, mean_q: 7.994306
622 (array([36]),) False
  13320/500000: episode: 333, duration: 30.829s, episode steps: 40, steps per second: 1, episode reward: 18.316, mean reward: 0.458 [0.047, 1.000], mean action: 31.475 [4.000, 56.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.574392, mean_absolute_error: 6.996133, mean_q: 8.043400
129 (array([22]),) False
  13360/500000: episode: 334, duration: 29.922s, episode steps: 40, steps per second: 1, episode reward: 31.597, mean reward: 0.790 [0.326, 1.000], mean action: 21.075 [7.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.561669, mean_absolute_error: 6.961110, mean_q: 8.055190
571 (array([48]),) False
  13400/500000: episode: 335, duration: 30.725s, episode steps: 40, steps per second: 1, episode reward: 23.531, mean reward: 0.588 [0.039, 1.000], mean action: 19.050 [6.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.668323, mean_absolute_error: 6.941542, mean_q: 8.007156
330 (array([38]),) False
  13440/500000: episode: 336, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 32.815, mean reward: 0.820 [0.210, 1.000], mean action: 19.525 [6.000, 57.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.562218, mean_absolute_error: 6.943235, mean_q: 8.009864
679 (array([44]),) False
  13480/500000: episode: 337, duration: 30.729s, episode steps: 40, steps per second: 1, episode reward: 24.530, mean reward: 0.613 [0.000, 0.988], mean action: 15.725 [1.000, 45.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.550263, mean_absolute_error: 6.959665, mean_q: 8.030341
781 (array([8]),) False
  13520/500000: episode: 338, duration: 29.961s, episode steps: 40, steps per second: 1, episode reward: 20.945, mean reward: 0.524 [0.117, 0.988], mean action: 23.325 [7.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.595171, mean_absolute_error: 6.924933, mean_q: 8.012041
193 (array([36]),) False
  13560/500000: episode: 339, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 19.506, mean reward: 0.488 [0.000, 0.814], mean action: 18.275 [0.000, 52.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.560970, mean_absolute_error: 6.965636, mean_q: 8.021013
116 (array([22]),) False
  13600/500000: episode: 340, duration: 30.636s, episode steps: 40, steps per second: 1, episode reward: 28.464, mean reward: 0.712 [0.024, 1.000], mean action: 22.250 [4.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.618157, mean_absolute_error: 6.930952, mean_q: 7.983942
631 (array([22]),) False
  13640/500000: episode: 341, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 30.536, mean reward: 0.763 [0.224, 1.000], mean action: 19.925 [0.000, 48.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.567670, mean_absolute_error: 6.959975, mean_q: 8.026644
738 (array([12]),) False
  13680/500000: episode: 342, duration: 30.000s, episode steps: 40, steps per second: 1, episode reward: 28.842, mean reward: 0.721 [0.000, 1.000], mean action: 22.825 [10.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.504036, mean_absolute_error: 6.971648, mean_q: 8.034113
261 (array([44]),) False
  13720/500000: episode: 343, duration: 30.762s, episode steps: 40, steps per second: 1, episode reward: 27.236, mean reward: 0.681 [0.238, 0.882], mean action: 21.575 [1.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.584977, mean_absolute_error: 6.964606, mean_q: 8.031792
515 (array([22]),) False
  13760/500000: episode: 344, duration: 30.640s, episode steps: 40, steps per second: 1, episode reward: 32.604, mean reward: 0.815 [0.205, 1.000], mean action: 24.000 [1.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.547584, mean_absolute_error: 6.994761, mean_q: 8.056362
268 (array([22]),) False
  13800/500000: episode: 345, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 28.028, mean reward: 0.701 [0.111, 1.000], mean action: 23.250 [1.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.609283, mean_absolute_error: 7.010404, mean_q: 8.077052
528 (array([12]),) False
  13840/500000: episode: 346, duration: 29.944s, episode steps: 40, steps per second: 1, episode reward: 30.003, mean reward: 0.750 [0.159, 1.000], mean action: 15.050 [3.000, 52.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.658109, mean_absolute_error: 6.975610, mean_q: 8.039008
490 (array([12]),) False
  13880/500000: episode: 347, duration: 30.765s, episode steps: 40, steps per second: 1, episode reward: 29.914, mean reward: 0.748 [0.016, 1.000], mean action: 18.275 [1.000, 60.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.596290, mean_absolute_error: 6.976098, mean_q: 8.058309
310 (array([12]),) False
  13920/500000: episode: 348, duration: 30.697s, episode steps: 40, steps per second: 1, episode reward: 30.787, mean reward: 0.770 [0.158, 1.000], mean action: 20.625 [4.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.620832, mean_absolute_error: 6.982250, mean_q: 8.068469
463 (array([22]),) False
  13960/500000: episode: 349, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 29.637, mean reward: 0.741 [0.009, 1.000], mean action: 20.725 [6.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.557067, mean_absolute_error: 7.010713, mean_q: 8.090680
298 (array([22]),) False
  14000/500000: episode: 350, duration: 29.938s, episode steps: 40, steps per second: 1, episode reward: 27.120, mean reward: 0.678 [0.000, 1.000], mean action: 23.925 [3.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.536635, mean_absolute_error: 7.016717, mean_q: 8.123688
769 (array([12]),) False
  14040/500000: episode: 351, duration: 30.781s, episode steps: 40, steps per second: 1, episode reward: 26.272, mean reward: 0.657 [0.093, 1.000], mean action: 17.950 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.629397, mean_absolute_error: 6.988771, mean_q: 8.051282
799 (array([36]),) False
  14080/500000: episode: 352, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 31.322, mean reward: 0.783 [0.077, 0.999], mean action: 36.300 [6.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.626508, mean_absolute_error: 7.012325, mean_q: 8.088704
102 (array([22]),) False
  14120/500000: episode: 353, duration: 30.854s, episode steps: 40, steps per second: 1, episode reward: 24.127, mean reward: 0.603 [0.106, 1.000], mean action: 22.775 [2.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.587140, mean_absolute_error: 7.012438, mean_q: 8.104453
312 (array([12]),) False
  14160/500000: episode: 354, duration: 29.981s, episode steps: 40, steps per second: 1, episode reward: 28.456, mean reward: 0.711 [0.015, 1.000], mean action: 19.975 [2.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.639277, mean_absolute_error: 6.980364, mean_q: 8.069516
714 (array([22]),) False
  14200/500000: episode: 355, duration: 30.733s, episode steps: 40, steps per second: 1, episode reward: 28.652, mean reward: 0.716 [0.032, 0.973], mean action: 20.075 [6.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.582926, mean_absolute_error: 7.010516, mean_q: 8.107844
434 (array([22]),) False
  14240/500000: episode: 356, duration: 30.722s, episode steps: 40, steps per second: 1, episode reward: 26.096, mean reward: 0.652 [0.173, 1.000], mean action: 20.350 [6.000, 58.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.559263, mean_absolute_error: 7.021912, mean_q: 8.103090
358 (array([22]),) False
  14280/500000: episode: 357, duration: 30.856s, episode steps: 40, steps per second: 1, episode reward: 28.616, mean reward: 0.715 [0.024, 1.000], mean action: 41.575 [3.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.616203, mean_absolute_error: 7.036757, mean_q: 8.099325
262 (array([22]),) False
  14320/500000: episode: 358, duration: 30.004s, episode steps: 40, steps per second: 1, episode reward: 21.636, mean reward: 0.541 [0.026, 0.864], mean action: 18.425 [9.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.576834, mean_absolute_error: 7.048172, mean_q: 8.103199
65 (array([48]),) False
  14360/500000: episode: 359, duration: 30.701s, episode steps: 40, steps per second: 1, episode reward: 26.854, mean reward: 0.671 [0.000, 1.000], mean action: 21.950 [0.000, 52.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.597461, mean_absolute_error: 7.039266, mean_q: 8.108066
755 (array([22]),) False
  14400/500000: episode: 360, duration: 30.649s, episode steps: 40, steps per second: 1, episode reward: 24.426, mean reward: 0.611 [0.000, 1.000], mean action: 20.550 [1.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.608135, mean_absolute_error: 7.062295, mean_q: 8.155394
550 (array([12]),) False
  14440/500000: episode: 361, duration: 30.722s, episode steps: 40, steps per second: 1, episode reward: 32.049, mean reward: 0.801 [0.009, 1.000], mean action: 21.275 [12.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.553735, mean_absolute_error: 7.073041, mean_q: 8.143614
320 (array([22]),) False
  14480/500000: episode: 362, duration: 29.939s, episode steps: 40, steps per second: 1, episode reward: 27.352, mean reward: 0.684 [0.123, 0.960], mean action: 19.450 [4.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.501019, mean_absolute_error: 7.101611, mean_q: 8.180384
428 (array([22]),) False
  14520/500000: episode: 363, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 28.031, mean reward: 0.701 [0.045, 0.957], mean action: 36.300 [1.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.596335, mean_absolute_error: 7.085326, mean_q: 8.124113
331 (array([22]),) False
  14560/500000: episode: 364, duration: 30.681s, episode steps: 40, steps per second: 1, episode reward: 23.890, mean reward: 0.597 [0.000, 1.000], mean action: 21.500 [1.000, 58.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.592513, mean_absolute_error: 7.067880, mean_q: 8.130539
137 (array([22]),) False
  14600/500000: episode: 365, duration: 30.785s, episode steps: 40, steps per second: 1, episode reward: 28.493, mean reward: 0.712 [0.032, 0.926], mean action: 24.450 [0.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.621022, mean_absolute_error: 7.107635, mean_q: 8.178244
33 (array([48]),) False
  14640/500000: episode: 366, duration: 30.011s, episode steps: 40, steps per second: 1, episode reward: 27.111, mean reward: 0.678 [0.065, 1.000], mean action: 26.425 [1.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.649716, mean_absolute_error: 7.090195, mean_q: 8.173272
536 (array([22]),) False
  14680/500000: episode: 367, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 24.928, mean reward: 0.623 [0.025, 0.743], mean action: 20.825 [1.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.617776, mean_absolute_error: 7.127600, mean_q: 8.191195
327 (array([22]),) False
  14720/500000: episode: 368, duration: 30.631s, episode steps: 40, steps per second: 1, episode reward: 28.160, mean reward: 0.704 [0.085, 0.919], mean action: 23.050 [0.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.543281, mean_absolute_error: 7.122727, mean_q: 8.229960
609 (array([22]),) False
  14760/500000: episode: 369, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 22.496, mean reward: 0.562 [0.028, 0.830], mean action: 28.975 [0.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.567895, mean_absolute_error: 7.182695, mean_q: 8.249331
479 (array([22]),) False
  14800/500000: episode: 370, duration: 30.035s, episode steps: 40, steps per second: 1, episode reward: 28.296, mean reward: 0.707 [0.000, 1.000], mean action: 22.650 [6.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.630615, mean_absolute_error: 7.133052, mean_q: 8.202322
515 (array([22]),) False
  14840/500000: episode: 371, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 25.453, mean reward: 0.636 [0.064, 1.000], mean action: 19.700 [0.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.562534, mean_absolute_error: 7.182588, mean_q: 8.223508
271 (array([18]),) False
  14880/500000: episode: 372, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 26.695, mean reward: 0.667 [0.058, 1.000], mean action: 24.125 [1.000, 54.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.576120, mean_absolute_error: 7.155334, mean_q: 8.217287
242 (array([22]),) False
  14920/500000: episode: 373, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 24.442, mean reward: 0.611 [0.067, 1.000], mean action: 17.225 [4.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.572352, mean_absolute_error: 7.172774, mean_q: 8.219283
387 (array([22]),) False
  14960/500000: episode: 374, duration: 29.968s, episode steps: 40, steps per second: 1, episode reward: 25.620, mean reward: 0.641 [0.193, 0.786], mean action: 25.500 [1.000, 55.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.631830, mean_absolute_error: 7.170625, mean_q: 8.224994
241 (array([22]),) False
  15000/500000: episode: 375, duration: 30.742s, episode steps: 40, steps per second: 1, episode reward: 22.526, mean reward: 0.563 [0.028, 0.792], mean action: 21.650 [0.000, 59.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.657860, mean_absolute_error: 7.168638, mean_q: 8.243043
104 (array([22]),) False
  15040/500000: episode: 376, duration: 30.629s, episode steps: 40, steps per second: 1, episode reward: 28.762, mean reward: 0.719 [0.035, 1.000], mean action: 32.100 [8.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.559772, mean_absolute_error: 7.172906, mean_q: 8.282486
640 (array([22]),) False
  15080/500000: episode: 377, duration: 30.720s, episode steps: 40, steps per second: 1, episode reward: 29.409, mean reward: 0.735 [0.025, 0.935], mean action: 23.125 [6.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.572169, mean_absolute_error: 7.196135, mean_q: 8.240985
745 (array([22]),) False
  15120/500000: episode: 378, duration: 29.888s, episode steps: 40, steps per second: 1, episode reward: 27.742, mean reward: 0.694 [0.000, 0.957], mean action: 20.475 [4.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.521021, mean_absolute_error: 7.207356, mean_q: 8.283350
752 (array([3]),) False
  15160/500000: episode: 379, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 12.689, mean reward: 0.317 [0.000, 1.000], mean action: 19.300 [2.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.568130, mean_absolute_error: 7.239056, mean_q: 8.303222
125 (array([58]),) False
  15200/500000: episode: 380, duration: 30.678s, episode steps: 40, steps per second: 1, episode reward: 10.933, mean reward: 0.273 [0.000, 0.813], mean action: 29.250 [0.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.594068, mean_absolute_error: 7.231863, mean_q: 8.294922
803 (array([58]),) False
  15240/500000: episode: 381, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 23.708, mean reward: 0.593 [0.306, 0.993], mean action: 34.200 [6.000, 50.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.663704, mean_absolute_error: 7.216133, mean_q: 8.276949
4 (array([22]),) False
  15280/500000: episode: 382, duration: 29.930s, episode steps: 40, steps per second: 1, episode reward: 22.356, mean reward: 0.559 [0.036, 1.000], mean action: 24.750 [1.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.612852, mean_absolute_error: 7.237758, mean_q: 8.282507
5 (array([37]),) False
  15320/500000: episode: 383, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 30.939, mean reward: 0.773 [0.035, 1.000], mean action: 18.075 [3.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.659900, mean_absolute_error: 7.211806, mean_q: 8.263188
725 (array([36]),) False
  15360/500000: episode: 384, duration: 30.698s, episode steps: 40, steps per second: 1, episode reward: 20.229, mean reward: 0.506 [0.228, 0.883], mean action: 31.000 [0.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.645327, mean_absolute_error: 7.254874, mean_q: 8.320240
682 (array([22]),) False
  15400/500000: episode: 385, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 28.810, mean reward: 0.720 [0.116, 0.977], mean action: 18.350 [3.000, 53.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.543072, mean_absolute_error: 7.252799, mean_q: 8.312045
449 (array([22]),) False
  15440/500000: episode: 386, duration: 29.956s, episode steps: 40, steps per second: 1, episode reward: 27.957, mean reward: 0.699 [0.000, 0.913], mean action: 22.200 [2.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.630732, mean_absolute_error: 7.259264, mean_q: 8.364113
297 (array([15]),) False
  15480/500000: episode: 387, duration: 30.690s, episode steps: 40, steps per second: 1, episode reward: 28.678, mean reward: 0.717 [0.143, 0.989], mean action: 35.550 [1.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.764208, mean_absolute_error: 7.219927, mean_q: 8.290814
714 (array([22]),) False
  15520/500000: episode: 388, duration: 30.670s, episode steps: 40, steps per second: 1, episode reward: 31.517, mean reward: 0.788 [0.062, 0.974], mean action: 19.150 [0.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.603350, mean_absolute_error: 7.265827, mean_q: 8.335920
631 (array([22]),) False
  15560/500000: episode: 389, duration: 30.814s, episode steps: 40, steps per second: 1, episode reward: 29.835, mean reward: 0.746 [0.259, 0.896], mean action: 25.325 [8.000, 49.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.609654, mean_absolute_error: 7.243144, mean_q: 8.338526
350 (array([12]),) False
  15600/500000: episode: 390, duration: 29.910s, episode steps: 40, steps per second: 1, episode reward: 31.912, mean reward: 0.798 [0.152, 1.000], mean action: 20.625 [1.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.633499, mean_absolute_error: 7.275046, mean_q: 8.340559
851 (array([48]),) False
  15640/500000: episode: 391, duration: 30.787s, episode steps: 40, steps per second: 1, episode reward: 26.604, mean reward: 0.665 [0.103, 1.000], mean action: 36.350 [0.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.599870, mean_absolute_error: 7.266152, mean_q: 8.353651
603 (array([58]),) False
  15680/500000: episode: 392, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 20.396, mean reward: 0.510 [0.021, 0.878], mean action: 43.950 [3.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.630846, mean_absolute_error: 7.289778, mean_q: 8.385706
360 (array([22]),) False
  15720/500000: episode: 393, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 26.242, mean reward: 0.656 [0.156, 0.970], mean action: 20.125 [1.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.622819, mean_absolute_error: 7.266480, mean_q: 8.341134
719 (array([22]),) False
  15760/500000: episode: 394, duration: 30.002s, episode steps: 40, steps per second: 1, episode reward: 28.356, mean reward: 0.709 [0.000, 1.000], mean action: 21.650 [0.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.652681, mean_absolute_error: 7.270575, mean_q: 8.343877
183 (array([22]),) False
  15800/500000: episode: 395, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 20.433, mean reward: 0.511 [0.069, 0.618], mean action: 20.300 [1.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.659498, mean_absolute_error: 7.278134, mean_q: 8.341896
219 (array([36]),) False
  15840/500000: episode: 396, duration: 30.773s, episode steps: 40, steps per second: 1, episode reward: 16.585, mean reward: 0.415 [0.027, 1.000], mean action: 25.325 [0.000, 60.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.625280, mean_absolute_error: 7.322224, mean_q: 8.403590
740 (array([58]),) False
  15880/500000: episode: 397, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 20.212, mean reward: 0.505 [0.035, 0.758], mean action: 36.875 [1.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.626253, mean_absolute_error: 7.327574, mean_q: 8.381756
372 (array([22]),) False
  15920/500000: episode: 398, duration: 29.948s, episode steps: 40, steps per second: 1, episode reward: 25.465, mean reward: 0.637 [0.036, 0.804], mean action: 18.025 [8.000, 54.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.602232, mean_absolute_error: 7.322444, mean_q: 8.417316
562 (array([22]),) False
  15960/500000: episode: 399, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 25.378, mean reward: 0.634 [0.058, 1.000], mean action: 20.200 [7.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.588173, mean_absolute_error: 7.329937, mean_q: 8.384720
65 (array([48]),) False
  16000/500000: episode: 400, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 28.012, mean reward: 0.700 [0.053, 1.000], mean action: 19.500 [4.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.634223, mean_absolute_error: 7.358070, mean_q: 8.416121
445 (array([22]),) False
  16040/500000: episode: 401, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 27.866, mean reward: 0.697 [0.063, 1.000], mean action: 24.400 [0.000, 59.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.629951, mean_absolute_error: 7.338229, mean_q: 8.440251
821 (array([22]),) False
  16080/500000: episode: 402, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 28.746, mean reward: 0.719 [0.005, 1.000], mean action: 20.550 [5.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.656087, mean_absolute_error: 7.356908, mean_q: 8.404965
791 (array([54]),) False
  16120/500000: episode: 403, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 25.548, mean reward: 0.639 [0.036, 0.970], mean action: 24.400 [0.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.632368, mean_absolute_error: 7.391047, mean_q: 8.455029
467 (array([48]),) False
  16160/500000: episode: 404, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 29.208, mean reward: 0.730 [0.000, 1.000], mean action: 17.725 [2.000, 47.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.670817, mean_absolute_error: 7.373534, mean_q: 8.444054
658 (array([48]),) False
  16200/500000: episode: 405, duration: 30.773s, episode steps: 40, steps per second: 1, episode reward: 29.639, mean reward: 0.741 [0.027, 1.000], mean action: 19.225 [0.000, 55.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.665365, mean_absolute_error: 7.372795, mean_q: 8.429461
158 (array([22]),) False
  16240/500000: episode: 406, duration: 29.976s, episode steps: 40, steps per second: 1, episode reward: 26.048, mean reward: 0.651 [0.237, 0.923], mean action: 27.725 [4.000, 59.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.612680, mean_absolute_error: 7.397011, mean_q: 8.473866
684 (array([22]),) False
  16280/500000: episode: 407, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 29.277, mean reward: 0.732 [0.054, 0.871], mean action: 18.850 [11.000, 58.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.697353, mean_absolute_error: 7.360034, mean_q: 8.449768
477 (array([22]),) False
  16320/500000: episode: 408, duration: 30.720s, episode steps: 40, steps per second: 1, episode reward: 24.709, mean reward: 0.618 [0.092, 0.861], mean action: 26.300 [0.000, 54.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.638613, mean_absolute_error: 7.405676, mean_q: 8.496325
303 (array([22]),) False
  16360/500000: episode: 409, duration: 30.829s, episode steps: 40, steps per second: 1, episode reward: 20.458, mean reward: 0.511 [0.009, 1.000], mean action: 23.075 [0.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.696883, mean_absolute_error: 7.347754, mean_q: 8.438986
175 (array([22]),) False
  16400/500000: episode: 410, duration: 29.929s, episode steps: 40, steps per second: 1, episode reward: 28.799, mean reward: 0.720 [0.000, 0.983], mean action: 19.000 [2.000, 59.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.642831, mean_absolute_error: 7.356734, mean_q: 8.446808
121 (array([22]),) False
  16440/500000: episode: 411, duration: 30.734s, episode steps: 40, steps per second: 1, episode reward: 28.946, mean reward: 0.724 [0.000, 1.000], mean action: 25.200 [5.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.629976, mean_absolute_error: 7.345697, mean_q: 8.413049
608 (array([36]),) False
  16480/500000: episode: 412, duration: 30.726s, episode steps: 40, steps per second: 1, episode reward: 29.267, mean reward: 0.732 [0.000, 1.000], mean action: 33.450 [1.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.636355, mean_absolute_error: 7.346074, mean_q: 8.413014
252 (array([22]),) False
  16520/500000: episode: 413, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 20.081, mean reward: 0.502 [0.024, 1.000], mean action: 23.275 [3.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.685153, mean_absolute_error: 7.304889, mean_q: 8.388974
131 (array([22]),) False
  16560/500000: episode: 414, duration: 29.844s, episode steps: 40, steps per second: 1, episode reward: 30.752, mean reward: 0.769 [0.013, 1.000], mean action: 21.550 [2.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.668077, mean_absolute_error: 7.312876, mean_q: 8.426579
848 (array([44]),) False
  16600/500000: episode: 415, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 29.007, mean reward: 0.725 [0.000, 0.930], mean action: 38.850 [1.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.577792, mean_absolute_error: 7.332928, mean_q: 8.438440
214 (array([22]),) False
  16640/500000: episode: 416, duration: 30.702s, episode steps: 40, steps per second: 1, episode reward: 27.785, mean reward: 0.695 [0.229, 0.888], mean action: 30.850 [0.000, 56.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.641392, mean_absolute_error: 7.324576, mean_q: 8.406635
104 (array([22]),) False
  16680/500000: episode: 417, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 29.322, mean reward: 0.733 [0.232, 1.000], mean action: 21.075 [1.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.557089, mean_absolute_error: 7.329081, mean_q: 8.408773
502 (array([22]),) False
  16720/500000: episode: 418, duration: 29.984s, episode steps: 40, steps per second: 1, episode reward: 24.355, mean reward: 0.609 [0.087, 0.827], mean action: 18.725 [2.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.653740, mean_absolute_error: 7.357498, mean_q: 8.468126
794 (array([22]),) False
  16760/500000: episode: 419, duration: 30.802s, episode steps: 40, steps per second: 1, episode reward: 24.423, mean reward: 0.611 [0.073, 0.963], mean action: 26.600 [0.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.568691, mean_absolute_error: 7.372728, mean_q: 8.424696
801 (array([58]),) False
  16800/500000: episode: 420, duration: 30.661s, episode steps: 40, steps per second: 1, episode reward: 13.620, mean reward: 0.340 [0.000, 0.738], mean action: 25.825 [12.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.625501, mean_absolute_error: 7.358899, mean_q: 8.425676
110 (array([22]),) False
  16840/500000: episode: 421, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 23.818, mean reward: 0.595 [0.143, 0.825], mean action: 17.425 [0.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.541022, mean_absolute_error: 7.386667, mean_q: 8.468689
830 (array([22]),) False
  16880/500000: episode: 422, duration: 29.930s, episode steps: 40, steps per second: 1, episode reward: 28.838, mean reward: 0.721 [0.066, 0.870], mean action: 20.425 [2.000, 55.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.604749, mean_absolute_error: 7.369704, mean_q: 8.457346
653 (array([48]),) False
  16920/500000: episode: 423, duration: 30.797s, episode steps: 40, steps per second: 1, episode reward: 32.254, mean reward: 0.806 [0.000, 1.000], mean action: 41.650 [1.000, 52.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.679038, mean_absolute_error: 7.373776, mean_q: 8.469919
279 (array([22]),) False
  16960/500000: episode: 424, duration: 30.765s, episode steps: 40, steps per second: 1, episode reward: 27.284, mean reward: 0.682 [0.038, 0.964], mean action: 21.100 [4.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.668091, mean_absolute_error: 7.391156, mean_q: 8.447412
578 (array([22]),) False
  17000/500000: episode: 425, duration: 30.702s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.000, 1.000], mean action: 20.900 [2.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.567730, mean_absolute_error: 7.419650, mean_q: 8.490062
117 (array([44]),) False
  17040/500000: episode: 426, duration: 30.032s, episode steps: 40, steps per second: 1, episode reward: 26.319, mean reward: 0.658 [0.100, 1.000], mean action: 19.350 [2.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.568914, mean_absolute_error: 7.425063, mean_q: 8.481766
585 (array([48]),) False
  17080/500000: episode: 427, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 29.399, mean reward: 0.735 [0.019, 1.000], mean action: 18.600 [8.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.638550, mean_absolute_error: 7.432976, mean_q: 8.474420
825 (array([22]),) False
  17120/500000: episode: 428, duration: 30.748s, episode steps: 40, steps per second: 1, episode reward: 26.731, mean reward: 0.668 [0.222, 0.763], mean action: 18.250 [4.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.632446, mean_absolute_error: 7.412289, mean_q: 8.481173
188 (array([22]),) False
  17160/500000: episode: 429, duration: 30.838s, episode steps: 40, steps per second: 1, episode reward: 30.845, mean reward: 0.771 [0.050, 0.949], mean action: 18.875 [0.000, 54.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.596286, mean_absolute_error: 7.450009, mean_q: 8.527888
740 (array([58]),) False
  17200/500000: episode: 430, duration: 29.954s, episode steps: 40, steps per second: 1, episode reward: 20.872, mean reward: 0.522 [0.000, 0.918], mean action: 24.900 [0.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.644502, mean_absolute_error: 7.432854, mean_q: 8.510008
840 (array([12]),) False
  17240/500000: episode: 431, duration: 30.779s, episode steps: 40, steps per second: 1, episode reward: 30.341, mean reward: 0.759 [0.185, 1.000], mean action: 19.500 [3.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.618263, mean_absolute_error: 7.418585, mean_q: 8.519577
647 (array([22]),) False
  17280/500000: episode: 432, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 31.116, mean reward: 0.778 [0.028, 1.000], mean action: 20.050 [10.000, 59.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.708917, mean_absolute_error: 7.411249, mean_q: 8.514174
28 (array([58]),) False
  17320/500000: episode: 433, duration: 30.757s, episode steps: 40, steps per second: 1, episode reward: 19.845, mean reward: 0.496 [0.028, 0.867], mean action: 22.850 [12.000, 57.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.648019, mean_absolute_error: 7.402827, mean_q: 8.500024
525 (array([22]),) False
  17360/500000: episode: 434, duration: 30.014s, episode steps: 40, steps per second: 1, episode reward: 25.595, mean reward: 0.640 [0.082, 1.000], mean action: 21.625 [2.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.677666, mean_absolute_error: 7.385980, mean_q: 8.453142
791 (array([54]),) False
  17400/500000: episode: 435, duration: 30.711s, episode steps: 40, steps per second: 1, episode reward: 26.261, mean reward: 0.657 [0.123, 1.000], mean action: 24.925 [0.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.735429, mean_absolute_error: 7.370583, mean_q: 8.456344
575 (array([44]),) False
  17440/500000: episode: 436, duration: 30.786s, episode steps: 40, steps per second: 1, episode reward: 28.847, mean reward: 0.721 [0.217, 0.899], mean action: 19.400 [2.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.694871, mean_absolute_error: 7.359148, mean_q: 8.437359
395 (array([22]),) False
  17480/500000: episode: 437, duration: 30.858s, episode steps: 40, steps per second: 1, episode reward: 24.202, mean reward: 0.605 [0.041, 1.000], mean action: 20.975 [3.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.544163, mean_absolute_error: 7.397812, mean_q: 8.454178
242 (array([22]),) False
  17520/500000: episode: 438, duration: 29.941s, episode steps: 40, steps per second: 1, episode reward: 25.396, mean reward: 0.635 [0.134, 0.900], mean action: 21.050 [1.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.593452, mean_absolute_error: 7.375389, mean_q: 8.445448
852 (array([44]),) False
  17560/500000: episode: 439, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 31.639, mean reward: 0.791 [0.078, 1.000], mean action: 18.575 [0.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.615455, mean_absolute_error: 7.388907, mean_q: 8.454980
18 (array([22]),) False
  17600/500000: episode: 440, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 28.598, mean reward: 0.715 [0.141, 1.000], mean action: 26.450 [4.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.679719, mean_absolute_error: 7.364340, mean_q: 8.430615
205 (array([22]),) False
  17640/500000: episode: 441, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 24.351, mean reward: 0.609 [0.216, 0.788], mean action: 23.100 [6.000, 59.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.608496, mean_absolute_error: 7.413809, mean_q: 8.484793
614 (array([22]),) False
  17680/500000: episode: 442, duration: 30.025s, episode steps: 40, steps per second: 1, episode reward: 24.415, mean reward: 0.610 [0.103, 0.917], mean action: 19.125 [5.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.678149, mean_absolute_error: 7.406994, mean_q: 8.487373
616 (array([22]),) False
  17720/500000: episode: 443, duration: 30.779s, episode steps: 40, steps per second: 1, episode reward: 26.302, mean reward: 0.658 [0.075, 0.858], mean action: 20.700 [6.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.630301, mean_absolute_error: 7.409239, mean_q: 8.445259
569 (array([22]),) False
  17760/500000: episode: 444, duration: 30.697s, episode steps: 40, steps per second: 1, episode reward: 25.919, mean reward: 0.648 [0.056, 1.000], mean action: 16.350 [0.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.595130, mean_absolute_error: 7.438155, mean_q: 8.461424
290 (array([22]),) False
  17800/500000: episode: 445, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 27.972, mean reward: 0.699 [0.056, 0.908], mean action: 16.425 [3.000, 53.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.586934, mean_absolute_error: 7.447953, mean_q: 8.498940
782 (array([22]),) False
  17840/500000: episode: 446, duration: 29.931s, episode steps: 40, steps per second: 1, episode reward: 20.289, mean reward: 0.507 [0.196, 0.854], mean action: 25.250 [11.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.595087, mean_absolute_error: 7.442323, mean_q: 8.482195
483 (array([48]),) False
  17880/500000: episode: 447, duration: 30.745s, episode steps: 40, steps per second: 1, episode reward: 28.599, mean reward: 0.715 [0.076, 0.950], mean action: 21.775 [1.000, 47.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.691675, mean_absolute_error: 7.420000, mean_q: 8.462122
711 (array([22]),) False
  17920/500000: episode: 448, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 30.800, mean reward: 0.770 [0.141, 1.000], mean action: 19.250 [5.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.684759, mean_absolute_error: 7.453322, mean_q: 8.510562
767 (array([48]),) False
  17960/500000: episode: 449, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 29.828, mean reward: 0.746 [0.000, 1.000], mean action: 35.025 [10.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.688015, mean_absolute_error: 7.413982, mean_q: 8.543559
311 (array([22]),) False
  18000/500000: episode: 450, duration: 29.976s, episode steps: 40, steps per second: 1, episode reward: 27.501, mean reward: 0.688 [0.028, 1.000], mean action: 24.000 [4.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.645646, mean_absolute_error: 7.447302, mean_q: 8.543826
667 (array([48]),) False
  18040/500000: episode: 451, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 31.491, mean reward: 0.787 [0.057, 1.000], mean action: 19.375 [4.000, 50.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.706503, mean_absolute_error: 7.448312, mean_q: 8.511258
133 (array([22]),) False
  18080/500000: episode: 452, duration: 30.700s, episode steps: 40, steps per second: 1, episode reward: 26.519, mean reward: 0.663 [0.037, 0.878], mean action: 18.650 [0.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.650734, mean_absolute_error: 7.457112, mean_q: 8.525009
279 (array([22]),) False
  18120/500000: episode: 453, duration: 30.777s, episode steps: 40, steps per second: 1, episode reward: 27.722, mean reward: 0.693 [0.000, 0.978], mean action: 19.325 [3.000, 50.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.572066, mean_absolute_error: 7.475591, mean_q: 8.563985
291 (array([22]),) False
  18160/500000: episode: 454, duration: 29.979s, episode steps: 40, steps per second: 1, episode reward: 28.849, mean reward: 0.721 [0.000, 0.968], mean action: 22.175 [0.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.649020, mean_absolute_error: 7.444499, mean_q: 8.499254
660 (array([2]),) False
  18200/500000: episode: 455, duration: 30.810s, episode steps: 40, steps per second: 1, episode reward: 20.871, mean reward: 0.522 [0.069, 1.000], mean action: 29.050 [1.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.601669, mean_absolute_error: 7.420295, mean_q: 8.506495
700 (array([44]),) False
  18240/500000: episode: 456, duration: 30.752s, episode steps: 40, steps per second: 1, episode reward: 28.266, mean reward: 0.707 [0.000, 1.000], mean action: 22.550 [0.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.679389, mean_absolute_error: 7.404935, mean_q: 8.506798
602 (array([36]),) False
  18280/500000: episode: 457, duration: 30.800s, episode steps: 40, steps per second: 1, episode reward: 7.916, mean reward: 0.198 [0.000, 0.963], mean action: 19.025 [8.000, 55.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.629143, mean_absolute_error: 7.414833, mean_q: 8.500587
527 (array([58]),) False
  18320/500000: episode: 458, duration: 29.940s, episode steps: 40, steps per second: 1, episode reward: 16.753, mean reward: 0.419 [0.086, 0.678], mean action: 19.325 [2.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.659931, mean_absolute_error: 7.375787, mean_q: 8.445326
830 (array([22]),) False
  18360/500000: episode: 459, duration: 30.722s, episode steps: 40, steps per second: 1, episode reward: 26.595, mean reward: 0.665 [0.100, 1.000], mean action: 21.500 [1.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.606963, mean_absolute_error: 7.392014, mean_q: 8.490224
575 (array([44]),) False
  18400/500000: episode: 460, duration: 30.699s, episode steps: 40, steps per second: 1, episode reward: 28.053, mean reward: 0.701 [0.000, 0.969], mean action: 25.850 [3.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.650436, mean_absolute_error: 7.409732, mean_q: 8.464190
279 (array([22]),) False
  18440/500000: episode: 461, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 24.695, mean reward: 0.617 [0.094, 1.000], mean action: 23.975 [2.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.594912, mean_absolute_error: 7.420480, mean_q: 8.462979
172 (array([12]),) False
  18480/500000: episode: 462, duration: 29.951s, episode steps: 40, steps per second: 1, episode reward: 30.467, mean reward: 0.762 [0.036, 1.000], mean action: 18.975 [3.000, 53.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.578482, mean_absolute_error: 7.411406, mean_q: 8.469358
504 (array([48]),) False
  18520/500000: episode: 463, duration: 30.724s, episode steps: 40, steps per second: 1, episode reward: 18.369, mean reward: 0.459 [0.026, 0.656], mean action: 16.175 [6.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.567113, mean_absolute_error: 7.460626, mean_q: 8.523330
51 (array([22]),) False
  18560/500000: episode: 464, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 31.218, mean reward: 0.780 [0.118, 1.000], mean action: 24.700 [3.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.622572, mean_absolute_error: 7.463600, mean_q: 8.511072
694 (array([22]),) False
  18600/500000: episode: 465, duration: 30.812s, episode steps: 40, steps per second: 1, episode reward: 22.072, mean reward: 0.552 [0.072, 0.784], mean action: 23.450 [2.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.631209, mean_absolute_error: 7.434891, mean_q: 8.508886
34 (array([22]),) False
  18640/500000: episode: 466, duration: 29.935s, episode steps: 40, steps per second: 1, episode reward: 28.486, mean reward: 0.712 [0.000, 1.000], mean action: 24.775 [5.000, 60.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.606604, mean_absolute_error: 7.448261, mean_q: 8.492404
610 (array([48]),) False
  18680/500000: episode: 467, duration: 30.673s, episode steps: 40, steps per second: 1, episode reward: 29.781, mean reward: 0.745 [0.045, 0.997], mean action: 17.225 [5.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.590587, mean_absolute_error: 7.475157, mean_q: 8.508490
564 (array([22]),) False
  18720/500000: episode: 468, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 29.875, mean reward: 0.747 [0.152, 1.000], mean action: 18.300 [1.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.572104, mean_absolute_error: 7.490302, mean_q: 8.540266
465 (array([48]),) False
  18760/500000: episode: 469, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 28.238, mean reward: 0.706 [0.036, 0.999], mean action: 28.200 [2.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.599379, mean_absolute_error: 7.449786, mean_q: 8.525633
136 (array([12]),) False
  18800/500000: episode: 470, duration: 29.960s, episode steps: 40, steps per second: 1, episode reward: 32.953, mean reward: 0.824 [0.181, 1.000], mean action: 18.875 [1.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.681667, mean_absolute_error: 7.449637, mean_q: 8.517207
211 (array([22]),) False
  18840/500000: episode: 471, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 22.686, mean reward: 0.567 [0.034, 0.896], mean action: 22.875 [3.000, 58.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.631587, mean_absolute_error: 7.436059, mean_q: 8.545414
514 (array([54]),) False
  18880/500000: episode: 472, duration: 30.692s, episode steps: 40, steps per second: 1, episode reward: 18.473, mean reward: 0.462 [0.124, 0.751], mean action: 19.850 [5.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.623515, mean_absolute_error: 7.455612, mean_q: 8.546999
740 (array([58]),) False
  18920/500000: episode: 473, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 23.982, mean reward: 0.600 [0.191, 0.949], mean action: 19.975 [1.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.723207, mean_absolute_error: 7.401985, mean_q: 8.487358
395 (array([22]),) False
  18960/500000: episode: 474, duration: 29.988s, episode steps: 40, steps per second: 1, episode reward: 25.360, mean reward: 0.634 [0.001, 0.958], mean action: 21.775 [0.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.608439, mean_absolute_error: 7.397928, mean_q: 8.477407
518 (array([22]),) False
  19000/500000: episode: 475, duration: 30.691s, episode steps: 40, steps per second: 1, episode reward: 25.633, mean reward: 0.641 [0.116, 0.930], mean action: 22.150 [3.000, 56.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.712107, mean_absolute_error: 7.415570, mean_q: 8.499922
769 (array([12]),) False
  19040/500000: episode: 476, duration: 30.720s, episode steps: 40, steps per second: 1, episode reward: 27.114, mean reward: 0.678 [0.025, 1.000], mean action: 19.850 [6.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.642668, mean_absolute_error: 7.396042, mean_q: 8.497207
795 (array([3]),) False
  19080/500000: episode: 477, duration: 30.792s, episode steps: 40, steps per second: 1, episode reward: 32.425, mean reward: 0.811 [0.303, 1.000], mean action: 43.450 [0.000, 60.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.670539, mean_absolute_error: 7.412533, mean_q: 8.502307
443 (array([22]),) False
  19120/500000: episode: 478, duration: 29.941s, episode steps: 40, steps per second: 1, episode reward: 29.188, mean reward: 0.730 [0.000, 1.000], mean action: 17.975 [1.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.554593, mean_absolute_error: 7.434350, mean_q: 8.504906
822 (array([22]),) False
  19160/500000: episode: 479, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 27.839, mean reward: 0.696 [0.056, 1.000], mean action: 14.375 [6.000, 39.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.685603, mean_absolute_error: 7.412038, mean_q: 8.460764
298 (array([22]),) False
  19200/500000: episode: 480, duration: 30.694s, episode steps: 40, steps per second: 1, episode reward: 28.627, mean reward: 0.716 [0.046, 1.000], mean action: 25.700 [2.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.583576, mean_absolute_error: 7.406251, mean_q: 8.482601
400 (array([22]),) False
  19240/500000: episode: 481, duration: 30.700s, episode steps: 40, steps per second: 1, episode reward: 32.791, mean reward: 0.820 [0.172, 1.000], mean action: 18.050 [1.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.680437, mean_absolute_error: 7.383845, mean_q: 8.463911
702 (array([22]),) False
  19280/500000: episode: 482, duration: 29.959s, episode steps: 40, steps per second: 1, episode reward: 23.144, mean reward: 0.579 [0.022, 1.000], mean action: 22.100 [5.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.632383, mean_absolute_error: 7.373559, mean_q: 8.429015
604 (array([40]),) False
  19320/500000: episode: 483, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 29.690, mean reward: 0.742 [0.070, 0.946], mean action: 21.000 [3.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.621501, mean_absolute_error: 7.359197, mean_q: 8.409942
381 (array([22]),) False
  19360/500000: episode: 484, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 27.434, mean reward: 0.686 [0.000, 1.000], mean action: 27.725 [6.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.631545, mean_absolute_error: 7.340482, mean_q: 8.404475
472 (array([22]),) False
  19400/500000: episode: 485, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 24.100, mean reward: 0.602 [0.053, 0.934], mean action: 30.300 [2.000, 51.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.706612, mean_absolute_error: 7.317777, mean_q: 8.394491
579 (array([58]),) False
  19440/500000: episode: 486, duration: 29.969s, episode steps: 40, steps per second: 1, episode reward: 30.449, mean reward: 0.761 [0.000, 1.000], mean action: 37.275 [4.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.665937, mean_absolute_error: 7.332016, mean_q: 8.428595
378 (array([22]),) False
  19480/500000: episode: 487, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 21.063, mean reward: 0.527 [0.000, 1.000], mean action: 35.425 [2.000, 56.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.682970, mean_absolute_error: 7.291634, mean_q: 8.361814
544 (array([22]),) False
  19520/500000: episode: 488, duration: 30.725s, episode steps: 40, steps per second: 1, episode reward: 27.949, mean reward: 0.699 [0.212, 0.907], mean action: 16.275 [0.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.653497, mean_absolute_error: 7.287730, mean_q: 8.357237
260 (array([22]),) False
  19560/500000: episode: 489, duration: 30.826s, episode steps: 40, steps per second: 1, episode reward: 27.883, mean reward: 0.697 [0.038, 1.000], mean action: 21.025 [1.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.622733, mean_absolute_error: 7.265429, mean_q: 8.354177
259 (array([12]),) False
  19600/500000: episode: 490, duration: 29.958s, episode steps: 40, steps per second: 1, episode reward: 30.379, mean reward: 0.759 [0.099, 1.000], mean action: 20.925 [3.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.599464, mean_absolute_error: 7.287169, mean_q: 8.361876
504 (array([48]),) False
  19640/500000: episode: 491, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 17.851, mean reward: 0.446 [0.051, 0.656], mean action: 19.025 [1.000, 56.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.583911, mean_absolute_error: 7.295918, mean_q: 8.361294
496 (array([48]),) False
  19680/500000: episode: 492, duration: 30.685s, episode steps: 40, steps per second: 1, episode reward: 17.227, mean reward: 0.431 [0.000, 0.905], mean action: 18.600 [0.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.549591, mean_absolute_error: 7.317278, mean_q: 8.360121
446 (array([22]),) False
  19720/500000: episode: 493, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 25.469, mean reward: 0.637 [0.000, 1.000], mean action: 20.200 [1.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.633316, mean_absolute_error: 7.332721, mean_q: 8.380427
73 (array([22]),) False
  19760/500000: episode: 494, duration: 29.979s, episode steps: 40, steps per second: 1, episode reward: 29.065, mean reward: 0.727 [0.072, 0.982], mean action: 19.525 [3.000, 57.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.559539, mean_absolute_error: 7.338905, mean_q: 8.365003
162 (array([22]),) False
  19800/500000: episode: 495, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 26.695, mean reward: 0.667 [0.069, 1.000], mean action: 23.100 [1.000, 59.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.621068, mean_absolute_error: 7.312200, mean_q: 8.370845
843 (array([3]),) False
  19840/500000: episode: 496, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 13.637, mean reward: 0.341 [0.000, 0.797], mean action: 32.000 [9.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.618358, mean_absolute_error: 7.326982, mean_q: 8.380534
765 (array([48]),) False
  19880/500000: episode: 497, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 23.375, mean reward: 0.584 [0.086, 1.000], mean action: 33.525 [9.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.552194, mean_absolute_error: 7.332959, mean_q: 8.391653
425 (array([22]),) False
  19920/500000: episode: 498, duration: 29.986s, episode steps: 40, steps per second: 1, episode reward: 23.582, mean reward: 0.590 [0.007, 1.000], mean action: 33.450 [11.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.600766, mean_absolute_error: 7.320123, mean_q: 8.394534
215 (array([22]),) False
  19960/500000: episode: 499, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 25.317, mean reward: 0.633 [0.102, 1.000], mean action: 21.900 [9.000, 54.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.594219, mean_absolute_error: 7.349570, mean_q: 8.369491
60 (array([22]),) False
  20000/500000: episode: 500, duration: 30.675s, episode steps: 40, steps per second: 1, episode reward: 25.070, mean reward: 0.627 [0.030, 0.962], mean action: 21.825 [2.000, 46.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.664994, mean_absolute_error: 7.309151, mean_q: 8.328836
248 (array([12]),) False
  20040/500000: episode: 501, duration: 30.843s, episode steps: 40, steps per second: 1, episode reward: 28.414, mean reward: 0.710 [0.148, 1.000], mean action: 19.600 [0.000, 57.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.615743, mean_absolute_error: 7.314625, mean_q: 8.329613
84 (array([22]),) False
  20080/500000: episode: 502, duration: 30.014s, episode steps: 40, steps per second: 1, episode reward: 28.368, mean reward: 0.709 [0.057, 0.942], mean action: 23.250 [4.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.646824, mean_absolute_error: 7.314589, mean_q: 8.366757
594 (array([48]),) False
  20120/500000: episode: 503, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 27.102, mean reward: 0.678 [0.017, 0.962], mean action: 18.000 [0.000, 52.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.623254, mean_absolute_error: 7.302727, mean_q: 8.334023
107 (array([22]),) False
  20160/500000: episode: 504, duration: 30.726s, episode steps: 40, steps per second: 1, episode reward: 25.574, mean reward: 0.639 [0.095, 1.000], mean action: 22.775 [4.000, 55.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.519774, mean_absolute_error: 7.341460, mean_q: 8.369819
327 (array([22]),) False
  20200/500000: episode: 505, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 30.290, mean reward: 0.757 [0.137, 0.957], mean action: 17.100 [1.000, 52.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.719422, mean_absolute_error: 7.261497, mean_q: 8.349768
409 (array([22]),) False
  20240/500000: episode: 506, duration: 30.003s, episode steps: 40, steps per second: 1, episode reward: 25.922, mean reward: 0.648 [0.000, 0.992], mean action: 26.700 [2.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.547659, mean_absolute_error: 7.313897, mean_q: 8.359648
515 (array([22]),) False
  20280/500000: episode: 507, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 25.532, mean reward: 0.638 [0.062, 1.000], mean action: 18.450 [0.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.654855, mean_absolute_error: 7.292101, mean_q: 8.340268
515 (array([22]),) False
  20320/500000: episode: 508, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 26.705, mean reward: 0.668 [0.037, 1.000], mean action: 21.750 [8.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.572539, mean_absolute_error: 7.266126, mean_q: 8.347775
48 (array([12]),) False
  20360/500000: episode: 509, duration: 30.825s, episode steps: 40, steps per second: 1, episode reward: 34.157, mean reward: 0.854 [0.000, 1.000], mean action: 20.600 [3.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.620204, mean_absolute_error: 7.280021, mean_q: 8.341249
123 (array([22]),) False
  20400/500000: episode: 510, duration: 29.939s, episode steps: 40, steps per second: 1, episode reward: 27.367, mean reward: 0.684 [0.042, 0.952], mean action: 21.300 [3.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.572231, mean_absolute_error: 7.264552, mean_q: 8.326159
107 (array([22]),) False
  20440/500000: episode: 511, duration: 30.772s, episode steps: 40, steps per second: 1, episode reward: 28.401, mean reward: 0.710 [0.083, 1.000], mean action: 18.675 [2.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.618055, mean_absolute_error: 7.255612, mean_q: 8.301706
40 (array([22]),) False
  20480/500000: episode: 512, duration: 30.734s, episode steps: 40, steps per second: 1, episode reward: 26.827, mean reward: 0.671 [0.000, 1.000], mean action: 18.425 [0.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.612124, mean_absolute_error: 7.284838, mean_q: 8.315381
162 (array([22]),) False
  20520/500000: episode: 513, duration: 30.741s, episode steps: 40, steps per second: 1, episode reward: 24.289, mean reward: 0.607 [0.039, 0.906], mean action: 23.775 [1.000, 58.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.603404, mean_absolute_error: 7.261355, mean_q: 8.341374
381 (array([22]),) False
  20560/500000: episode: 514, duration: 29.954s, episode steps: 40, steps per second: 1, episode reward: 28.759, mean reward: 0.719 [0.000, 1.000], mean action: 22.300 [6.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.655643, mean_absolute_error: 7.229901, mean_q: 8.284830
57 (array([37]),) False
  20600/500000: episode: 515, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 23.791, mean reward: 0.595 [0.079, 0.823], mean action: 18.700 [0.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.623881, mean_absolute_error: 7.262961, mean_q: 8.293306
88 (array([22]),) False
  20640/500000: episode: 516, duration: 30.757s, episode steps: 40, steps per second: 1, episode reward: 25.001, mean reward: 0.625 [0.186, 1.000], mean action: 21.325 [2.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.759102, mean_absolute_error: 7.196174, mean_q: 8.235346
154 (array([44]),) False
  20680/500000: episode: 517, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 29.404, mean reward: 0.735 [0.042, 0.998], mean action: 26.725 [5.000, 53.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.709825, mean_absolute_error: 7.209003, mean_q: 8.279743
681 (array([12]),) False
  20720/500000: episode: 518, duration: 29.914s, episode steps: 40, steps per second: 1, episode reward: 28.149, mean reward: 0.704 [0.027, 1.000], mean action: 20.200 [5.000, 55.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.595664, mean_absolute_error: 7.225981, mean_q: 8.295324
673 (array([3]),) False
  20760/500000: episode: 519, duration: 30.708s, episode steps: 40, steps per second: 1, episode reward: 16.094, mean reward: 0.402 [0.000, 0.923], mean action: 30.325 [4.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.595014, mean_absolute_error: 7.188148, mean_q: 8.249150
6 (array([58]),) False
  20800/500000: episode: 520, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 24.471, mean reward: 0.612 [0.086, 1.000], mean action: 27.825 [2.000, 57.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.582674, mean_absolute_error: 7.178651, mean_q: 8.235503
561 (array([22]),) False
  20840/500000: episode: 521, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 23.982, mean reward: 0.600 [0.205, 1.000], mean action: 22.425 [0.000, 60.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.560969, mean_absolute_error: 7.203146, mean_q: 8.260657
244 (array([14]),) False
  20880/500000: episode: 522, duration: 29.971s, episode steps: 40, steps per second: 1, episode reward: 28.034, mean reward: 0.701 [0.000, 0.911], mean action: 28.500 [12.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.567529, mean_absolute_error: 7.223911, mean_q: 8.263941
715 (array([22]),) False
  20920/500000: episode: 523, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 29.962, mean reward: 0.749 [0.086, 0.940], mean action: 17.950 [3.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.491753, mean_absolute_error: 7.246032, mean_q: 8.263256
566 (array([12]),) False
  20960/500000: episode: 524, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 33.614, mean reward: 0.840 [0.292, 1.000], mean action: 18.050 [1.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.573100, mean_absolute_error: 7.238270, mean_q: 8.278135
178 (array([38]),) False
  21000/500000: episode: 525, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 26.474, mean reward: 0.662 [0.161, 0.992], mean action: 26.375 [6.000, 57.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.636254, mean_absolute_error: 7.226903, mean_q: 8.280795
472 (array([22]),) False
  21040/500000: episode: 526, duration: 29.953s, episode steps: 40, steps per second: 1, episode reward: 23.450, mean reward: 0.586 [0.152, 0.934], mean action: 22.300 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.606020, mean_absolute_error: 7.243680, mean_q: 8.285415
389 (array([48]),) False
  21080/500000: episode: 527, duration: 30.695s, episode steps: 40, steps per second: 1, episode reward: 31.666, mean reward: 0.792 [0.002, 1.000], mean action: 27.175 [0.000, 60.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.561319, mean_absolute_error: 7.276951, mean_q: 8.310768
696 (array([36]),) False
  21120/500000: episode: 528, duration: 30.667s, episode steps: 40, steps per second: 1, episode reward: 33.433, mean reward: 0.836 [0.051, 1.000], mean action: 40.400 [1.000, 56.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.477246, mean_absolute_error: 7.261214, mean_q: 8.270452
503 (array([3]),) False
  21160/500000: episode: 529, duration: 30.849s, episode steps: 40, steps per second: 1, episode reward: 17.133, mean reward: 0.428 [0.159, 0.868], mean action: 29.675 [0.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.616531, mean_absolute_error: 7.241739, mean_q: 8.269551
59 (array([12]),) False
  21200/500000: episode: 530, duration: 29.972s, episode steps: 40, steps per second: 1, episode reward: 31.974, mean reward: 0.799 [0.141, 1.000], mean action: 19.725 [0.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.528397, mean_absolute_error: 7.283040, mean_q: 8.316023
48 (array([12]),) False
  21240/500000: episode: 531, duration: 30.799s, episode steps: 40, steps per second: 1, episode reward: 31.190, mean reward: 0.780 [0.230, 1.000], mean action: 22.550 [1.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.652240, mean_absolute_error: 7.251894, mean_q: 8.294456
624 (array([48]),) False
  21280/500000: episode: 532, duration: 30.673s, episode steps: 40, steps per second: 1, episode reward: 32.446, mean reward: 0.811 [0.083, 1.000], mean action: 34.700 [3.000, 55.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.534613, mean_absolute_error: 7.297908, mean_q: 8.298297
145 (array([19]),) False
  21320/500000: episode: 533, duration: 30.748s, episode steps: 40, steps per second: 1, episode reward: 23.951, mean reward: 0.599 [0.067, 0.753], mean action: 20.100 [2.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.595373, mean_absolute_error: 7.295121, mean_q: 8.334201
438 (array([22]),) False
  21360/500000: episode: 534, duration: 29.999s, episode steps: 40, steps per second: 1, episode reward: 25.242, mean reward: 0.631 [0.032, 0.951], mean action: 39.450 [1.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.589087, mean_absolute_error: 7.283850, mean_q: 8.292247
853 (array([22]),) False
  21400/500000: episode: 535, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 26.361, mean reward: 0.659 [0.177, 1.000], mean action: 22.375 [4.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.586030, mean_absolute_error: 7.272792, mean_q: 8.294329
104 (array([22]),) False
  21440/500000: episode: 536, duration: 30.678s, episode steps: 40, steps per second: 1, episode reward: 27.955, mean reward: 0.699 [0.006, 1.000], mean action: 20.025 [3.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.576995, mean_absolute_error: 7.253626, mean_q: 8.258398
515 (array([22]),) False
  21480/500000: episode: 537, duration: 30.775s, episode steps: 40, steps per second: 1, episode reward: 27.401, mean reward: 0.685 [0.000, 1.000], mean action: 27.225 [4.000, 58.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.640115, mean_absolute_error: 7.272895, mean_q: 8.290319
48 (array([12]),) False
  21520/500000: episode: 538, duration: 29.968s, episode steps: 40, steps per second: 1, episode reward: 33.363, mean reward: 0.834 [0.230, 1.000], mean action: 20.375 [2.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.614429, mean_absolute_error: 7.245528, mean_q: 8.275246
677 (array([48]),) False
  21560/500000: episode: 539, duration: 30.773s, episode steps: 40, steps per second: 1, episode reward: 29.284, mean reward: 0.732 [0.179, 1.000], mean action: 22.000 [1.000, 60.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.594325, mean_absolute_error: 7.242318, mean_q: 8.293705
588 (array([22]),) False
  21600/500000: episode: 540, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 28.303, mean reward: 0.708 [0.000, 0.910], mean action: 19.475 [2.000, 52.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.647337, mean_absolute_error: 7.179034, mean_q: 8.197234
189 (array([12]),) False
  21640/500000: episode: 541, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 32.382, mean reward: 0.810 [0.128, 1.000], mean action: 19.400 [0.000, 55.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.567604, mean_absolute_error: 7.215452, mean_q: 8.246099
636 (array([12]),) False
  21680/500000: episode: 542, duration: 29.961s, episode steps: 40, steps per second: 1, episode reward: 28.192, mean reward: 0.705 [0.025, 1.000], mean action: 26.950 [6.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.592005, mean_absolute_error: 7.235480, mean_q: 8.276970
398 (array([22]),) False
  21720/500000: episode: 543, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 24.480, mean reward: 0.612 [0.051, 0.914], mean action: 24.300 [5.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.531545, mean_absolute_error: 7.249732, mean_q: 8.266688
26 (array([22]),) False
  21760/500000: episode: 544, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 31.398, mean reward: 0.785 [0.074, 1.000], mean action: 23.325 [6.000, 55.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.518673, mean_absolute_error: 7.239973, mean_q: 8.231849
166 (array([22]),) False
  21800/500000: episode: 545, duration: 30.837s, episode steps: 40, steps per second: 1, episode reward: 24.643, mean reward: 0.616 [0.109, 1.000], mean action: 19.150 [1.000, 60.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.551443, mean_absolute_error: 7.272406, mean_q: 8.273386
673 (array([3]),) False
  21840/500000: episode: 546, duration: 30.029s, episode steps: 40, steps per second: 1, episode reward: 13.826, mean reward: 0.346 [0.031, 0.815], mean action: 23.975 [2.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.572786, mean_absolute_error: 7.260745, mean_q: 8.285383
158 (array([22]),) False
  21880/500000: episode: 547, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 29.106, mean reward: 0.728 [0.158, 1.000], mean action: 19.250 [2.000, 57.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.621696, mean_absolute_error: 7.249218, mean_q: 8.289737
721 (array([22]),) False
  21920/500000: episode: 548, duration: 30.726s, episode steps: 40, steps per second: 1, episode reward: 23.883, mean reward: 0.597 [0.000, 0.939], mean action: 17.550 [2.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.631310, mean_absolute_error: 7.273940, mean_q: 8.291510
282 (array([22]),) False
  21960/500000: episode: 549, duration: 30.826s, episode steps: 40, steps per second: 1, episode reward: 28.029, mean reward: 0.701 [0.234, 0.845], mean action: 26.800 [6.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.600111, mean_absolute_error: 7.285781, mean_q: 8.342148
271 (array([18]),) False
  22000/500000: episode: 550, duration: 29.935s, episode steps: 40, steps per second: 1, episode reward: 26.582, mean reward: 0.665 [0.044, 0.907], mean action: 23.350 [1.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.547301, mean_absolute_error: 7.302879, mean_q: 8.352780
48 (array([12]),) False
  22040/500000: episode: 551, duration: 30.696s, episode steps: 40, steps per second: 1, episode reward: 34.701, mean reward: 0.868 [0.000, 1.000], mean action: 22.325 [4.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.525531, mean_absolute_error: 7.297462, mean_q: 8.365434
38 (array([22]),) False
  22080/500000: episode: 552, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 25.469, mean reward: 0.637 [0.022, 1.000], mean action: 31.025 [0.000, 56.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.605651, mean_absolute_error: 7.270741, mean_q: 8.318121
830 (array([22]),) False
  22120/500000: episode: 553, duration: 30.721s, episode steps: 40, steps per second: 1, episode reward: 26.174, mean reward: 0.654 [0.068, 0.870], mean action: 20.200 [1.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.590773, mean_absolute_error: 7.236615, mean_q: 8.264366
816 (array([4]),) False
  22160/500000: episode: 554, duration: 29.950s, episode steps: 40, steps per second: 1, episode reward: 16.328, mean reward: 0.408 [0.000, 0.930], mean action: 35.650 [0.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.594445, mean_absolute_error: 7.231447, mean_q: 8.300194
301 (array([22]),) False
  22200/500000: episode: 555, duration: 30.781s, episode steps: 40, steps per second: 1, episode reward: 24.982, mean reward: 0.625 [0.000, 1.000], mean action: 37.050 [6.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.601295, mean_absolute_error: 7.215639, mean_q: 8.237102
763 (array([48]),) False
  22240/500000: episode: 556, duration: 30.706s, episode steps: 40, steps per second: 1, episode reward: 26.408, mean reward: 0.660 [0.060, 1.000], mean action: 24.675 [3.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.563449, mean_absolute_error: 7.230331, mean_q: 8.251875
47 (array([44]),) False
  22280/500000: episode: 557, duration: 30.804s, episode steps: 40, steps per second: 1, episode reward: 27.969, mean reward: 0.699 [0.000, 1.000], mean action: 29.125 [3.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.618435, mean_absolute_error: 7.190062, mean_q: 8.213834
483 (array([48]),) False
  22320/500000: episode: 558, duration: 29.911s, episode steps: 40, steps per second: 1, episode reward: 24.956, mean reward: 0.624 [0.083, 0.943], mean action: 27.175 [3.000, 52.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.552657, mean_absolute_error: 7.216732, mean_q: 8.244977
591 (array([22]),) False
  22360/500000: episode: 559, duration: 30.776s, episode steps: 40, steps per second: 1, episode reward: 23.718, mean reward: 0.593 [0.049, 0.801], mean action: 15.850 [0.000, 46.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.601393, mean_absolute_error: 7.212049, mean_q: 8.215357
208 (array([22]),) False
  22400/500000: episode: 560, duration: 30.650s, episode steps: 40, steps per second: 1, episode reward: 29.233, mean reward: 0.731 [0.224, 1.000], mean action: 22.175 [0.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.683358, mean_absolute_error: 7.145904, mean_q: 8.214167
700 (array([44]),) False
  22440/500000: episode: 561, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 28.086, mean reward: 0.702 [0.000, 1.000], mean action: 28.550 [5.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.608497, mean_absolute_error: 7.151188, mean_q: 8.200318
741 (array([22]),) False
  22480/500000: episode: 562, duration: 29.970s, episode steps: 40, steps per second: 1, episode reward: 32.681, mean reward: 0.817 [0.207, 1.000], mean action: 17.625 [0.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.575974, mean_absolute_error: 7.146100, mean_q: 8.161236
717 (array([22]),) False
  22520/500000: episode: 563, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 28.775, mean reward: 0.719 [0.127, 1.000], mean action: 24.100 [0.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.564657, mean_absolute_error: 7.161799, mean_q: 8.199688
526 (array([22]),) False
  22560/500000: episode: 564, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 26.111, mean reward: 0.653 [0.020, 0.932], mean action: 20.800 [2.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.581699, mean_absolute_error: 7.138742, mean_q: 8.164267
346 (array([12]),) False
  22600/500000: episode: 565, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 30.352, mean reward: 0.759 [0.000, 1.000], mean action: 23.200 [3.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.573657, mean_absolute_error: 7.143427, mean_q: 8.154558
741 (array([22]),) False
  22640/500000: episode: 566, duration: 29.986s, episode steps: 40, steps per second: 1, episode reward: 31.280, mean reward: 0.782 [0.092, 1.000], mean action: 18.600 [0.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.489847, mean_absolute_error: 7.133710, mean_q: 8.129482
133 (array([22]),) False
  22680/500000: episode: 567, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 28.013, mean reward: 0.700 [0.306, 1.000], mean action: 19.500 [0.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.561012, mean_absolute_error: 7.153946, mean_q: 8.150118
477 (array([22]),) False
  22720/500000: episode: 568, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 26.374, mean reward: 0.659 [0.036, 0.865], mean action: 21.850 [7.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.558927, mean_absolute_error: 7.127601, mean_q: 8.143166
548 (array([22]),) False
  22760/500000: episode: 569, duration: 30.878s, episode steps: 40, steps per second: 1, episode reward: 24.884, mean reward: 0.622 [0.106, 0.796], mean action: 20.700 [2.000, 57.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.566213, mean_absolute_error: 7.154782, mean_q: 8.153701
697 (array([22]),) False
  22800/500000: episode: 570, duration: 29.944s, episode steps: 40, steps per second: 1, episode reward: 31.193, mean reward: 0.780 [0.025, 1.000], mean action: 21.850 [0.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.580157, mean_absolute_error: 7.143600, mean_q: 8.134517
157 (array([48]),) False
  22840/500000: episode: 571, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 29.535, mean reward: 0.738 [0.023, 1.000], mean action: 27.575 [1.000, 57.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.558145, mean_absolute_error: 7.133493, mean_q: 8.143588
564 (array([22]),) False
  22880/500000: episode: 572, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 29.202, mean reward: 0.730 [0.059, 1.000], mean action: 23.150 [8.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.641681, mean_absolute_error: 7.081913, mean_q: 8.120494
819 (array([48]),) False
  22920/500000: episode: 573, duration: 30.799s, episode steps: 40, steps per second: 1, episode reward: 22.426, mean reward: 0.561 [0.114, 1.000], mean action: 19.300 [2.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.652531, mean_absolute_error: 7.070045, mean_q: 8.106354
79 (array([22]),) False
  22960/500000: episode: 574, duration: 30.036s, episode steps: 40, steps per second: 1, episode reward: 31.819, mean reward: 0.795 [0.072, 1.000], mean action: 18.325 [0.000, 55.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.523423, mean_absolute_error: 7.092341, mean_q: 8.090370
573 (array([22]),) False
  23000/500000: episode: 575, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 24.030, mean reward: 0.601 [0.000, 0.906], mean action: 22.200 [0.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.560135, mean_absolute_error: 7.077033, mean_q: 8.085097
398 (array([22]),) False
  23040/500000: episode: 576, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 22.833, mean reward: 0.571 [0.000, 0.914], mean action: 23.150 [2.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.444939, mean_absolute_error: 7.132977, mean_q: 8.104582
688 (array([22]),) False
  23080/500000: episode: 577, duration: 30.792s, episode steps: 40, steps per second: 1, episode reward: 27.272, mean reward: 0.682 [0.000, 0.843], mean action: 20.075 [0.000, 50.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.519432, mean_absolute_error: 7.133560, mean_q: 8.104686
413 (array([22]),) False
  23120/500000: episode: 578, duration: 29.965s, episode steps: 40, steps per second: 1, episode reward: 15.820, mean reward: 0.396 [0.000, 0.948], mean action: 45.275 [6.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.514539, mean_absolute_error: 7.178782, mean_q: 8.160818
168 (array([22]),) False
  23160/500000: episode: 579, duration: 30.704s, episode steps: 40, steps per second: 1, episode reward: 29.082, mean reward: 0.727 [0.055, 0.913], mean action: 21.600 [1.000, 59.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.637885, mean_absolute_error: 7.140712, mean_q: 8.156499
678 (array([22]),) False
  23200/500000: episode: 580, duration: 30.663s, episode steps: 40, steps per second: 1, episode reward: 24.435, mean reward: 0.611 [0.154, 0.875], mean action: 21.575 [1.000, 58.000], mean observation: -0.107 [-1.000, 1.000], loss: 0.642840, mean_absolute_error: 7.091289, mean_q: 8.108976
583 (array([22]),) False
  23240/500000: episode: 581, duration: 30.759s, episode steps: 40, steps per second: 1, episode reward: 30.601, mean reward: 0.765 [0.115, 1.000], mean action: 18.400 [1.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.495335, mean_absolute_error: 7.105386, mean_q: 8.135551
755 (array([22]),) False
  23280/500000: episode: 582, duration: 29.925s, episode steps: 40, steps per second: 1, episode reward: 26.893, mean reward: 0.672 [0.000, 0.849], mean action: 17.600 [1.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.530366, mean_absolute_error: 7.087045, mean_q: 8.096423
41 (array([12]),) False
  23320/500000: episode: 583, duration: 30.752s, episode steps: 40, steps per second: 1, episode reward: 26.605, mean reward: 0.665 [0.072, 1.000], mean action: 15.275 [3.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.512778, mean_absolute_error: 7.095113, mean_q: 8.097504
219 (array([36]),) False
  23360/500000: episode: 584, duration: 30.775s, episode steps: 40, steps per second: 1, episode reward: 11.605, mean reward: 0.290 [0.075, 0.768], mean action: 18.800 [2.000, 60.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.633137, mean_absolute_error: 7.091370, mean_q: 8.091809
404 (array([12]),) False
  23400/500000: episode: 585, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 33.167, mean reward: 0.829 [0.029, 1.000], mean action: 19.275 [5.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.600577, mean_absolute_error: 7.099014, mean_q: 8.100560
731 (array([21]),) False
  23440/500000: episode: 586, duration: 29.975s, episode steps: 40, steps per second: 1, episode reward: 29.055, mean reward: 0.726 [0.090, 1.000], mean action: 15.550 [3.000, 51.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.526383, mean_absolute_error: 7.125960, mean_q: 8.148539
443 (array([22]),) False
  23480/500000: episode: 587, duration: 30.787s, episode steps: 40, steps per second: 1, episode reward: 31.814, mean reward: 0.795 [0.053, 1.000], mean action: 19.075 [5.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.501648, mean_absolute_error: 7.129214, mean_q: 8.124148
123 (array([22]),) False
  23520/500000: episode: 588, duration: 30.686s, episode steps: 40, steps per second: 1, episode reward: 30.307, mean reward: 0.758 [0.079, 1.000], mean action: 21.475 [5.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.525430, mean_absolute_error: 7.123849, mean_q: 8.110298
407 (array([22]),) False
  23560/500000: episode: 589, duration: 30.783s, episode steps: 40, steps per second: 1, episode reward: 30.015, mean reward: 0.750 [0.067, 1.000], mean action: 22.950 [1.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.524998, mean_absolute_error: 7.125372, mean_q: 8.120217
232 (array([22]),) False
  23600/500000: episode: 590, duration: 29.959s, episode steps: 40, steps per second: 1, episode reward: 26.618, mean reward: 0.665 [0.000, 0.981], mean action: 19.150 [1.000, 49.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.589017, mean_absolute_error: 7.123746, mean_q: 8.145529
783 (array([22]),) False
  23640/500000: episode: 591, duration: 30.682s, episode steps: 40, steps per second: 1, episode reward: 28.383, mean reward: 0.710 [0.119, 1.000], mean action: 23.775 [1.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.619090, mean_absolute_error: 7.124492, mean_q: 8.113187
470 (array([22]),) False
  23680/500000: episode: 592, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 30.809, mean reward: 0.770 [0.057, 0.994], mean action: 23.775 [3.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.584415, mean_absolute_error: 7.106611, mean_q: 8.120329
5 (array([37]),) False
  23720/500000: episode: 593, duration: 30.797s, episode steps: 40, steps per second: 1, episode reward: 32.167, mean reward: 0.804 [0.035, 1.000], mean action: 21.350 [12.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.586813, mean_absolute_error: 7.114986, mean_q: 8.116911
268 (array([22]),) False
  23760/500000: episode: 594, duration: 29.902s, episode steps: 40, steps per second: 1, episode reward: 27.246, mean reward: 0.681 [0.000, 0.937], mean action: 19.575 [3.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.573459, mean_absolute_error: 7.104907, mean_q: 8.106581
161 (array([22]),) False
  23800/500000: episode: 595, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 30.024, mean reward: 0.751 [0.271, 0.906], mean action: 24.150 [11.000, 60.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.561850, mean_absolute_error: 7.106239, mean_q: 8.133687
59 (array([12]),) False
  23840/500000: episode: 596, duration: 30.687s, episode steps: 40, steps per second: 1, episode reward: 29.725, mean reward: 0.743 [0.082, 1.000], mean action: 18.550 [5.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.604125, mean_absolute_error: 7.085690, mean_q: 8.089310
473 (array([22]),) False
  23880/500000: episode: 597, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 18.730, mean reward: 0.468 [0.000, 0.882], mean action: 22.800 [1.000, 59.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.600203, mean_absolute_error: 7.081056, mean_q: 8.126180
180 (array([48]),) False
  23920/500000: episode: 598, duration: 29.962s, episode steps: 40, steps per second: 1, episode reward: 31.776, mean reward: 0.794 [0.044, 0.981], mean action: 18.525 [3.000, 59.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.509738, mean_absolute_error: 7.106941, mean_q: 8.097444
8 (array([22]),) False
  23960/500000: episode: 599, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 28.695, mean reward: 0.717 [0.092, 1.000], mean action: 30.600 [1.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.589845, mean_absolute_error: 7.030214, mean_q: 8.035158
513 (array([12]),) False
  24000/500000: episode: 600, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 31.358, mean reward: 0.784 [0.043, 1.000], mean action: 23.675 [6.000, 57.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.476385, mean_absolute_error: 7.064246, mean_q: 8.035305
116 (array([22]),) False
  24040/500000: episode: 601, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 28.575, mean reward: 0.714 [0.115, 1.000], mean action: 22.375 [3.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.560329, mean_absolute_error: 7.037028, mean_q: 8.069697
562 (array([22]),) False
  24080/500000: episode: 602, duration: 29.872s, episode steps: 40, steps per second: 1, episode reward: 24.142, mean reward: 0.604 [0.000, 1.000], mean action: 21.975 [0.000, 51.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.562023, mean_absolute_error: 7.029373, mean_q: 8.046861
338 (array([12]),) False
  24120/500000: episode: 603, duration: 30.760s, episode steps: 40, steps per second: 1, episode reward: 27.606, mean reward: 0.690 [0.033, 1.000], mean action: 22.325 [3.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.608104, mean_absolute_error: 7.025458, mean_q: 8.018321
537 (array([22]),) False
  24160/500000: episode: 604, duration: 30.691s, episode steps: 40, steps per second: 1, episode reward: 30.122, mean reward: 0.753 [0.296, 1.000], mean action: 21.800 [8.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.543120, mean_absolute_error: 7.035986, mean_q: 8.045984
169 (array([22]),) False
  24200/500000: episode: 605, duration: 30.802s, episode steps: 40, steps per second: 1, episode reward: 26.656, mean reward: 0.666 [0.000, 0.918], mean action: 20.650 [0.000, 57.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.506636, mean_absolute_error: 7.068391, mean_q: 8.077925
814 (array([22]),) False
  24240/500000: episode: 606, duration: 29.946s, episode steps: 40, steps per second: 1, episode reward: 27.391, mean reward: 0.685 [0.000, 0.858], mean action: 19.500 [4.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.626032, mean_absolute_error: 7.021976, mean_q: 8.037122
855 (array([12]),) False
  24280/500000: episode: 607, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 34.185, mean reward: 0.855 [0.304, 1.000], mean action: 17.325 [5.000, 51.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.571768, mean_absolute_error: 7.025049, mean_q: 8.064255
18 (array([22]),) False
  24320/500000: episode: 608, duration: 30.756s, episode steps: 40, steps per second: 1, episode reward: 25.835, mean reward: 0.646 [0.000, 1.000], mean action: 30.550 [2.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.544950, mean_absolute_error: 7.023978, mean_q: 8.017097
784 (array([22]),) False
  24360/500000: episode: 609, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 28.629, mean reward: 0.716 [0.179, 0.966], mean action: 20.725 [0.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.510649, mean_absolute_error: 7.068418, mean_q: 8.080173
315 (array([12]),) False
  24400/500000: episode: 610, duration: 29.983s, episode steps: 40, steps per second: 1, episode reward: 30.081, mean reward: 0.752 [0.004, 1.000], mean action: 20.150 [1.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.432476, mean_absolute_error: 7.095037, mean_q: 8.059896
793 (array([12]),) False
  24440/500000: episode: 611, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 29.851, mean reward: 0.746 [0.000, 1.000], mean action: 16.650 [4.000, 45.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.564228, mean_absolute_error: 7.076755, mean_q: 8.046930
699 (array([22]),) False
  24480/500000: episode: 612, duration: 30.720s, episode steps: 40, steps per second: 1, episode reward: 22.665, mean reward: 0.567 [0.130, 1.000], mean action: 24.175 [0.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.584056, mean_absolute_error: 7.089598, mean_q: 8.068533
447 (array([44]),) False
  24520/500000: episode: 613, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 21.649, mean reward: 0.541 [0.089, 1.000], mean action: 23.650 [1.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.536465, mean_absolute_error: 7.085999, mean_q: 8.070880
258 (array([22]),) False
  24560/500000: episode: 614, duration: 29.993s, episode steps: 40, steps per second: 1, episode reward: 31.459, mean reward: 0.786 [0.010, 0.994], mean action: 14.850 [3.000, 52.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.547278, mean_absolute_error: 7.044887, mean_q: 8.010425
61 (array([48]),) False
  24600/500000: episode: 615, duration: 30.748s, episode steps: 40, steps per second: 1, episode reward: 33.625, mean reward: 0.841 [0.079, 1.000], mean action: 24.875 [0.000, 60.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.540480, mean_absolute_error: 7.053920, mean_q: 8.046575
719 (array([22]),) False
  24640/500000: episode: 616, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 27.204, mean reward: 0.680 [0.037, 1.000], mean action: 24.450 [1.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.534530, mean_absolute_error: 7.052365, mean_q: 8.041527
376 (array([22]),) False
  24680/500000: episode: 617, duration: 30.649s, episode steps: 40, steps per second: 1, episode reward: 27.287, mean reward: 0.682 [0.075, 0.928], mean action: 23.425 [0.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.593678, mean_absolute_error: 7.052237, mean_q: 8.031043
625 (array([22]),) False
  24720/500000: episode: 618, duration: 29.937s, episode steps: 40, steps per second: 1, episode reward: 26.408, mean reward: 0.660 [0.000, 1.000], mean action: 20.650 [2.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.557432, mean_absolute_error: 7.034425, mean_q: 8.030654
195 (array([22]),) False
  24760/500000: episode: 619, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 29.667, mean reward: 0.742 [0.092, 0.985], mean action: 19.325 [2.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.597058, mean_absolute_error: 7.029925, mean_q: 8.031377
447 (array([44]),) False
  24800/500000: episode: 620, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 21.311, mean reward: 0.533 [0.067, 0.989], mean action: 23.075 [1.000, 54.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.514234, mean_absolute_error: 7.044972, mean_q: 8.041125
661 (array([48]),) False
  24840/500000: episode: 621, duration: 30.775s, episode steps: 40, steps per second: 1, episode reward: 30.067, mean reward: 0.752 [0.184, 0.940], mean action: 21.675 [10.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.495614, mean_absolute_error: 7.023121, mean_q: 8.056078
670 (array([22]),) False
  24880/500000: episode: 622, duration: 29.977s, episode steps: 40, steps per second: 1, episode reward: 29.780, mean reward: 0.744 [0.128, 1.000], mean action: 20.700 [12.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.594170, mean_absolute_error: 6.996432, mean_q: 8.006668
636 (array([12]),) False
  24920/500000: episode: 623, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 30.663, mean reward: 0.767 [0.000, 1.000], mean action: 20.075 [7.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.507404, mean_absolute_error: 6.990597, mean_q: 8.024126
576 (array([58]),) False
  24960/500000: episode: 624, duration: 30.693s, episode steps: 40, steps per second: 1, episode reward: 26.751, mean reward: 0.669 [0.163, 1.000], mean action: 39.225 [10.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.616759, mean_absolute_error: 6.930541, mean_q: 7.974058
392 (array([40]),) False
  25000/500000: episode: 625, duration: 30.764s, episode steps: 40, steps per second: 1, episode reward: 33.228, mean reward: 0.831 [0.211, 1.000], mean action: 23.000 [4.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.467924, mean_absolute_error: 6.935083, mean_q: 7.916240
211 (array([22]),) False
  25040/500000: episode: 626, duration: 29.989s, episode steps: 40, steps per second: 1, episode reward: 25.528, mean reward: 0.638 [0.035, 1.000], mean action: 18.025 [3.000, 53.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.527604, mean_absolute_error: 6.947495, mean_q: 7.981101
181 (array([22]),) False
  25080/500000: episode: 627, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 21.974, mean reward: 0.549 [0.054, 1.000], mean action: 22.225 [9.000, 58.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.511371, mean_absolute_error: 6.946924, mean_q: 7.932523
505 (array([22]),) False
  25120/500000: episode: 628, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 26.300, mean reward: 0.658 [0.000, 0.875], mean action: 20.100 [4.000, 58.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.478788, mean_absolute_error: 6.976347, mean_q: 7.987547
801 (array([58]),) False
  25160/500000: episode: 629, duration: 30.840s, episode steps: 40, steps per second: 1, episode reward: 15.203, mean reward: 0.380 [0.000, 0.746], mean action: 20.625 [3.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.511338, mean_absolute_error: 6.973802, mean_q: 7.953795
615 (array([36]),) False
  25200/500000: episode: 630, duration: 29.984s, episode steps: 40, steps per second: 1, episode reward: 21.062, mean reward: 0.527 [0.111, 0.931], mean action: 35.275 [0.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.453426, mean_absolute_error: 7.028650, mean_q: 8.015709
849 (array([3]),) False
  25240/500000: episode: 631, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 9.704, mean reward: 0.243 [0.000, 0.876], mean action: 23.575 [4.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.506216, mean_absolute_error: 6.990864, mean_q: 7.966341
831 (array([3]),) False
  25280/500000: episode: 632, duration: 30.670s, episode steps: 40, steps per second: 1, episode reward: 17.208, mean reward: 0.430 [0.000, 0.868], mean action: 33.325 [2.000, 60.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.569926, mean_absolute_error: 6.956683, mean_q: 7.946617
539 (array([22]),) False
  25320/500000: episode: 633, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 31.702, mean reward: 0.793 [0.022, 0.955], mean action: 18.050 [6.000, 55.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.538651, mean_absolute_error: 6.988122, mean_q: 7.954120
493 (array([22]),) False
  25360/500000: episode: 634, duration: 29.974s, episode steps: 40, steps per second: 1, episode reward: 25.872, mean reward: 0.647 [0.114, 0.911], mean action: 21.150 [8.000, 58.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.484952, mean_absolute_error: 6.985924, mean_q: 7.966925
260 (array([22]),) False
  25400/500000: episode: 635, duration: 30.718s, episode steps: 40, steps per second: 1, episode reward: 25.515, mean reward: 0.638 [0.090, 0.819], mean action: 21.750 [9.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.506079, mean_absolute_error: 7.001634, mean_q: 7.982127
152 (array([58]),) False
  25440/500000: episode: 636, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 15.700, mean reward: 0.393 [0.151, 0.786], mean action: 31.275 [3.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.491720, mean_absolute_error: 7.028450, mean_q: 8.012206
343 (array([22]),) False
  25480/500000: episode: 637, duration: 30.802s, episode steps: 40, steps per second: 1, episode reward: 27.528, mean reward: 0.688 [0.025, 1.000], mean action: 22.075 [0.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.550488, mean_absolute_error: 7.005275, mean_q: 8.002507
786 (array([22]),) False
  25520/500000: episode: 638, duration: 29.942s, episode steps: 40, steps per second: 1, episode reward: 24.860, mean reward: 0.621 [0.109, 0.784], mean action: 15.925 [2.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.589718, mean_absolute_error: 6.984703, mean_q: 8.001343
186 (array([22]),) False
  25560/500000: episode: 639, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 27.552, mean reward: 0.689 [0.000, 0.905], mean action: 17.550 [9.000, 60.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.596875, mean_absolute_error: 6.940089, mean_q: 7.949866
262 (array([22]),) False
  25600/500000: episode: 640, duration: 30.640s, episode steps: 40, steps per second: 1, episode reward: 23.817, mean reward: 0.595 [0.000, 1.000], mean action: 18.875 [1.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.543428, mean_absolute_error: 6.895285, mean_q: 7.934002
226 (array([22]),) False
  25640/500000: episode: 641, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 30.655, mean reward: 0.766 [0.015, 0.908], mean action: 19.975 [9.000, 59.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.535879, mean_absolute_error: 6.867723, mean_q: 7.864012
419 (array([40]),) False
  25680/500000: episode: 642, duration: 29.941s, episode steps: 40, steps per second: 1, episode reward: 25.038, mean reward: 0.626 [0.121, 0.908], mean action: 23.950 [0.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.534239, mean_absolute_error: 6.837752, mean_q: 7.838252
691 (array([22]),) False
  25720/500000: episode: 643, duration: 30.756s, episode steps: 40, steps per second: 1, episode reward: 23.306, mean reward: 0.583 [0.128, 0.740], mean action: 23.250 [7.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.553204, mean_absolute_error: 6.829715, mean_q: 7.810206
158 (array([22]),) False
  25760/500000: episode: 644, duration: 30.785s, episode steps: 40, steps per second: 1, episode reward: 29.314, mean reward: 0.733 [0.079, 0.923], mean action: 16.725 [2.000, 55.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.551728, mean_absolute_error: 6.824426, mean_q: 7.819162
67 (array([8]),) False
  25800/500000: episode: 645, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 19.754, mean reward: 0.494 [0.242, 0.978], mean action: 29.250 [5.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.503602, mean_absolute_error: 6.816610, mean_q: 7.782808
858 (array([12]),) False
  25840/500000: episode: 646, duration: 29.972s, episode steps: 40, steps per second: 1, episode reward: 33.534, mean reward: 0.838 [0.051, 1.000], mean action: 17.750 [9.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.536130, mean_absolute_error: 6.787953, mean_q: 7.781301
810 (array([12]),) False
  25880/500000: episode: 647, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 27.804, mean reward: 0.695 [0.101, 1.000], mean action: 24.775 [4.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.499269, mean_absolute_error: 6.780121, mean_q: 7.761395
829 (array([21]),) False
  25920/500000: episode: 648, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 31.681, mean reward: 0.792 [0.148, 0.988], mean action: 17.800 [7.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.539732, mean_absolute_error: 6.750052, mean_q: 7.734213
849 (array([3]),) False
  25960/500000: episode: 649, duration: 30.810s, episode steps: 40, steps per second: 1, episode reward: 11.654, mean reward: 0.291 [0.000, 0.734], mean action: 32.925 [0.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.497449, mean_absolute_error: 6.748190, mean_q: 7.722573
727 (array([12]),) False
  26000/500000: episode: 650, duration: 30.039s, episode steps: 40, steps per second: 1, episode reward: 28.545, mean reward: 0.714 [0.000, 1.000], mean action: 19.625 [0.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.492390, mean_absolute_error: 6.755803, mean_q: 7.683144
236 (array([22]),) False
  26040/500000: episode: 651, duration: 30.721s, episode steps: 40, steps per second: 1, episode reward: 25.287, mean reward: 0.632 [0.140, 1.000], mean action: 26.575 [12.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.472868, mean_absolute_error: 6.784539, mean_q: 7.752194
110 (array([22]),) False
  26080/500000: episode: 652, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 23.951, mean reward: 0.599 [0.016, 0.945], mean action: 19.725 [6.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.459811, mean_absolute_error: 6.799991, mean_q: 7.755512
424 (array([22]),) False
  26120/500000: episode: 653, duration: 30.814s, episode steps: 40, steps per second: 1, episode reward: 22.166, mean reward: 0.554 [0.026, 1.000], mean action: 30.150 [1.000, 58.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.513459, mean_absolute_error: 6.785931, mean_q: 7.739680
81 (array([22]),) False
  26160/500000: episode: 654, duration: 29.930s, episode steps: 40, steps per second: 1, episode reward: 25.723, mean reward: 0.643 [0.000, 1.000], mean action: 23.600 [5.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.481015, mean_absolute_error: 6.795249, mean_q: 7.755704
209 (array([8]),) False
  26200/500000: episode: 655, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 17.000, mean reward: 0.425 [0.080, 0.653], mean action: 23.825 [0.000, 58.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.488288, mean_absolute_error: 6.801315, mean_q: 7.741587
261 (array([44]),) False
  26240/500000: episode: 656, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 29.263, mean reward: 0.732 [0.338, 1.000], mean action: 32.625 [7.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.486288, mean_absolute_error: 6.805669, mean_q: 7.763177
548 (array([22]),) False
  26280/500000: episode: 657, duration: 30.701s, episode steps: 40, steps per second: 1, episode reward: 23.263, mean reward: 0.582 [0.044, 0.788], mean action: 24.025 [1.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.436588, mean_absolute_error: 6.803673, mean_q: 7.785193
558 (array([40]),) False
  26320/500000: episode: 658, duration: 29.950s, episode steps: 40, steps per second: 1, episode reward: 26.405, mean reward: 0.660 [0.203, 1.000], mean action: 21.425 [5.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.502566, mean_absolute_error: 6.781563, mean_q: 7.743492
366 (array([22]),) False
  26360/500000: episode: 659, duration: 30.821s, episode steps: 40, steps per second: 1, episode reward: 28.447, mean reward: 0.711 [0.118, 1.000], mean action: 20.700 [0.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.517135, mean_absolute_error: 6.791530, mean_q: 7.771334
594 (array([48]),) False
  26400/500000: episode: 660, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 25.658, mean reward: 0.641 [0.075, 1.000], mean action: 17.175 [0.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.476163, mean_absolute_error: 6.740280, mean_q: 7.755773
67 (array([8]),) False
  26440/500000: episode: 661, duration: 30.847s, episode steps: 40, steps per second: 1, episode reward: 19.058, mean reward: 0.476 [0.337, 1.000], mean action: 38.875 [1.000, 53.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.504956, mean_absolute_error: 6.735695, mean_q: 7.722716
439 (array([12]),) False
  26480/500000: episode: 662, duration: 29.949s, episode steps: 40, steps per second: 1, episode reward: 28.918, mean reward: 0.723 [0.000, 1.000], mean action: 29.600 [0.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.518210, mean_absolute_error: 6.713908, mean_q: 7.674937
481 (array([22]),) False
  26520/500000: episode: 663, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 29.562, mean reward: 0.739 [0.015, 0.969], mean action: 21.125 [4.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.507744, mean_absolute_error: 6.680151, mean_q: 7.644324
621 (array([22]),) False
  26560/500000: episode: 664, duration: 30.706s, episode steps: 40, steps per second: 1, episode reward: 28.371, mean reward: 0.709 [0.008, 0.852], mean action: 16.000 [5.000, 53.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.458315, mean_absolute_error: 6.678191, mean_q: 7.650922
302 (array([22]),) False
  26600/500000: episode: 665, duration: 30.825s, episode steps: 40, steps per second: 1, episode reward: 31.318, mean reward: 0.783 [0.054, 0.976], mean action: 18.875 [4.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.490357, mean_absolute_error: 6.660156, mean_q: 7.624632
461 (array([22]),) False
  26640/500000: episode: 666, duration: 29.935s, episode steps: 40, steps per second: 1, episode reward: 31.708, mean reward: 0.793 [0.140, 1.000], mean action: 15.425 [2.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.448663, mean_absolute_error: 6.721169, mean_q: 7.670267
501 (array([12]),) False
  26680/500000: episode: 667, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 32.366, mean reward: 0.809 [0.297, 1.000], mean action: 17.775 [1.000, 54.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.398098, mean_absolute_error: 6.771487, mean_q: 7.715983
731 (array([21]),) False
  26720/500000: episode: 668, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 27.547, mean reward: 0.689 [0.097, 1.000], mean action: 21.050 [12.000, 52.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.503162, mean_absolute_error: 6.788568, mean_q: 7.726781
341 (array([22]),) False
  26760/500000: episode: 669, duration: 30.873s, episode steps: 40, steps per second: 1, episode reward: 26.993, mean reward: 0.675 [0.004, 0.953], mean action: 19.425 [3.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.501248, mean_absolute_error: 6.785643, mean_q: 7.758283
734 (array([48]),) False
  26800/500000: episode: 670, duration: 29.992s, episode steps: 40, steps per second: 1, episode reward: 30.842, mean reward: 0.771 [0.093, 1.000], mean action: 19.375 [3.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.513088, mean_absolute_error: 6.791781, mean_q: 7.745300
225 (array([48]),) False
  26840/500000: episode: 671, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 35.022, mean reward: 0.876 [0.065, 1.000], mean action: 24.225 [1.000, 48.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.464681, mean_absolute_error: 6.818970, mean_q: 7.763064
472 (array([22]),) False
  26880/500000: episode: 672, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 20.666, mean reward: 0.517 [0.062, 0.934], mean action: 32.150 [0.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.525066, mean_absolute_error: 6.825937, mean_q: 7.777637
527 (array([58]),) False
  26920/500000: episode: 673, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 17.368, mean reward: 0.434 [0.081, 0.783], mean action: 27.850 [8.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.524938, mean_absolute_error: 6.821777, mean_q: 7.776567
363 (array([36]),) False
  26960/500000: episode: 674, duration: 30.003s, episode steps: 40, steps per second: 1, episode reward: 20.994, mean reward: 0.525 [0.000, 0.871], mean action: 19.025 [3.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.549266, mean_absolute_error: 6.779111, mean_q: 7.742043
710 (array([12]),) False
  27000/500000: episode: 675, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 28.891, mean reward: 0.722 [0.027, 1.000], mean action: 18.025 [0.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.451528, mean_absolute_error: 6.781792, mean_q: 7.730467
529 (array([3]),) False
  27040/500000: episode: 676, duration: 30.653s, episode steps: 40, steps per second: 1, episode reward: 18.508, mean reward: 0.463 [0.133, 1.000], mean action: 21.625 [2.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.491963, mean_absolute_error: 6.769162, mean_q: 7.744318
575 (array([44]),) False
  27080/500000: episode: 677, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 31.603, mean reward: 0.790 [0.299, 0.985], mean action: 20.050 [0.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.421243, mean_absolute_error: 6.790018, mean_q: 7.754852
609 (array([22]),) False
  27120/500000: episode: 678, duration: 29.971s, episode steps: 40, steps per second: 1, episode reward: 26.923, mean reward: 0.673 [0.237, 0.863], mean action: 21.325 [5.000, 54.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.502220, mean_absolute_error: 6.743036, mean_q: 7.732982
673 (array([3]),) False
  27160/500000: episode: 679, duration: 30.670s, episode steps: 40, steps per second: 1, episode reward: 16.654, mean reward: 0.416 [0.033, 1.000], mean action: 20.825 [3.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.503067, mean_absolute_error: 6.707796, mean_q: 7.701369
261 (array([44]),) False
  27200/500000: episode: 680, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 26.465, mean reward: 0.662 [0.000, 0.881], mean action: 15.650 [4.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.487688, mean_absolute_error: 6.689347, mean_q: 7.668923
605 (array([22]),) False
  27240/500000: episode: 681, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 26.476, mean reward: 0.662 [0.193, 0.867], mean action: 20.325 [0.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.442582, mean_absolute_error: 6.698657, mean_q: 7.649786
544 (array([22]),) False
  27280/500000: episode: 682, duration: 29.942s, episode steps: 40, steps per second: 1, episode reward: 28.535, mean reward: 0.713 [0.000, 0.907], mean action: 19.650 [3.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.428888, mean_absolute_error: 6.752198, mean_q: 7.698915
227 (array([22]),) False
  27320/500000: episode: 683, duration: 30.694s, episode steps: 40, steps per second: 1, episode reward: 19.286, mean reward: 0.482 [0.056, 1.000], mean action: 19.375 [3.000, 52.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.500771, mean_absolute_error: 6.716287, mean_q: 7.684187
395 (array([22]),) False
  27360/500000: episode: 684, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 29.183, mean reward: 0.730 [0.124, 1.000], mean action: 20.750 [7.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.547784, mean_absolute_error: 6.705896, mean_q: 7.670423
787 (array([3]),) False
  27400/500000: episode: 685, duration: 29.935s, episode steps: 40, steps per second: 1, episode reward: 20.275, mean reward: 0.507 [0.000, 0.934], mean action: 21.275 [9.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.453382, mean_absolute_error: 6.727222, mean_q: 7.704434
484 (array([22]),) False
  27440/500000: episode: 686, duration: 30.711s, episode steps: 40, steps per second: 1, episode reward: 26.475, mean reward: 0.662 [0.120, 1.000], mean action: 19.550 [1.000, 59.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.455712, mean_absolute_error: 6.740504, mean_q: 7.718872
482 (array([22]),) False
  27480/500000: episode: 687, duration: 30.684s, episode steps: 40, steps per second: 1, episode reward: 29.695, mean reward: 0.742 [0.041, 1.000], mean action: 20.275 [0.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.503761, mean_absolute_error: 6.722866, mean_q: 7.706014
349 (array([48]),) False
  27520/500000: episode: 688, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 24.842, mean reward: 0.621 [0.000, 1.000], mean action: 21.375 [1.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.452434, mean_absolute_error: 6.706346, mean_q: 7.698184
309 (array([22]),) False
  27560/500000: episode: 689, duration: 30.022s, episode steps: 40, steps per second: 1, episode reward: 26.966, mean reward: 0.674 [0.000, 0.921], mean action: 21.375 [0.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.461363, mean_absolute_error: 6.704202, mean_q: 7.677905
12 (array([22]),) False
  27600/500000: episode: 690, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 26.956, mean reward: 0.674 [0.000, 1.000], mean action: 27.450 [4.000, 60.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.480066, mean_absolute_error: 6.672743, mean_q: 7.649170
298 (array([22]),) False
  27640/500000: episode: 691, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 21.523, mean reward: 0.538 [0.046, 0.852], mean action: 27.450 [5.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.476672, mean_absolute_error: 6.664769, mean_q: 7.621128
350 (array([12]),) False
  27680/500000: episode: 692, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 30.513, mean reward: 0.763 [0.181, 1.000], mean action: 21.600 [2.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.463311, mean_absolute_error: 6.685548, mean_q: 7.632086
758 (array([38]),) False
  27720/500000: episode: 693, duration: 29.991s, episode steps: 40, steps per second: 1, episode reward: 33.367, mean reward: 0.834 [0.182, 0.990], mean action: 20.125 [1.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.480514, mean_absolute_error: 6.687814, mean_q: 7.644670
201 (array([22]),) False
  27760/500000: episode: 694, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 26.966, mean reward: 0.674 [0.087, 0.838], mean action: 18.275 [4.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.462299, mean_absolute_error: 6.650100, mean_q: 7.609173
38 (array([22]),) False
  27800/500000: episode: 695, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 28.990, mean reward: 0.725 [0.051, 1.000], mean action: 34.625 [3.000, 49.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.488903, mean_absolute_error: 6.663178, mean_q: 7.604877
756 (array([48]),) False
  27840/500000: episode: 696, duration: 30.802s, episode steps: 40, steps per second: 1, episode reward: 31.385, mean reward: 0.785 [0.000, 0.957], mean action: 17.850 [0.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.446182, mean_absolute_error: 6.650076, mean_q: 7.601065
582 (array([44]),) False
  27880/500000: episode: 697, duration: 30.013s, episode steps: 40, steps per second: 1, episode reward: 31.062, mean reward: 0.777 [0.084, 0.978], mean action: 20.325 [0.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.435207, mean_absolute_error: 6.665051, mean_q: 7.602519
197 (array([22]),) False
  27920/500000: episode: 698, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 29.764, mean reward: 0.744 [0.000, 0.938], mean action: 18.150 [4.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.474665, mean_absolute_error: 6.709538, mean_q: 7.658310
204 (array([22]),) False
  27960/500000: episode: 699, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 24.809, mean reward: 0.620 [0.126, 1.000], mean action: 15.800 [1.000, 58.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.446995, mean_absolute_error: 6.713675, mean_q: 7.667336
215 (array([22]),) False
  28000/500000: episode: 700, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 25.694, mean reward: 0.642 [0.153, 0.785], mean action: 18.425 [10.000, 55.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.446818, mean_absolute_error: 6.709290, mean_q: 7.671007
25 (array([48]),) False
  28040/500000: episode: 701, duration: 29.914s, episode steps: 40, steps per second: 1, episode reward: 33.476, mean reward: 0.837 [0.053, 1.000], mean action: 25.100 [2.000, 58.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.490535, mean_absolute_error: 6.680305, mean_q: 7.665842
613 (array([22]),) False
  28080/500000: episode: 702, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 31.591, mean reward: 0.790 [0.104, 0.944], mean action: 18.425 [9.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.486668, mean_absolute_error: 6.686076, mean_q: 7.651439
95 (array([22]),) False
  28120/500000: episode: 703, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 25.388, mean reward: 0.635 [0.000, 0.809], mean action: 14.225 [1.000, 51.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.477335, mean_absolute_error: 6.660437, mean_q: 7.624765
329 (array([12]),) False
  28160/500000: episode: 704, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 33.217, mean reward: 0.830 [0.139, 1.000], mean action: 20.200 [4.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.467745, mean_absolute_error: 6.658576, mean_q: 7.626340
158 (array([22]),) False
  28200/500000: episode: 705, duration: 29.987s, episode steps: 40, steps per second: 1, episode reward: 30.437, mean reward: 0.761 [0.045, 0.921], mean action: 16.900 [1.000, 56.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.444418, mean_absolute_error: 6.676701, mean_q: 7.622920
285 (array([58]),) False
  28240/500000: episode: 706, duration: 30.706s, episode steps: 40, steps per second: 1, episode reward: 17.777, mean reward: 0.444 [0.065, 0.882], mean action: 26.100 [2.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.456521, mean_absolute_error: 6.695209, mean_q: 7.616746
824 (array([22]),) False
  28280/500000: episode: 707, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 27.585, mean reward: 0.690 [0.131, 1.000], mean action: 18.625 [0.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.512239, mean_absolute_error: 6.644231, mean_q: 7.600934
544 (array([22]),) False
  28320/500000: episode: 708, duration: 30.757s, episode steps: 40, steps per second: 1, episode reward: 30.669, mean reward: 0.767 [0.049, 0.907], mean action: 16.375 [1.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.460053, mean_absolute_error: 6.668344, mean_q: 7.602261
757 (array([48]),) False
  28360/500000: episode: 709, duration: 30.053s, episode steps: 40, steps per second: 1, episode reward: 32.930, mean reward: 0.823 [0.165, 1.000], mean action: 36.425 [1.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.388276, mean_absolute_error: 6.683188, mean_q: 7.605460
466 (array([22]),) False
  28400/500000: episode: 710, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 24.913, mean reward: 0.623 [0.121, 0.910], mean action: 14.575 [0.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.413660, mean_absolute_error: 6.689310, mean_q: 7.599608
104 (array([22]),) False
  28440/500000: episode: 711, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 30.829, mean reward: 0.771 [0.035, 1.000], mean action: 21.375 [4.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.439944, mean_absolute_error: 6.679394, mean_q: 7.599499
671 (array([57]),) False
  28480/500000: episode: 712, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 16.766, mean reward: 0.419 [0.000, 0.997], mean action: 23.725 [0.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.441361, mean_absolute_error: 6.700816, mean_q: 7.629873
663 (array([22]),) False
  28520/500000: episode: 713, duration: 30.003s, episode steps: 40, steps per second: 1, episode reward: 19.957, mean reward: 0.499 [0.149, 1.000], mean action: 19.275 [1.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.483730, mean_absolute_error: 6.677144, mean_q: 7.589368
837 (array([48]),) False
  28560/500000: episode: 714, duration: 30.837s, episode steps: 40, steps per second: 1, episode reward: 29.363, mean reward: 0.734 [0.000, 0.974], mean action: 26.025 [0.000, 59.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.485380, mean_absolute_error: 6.689348, mean_q: 7.638615
102 (array([22]),) False
  28600/500000: episode: 715, duration: 30.741s, episode steps: 40, steps per second: 1, episode reward: 29.523, mean reward: 0.738 [0.016, 1.000], mean action: 19.525 [6.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.512451, mean_absolute_error: 6.661353, mean_q: 7.606061
9 (array([14]),) False
  28640/500000: episode: 716, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 30.917, mean reward: 0.773 [0.061, 0.988], mean action: 22.975 [3.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.421152, mean_absolute_error: 6.661200, mean_q: 7.604456
20 (array([22]),) False
  28680/500000: episode: 717, duration: 30.019s, episode steps: 40, steps per second: 1, episode reward: 27.970, mean reward: 0.699 [0.024, 1.000], mean action: 24.675 [2.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.487254, mean_absolute_error: 6.676023, mean_q: 7.608392
96 (array([22]),) False
  28720/500000: episode: 718, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 32.120, mean reward: 0.803 [0.053, 1.000], mean action: 20.375 [0.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.445342, mean_absolute_error: 6.675370, mean_q: 7.594993
461 (array([22]),) False
  28760/500000: episode: 719, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 34.757, mean reward: 0.869 [0.095, 1.000], mean action: 20.325 [6.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.439660, mean_absolute_error: 6.678802, mean_q: 7.616269
547 (array([21]),) False
  28800/500000: episode: 720, duration: 30.801s, episode steps: 40, steps per second: 1, episode reward: 30.374, mean reward: 0.759 [0.047, 1.000], mean action: 23.475 [3.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.478918, mean_absolute_error: 6.703099, mean_q: 7.644458
49 (array([22]),) False
  28840/500000: episode: 721, duration: 30.000s, episode steps: 40, steps per second: 1, episode reward: 32.656, mean reward: 0.816 [0.049, 1.000], mean action: 25.375 [1.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.480417, mean_absolute_error: 6.630640, mean_q: 7.552080
746 (array([37]),) False
  28880/500000: episode: 722, duration: 30.712s, episode steps: 40, steps per second: 1, episode reward: 26.705, mean reward: 0.668 [0.027, 0.910], mean action: 20.300 [0.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.441619, mean_absolute_error: 6.672343, mean_q: 7.608798
73 (array([22]),) False
  28920/500000: episode: 723, duration: 30.748s, episode steps: 40, steps per second: 1, episode reward: 32.433, mean reward: 0.811 [0.212, 0.981], mean action: 18.725 [3.000, 56.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.547332, mean_absolute_error: 6.689280, mean_q: 7.621966
704 (array([22]),) False
  28960/500000: episode: 724, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 22.192, mean reward: 0.555 [0.000, 0.735], mean action: 18.450 [0.000, 52.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.503167, mean_absolute_error: 6.692511, mean_q: 7.649261
588 (array([22]),) False
  29000/500000: episode: 725, duration: 29.924s, episode steps: 40, steps per second: 1, episode reward: 27.096, mean reward: 0.677 [0.045, 1.000], mean action: 18.475 [2.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.449532, mean_absolute_error: 6.679755, mean_q: 7.629579
339 (array([22]),) False
  29040/500000: episode: 726, duration: 30.781s, episode steps: 40, steps per second: 1, episode reward: 31.361, mean reward: 0.784 [0.109, 0.939], mean action: 16.300 [1.000, 50.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.495196, mean_absolute_error: 6.648610, mean_q: 7.635994
563 (array([22]),) False
  29080/500000: episode: 727, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 27.994, mean reward: 0.700 [0.000, 0.976], mean action: 18.200 [0.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.414394, mean_absolute_error: 6.663164, mean_q: 7.630400
643 (array([44]),) False
  29120/500000: episode: 728, duration: 30.783s, episode steps: 40, steps per second: 1, episode reward: 27.702, mean reward: 0.693 [0.047, 1.000], mean action: 29.725 [0.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.461712, mean_absolute_error: 6.655601, mean_q: 7.624827
511 (array([22]),) False
  29160/500000: episode: 729, duration: 29.952s, episode steps: 40, steps per second: 1, episode reward: 33.056, mean reward: 0.826 [0.000, 0.951], mean action: 18.450 [11.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.506857, mean_absolute_error: 6.623604, mean_q: 7.594896
593 (array([37]),) False
  29200/500000: episode: 730, duration: 30.813s, episode steps: 40, steps per second: 1, episode reward: 31.859, mean reward: 0.796 [0.086, 1.000], mean action: 18.500 [11.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.412715, mean_absolute_error: 6.624451, mean_q: 7.579680
593 (array([37]),) False
  29240/500000: episode: 731, duration: 30.799s, episode steps: 40, steps per second: 1, episode reward: 30.388, mean reward: 0.760 [0.000, 1.000], mean action: 16.975 [1.000, 57.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.437162, mean_absolute_error: 6.633157, mean_q: 7.577985
698 (array([22]),) False
  29280/500000: episode: 732, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 29.831, mean reward: 0.746 [0.160, 0.963], mean action: 21.700 [12.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.471796, mean_absolute_error: 6.578015, mean_q: 7.518041
723 (array([48]),) False
  29320/500000: episode: 733, duration: 29.917s, episode steps: 40, steps per second: 1, episode reward: 28.840, mean reward: 0.721 [0.072, 1.000], mean action: 22.025 [5.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.422821, mean_absolute_error: 6.587613, mean_q: 7.548578
744 (array([22]),) False
  29360/500000: episode: 734, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 25.137, mean reward: 0.628 [0.216, 0.877], mean action: 20.750 [4.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.455430, mean_absolute_error: 6.612466, mean_q: 7.569745
691 (array([22]),) False
  29400/500000: episode: 735, duration: 30.700s, episode steps: 40, steps per second: 1, episode reward: 23.752, mean reward: 0.594 [0.000, 0.739], mean action: 18.425 [4.000, 54.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.378717, mean_absolute_error: 6.612947, mean_q: 7.557477
409 (array([22]),) False
  29440/500000: episode: 736, duration: 30.792s, episode steps: 40, steps per second: 1, episode reward: 29.464, mean reward: 0.737 [0.043, 1.000], mean action: 28.175 [2.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.432888, mean_absolute_error: 6.599557, mean_q: 7.525893
747 (array([22]),) False
  29480/500000: episode: 737, duration: 29.934s, episode steps: 40, steps per second: 1, episode reward: 30.593, mean reward: 0.765 [0.085, 1.000], mean action: 18.175 [8.000, 53.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.482352, mean_absolute_error: 6.583232, mean_q: 7.506697
522 (array([22]),) False
  29520/500000: episode: 738, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 28.098, mean reward: 0.702 [0.033, 0.958], mean action: 17.750 [3.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.395925, mean_absolute_error: 6.619161, mean_q: 7.566314
793 (array([12]),) False
  29560/500000: episode: 739, duration: 30.680s, episode steps: 40, steps per second: 1, episode reward: 32.950, mean reward: 0.824 [0.077, 1.000], mean action: 18.100 [5.000, 58.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.422996, mean_absolute_error: 6.607815, mean_q: 7.538310
323 (array([55]),) False
  29600/500000: episode: 740, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 31.297, mean reward: 0.782 [0.359, 1.000], mean action: 36.325 [2.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.475059, mean_absolute_error: 6.559143, mean_q: 7.501830
283 (array([34]),) False
  29640/500000: episode: 741, duration: 29.899s, episode steps: 40, steps per second: 1, episode reward: 16.414, mean reward: 0.410 [0.077, 1.000], mean action: 19.100 [1.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.474310, mean_absolute_error: 6.538973, mean_q: 7.463675
261 (array([44]),) False
  29680/500000: episode: 742, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 27.747, mean reward: 0.694 [0.218, 1.000], mean action: 22.475 [0.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.410596, mean_absolute_error: 6.565607, mean_q: 7.501885
578 (array([22]),) False
  29720/500000: episode: 743, duration: 30.756s, episode steps: 40, steps per second: 1, episode reward: 30.034, mean reward: 0.751 [0.032, 1.000], mean action: 20.075 [8.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.454400, mean_absolute_error: 6.549772, mean_q: 7.476669
56 (array([12]),) False
  29760/500000: episode: 744, duration: 30.775s, episode steps: 40, steps per second: 1, episode reward: 31.451, mean reward: 0.786 [0.073, 1.000], mean action: 29.600 [4.000, 58.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.475758, mean_absolute_error: 6.499074, mean_q: 7.450345
96 (array([22]),) False
  29800/500000: episode: 745, duration: 29.917s, episode steps: 40, steps per second: 1, episode reward: 32.217, mean reward: 0.805 [0.000, 1.000], mean action: 24.525 [9.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.411384, mean_absolute_error: 6.537992, mean_q: 7.481148
773 (array([22]),) False
  29840/500000: episode: 746, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 24.968, mean reward: 0.624 [0.108, 0.775], mean action: 22.825 [9.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.403556, mean_absolute_error: 6.565460, mean_q: 7.505243
452 (array([22]),) False
  29880/500000: episode: 747, duration: 30.714s, episode steps: 40, steps per second: 1, episode reward: 27.045, mean reward: 0.676 [0.000, 0.939], mean action: 23.600 [2.000, 60.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.425279, mean_absolute_error: 6.526643, mean_q: 7.436541
799 (array([36]),) False
  29920/500000: episode: 748, duration: 30.726s, episode steps: 40, steps per second: 1, episode reward: 21.119, mean reward: 0.528 [0.000, 0.991], mean action: 29.300 [3.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.386475, mean_absolute_error: 6.578804, mean_q: 7.495438
643 (array([44]),) False
  29960/500000: episode: 749, duration: 29.996s, episode steps: 40, steps per second: 1, episode reward: 28.376, mean reward: 0.709 [0.183, 1.000], mean action: 19.325 [0.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.459221, mean_absolute_error: 6.604004, mean_q: 7.505623
646 (array([44]),) False
  30000/500000: episode: 750, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 15.460, mean reward: 0.387 [0.000, 0.986], mean action: 41.025 [1.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.495428, mean_absolute_error: 6.583712, mean_q: 7.523390
71 (array([58]),) False
  30040/500000: episode: 751, duration: 30.666s, episode steps: 40, steps per second: 1, episode reward: 22.982, mean reward: 0.575 [0.000, 0.920], mean action: 33.425 [12.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.419415, mean_absolute_error: 6.634659, mean_q: 7.557439
31 (array([48]),) False
  30080/500000: episode: 752, duration: 30.794s, episode steps: 40, steps per second: 1, episode reward: 29.348, mean reward: 0.734 [0.065, 0.897], mean action: 23.675 [1.000, 56.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.485828, mean_absolute_error: 6.613246, mean_q: 7.544698
438 (array([22]),) False
  30120/500000: episode: 753, duration: 29.973s, episode steps: 40, steps per second: 1, episode reward: 29.157, mean reward: 0.729 [0.000, 1.000], mean action: 21.425 [3.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.493037, mean_absolute_error: 6.617142, mean_q: 7.561473
485 (array([22]),) False
  30160/500000: episode: 754, duration: 30.672s, episode steps: 40, steps per second: 1, episode reward: 28.076, mean reward: 0.702 [0.024, 1.000], mean action: 17.825 [1.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.486498, mean_absolute_error: 6.580564, mean_q: 7.510649
107 (array([22]),) False
  30200/500000: episode: 755, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 26.148, mean reward: 0.654 [0.012, 1.000], mean action: 19.325 [1.000, 57.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.422085, mean_absolute_error: 6.577374, mean_q: 7.508413
241 (array([22]),) False
  30240/500000: episode: 756, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 24.022, mean reward: 0.601 [0.030, 0.796], mean action: 18.250 [0.000, 60.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.402462, mean_absolute_error: 6.564401, mean_q: 7.473698
122 (array([12]),) False
  30280/500000: episode: 757, duration: 30.045s, episode steps: 40, steps per second: 1, episode reward: 30.153, mean reward: 0.754 [0.093, 1.000], mean action: 21.475 [5.000, 56.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.415365, mean_absolute_error: 6.600317, mean_q: 7.505681
130 (array([22]),) False
  30320/500000: episode: 758, duration: 30.675s, episode steps: 40, steps per second: 1, episode reward: 32.338, mean reward: 0.808 [0.040, 1.000], mean action: 20.025 [4.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.445964, mean_absolute_error: 6.560487, mean_q: 7.472511
40 (array([22]),) False
  30360/500000: episode: 759, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 29.425, mean reward: 0.736 [0.098, 1.000], mean action: 23.700 [1.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.406312, mean_absolute_error: 6.610181, mean_q: 7.537256
268 (array([22]),) False
  30400/500000: episode: 760, duration: 30.742s, episode steps: 40, steps per second: 1, episode reward: 31.179, mean reward: 0.779 [0.000, 1.000], mean action: 15.775 [1.000, 52.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.437260, mean_absolute_error: 6.582372, mean_q: 7.498182
181 (array([22]),) False
  30440/500000: episode: 761, duration: 29.977s, episode steps: 40, steps per second: 1, episode reward: 20.097, mean reward: 0.502 [0.009, 1.000], mean action: 19.400 [3.000, 55.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.439050, mean_absolute_error: 6.579726, mean_q: 7.500518
669 (array([15]),) False
  30480/500000: episode: 762, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 30.543, mean reward: 0.764 [0.068, 0.954], mean action: 21.550 [4.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.466058, mean_absolute_error: 6.559939, mean_q: 7.498057
613 (array([22]),) False
  30520/500000: episode: 763, duration: 30.624s, episode steps: 40, steps per second: 1, episode reward: 29.799, mean reward: 0.745 [0.194, 1.000], mean action: 18.500 [0.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.452622, mean_absolute_error: 6.554916, mean_q: 7.469254
764 (array([48]),) False
  30560/500000: episode: 764, duration: 30.812s, episode steps: 40, steps per second: 1, episode reward: 32.026, mean reward: 0.801 [0.278, 1.000], mean action: 18.550 [1.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.456115, mean_absolute_error: 6.557265, mean_q: 7.478742
68 (array([22]),) False
  30600/500000: episode: 765, duration: 30.011s, episode steps: 40, steps per second: 1, episode reward: 22.874, mean reward: 0.572 [0.054, 1.000], mean action: 22.475 [2.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.417293, mean_absolute_error: 6.561759, mean_q: 7.481667
86 (array([22]),) False
  30640/500000: episode: 766, duration: 30.827s, episode steps: 40, steps per second: 1, episode reward: 30.771, mean reward: 0.769 [0.000, 1.000], mean action: 24.625 [3.000, 56.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.433508, mean_absolute_error: 6.577167, mean_q: 7.494193
33 (array([48]),) False
  30680/500000: episode: 767, duration: 30.661s, episode steps: 40, steps per second: 1, episode reward: 27.382, mean reward: 0.685 [0.000, 1.000], mean action: 27.150 [2.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.413591, mean_absolute_error: 6.557709, mean_q: 7.489417
703 (array([3]),) False
  30720/500000: episode: 768, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 8.947, mean reward: 0.224 [0.000, 0.798], mean action: 20.400 [0.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.407435, mean_absolute_error: 6.518052, mean_q: 7.451480
842 (array([22]),) False
  30760/500000: episode: 769, duration: 29.948s, episode steps: 40, steps per second: 1, episode reward: 25.335, mean reward: 0.633 [0.046, 1.000], mean action: 17.525 [3.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.418534, mean_absolute_error: 6.490494, mean_q: 7.437158
253 (array([44]),) False
  30800/500000: episode: 770, duration: 30.660s, episode steps: 40, steps per second: 1, episode reward: 15.711, mean reward: 0.393 [0.000, 0.956], mean action: 21.925 [3.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.451218, mean_absolute_error: 6.503160, mean_q: 7.428221
218 (array([22]),) False
  30840/500000: episode: 771, duration: 30.705s, episode steps: 40, steps per second: 1, episode reward: 27.455, mean reward: 0.686 [0.190, 1.000], mean action: 20.475 [12.000, 56.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.383064, mean_absolute_error: 6.506892, mean_q: 7.395837
130 (array([22]),) False
  30880/500000: episode: 772, duration: 30.755s, episode steps: 40, steps per second: 1, episode reward: 33.231, mean reward: 0.831 [0.078, 0.999], mean action: 15.525 [3.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.411675, mean_absolute_error: 6.506647, mean_q: 7.415138
604 (array([40]),) False
  30920/500000: episode: 773, duration: 29.940s, episode steps: 40, steps per second: 1, episode reward: 32.305, mean reward: 0.808 [0.000, 0.949], mean action: 19.275 [3.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.431311, mean_absolute_error: 6.523935, mean_q: 7.452544
761 (array([3]),) False
  30960/500000: episode: 774, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 21.928, mean reward: 0.548 [0.000, 0.847], mean action: 26.900 [4.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.438187, mean_absolute_error: 6.495181, mean_q: 7.402505
810 (array([12]),) False
  31000/500000: episode: 775, duration: 30.684s, episode steps: 40, steps per second: 1, episode reward: 28.108, mean reward: 0.703 [0.105, 1.000], mean action: 20.675 [2.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.452451, mean_absolute_error: 6.478631, mean_q: 7.433366
5 (array([37]),) False
  31040/500000: episode: 776, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 31.666, mean reward: 0.792 [0.156, 0.985], mean action: 17.750 [1.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.396029, mean_absolute_error: 6.490095, mean_q: 7.409286
524 (array([22]),) False
  31080/500000: episode: 777, duration: 29.913s, episode steps: 40, steps per second: 1, episode reward: 27.295, mean reward: 0.682 [0.069, 0.943], mean action: 17.825 [3.000, 57.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.445636, mean_absolute_error: 6.479131, mean_q: 7.400145
666 (array([22]),) False
  31120/500000: episode: 778, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 27.839, mean reward: 0.696 [0.000, 1.000], mean action: 24.400 [4.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.436939, mean_absolute_error: 6.466745, mean_q: 7.397443
35 (array([48]),) False
  31160/500000: episode: 779, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 32.697, mean reward: 0.817 [0.162, 1.000], mean action: 31.200 [5.000, 54.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.440604, mean_absolute_error: 6.512389, mean_q: 7.411679
500 (array([22]),) False
  31200/500000: episode: 780, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 32.920, mean reward: 0.823 [0.208, 1.000], mean action: 20.800 [6.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.449780, mean_absolute_error: 6.522859, mean_q: 7.427669
161 (array([22]),) False
  31240/500000: episode: 781, duration: 29.987s, episode steps: 40, steps per second: 1, episode reward: 26.048, mean reward: 0.651 [0.018, 1.000], mean action: 23.625 [1.000, 60.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.437582, mean_absolute_error: 6.524743, mean_q: 7.443419
261 (array([44]),) False
  31280/500000: episode: 782, duration: 30.659s, episode steps: 40, steps per second: 1, episode reward: 26.990, mean reward: 0.675 [0.305, 0.890], mean action: 18.975 [0.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.450476, mean_absolute_error: 6.529963, mean_q: 7.440733
554 (array([22]),) False
  31320/500000: episode: 783, duration: 30.660s, episode steps: 40, steps per second: 1, episode reward: 27.360, mean reward: 0.684 [0.008, 0.914], mean action: 19.425 [1.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.419933, mean_absolute_error: 6.519917, mean_q: 7.435550
143 (array([12]),) False
  31360/500000: episode: 784, duration: 30.672s, episode steps: 40, steps per second: 1, episode reward: 30.650, mean reward: 0.766 [0.102, 1.000], mean action: 20.600 [11.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.441232, mean_absolute_error: 6.529243, mean_q: 7.440450
680 (array([22]),) False
  31400/500000: episode: 785, duration: 29.969s, episode steps: 40, steps per second: 1, episode reward: 33.121, mean reward: 0.828 [0.072, 1.000], mean action: 16.475 [9.000, 58.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.425499, mean_absolute_error: 6.525104, mean_q: 7.439615
477 (array([22]),) False
  31440/500000: episode: 786, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 29.269, mean reward: 0.732 [0.060, 0.925], mean action: 19.600 [8.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.431167, mean_absolute_error: 6.474634, mean_q: 7.376177
359 (array([22]),) False
  31480/500000: episode: 787, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 21.421, mean reward: 0.536 [0.077, 0.684], mean action: 18.725 [4.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.399362, mean_absolute_error: 6.493711, mean_q: 7.386843
568 (array([22]),) False
  31520/500000: episode: 788, duration: 30.766s, episode steps: 40, steps per second: 1, episode reward: 29.425, mean reward: 0.736 [0.000, 0.942], mean action: 21.650 [11.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.360220, mean_absolute_error: 6.540056, mean_q: 7.428425
650 (array([22]),) False
  31560/500000: episode: 789, duration: 29.991s, episode steps: 40, steps per second: 1, episode reward: 27.821, mean reward: 0.696 [0.000, 1.000], mean action: 17.400 [6.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.411046, mean_absolute_error: 6.545729, mean_q: 7.436058
267 (array([22]),) False
  31600/500000: episode: 790, duration: 30.680s, episode steps: 40, steps per second: 1, episode reward: 22.217, mean reward: 0.555 [0.126, 1.000], mean action: 24.425 [6.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.441082, mean_absolute_error: 6.505379, mean_q: 7.425932
343 (array([22]),) False
  31640/500000: episode: 791, duration: 30.712s, episode steps: 40, steps per second: 1, episode reward: 27.875, mean reward: 0.697 [0.000, 0.954], mean action: 16.975 [0.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.469096, mean_absolute_error: 6.482556, mean_q: 7.382219
595 (array([22]),) False
  31680/500000: episode: 792, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 29.429, mean reward: 0.736 [0.087, 0.878], mean action: 18.025 [1.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.417805, mean_absolute_error: 6.514340, mean_q: 7.432086
813 (array([22]),) False
  31720/500000: episode: 793, duration: 29.887s, episode steps: 40, steps per second: 1, episode reward: 31.707, mean reward: 0.793 [0.000, 1.000], mean action: 16.350 [0.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.436537, mean_absolute_error: 6.510711, mean_q: 7.433843
614 (array([22]),) False
  31760/500000: episode: 794, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 28.152, mean reward: 0.704 [0.305, 1.000], mean action: 19.025 [1.000, 51.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.440963, mean_absolute_error: 6.535800, mean_q: 7.464328
9 (array([14]),) False
  31800/500000: episode: 795, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 32.020, mean reward: 0.800 [0.174, 0.989], mean action: 24.325 [10.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.456002, mean_absolute_error: 6.543897, mean_q: 7.464828
509 (array([22]),) False
  31840/500000: episode: 796, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 29.907, mean reward: 0.748 [0.032, 0.964], mean action: 22.725 [12.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.427390, mean_absolute_error: 6.512909, mean_q: 7.421860
111 (array([22]),) False
  31880/500000: episode: 797, duration: 29.990s, episode steps: 40, steps per second: 1, episode reward: 27.094, mean reward: 0.677 [0.000, 1.000], mean action: 16.750 [4.000, 55.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.384654, mean_absolute_error: 6.556155, mean_q: 7.460835
801 (array([58]),) False
  31920/500000: episode: 798, duration: 30.758s, episode steps: 40, steps per second: 1, episode reward: 16.579, mean reward: 0.414 [0.000, 1.000], mean action: 19.200 [0.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.459357, mean_absolute_error: 6.514132, mean_q: 7.410752
696 (array([36]),) False
  31960/500000: episode: 799, duration: 30.704s, episode steps: 40, steps per second: 1, episode reward: 23.411, mean reward: 0.585 [0.000, 1.000], mean action: 35.975 [2.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.384362, mean_absolute_error: 6.512454, mean_q: 7.467255
726 (array([12]),) False
  32000/500000: episode: 800, duration: 30.720s, episode steps: 40, steps per second: 1, episode reward: 34.874, mean reward: 0.872 [0.185, 1.000], mean action: 18.425 [10.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.426629, mean_absolute_error: 6.495706, mean_q: 7.415507
810 (array([12]),) False
  32040/500000: episode: 801, duration: 30.008s, episode steps: 40, steps per second: 1, episode reward: 36.357, mean reward: 0.909 [0.322, 1.000], mean action: 18.500 [12.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.442609, mean_absolute_error: 6.468368, mean_q: 7.386262
45 (array([22]),) False
  32080/500000: episode: 802, duration: 30.787s, episode steps: 40, steps per second: 1, episode reward: 26.103, mean reward: 0.653 [0.054, 1.000], mean action: 21.875 [0.000, 53.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.378068, mean_absolute_error: 6.482257, mean_q: 7.405540
42 (array([22]),) False
  32120/500000: episode: 803, duration: 30.655s, episode steps: 40, steps per second: 1, episode reward: 32.375, mean reward: 0.809 [0.038, 1.000], mean action: 17.400 [1.000, 52.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.401062, mean_absolute_error: 6.473030, mean_q: 7.390339
214 (array([22]),) False
  32160/500000: episode: 804, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 30.679, mean reward: 0.767 [0.091, 0.966], mean action: 20.575 [8.000, 60.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.459294, mean_absolute_error: 6.426581, mean_q: 7.355757
694 (array([22]),) False
  32200/500000: episode: 805, duration: 29.980s, episode steps: 40, steps per second: 1, episode reward: 19.807, mean reward: 0.495 [0.026, 1.000], mean action: 24.575 [4.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.393869, mean_absolute_error: 6.414178, mean_q: 7.310307
345 (array([22]),) False
  32240/500000: episode: 806, duration: 30.690s, episode steps: 40, steps per second: 1, episode reward: 30.445, mean reward: 0.761 [0.000, 0.901], mean action: 17.500 [2.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.353668, mean_absolute_error: 6.441377, mean_q: 7.345908
135 (array([22]),) False
  32280/500000: episode: 807, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 31.723, mean reward: 0.793 [0.000, 0.945], mean action: 17.575 [3.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.426809, mean_absolute_error: 6.428052, mean_q: 7.323514
390 (array([22]),) False
  32320/500000: episode: 808, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 25.933, mean reward: 0.648 [0.000, 1.000], mean action: 30.825 [0.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.389228, mean_absolute_error: 6.437498, mean_q: 7.337396
15 (array([22]),) False
  32360/500000: episode: 809, duration: 30.052s, episode steps: 40, steps per second: 1, episode reward: 30.129, mean reward: 0.753 [0.007, 1.000], mean action: 26.850 [18.000, 59.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.396514, mean_absolute_error: 6.486745, mean_q: 7.382949
692 (array([22]),) False
  32400/500000: episode: 810, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 32.443, mean reward: 0.811 [0.187, 1.000], mean action: 16.350 [1.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.424701, mean_absolute_error: 6.463852, mean_q: 7.368706
716 (array([48]),) False
  32440/500000: episode: 811, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 29.945, mean reward: 0.749 [0.000, 0.993], mean action: 22.350 [7.000, 47.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.353125, mean_absolute_error: 6.508517, mean_q: 7.426585
456 (array([22]),) False
  32480/500000: episode: 812, duration: 30.686s, episode steps: 40, steps per second: 1, episode reward: 31.740, mean reward: 0.793 [0.000, 1.000], mean action: 18.950 [3.000, 56.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.398514, mean_absolute_error: 6.461090, mean_q: 7.381284
551 (array([22]),) False
  32520/500000: episode: 813, duration: 29.984s, episode steps: 40, steps per second: 1, episode reward: 29.454, mean reward: 0.736 [0.000, 0.953], mean action: 20.900 [4.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.430966, mean_absolute_error: 6.449746, mean_q: 7.368437
464 (array([22]),) False
  32560/500000: episode: 814, duration: 30.712s, episode steps: 40, steps per second: 1, episode reward: 28.478, mean reward: 0.712 [0.040, 1.000], mean action: 18.525 [5.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.466473, mean_absolute_error: 6.452884, mean_q: 7.382154
107 (array([22]),) False
  32600/500000: episode: 815, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 31.292, mean reward: 0.782 [0.012, 0.901], mean action: 15.625 [4.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.440753, mean_absolute_error: 6.411368, mean_q: 7.340360
755 (array([22]),) False
  32640/500000: episode: 816, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 27.229, mean reward: 0.681 [0.100, 1.000], mean action: 18.025 [3.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.392046, mean_absolute_error: 6.411815, mean_q: 7.329003
194 (array([44]),) False
  32680/500000: episode: 817, duration: 29.929s, episode steps: 40, steps per second: 1, episode reward: 22.379, mean reward: 0.559 [0.043, 0.852], mean action: 17.650 [1.000, 56.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.400314, mean_absolute_error: 6.409189, mean_q: 7.320578
605 (array([22]),) False
  32720/500000: episode: 818, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 29.180, mean reward: 0.729 [0.095, 1.000], mean action: 17.425 [3.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.393860, mean_absolute_error: 6.417172, mean_q: 7.320618
707 (array([48]),) False
  32760/500000: episode: 819, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 30.132, mean reward: 0.753 [0.149, 0.943], mean action: 17.075 [12.000, 52.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.452831, mean_absolute_error: 6.411030, mean_q: 7.327778
769 (array([12]),) False
  32800/500000: episode: 820, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 29.520, mean reward: 0.738 [0.216, 1.000], mean action: 18.975 [2.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.373384, mean_absolute_error: 6.404900, mean_q: 7.308375
68 (array([22]),) False
  32840/500000: episode: 821, duration: 30.042s, episode steps: 40, steps per second: 1, episode reward: 18.551, mean reward: 0.464 [0.000, 0.683], mean action: 21.875 [3.000, 57.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.436663, mean_absolute_error: 6.389592, mean_q: 7.302480
609 (array([22]),) False
  32880/500000: episode: 822, duration: 30.714s, episode steps: 40, steps per second: 1, episode reward: 29.981, mean reward: 0.750 [0.000, 1.000], mean action: 14.475 [5.000, 49.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.423939, mean_absolute_error: 6.346037, mean_q: 7.238687
665 (array([12]),) False
  32920/500000: episode: 823, duration: 30.639s, episode steps: 40, steps per second: 1, episode reward: 31.972, mean reward: 0.799 [0.000, 1.000], mean action: 17.450 [3.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.341002, mean_absolute_error: 6.425246, mean_q: 7.317159
469 (array([22]),) False
  32960/500000: episode: 824, duration: 30.792s, episode steps: 40, steps per second: 1, episode reward: 25.087, mean reward: 0.627 [0.215, 1.000], mean action: 23.000 [12.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.411431, mean_absolute_error: 6.427365, mean_q: 7.313514
829 (array([21]),) False
  33000/500000: episode: 825, duration: 30.022s, episode steps: 40, steps per second: 1, episode reward: 31.078, mean reward: 0.777 [0.000, 0.884], mean action: 15.475 [10.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.402618, mean_absolute_error: 6.389226, mean_q: 7.290155
153 (array([44]),) False
  33040/500000: episode: 826, duration: 30.755s, episode steps: 40, steps per second: 1, episode reward: 23.885, mean reward: 0.597 [0.374, 0.938], mean action: 18.950 [0.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.368445, mean_absolute_error: 6.382721, mean_q: 7.284041
165 (array([34]),) False
  33080/500000: episode: 827, duration: 30.670s, episode steps: 40, steps per second: 1, episode reward: 26.648, mean reward: 0.666 [0.214, 1.000], mean action: 21.100 [2.000, 57.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.427322, mean_absolute_error: 6.363389, mean_q: 7.239947
677 (array([48]),) False
  33120/500000: episode: 828, duration: 30.738s, episode steps: 40, steps per second: 1, episode reward: 33.302, mean reward: 0.833 [0.095, 0.994], mean action: 16.425 [3.000, 52.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.398722, mean_absolute_error: 6.402568, mean_q: 7.320610
460 (array([36]),) False
  33160/500000: episode: 829, duration: 29.988s, episode steps: 40, steps per second: 1, episode reward: 27.818, mean reward: 0.695 [0.164, 1.000], mean action: 21.400 [5.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.391725, mean_absolute_error: 6.382520, mean_q: 7.282465
688 (array([22]),) False
  33200/500000: episode: 830, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 30.357, mean reward: 0.759 [0.146, 1.000], mean action: 20.075 [0.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.346691, mean_absolute_error: 6.438220, mean_q: 7.313182
120 (array([44]),) False
  33240/500000: episode: 831, duration: 30.678s, episode steps: 40, steps per second: 1, episode reward: 34.677, mean reward: 0.867 [0.315, 1.000], mean action: 28.950 [12.000, 55.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.360115, mean_absolute_error: 6.439734, mean_q: 7.346456
447 (array([44]),) False
  33280/500000: episode: 832, duration: 30.762s, episode steps: 40, steps per second: 1, episode reward: 24.815, mean reward: 0.620 [0.161, 1.000], mean action: 21.650 [2.000, 56.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.364733, mean_absolute_error: 6.468406, mean_q: 7.359790
366 (array([22]),) False
  33320/500000: episode: 833, duration: 29.964s, episode steps: 40, steps per second: 1, episode reward: 27.378, mean reward: 0.684 [0.063, 1.000], mean action: 24.325 [2.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.393699, mean_absolute_error: 6.461851, mean_q: 7.343647
8 (array([22]),) False
  33360/500000: episode: 834, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 30.123, mean reward: 0.753 [0.188, 1.000], mean action: 28.750 [3.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.463837, mean_absolute_error: 6.449296, mean_q: 7.342723
338 (array([12]),) False
  33400/500000: episode: 835, duration: 30.707s, episode steps: 40, steps per second: 1, episode reward: 29.104, mean reward: 0.728 [0.110, 0.998], mean action: 19.450 [2.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.432523, mean_absolute_error: 6.434757, mean_q: 7.339708
240 (array([22]),) False
  33440/500000: episode: 836, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 26.626, mean reward: 0.666 [0.207, 0.820], mean action: 18.075 [1.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.394570, mean_absolute_error: 6.430249, mean_q: 7.315851
332 (array([22]),) False
  33480/500000: episode: 837, duration: 29.986s, episode steps: 40, steps per second: 1, episode reward: 27.778, mean reward: 0.694 [0.000, 1.000], mean action: 19.350 [2.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.395285, mean_absolute_error: 6.440909, mean_q: 7.342734
780 (array([22]),) False
  33520/500000: episode: 838, duration: 30.716s, episode steps: 40, steps per second: 1, episode reward: 30.811, mean reward: 0.770 [0.008, 1.000], mean action: 20.100 [5.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.346795, mean_absolute_error: 6.430898, mean_q: 7.307494
626 (array([22]),) False
  33560/500000: episode: 839, duration: 30.702s, episode steps: 40, steps per second: 1, episode reward: 31.035, mean reward: 0.776 [0.204, 0.907], mean action: 17.525 [0.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.342758, mean_absolute_error: 6.471312, mean_q: 7.357456
253 (array([44]),) False
  33600/500000: episode: 840, duration: 30.794s, episode steps: 40, steps per second: 1, episode reward: 19.887, mean reward: 0.497 [0.000, 0.867], mean action: 33.475 [9.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.426769, mean_absolute_error: 6.448972, mean_q: 7.332817
248 (array([12]),) False
  33640/500000: episode: 841, duration: 29.945s, episode steps: 40, steps per second: 1, episode reward: 32.828, mean reward: 0.821 [0.000, 1.000], mean action: 15.050 [0.000, 49.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.388113, mean_absolute_error: 6.448438, mean_q: 7.348551
308 (array([22]),) False
  33680/500000: episode: 842, duration: 30.757s, episode steps: 40, steps per second: 1, episode reward: 25.170, mean reward: 0.629 [0.090, 0.998], mean action: 23.375 [2.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.365954, mean_absolute_error: 6.430140, mean_q: 7.333739
441 (array([22]),) False
  33720/500000: episode: 843, duration: 30.661s, episode steps: 40, steps per second: 1, episode reward: 29.872, mean reward: 0.747 [0.057, 1.000], mean action: 23.725 [2.000, 60.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.361316, mean_absolute_error: 6.460487, mean_q: 7.342256
792 (array([58]),) False
  33760/500000: episode: 844, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 21.481, mean reward: 0.537 [0.074, 0.874], mean action: 37.525 [3.000, 60.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.423693, mean_absolute_error: 6.467361, mean_q: 7.348459
266 (array([12]),) False
  33800/500000: episode: 845, duration: 30.000s, episode steps: 40, steps per second: 1, episode reward: 28.976, mean reward: 0.724 [0.105, 1.000], mean action: 22.175 [4.000, 53.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.412654, mean_absolute_error: 6.459033, mean_q: 7.353127
636 (array([12]),) False
  33840/500000: episode: 846, duration: 30.733s, episode steps: 40, steps per second: 1, episode reward: 30.457, mean reward: 0.761 [0.070, 1.000], mean action: 18.450 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.371284, mean_absolute_error: 6.461769, mean_q: 7.371411
247 (array([14]),) False
  33880/500000: episode: 847, duration: 30.742s, episode steps: 40, steps per second: 1, episode reward: 30.107, mean reward: 0.753 [0.014, 1.000], mean action: 20.950 [0.000, 57.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.450329, mean_absolute_error: 6.460183, mean_q: 7.360233
239 (array([22]),) False
  33920/500000: episode: 848, duration: 30.737s, episode steps: 40, steps per second: 1, episode reward: 21.847, mean reward: 0.546 [0.266, 0.870], mean action: 31.675 [7.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.418849, mean_absolute_error: 6.397021, mean_q: 7.279938
612 (array([22]),) False
  33960/500000: episode: 849, duration: 29.945s, episode steps: 40, steps per second: 1, episode reward: 27.458, mean reward: 0.686 [0.070, 0.936], mean action: 18.700 [3.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.425561, mean_absolute_error: 6.382178, mean_q: 7.255359
452 (array([22]),) False
  34000/500000: episode: 850, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 27.775, mean reward: 0.694 [0.192, 1.000], mean action: 24.600 [0.000, 54.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.376175, mean_absolute_error: 6.432714, mean_q: 7.309435
603 (array([58]),) False
  34040/500000: episode: 851, duration: 30.677s, episode steps: 40, steps per second: 1, episode reward: 24.367, mean reward: 0.609 [0.028, 1.000], mean action: 36.825 [2.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.419692, mean_absolute_error: 6.379180, mean_q: 7.272749
483 (array([48]),) False
  34080/500000: episode: 852, duration: 30.753s, episode steps: 40, steps per second: 1, episode reward: 27.791, mean reward: 0.695 [0.087, 0.944], mean action: 26.250 [3.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.383136, mean_absolute_error: 6.372521, mean_q: 7.248801
312 (array([12]),) False
  34120/500000: episode: 853, duration: 29.954s, episode steps: 40, steps per second: 1, episode reward: 31.326, mean reward: 0.783 [0.100, 1.000], mean action: 18.150 [0.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.340290, mean_absolute_error: 6.419031, mean_q: 7.299144
253 (array([44]),) False
  34160/500000: episode: 854, duration: 30.734s, episode steps: 40, steps per second: 1, episode reward: 12.584, mean reward: 0.315 [0.000, 0.890], mean action: 19.650 [2.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.396514, mean_absolute_error: 6.401891, mean_q: 7.266570
259 (array([12]),) False
  34200/500000: episode: 855, duration: 30.608s, episode steps: 40, steps per second: 1, episode reward: 30.574, mean reward: 0.764 [0.099, 1.000], mean action: 18.525 [1.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.413516, mean_absolute_error: 6.420323, mean_q: 7.298181
638 (array([22]),) False
  34240/500000: episode: 856, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 29.589, mean reward: 0.740 [0.047, 0.887], mean action: 15.450 [6.000, 51.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.359534, mean_absolute_error: 6.450589, mean_q: 7.341199
479 (array([22]),) False
  34280/500000: episode: 857, duration: 29.955s, episode steps: 40, steps per second: 1, episode reward: 29.955, mean reward: 0.749 [0.120, 0.913], mean action: 21.425 [10.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.425533, mean_absolute_error: 6.449500, mean_q: 7.334739
817 (array([12]),) False
  34320/500000: episode: 858, duration: 30.697s, episode steps: 40, steps per second: 1, episode reward: 38.742, mean reward: 0.969 [0.568, 1.000], mean action: 13.275 [12.000, 37.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.409836, mean_absolute_error: 6.429399, mean_q: 7.329591
851 (array([48]),) False
  34360/500000: episode: 859, duration: 30.684s, episode steps: 40, steps per second: 1, episode reward: 32.699, mean reward: 0.817 [0.000, 1.000], mean action: 18.350 [8.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.414235, mean_absolute_error: 6.413227, mean_q: 7.288776
580 (array([22]),) False
  34400/500000: episode: 860, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 27.850, mean reward: 0.696 [0.025, 1.000], mean action: 23.575 [10.000, 55.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.433903, mean_absolute_error: 6.415411, mean_q: 7.307530
18 (array([22]),) False
  34440/500000: episode: 861, duration: 29.999s, episode steps: 40, steps per second: 1, episode reward: 29.733, mean reward: 0.743 [0.091, 1.000], mean action: 25.800 [3.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.438325, mean_absolute_error: 6.410354, mean_q: 7.310609
720 (array([22]),) False
  34480/500000: episode: 862, duration: 30.710s, episode steps: 40, steps per second: 1, episode reward: 27.589, mean reward: 0.690 [0.000, 0.940], mean action: 19.800 [2.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.394209, mean_absolute_error: 6.381098, mean_q: 7.260943
77 (array([22]),) False
  34520/500000: episode: 863, duration: 30.685s, episode steps: 40, steps per second: 1, episode reward: 27.598, mean reward: 0.690 [0.002, 1.000], mean action: 25.175 [1.000, 59.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.350166, mean_absolute_error: 6.401208, mean_q: 7.272827
228 (array([44]),) False
  34560/500000: episode: 864, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 26.964, mean reward: 0.674 [0.122, 0.978], mean action: 17.025 [4.000, 54.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.390836, mean_absolute_error: 6.371233, mean_q: 7.251799
6 (array([58]),) False
  34600/500000: episode: 865, duration: 29.949s, episode steps: 40, steps per second: 1, episode reward: 32.020, mean reward: 0.801 [0.032, 1.000], mean action: 23.225 [2.000, 48.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.360609, mean_absolute_error: 6.373391, mean_q: 7.249401
350 (array([12]),) False
  34640/500000: episode: 866, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 31.086, mean reward: 0.777 [0.043, 1.000], mean action: 21.625 [4.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.382922, mean_absolute_error: 6.391539, mean_q: 7.278833
113 (array([22]),) False
  34680/500000: episode: 867, duration: 30.775s, episode steps: 40, steps per second: 1, episode reward: 30.010, mean reward: 0.750 [0.183, 1.000], mean action: 24.850 [0.000, 50.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.371317, mean_absolute_error: 6.401928, mean_q: 7.284616
177 (array([22]),) False
  34720/500000: episode: 868, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 31.334, mean reward: 0.783 [0.083, 1.000], mean action: 20.575 [3.000, 56.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.380709, mean_absolute_error: 6.409728, mean_q: 7.280365
209 (array([8]),) False
  34760/500000: episode: 869, duration: 29.925s, episode steps: 40, steps per second: 1, episode reward: 21.595, mean reward: 0.540 [0.140, 1.000], mean action: 24.200 [0.000, 58.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.416541, mean_absolute_error: 6.387742, mean_q: 7.263804
581 (array([22]),) False
  34800/500000: episode: 870, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 18.879, mean reward: 0.472 [0.053, 0.664], mean action: 14.500 [1.000, 54.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.397916, mean_absolute_error: 6.371402, mean_q: 7.252727
26 (array([22]),) False
  34840/500000: episode: 871, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 30.455, mean reward: 0.761 [0.011, 1.000], mean action: 21.550 [2.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.448236, mean_absolute_error: 6.354062, mean_q: 7.238484
646 (array([44]),) False
  34880/500000: episode: 872, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 12.729, mean reward: 0.318 [0.000, 0.957], mean action: 28.375 [0.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.359004, mean_absolute_error: 6.391934, mean_q: 7.289046
538 (array([12]),) False
  34920/500000: episode: 873, duration: 29.921s, episode steps: 40, steps per second: 1, episode reward: 29.359, mean reward: 0.734 [0.195, 1.000], mean action: 25.100 [5.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.386207, mean_absolute_error: 6.366947, mean_q: 7.246523
524 (array([22]),) False
  34960/500000: episode: 874, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 29.911, mean reward: 0.748 [0.071, 0.945], mean action: 17.875 [0.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.424598, mean_absolute_error: 6.351142, mean_q: 7.235404
594 (array([48]),) False
  35000/500000: episode: 875, duration: 30.730s, episode steps: 40, steps per second: 1, episode reward: 29.228, mean reward: 0.731 [0.000, 0.959], mean action: 15.325 [8.000, 38.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.376015, mean_absolute_error: 6.369945, mean_q: 7.230024
335 (array([22]),) False
  35040/500000: episode: 876, duration: 30.781s, episode steps: 40, steps per second: 1, episode reward: 26.641, mean reward: 0.666 [0.201, 1.000], mean action: 16.250 [3.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.360737, mean_absolute_error: 6.422890, mean_q: 7.301346
247 (array([14]),) False
  35080/500000: episode: 877, duration: 29.970s, episode steps: 40, steps per second: 1, episode reward: 30.509, mean reward: 0.763 [0.000, 0.995], mean action: 22.075 [5.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.383422, mean_absolute_error: 6.407228, mean_q: 7.280103
645 (array([48]),) False
  35120/500000: episode: 878, duration: 30.777s, episode steps: 40, steps per second: 1, episode reward: 32.072, mean reward: 0.802 [0.078, 0.990], mean action: 16.975 [1.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.382583, mean_absolute_error: 6.371423, mean_q: 7.257275
149 (array([8]),) False
  35160/500000: episode: 879, duration: 30.702s, episode steps: 40, steps per second: 1, episode reward: 13.667, mean reward: 0.342 [0.000, 0.982], mean action: 19.475 [6.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.348193, mean_absolute_error: 6.397480, mean_q: 7.271896
546 (array([22]),) False
  35200/500000: episode: 880, duration: 30.825s, episode steps: 40, steps per second: 1, episode reward: 31.147, mean reward: 0.779 [0.226, 1.000], mean action: 21.550 [2.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.370475, mean_absolute_error: 6.405928, mean_q: 7.282413
515 (array([22]),) False
  35240/500000: episode: 881, duration: 30.000s, episode steps: 40, steps per second: 1, episode reward: 25.437, mean reward: 0.636 [0.113, 1.000], mean action: 27.625 [7.000, 55.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.392574, mean_absolute_error: 6.418364, mean_q: 7.292800
532 (array([25]),) False
  35280/500000: episode: 882, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 23.378, mean reward: 0.584 [0.310, 0.795], mean action: 24.050 [0.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.411406, mean_absolute_error: 6.372974, mean_q: 7.266606
665 (array([12]),) False
  35320/500000: episode: 883, duration: 30.658s, episode steps: 40, steps per second: 1, episode reward: 30.896, mean reward: 0.772 [0.042, 1.000], mean action: 19.050 [12.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.389209, mean_absolute_error: 6.409492, mean_q: 7.302615
63 (array([18]),) False
  35360/500000: episode: 884, duration: 30.789s, episode steps: 40, steps per second: 1, episode reward: 31.424, mean reward: 0.786 [0.075, 1.000], mean action: 19.775 [4.000, 56.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.439930, mean_absolute_error: 6.380837, mean_q: 7.247912
644 (array([12]),) False
  35400/500000: episode: 885, duration: 29.977s, episode steps: 40, steps per second: 1, episode reward: 33.775, mean reward: 0.844 [0.135, 1.000], mean action: 16.000 [0.000, 53.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.370982, mean_absolute_error: 6.350388, mean_q: 7.222890
175 (array([22]),) False
  35440/500000: episode: 886, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 32.635, mean reward: 0.816 [0.182, 0.986], mean action: 18.775 [3.000, 56.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.380625, mean_absolute_error: 6.380069, mean_q: 7.264466
722 (array([22]),) False
  35480/500000: episode: 887, duration: 30.783s, episode steps: 40, steps per second: 1, episode reward: 31.529, mean reward: 0.788 [0.040, 0.980], mean action: 18.775 [9.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.394548, mean_absolute_error: 6.359445, mean_q: 7.244798
553 (array([22]),) False
  35520/500000: episode: 888, duration: 30.773s, episode steps: 40, steps per second: 1, episode reward: 28.827, mean reward: 0.721 [0.034, 1.000], mean action: 20.475 [3.000, 57.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.405982, mean_absolute_error: 6.311474, mean_q: 7.207076
99 (array([22]),) False
  35560/500000: episode: 889, duration: 29.959s, episode steps: 40, steps per second: 1, episode reward: 33.387, mean reward: 0.835 [0.305, 1.000], mean action: 24.050 [9.000, 52.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.317699, mean_absolute_error: 6.358168, mean_q: 7.246814
612 (array([22]),) False
  35600/500000: episode: 890, duration: 30.745s, episode steps: 40, steps per second: 1, episode reward: 27.505, mean reward: 0.688 [0.043, 1.000], mean action: 19.300 [2.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.442589, mean_absolute_error: 6.309844, mean_q: 7.213313
29 (array([22]),) False
  35640/500000: episode: 891, duration: 30.748s, episode steps: 40, steps per second: 1, episode reward: 30.908, mean reward: 0.773 [0.043, 1.000], mean action: 25.000 [3.000, 60.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.376618, mean_absolute_error: 6.285516, mean_q: 7.173081
226 (array([22]),) False
  35680/500000: episode: 892, duration: 30.818s, episode steps: 40, steps per second: 1, episode reward: 28.529, mean reward: 0.713 [0.129, 0.909], mean action: 22.375 [6.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.460450, mean_absolute_error: 6.265393, mean_q: 7.130671
462 (array([12]),) False
  35720/500000: episode: 893, duration: 30.040s, episode steps: 40, steps per second: 1, episode reward: 30.157, mean reward: 0.754 [0.176, 1.000], mean action: 21.750 [7.000, 56.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.407142, mean_absolute_error: 6.259014, mean_q: 7.138940
780 (array([22]),) False
  35760/500000: episode: 894, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 28.870, mean reward: 0.722 [0.024, 1.000], mean action: 23.850 [0.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.369818, mean_absolute_error: 6.204738, mean_q: 7.079896
517 (array([22]),) False
  35800/500000: episode: 895, duration: 30.701s, episode steps: 40, steps per second: 1, episode reward: 31.527, mean reward: 0.788 [0.223, 1.000], mean action: 19.150 [2.000, 50.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.366175, mean_absolute_error: 6.232841, mean_q: 7.086732
384 (array([22]),) False
  35840/500000: episode: 896, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 31.996, mean reward: 0.800 [0.071, 1.000], mean action: 23.475 [3.000, 48.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.379700, mean_absolute_error: 6.274673, mean_q: 7.133393
759 (array([48]),) False
  35880/500000: episode: 897, duration: 30.003s, episode steps: 40, steps per second: 1, episode reward: 28.263, mean reward: 0.707 [0.039, 1.000], mean action: 20.700 [4.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.363163, mean_absolute_error: 6.292268, mean_q: 7.160203
412 (array([16]),) False
  35920/500000: episode: 898, duration: 30.824s, episode steps: 40, steps per second: 1, episode reward: 30.946, mean reward: 0.774 [0.000, 0.928], mean action: 22.025 [0.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.349649, mean_absolute_error: 6.282657, mean_q: 7.158034
731 (array([21]),) False
  35960/500000: episode: 899, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 29.981, mean reward: 0.750 [0.263, 1.000], mean action: 18.575 [2.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.354163, mean_absolute_error: 6.344149, mean_q: 7.224071
247 (array([14]),) False
  36000/500000: episode: 900, duration: 30.805s, episode steps: 40, steps per second: 1, episode reward: 34.202, mean reward: 0.855 [0.274, 1.000], mean action: 18.575 [0.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.362488, mean_absolute_error: 6.315197, mean_q: 7.207483
422 (array([48]),) False
  36040/500000: episode: 901, duration: 29.935s, episode steps: 40, steps per second: 1, episode reward: 29.170, mean reward: 0.729 [0.238, 0.988], mean action: 31.075 [5.000, 51.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.369157, mean_absolute_error: 6.311628, mean_q: 7.193945
15 (array([22]),) False
  36080/500000: episode: 902, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 27.206, mean reward: 0.680 [0.000, 1.000], mean action: 26.800 [0.000, 56.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.385837, mean_absolute_error: 6.312106, mean_q: 7.196902
829 (array([21]),) False
  36120/500000: episode: 903, duration: 30.688s, episode steps: 40, steps per second: 1, episode reward: 32.444, mean reward: 0.811 [0.360, 0.882], mean action: 15.775 [1.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.358137, mean_absolute_error: 6.316212, mean_q: 7.197157
700 (array([44]),) False
  36160/500000: episode: 904, duration: 30.710s, episode steps: 40, steps per second: 1, episode reward: 26.492, mean reward: 0.662 [0.184, 1.000], mean action: 18.575 [0.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.395864, mean_absolute_error: 6.318066, mean_q: 7.181970
723 (array([48]),) False
  36200/500000: episode: 905, duration: 29.993s, episode steps: 40, steps per second: 1, episode reward: 28.112, mean reward: 0.703 [0.037, 1.000], mean action: 18.200 [1.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.370461, mean_absolute_error: 6.314324, mean_q: 7.174528
76 (array([38]),) False
  36240/500000: episode: 906, duration: 30.780s, episode steps: 40, steps per second: 1, episode reward: 31.465, mean reward: 0.787 [0.034, 0.934], mean action: 17.250 [1.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.402281, mean_absolute_error: 6.332022, mean_q: 7.208238
667 (array([48]),) False
  36280/500000: episode: 907, duration: 30.754s, episode steps: 40, steps per second: 1, episode reward: 31.810, mean reward: 0.795 [0.044, 1.000], mean action: 33.375 [6.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.408979, mean_absolute_error: 6.296024, mean_q: 7.202176
242 (array([22]),) False
  36320/500000: episode: 908, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 28.392, mean reward: 0.710 [0.081, 0.901], mean action: 22.425 [4.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.375730, mean_absolute_error: 6.289217, mean_q: 7.162422
692 (array([22]),) False
  36360/500000: episode: 909, duration: 30.050s, episode steps: 40, steps per second: 1, episode reward: 29.133, mean reward: 0.728 [0.000, 0.943], mean action: 18.225 [1.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.376564, mean_absolute_error: 6.293734, mean_q: 7.171309
507 (array([44]),) False
  36400/500000: episode: 910, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 31.306, mean reward: 0.783 [0.396, 0.988], mean action: 19.950 [0.000, 45.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.362575, mean_absolute_error: 6.297919, mean_q: 7.176926
320 (array([22]),) False
  36440/500000: episode: 911, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 29.572, mean reward: 0.739 [0.005, 1.000], mean action: 20.025 [3.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.402169, mean_absolute_error: 6.248609, mean_q: 7.124223
480 (array([22]),) False
  36480/500000: episode: 912, duration: 30.689s, episode steps: 40, steps per second: 1, episode reward: 16.720, mean reward: 0.418 [0.000, 0.569], mean action: 20.750 [0.000, 58.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.323225, mean_absolute_error: 6.286485, mean_q: 7.158868
719 (array([22]),) False
  36520/500000: episode: 913, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 33.871, mean reward: 0.847 [0.044, 1.000], mean action: 17.700 [10.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.377039, mean_absolute_error: 6.306424, mean_q: 7.155246
202 (array([22]),) False
  36560/500000: episode: 914, duration: 30.760s, episode steps: 40, steps per second: 1, episode reward: 29.166, mean reward: 0.729 [0.147, 1.000], mean action: 16.500 [3.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.376878, mean_absolute_error: 6.305252, mean_q: 7.157295
848 (array([44]),) False
  36600/500000: episode: 915, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 24.836, mean reward: 0.621 [0.472, 0.906], mean action: 19.900 [7.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.341463, mean_absolute_error: 6.313514, mean_q: 7.185240
361 (array([22]),) False
  36640/500000: episode: 916, duration: 30.881s, episode steps: 40, steps per second: 1, episode reward: 32.684, mean reward: 0.817 [0.004, 1.000], mean action: 19.325 [1.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.385291, mean_absolute_error: 6.271934, mean_q: 7.130641
752 (array([3]),) False
  36680/500000: episode: 917, duration: 29.936s, episode steps: 40, steps per second: 1, episode reward: 24.757, mean reward: 0.619 [0.000, 1.000], mean action: 24.500 [3.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.391270, mean_absolute_error: 6.252727, mean_q: 7.124809
114 (array([22]),) False
  36720/500000: episode: 918, duration: 30.706s, episode steps: 40, steps per second: 1, episode reward: 30.634, mean reward: 0.766 [0.113, 1.000], mean action: 19.650 [10.000, 56.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.378172, mean_absolute_error: 6.284878, mean_q: 7.165177
45 (array([22]),) False
  36760/500000: episode: 919, duration: 30.600s, episode steps: 40, steps per second: 1, episode reward: 31.823, mean reward: 0.796 [0.000, 1.000], mean action: 24.950 [4.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.344889, mean_absolute_error: 6.244968, mean_q: 7.121176
564 (array([22]),) False
  36800/500000: episode: 920, duration: 30.693s, episode steps: 40, steps per second: 1, episode reward: 29.650, mean reward: 0.741 [0.027, 1.000], mean action: 17.400 [1.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.385946, mean_absolute_error: 6.262367, mean_q: 7.138430
765 (array([48]),) False
  36840/500000: episode: 921, duration: 30.029s, episode steps: 40, steps per second: 1, episode reward: 23.371, mean reward: 0.584 [0.000, 1.000], mean action: 24.700 [12.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.387270, mean_absolute_error: 6.256374, mean_q: 7.120692
838 (array([21]),) False
  36880/500000: episode: 922, duration: 30.698s, episode steps: 40, steps per second: 1, episode reward: 30.210, mean reward: 0.755 [0.176, 1.000], mean action: 23.175 [11.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.359561, mean_absolute_error: 6.286690, mean_q: 7.156598
646 (array([44]),) False
  36920/500000: episode: 923, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 13.327, mean reward: 0.333 [0.046, 0.957], mean action: 29.875 [4.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.388310, mean_absolute_error: 6.232339, mean_q: 7.096368
714 (array([22]),) False
  36960/500000: episode: 924, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 28.762, mean reward: 0.719 [0.024, 0.974], mean action: 18.925 [1.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.333914, mean_absolute_error: 6.253414, mean_q: 7.114517
625 (array([22]),) False
  37000/500000: episode: 925, duration: 29.952s, episode steps: 40, steps per second: 1, episode reward: 27.296, mean reward: 0.682 [0.048, 0.935], mean action: 32.450 [1.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.337024, mean_absolute_error: 6.232010, mean_q: 7.108871
212 (array([36]),) False
  37040/500000: episode: 926, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 17.799, mean reward: 0.445 [0.191, 0.661], mean action: 21.025 [7.000, 55.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.336993, mean_absolute_error: 6.219684, mean_q: 7.077401
779 (array([12]),) False
  37080/500000: episode: 927, duration: 30.720s, episode steps: 40, steps per second: 1, episode reward: 30.483, mean reward: 0.762 [0.025, 1.000], mean action: 25.975 [5.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.349659, mean_absolute_error: 6.242742, mean_q: 7.097291
666 (array([22]),) False
  37120/500000: episode: 928, duration: 30.779s, episode steps: 40, steps per second: 1, episode reward: 31.178, mean reward: 0.779 [0.001, 1.000], mean action: 25.000 [4.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.355132, mean_absolute_error: 6.287371, mean_q: 7.145738
411 (array([22]),) False
  37160/500000: episode: 929, duration: 30.015s, episode steps: 40, steps per second: 1, episode reward: 33.279, mean reward: 0.832 [0.053, 1.000], mean action: 23.825 [1.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.348197, mean_absolute_error: 6.276925, mean_q: 7.151641
372 (array([22]),) False
  37200/500000: episode: 930, duration: 30.762s, episode steps: 40, steps per second: 1, episode reward: 25.585, mean reward: 0.640 [0.080, 1.000], mean action: 16.250 [0.000, 56.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.399790, mean_absolute_error: 6.250513, mean_q: 7.117828
392 (array([40]),) False
  37240/500000: episode: 931, duration: 30.725s, episode steps: 40, steps per second: 1, episode reward: 29.165, mean reward: 0.729 [0.037, 1.000], mean action: 22.475 [2.000, 51.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.325923, mean_absolute_error: 6.251581, mean_q: 7.120887
699 (array([22]),) False
  37280/500000: episode: 932, duration: 30.812s, episode steps: 40, steps per second: 1, episode reward: 22.825, mean reward: 0.571 [0.075, 0.755], mean action: 23.975 [8.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.401288, mean_absolute_error: 6.256470, mean_q: 7.113276
120 (array([44]),) False
  37320/500000: episode: 933, duration: 29.969s, episode steps: 40, steps per second: 1, episode reward: 29.504, mean reward: 0.738 [0.185, 0.986], mean action: 25.300 [2.000, 51.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.357783, mean_absolute_error: 6.277674, mean_q: 7.145335
607 (array([12]),) False
  37360/500000: episode: 934, duration: 30.710s, episode steps: 40, steps per second: 1, episode reward: 35.117, mean reward: 0.878 [0.025, 1.000], mean action: 13.850 [2.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.395650, mean_absolute_error: 6.209889, mean_q: 7.084409
108 (array([48]),) False
  37400/500000: episode: 935, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 28.296, mean reward: 0.707 [0.084, 1.000], mean action: 24.600 [4.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.374834, mean_absolute_error: 6.229105, mean_q: 7.100000
272 (array([12]),) False
  37440/500000: episode: 936, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 28.300, mean reward: 0.707 [0.094, 1.000], mean action: 21.900 [0.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.383586, mean_absolute_error: 6.205469, mean_q: 7.084334
738 (array([12]),) False
  37480/500000: episode: 937, duration: 29.927s, episode steps: 40, steps per second: 1, episode reward: 31.177, mean reward: 0.779 [0.052, 1.000], mean action: 19.500 [10.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.341937, mean_absolute_error: 6.231558, mean_q: 7.094636
675 (array([22]),) False
  37520/500000: episode: 938, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 29.692, mean reward: 0.742 [0.141, 1.000], mean action: 23.750 [0.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.349347, mean_absolute_error: 6.210902, mean_q: 7.082906
538 (array([12]),) False
  37560/500000: episode: 939, duration: 30.787s, episode steps: 40, steps per second: 1, episode reward: 30.956, mean reward: 0.774 [0.061, 1.000], mean action: 23.150 [2.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.372717, mean_absolute_error: 6.230497, mean_q: 7.100095
565 (array([12]),) False
  37600/500000: episode: 940, duration: 30.772s, episode steps: 40, steps per second: 1, episode reward: 34.997, mean reward: 0.875 [0.348, 1.000], mean action: 19.275 [11.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.373224, mean_absolute_error: 6.183971, mean_q: 7.055727
34 (array([22]),) False
  37640/500000: episode: 941, duration: 30.033s, episode steps: 40, steps per second: 1, episode reward: 33.307, mean reward: 0.833 [0.079, 1.000], mean action: 23.600 [2.000, 59.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.370137, mean_absolute_error: 6.175201, mean_q: 7.025722
624 (array([48]),) False
  37680/500000: episode: 942, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 26.963, mean reward: 0.674 [0.069, 1.000], mean action: 25.100 [3.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.358986, mean_absolute_error: 6.207555, mean_q: 7.061662
353 (array([22]),) False
  37720/500000: episode: 943, duration: 30.760s, episode steps: 40, steps per second: 1, episode reward: 32.373, mean reward: 0.809 [0.129, 1.000], mean action: 24.575 [1.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.321666, mean_absolute_error: 6.231001, mean_q: 7.063844
595 (array([22]),) False
  37760/500000: episode: 944, duration: 30.744s, episode steps: 40, steps per second: 1, episode reward: 29.034, mean reward: 0.726 [0.149, 1.000], mean action: 19.025 [0.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.366356, mean_absolute_error: 6.254489, mean_q: 7.109803
369 (array([48]),) False
  37800/500000: episode: 945, duration: 30.020s, episode steps: 40, steps per second: 1, episode reward: 30.910, mean reward: 0.773 [0.025, 0.973], mean action: 23.150 [1.000, 56.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.391242, mean_absolute_error: 6.231256, mean_q: 7.102638
361 (array([22]),) False
  37840/500000: episode: 946, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 26.488, mean reward: 0.662 [0.000, 1.000], mean action: 18.825 [3.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.410245, mean_absolute_error: 6.214883, mean_q: 7.083143
407 (array([22]),) False
  37880/500000: episode: 947, duration: 30.689s, episode steps: 40, steps per second: 1, episode reward: 32.352, mean reward: 0.809 [0.014, 1.000], mean action: 24.275 [0.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.359910, mean_absolute_error: 6.183015, mean_q: 7.043527
804 (array([3]),) False
  37920/500000: episode: 948, duration: 30.807s, episode steps: 40, steps per second: 1, episode reward: 21.183, mean reward: 0.530 [0.094, 1.000], mean action: 20.350 [0.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.323616, mean_absolute_error: 6.219049, mean_q: 7.070827
536 (array([22]),) False
  37960/500000: episode: 949, duration: 29.991s, episode steps: 40, steps per second: 1, episode reward: 32.779, mean reward: 0.819 [0.025, 1.000], mean action: 26.025 [6.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.365445, mean_absolute_error: 6.186162, mean_q: 7.048043
191 (array([38]),) False
  38000/500000: episode: 950, duration: 30.723s, episode steps: 40, steps per second: 1, episode reward: 23.621, mean reward: 0.591 [0.039, 0.901], mean action: 16.950 [0.000, 48.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.369409, mean_absolute_error: 6.174998, mean_q: 7.023116
690 (array([22]),) False
  38040/500000: episode: 951, duration: 30.658s, episode steps: 40, steps per second: 1, episode reward: 30.228, mean reward: 0.756 [0.000, 1.000], mean action: 19.150 [3.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.332766, mean_absolute_error: 6.186043, mean_q: 7.038971
580 (array([22]),) False
  38080/500000: episode: 952, duration: 30.733s, episode steps: 40, steps per second: 1, episode reward: 28.792, mean reward: 0.720 [0.069, 1.000], mean action: 26.025 [9.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.393034, mean_absolute_error: 6.226151, mean_q: 7.067073
615 (array([36]),) False
  38120/500000: episode: 953, duration: 30.005s, episode steps: 40, steps per second: 1, episode reward: 23.525, mean reward: 0.588 [0.000, 0.930], mean action: 25.975 [2.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.366387, mean_absolute_error: 6.212791, mean_q: 7.045885
271 (array([18]),) False
  38160/500000: episode: 954, duration: 30.724s, episode steps: 40, steps per second: 1, episode reward: 27.933, mean reward: 0.698 [0.190, 0.895], mean action: 21.275 [10.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.337147, mean_absolute_error: 6.242532, mean_q: 7.100485
306 (array([22]),) False
  38200/500000: episode: 955, duration: 30.749s, episode steps: 40, steps per second: 1, episode reward: 33.412, mean reward: 0.835 [0.270, 1.000], mean action: 26.500 [12.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.358505, mean_absolute_error: 6.230370, mean_q: 7.091784
126 (array([22]),) False
  38240/500000: episode: 956, duration: 30.626s, episode steps: 40, steps per second: 1, episode reward: 26.717, mean reward: 0.668 [0.114, 1.000], mean action: 18.925 [0.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.378807, mean_absolute_error: 6.207311, mean_q: 7.063890
726 (array([12]),) False
  38280/500000: episode: 957, duration: 29.980s, episode steps: 40, steps per second: 1, episode reward: 28.584, mean reward: 0.715 [0.000, 1.000], mean action: 16.825 [0.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.357635, mean_absolute_error: 6.169706, mean_q: 7.035029
697 (array([22]),) False
  38320/500000: episode: 958, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 30.848, mean reward: 0.771 [0.058, 1.000], mean action: 16.400 [0.000, 43.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.328099, mean_absolute_error: 6.157928, mean_q: 6.998975
775 (array([58]),) False
  38360/500000: episode: 959, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 29.955, mean reward: 0.749 [0.036, 0.909], mean action: 41.125 [4.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.344943, mean_absolute_error: 6.165175, mean_q: 7.006296
124 (array([48]),) False
  38400/500000: episode: 960, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 28.866, mean reward: 0.722 [0.006, 0.970], mean action: 19.525 [6.000, 53.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.295893, mean_absolute_error: 6.162811, mean_q: 6.986475
209 (array([8]),) False
  38440/500000: episode: 961, duration: 29.982s, episode steps: 40, steps per second: 1, episode reward: 23.320, mean reward: 0.583 [0.122, 1.000], mean action: 29.100 [0.000, 56.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.359921, mean_absolute_error: 6.140862, mean_q: 6.970900
35 (array([48]),) False
  38480/500000: episode: 962, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 31.393, mean reward: 0.785 [0.000, 1.000], mean action: 32.150 [5.000, 60.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.392015, mean_absolute_error: 6.123934, mean_q: 6.962721
441 (array([22]),) False
  38520/500000: episode: 963, duration: 30.771s, episode steps: 40, steps per second: 1, episode reward: 30.103, mean reward: 0.753 [0.038, 1.000], mean action: 22.275 [6.000, 56.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.341543, mean_absolute_error: 6.125800, mean_q: 6.972764
258 (array([22]),) False
  38560/500000: episode: 964, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 28.089, mean reward: 0.702 [0.000, 1.000], mean action: 21.950 [1.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.359137, mean_absolute_error: 6.130173, mean_q: 6.975433
53 (array([22]),) False
  38600/500000: episode: 965, duration: 29.963s, episode steps: 40, steps per second: 1, episode reward: 32.920, mean reward: 0.823 [0.264, 1.000], mean action: 23.575 [3.000, 57.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.318889, mean_absolute_error: 6.157792, mean_q: 6.997228
538 (array([12]),) False
  38640/500000: episode: 966, duration: 30.758s, episode steps: 40, steps per second: 1, episode reward: 28.180, mean reward: 0.705 [0.000, 1.000], mean action: 21.200 [0.000, 59.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.317605, mean_absolute_error: 6.147334, mean_q: 6.972296
6 (array([58]),) False
  38680/500000: episode: 967, duration: 30.673s, episode steps: 40, steps per second: 1, episode reward: 33.308, mean reward: 0.833 [0.116, 1.000], mean action: 22.825 [0.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.353096, mean_absolute_error: 6.150289, mean_q: 7.000327
432 (array([22]),) False
  38720/500000: episode: 968, duration: 30.773s, episode steps: 40, steps per second: 1, episode reward: 32.035, mean reward: 0.801 [0.342, 1.000], mean action: 27.100 [7.000, 60.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.334992, mean_absolute_error: 6.193921, mean_q: 7.056670
90 (array([22]),) False
  38760/500000: episode: 969, duration: 29.964s, episode steps: 40, steps per second: 1, episode reward: 29.874, mean reward: 0.747 [0.168, 1.000], mean action: 24.550 [0.000, 54.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.329904, mean_absolute_error: 6.156945, mean_q: 7.025558
809 (array([48]),) False
  38800/500000: episode: 970, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 22.586, mean reward: 0.565 [0.007, 1.000], mean action: 19.050 [7.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.368344, mean_absolute_error: 6.130874, mean_q: 7.006151
775 (array([58]),) False
  38840/500000: episode: 971, duration: 30.664s, episode steps: 40, steps per second: 1, episode reward: 32.056, mean reward: 0.801 [0.000, 0.915], mean action: 47.450 [12.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.345194, mean_absolute_error: 6.184286, mean_q: 7.049428
556 (array([48]),) False
  38880/500000: episode: 972, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 18.998, mean reward: 0.475 [0.022, 0.657], mean action: 20.050 [9.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.327509, mean_absolute_error: 6.203748, mean_q: 7.075933
498 (array([12]),) False
  38920/500000: episode: 973, duration: 29.990s, episode steps: 40, steps per second: 1, episode reward: 24.404, mean reward: 0.610 [0.164, 1.000], mean action: 30.625 [5.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.354675, mean_absolute_error: 6.197146, mean_q: 7.052981
30 (array([22]),) False
  38960/500000: episode: 974, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 32.853, mean reward: 0.821 [0.065, 1.000], mean action: 27.375 [13.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.332538, mean_absolute_error: 6.197084, mean_q: 7.051197
602 (array([36]),) False
  39000/500000: episode: 975, duration: 30.725s, episode steps: 40, steps per second: 1, episode reward: 13.462, mean reward: 0.337 [0.000, 0.981], mean action: 28.050 [12.000, 53.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.357736, mean_absolute_error: 6.161078, mean_q: 7.015346
206 (array([22]),) False
  39040/500000: episode: 976, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 26.956, mean reward: 0.674 [0.176, 1.000], mean action: 18.400 [4.000, 60.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.289820, mean_absolute_error: 6.183784, mean_q: 7.026362
641 (array([22]),) False
  39080/500000: episode: 977, duration: 29.988s, episode steps: 40, steps per second: 1, episode reward: 28.700, mean reward: 0.718 [0.126, 1.000], mean action: 23.875 [3.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.358320, mean_absolute_error: 6.172482, mean_q: 7.007683
576 (array([58]),) False
  39120/500000: episode: 978, duration: 30.702s, episode steps: 40, steps per second: 1, episode reward: 24.894, mean reward: 0.622 [0.093, 1.000], mean action: 35.175 [1.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.330435, mean_absolute_error: 6.219047, mean_q: 7.047487
152 (array([58]),) False
  39160/500000: episode: 979, duration: 30.798s, episode steps: 40, steps per second: 1, episode reward: 27.871, mean reward: 0.697 [0.231, 1.000], mean action: 46.100 [6.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.332138, mean_absolute_error: 6.260347, mean_q: 7.111237
500 (array([22]),) False
  39200/500000: episode: 980, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 28.837, mean reward: 0.721 [0.035, 1.000], mean action: 23.150 [4.000, 56.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.313800, mean_absolute_error: 6.280193, mean_q: 7.139237
32 (array([48]),) False
  39240/500000: episode: 981, duration: 29.984s, episode steps: 40, steps per second: 1, episode reward: 29.349, mean reward: 0.734 [0.052, 1.000], mean action: 24.050 [1.000, 51.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.364288, mean_absolute_error: 6.255751, mean_q: 7.116301
516 (array([48]),) False
  39280/500000: episode: 982, duration: 30.760s, episode steps: 40, steps per second: 1, episode reward: 31.996, mean reward: 0.800 [0.117, 1.000], mean action: 23.600 [4.000, 52.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.363457, mean_absolute_error: 6.241526, mean_q: 7.082632
848 (array([44]),) False
  39320/500000: episode: 983, duration: 30.786s, episode steps: 40, steps per second: 1, episode reward: 25.414, mean reward: 0.635 [0.123, 0.920], mean action: 23.300 [0.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.339242, mean_absolute_error: 6.249315, mean_q: 7.099463
772 (array([46]),) False
  39360/500000: episode: 984, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 23.660, mean reward: 0.591 [0.099, 0.980], mean action: 18.950 [2.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.355804, mean_absolute_error: 6.252371, mean_q: 7.108793
338 (array([12]),) False
  39400/500000: episode: 985, duration: 30.013s, episode steps: 40, steps per second: 1, episode reward: 30.796, mean reward: 0.770 [0.086, 1.000], mean action: 17.325 [9.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.366412, mean_absolute_error: 6.215723, mean_q: 7.074870
116 (array([22]),) False
  39440/500000: episode: 986, duration: 30.768s, episode steps: 40, steps per second: 1, episode reward: 30.449, mean reward: 0.761 [0.000, 1.000], mean action: 21.175 [5.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.408267, mean_absolute_error: 6.222846, mean_q: 7.097703
525 (array([22]),) False
  39480/500000: episode: 987, duration: 30.731s, episode steps: 40, steps per second: 1, episode reward: 25.663, mean reward: 0.642 [0.019, 0.999], mean action: 20.875 [1.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.338044, mean_absolute_error: 6.226587, mean_q: 7.093182
184 (array([12]),) False
  39520/500000: episode: 988, duration: 30.780s, episode steps: 40, steps per second: 1, episode reward: 27.579, mean reward: 0.689 [0.062, 1.000], mean action: 23.025 [4.000, 54.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.382588, mean_absolute_error: 6.199927, mean_q: 7.062028
562 (array([22]),) False
  39560/500000: episode: 989, duration: 30.040s, episode steps: 40, steps per second: 1, episode reward: 24.757, mean reward: 0.619 [0.124, 1.000], mean action: 21.875 [1.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.357957, mean_absolute_error: 6.179784, mean_q: 7.059857
488 (array([22]),) False
  39600/500000: episode: 990, duration: 30.727s, episode steps: 40, steps per second: 1, episode reward: 32.599, mean reward: 0.815 [0.236, 1.000], mean action: 17.850 [12.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.366132, mean_absolute_error: 6.193011, mean_q: 7.071416
216 (array([22]),) False
  39640/500000: episode: 991, duration: 30.763s, episode steps: 40, steps per second: 1, episode reward: 24.542, mean reward: 0.614 [0.105, 1.000], mean action: 20.650 [0.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.374341, mean_absolute_error: 6.155819, mean_q: 7.016421
568 (array([22]),) False
  39680/500000: episode: 992, duration: 30.780s, episode steps: 40, steps per second: 1, episode reward: 29.227, mean reward: 0.731 [0.000, 0.960], mean action: 16.950 [0.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.322382, mean_absolute_error: 6.120889, mean_q: 6.974986
242 (array([22]),) False
  39720/500000: episode: 993, duration: 29.986s, episode steps: 40, steps per second: 1, episode reward: 31.408, mean reward: 0.785 [0.000, 1.000], mean action: 15.575 [1.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.371917, mean_absolute_error: 6.109515, mean_q: 6.951534
148 (array([22]),) False
  39760/500000: episode: 994, duration: 30.746s, episode steps: 40, steps per second: 1, episode reward: 32.477, mean reward: 0.812 [0.114, 1.000], mean action: 13.825 [1.000, 43.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.392709, mean_absolute_error: 6.096198, mean_q: 6.958371
454 (array([12]),) False
  39800/500000: episode: 995, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 27.369, mean reward: 0.684 [0.000, 1.000], mean action: 23.900 [4.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.331955, mean_absolute_error: 6.091147, mean_q: 6.932562
419 (array([40]),) False
  39840/500000: episode: 996, duration: 30.833s, episode steps: 40, steps per second: 1, episode reward: 29.646, mean reward: 0.741 [0.267, 1.000], mean action: 28.050 [0.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.345141, mean_absolute_error: 6.108311, mean_q: 6.960246
770 (array([22]),) False
  39880/500000: episode: 997, duration: 29.999s, episode steps: 40, steps per second: 1, episode reward: 29.509, mean reward: 0.738 [0.120, 1.000], mean action: 18.975 [5.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.318852, mean_absolute_error: 6.119666, mean_q: 6.953560
150 (array([22]),) False
  39920/500000: episode: 998, duration: 30.760s, episode steps: 40, steps per second: 1, episode reward: 31.177, mean reward: 0.779 [0.171, 1.000], mean action: 19.575 [12.000, 54.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.306995, mean_absolute_error: 6.151278, mean_q: 6.979341
570 (array([47]),) False
  39960/500000: episode: 999, duration: 30.750s, episode steps: 40, steps per second: 1, episode reward: 25.321, mean reward: 0.633 [0.063, 1.000], mean action: 24.800 [0.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.318725, mean_absolute_error: 6.162876, mean_q: 7.001845
92 (array([22]),) False
  40000/500000: episode: 1000, duration: 30.844s, episode steps: 40, steps per second: 1, episode reward: 33.845, mean reward: 0.846 [0.183, 1.000], mean action: 22.125 [4.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.341127, mean_absolute_error: 6.212152, mean_q: 7.057445
650 (array([22]),) False
  40040/500000: episode: 1001, duration: 30.107s, episode steps: 40, steps per second: 1, episode reward: 29.105, mean reward: 0.728 [0.073, 1.000], mean action: 23.500 [12.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.364913, mean_absolute_error: 6.186327, mean_q: 7.029194
639 (array([22]),) False
  40080/500000: episode: 1002, duration: 30.712s, episode steps: 40, steps per second: 1, episode reward: 25.324, mean reward: 0.633 [0.059, 0.817], mean action: 18.725 [0.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.322732, mean_absolute_error: 6.177310, mean_q: 7.021773
290 (array([22]),) False
  40120/500000: episode: 1003, duration: 30.703s, episode steps: 40, steps per second: 1, episode reward: 28.975, mean reward: 0.724 [0.039, 0.909], mean action: 19.100 [3.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.332337, mean_absolute_error: 6.165895, mean_q: 7.023514
9 (array([14]),) False
  40160/500000: episode: 1004, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 27.373, mean reward: 0.684 [0.000, 1.000], mean action: 27.850 [3.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.343531, mean_absolute_error: 6.148262, mean_q: 7.004239
370 (array([58]),) False
  40200/500000: episode: 1005, duration: 29.994s, episode steps: 40, steps per second: 1, episode reward: 18.807, mean reward: 0.470 [0.000, 1.000], mean action: 29.575 [1.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.335396, mean_absolute_error: 6.138367, mean_q: 6.991411
513 (array([12]),) False
  40240/500000: episode: 1006, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 27.995, mean reward: 0.700 [0.092, 1.000], mean action: 23.750 [2.000, 60.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.291135, mean_absolute_error: 6.180837, mean_q: 7.025804
215 (array([22]),) False
  40280/500000: episode: 1007, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 29.188, mean reward: 0.730 [0.152, 1.000], mean action: 20.450 [11.000, 51.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.362616, mean_absolute_error: 6.161751, mean_q: 7.009293
828 (array([48]),) False
  40320/500000: episode: 1008, duration: 30.844s, episode steps: 40, steps per second: 1, episode reward: 28.569, mean reward: 0.714 [0.000, 1.000], mean action: 21.225 [0.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.341254, mean_absolute_error: 6.128971, mean_q: 6.980408
699 (array([22]),) False
  40360/500000: episode: 1009, duration: 30.049s, episode steps: 40, steps per second: 1, episode reward: 27.398, mean reward: 0.685 [0.193, 1.000], mean action: 18.425 [12.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.338048, mean_absolute_error: 6.090224, mean_q: 6.934416
644 (array([12]),) False
  40400/500000: episode: 1010, duration: 30.780s, episode steps: 40, steps per second: 1, episode reward: 32.449, mean reward: 0.811 [0.266, 1.000], mean action: 24.150 [12.000, 55.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.348623, mean_absolute_error: 6.091662, mean_q: 6.929147
438 (array([22]),) False
  40440/500000: episode: 1011, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 34.081, mean reward: 0.852 [0.088, 1.000], mean action: 23.000 [2.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.341197, mean_absolute_error: 6.077014, mean_q: 6.917682
488 (array([22]),) False
  40480/500000: episode: 1012, duration: 30.841s, episode steps: 40, steps per second: 1, episode reward: 30.481, mean reward: 0.762 [0.000, 1.000], mean action: 15.875 [2.000, 50.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.324053, mean_absolute_error: 6.065549, mean_q: 6.908714
172 (array([12]),) False
  40520/500000: episode: 1013, duration: 30.024s, episode steps: 40, steps per second: 1, episode reward: 33.044, mean reward: 0.826 [0.245, 1.000], mean action: 18.275 [4.000, 59.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.281607, mean_absolute_error: 6.060033, mean_q: 6.914757
787 (array([3]),) False
  40560/500000: episode: 1014, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 19.706, mean reward: 0.493 [0.000, 1.000], mean action: 25.800 [1.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.349441, mean_absolute_error: 6.013058, mean_q: 6.854881
338 (array([12]),) False
  40600/500000: episode: 1015, duration: 30.695s, episode steps: 40, steps per second: 1, episode reward: 31.995, mean reward: 0.800 [0.100, 1.000], mean action: 17.200 [1.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.332621, mean_absolute_error: 6.024515, mean_q: 6.873548
730 (array([54]),) False
  40640/500000: episode: 1016, duration: 30.827s, episode steps: 40, steps per second: 1, episode reward: 28.427, mean reward: 0.711 [0.140, 1.000], mean action: 37.550 [4.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.307998, mean_absolute_error: 6.048190, mean_q: 6.872092
733 (array([22]),) False
  40680/500000: episode: 1017, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 31.837, mean reward: 0.796 [0.075, 0.998], mean action: 18.100 [4.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.301183, mean_absolute_error: 6.036395, mean_q: 6.863116
596 (array([22]),) False
  40720/500000: episode: 1018, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 29.346, mean reward: 0.734 [0.096, 1.000], mean action: 18.375 [9.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.332471, mean_absolute_error: 5.986476, mean_q: 6.821464
368 (array([22]),) False
  40760/500000: episode: 1019, duration: 30.799s, episode steps: 40, steps per second: 1, episode reward: 30.166, mean reward: 0.754 [0.000, 1.000], mean action: 19.525 [6.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.352365, mean_absolute_error: 6.000306, mean_q: 6.814003
633 (array([22]),) False
  40800/500000: episode: 1020, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 26.897, mean reward: 0.672 [0.051, 1.000], mean action: 19.625 [3.000, 49.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.318984, mean_absolute_error: 5.972830, mean_q: 6.802903
318 (array([48]),) False
  40840/500000: episode: 1021, duration: 30.020s, episode steps: 40, steps per second: 1, episode reward: 30.953, mean reward: 0.774 [0.000, 1.000], mean action: 20.650 [8.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.310499, mean_absolute_error: 6.016359, mean_q: 6.840752
90 (array([22]),) False
  40880/500000: episode: 1022, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 34.611, mean reward: 0.865 [0.138, 1.000], mean action: 26.300 [12.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.309611, mean_absolute_error: 6.049801, mean_q: 6.882802
730 (array([54]),) False
  40920/500000: episode: 1023, duration: 30.760s, episode steps: 40, steps per second: 1, episode reward: 25.261, mean reward: 0.632 [0.093, 1.000], mean action: 33.875 [1.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.342705, mean_absolute_error: 5.988521, mean_q: 6.826266
768 (array([22]),) False
  40960/500000: episode: 1024, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 25.236, mean reward: 0.631 [0.000, 1.000], mean action: 23.350 [2.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.336522, mean_absolute_error: 5.997209, mean_q: 6.817477
511 (array([22]),) False
  41000/500000: episode: 1025, duration: 29.955s, episode steps: 40, steps per second: 1, episode reward: 33.560, mean reward: 0.839 [0.000, 1.000], mean action: 21.125 [4.000, 57.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.319391, mean_absolute_error: 6.000075, mean_q: 6.826833
495 (array([48]),) False
  41040/500000: episode: 1026, duration: 30.736s, episode steps: 40, steps per second: 1, episode reward: 30.599, mean reward: 0.765 [0.000, 0.966], mean action: 20.325 [1.000, 55.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.307706, mean_absolute_error: 6.004636, mean_q: 6.833606
124 (array([48]),) False
  41080/500000: episode: 1027, duration: 30.740s, episode steps: 40, steps per second: 1, episode reward: 34.284, mean reward: 0.857 [0.169, 1.000], mean action: 22.775 [0.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.317025, mean_absolute_error: 6.010009, mean_q: 6.821803
162 (array([22]),) False
  41120/500000: episode: 1028, duration: 30.827s, episode steps: 40, steps per second: 1, episode reward: 29.134, mean reward: 0.728 [0.000, 0.906], mean action: 17.600 [2.000, 60.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.321369, mean_absolute_error: 5.977340, mean_q: 6.786572
1 (array([22]),) False
  41160/500000: episode: 1029, duration: 30.038s, episode steps: 40, steps per second: 1, episode reward: 18.459, mean reward: 0.461 [0.000, 1.000], mean action: 24.750 [2.000, 60.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.319055, mean_absolute_error: 5.940508, mean_q: 6.755114
645 (array([48]),) False
  41200/500000: episode: 1030, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 30.452, mean reward: 0.761 [0.000, 0.990], mean action: 17.275 [1.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.318062, mean_absolute_error: 5.971342, mean_q: 6.773515
827 (array([14]),) False
  41240/500000: episode: 1031, duration: 30.742s, episode steps: 40, steps per second: 1, episode reward: 27.869, mean reward: 0.697 [0.117, 1.000], mean action: 24.525 [5.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.325515, mean_absolute_error: 5.979154, mean_q: 6.802356
398 (array([22]),) False
  41280/500000: episode: 1032, duration: 30.765s, episode steps: 40, steps per second: 1, episode reward: 25.801, mean reward: 0.645 [0.055, 1.000], mean action: 26.225 [3.000, 57.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.334554, mean_absolute_error: 5.974892, mean_q: 6.802302
707 (array([48]),) False
  41320/500000: episode: 1033, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 29.526, mean reward: 0.738 [0.031, 0.943], mean action: 18.575 [2.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.292600, mean_absolute_error: 6.010567, mean_q: 6.827410
101 (array([22]),) False
  41360/500000: episode: 1034, duration: 30.784s, episode steps: 40, steps per second: 1, episode reward: 34.176, mean reward: 0.854 [0.207, 1.000], mean action: 24.600 [9.000, 55.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.359198, mean_absolute_error: 6.036529, mean_q: 6.868060
3 (array([48]),) False
  41400/500000: episode: 1035, duration: 30.751s, episode steps: 40, steps per second: 1, episode reward: 28.318, mean reward: 0.708 [0.016, 1.000], mean action: 25.800 [4.000, 54.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.333855, mean_absolute_error: 6.038100, mean_q: 6.879921
313 (array([22]),) False
  41440/500000: episode: 1036, duration: 30.743s, episode steps: 40, steps per second: 1, episode reward: 25.824, mean reward: 0.646 [0.007, 1.000], mean action: 25.650 [6.000, 58.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.301632, mean_absolute_error: 6.059246, mean_q: 6.869958
53 (array([22]),) False
  41480/500000: episode: 1037, duration: 29.959s, episode steps: 40, steps per second: 1, episode reward: 30.654, mean reward: 0.766 [0.000, 1.000], mean action: 23.400 [0.000, 53.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.318186, mean_absolute_error: 6.017505, mean_q: 6.844193
625 (array([22]),) False
  41520/500000: episode: 1038, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 33.639, mean reward: 0.841 [0.070, 1.000], mean action: 38.575 [3.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.328864, mean_absolute_error: 6.070341, mean_q: 6.896620
764 (array([48]),) False
  41560/500000: episode: 1039, duration: 30.747s, episode steps: 40, steps per second: 1, episode reward: 29.153, mean reward: 0.729 [0.177, 1.000], mean action: 19.650 [0.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.375286, mean_absolute_error: 6.072546, mean_q: 6.907659
489 (array([22]),) False
  41600/500000: episode: 1040, duration: 30.811s, episode steps: 40, steps per second: 1, episode reward: 28.196, mean reward: 0.705 [0.000, 1.000], mean action: 21.650 [7.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.317900, mean_absolute_error: 6.048755, mean_q: 6.876119
416 (array([22]),) False
  41640/500000: episode: 1041, duration: 29.946s, episode steps: 40, steps per second: 1, episode reward: 30.090, mean reward: 0.752 [0.135, 1.000], mean action: 30.425 [9.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.320623, mean_absolute_error: 6.059547, mean_q: 6.879161
585 (array([48]),) False
  41680/500000: episode: 1042, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 29.327, mean reward: 0.733 [0.000, 1.000], mean action: 23.900 [0.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.311106, mean_absolute_error: 6.057233, mean_q: 6.900031
615 (array([36]),) False
  41720/500000: episode: 1043, duration: 30.769s, episode steps: 40, steps per second: 1, episode reward: 25.957, mean reward: 0.649 [0.295, 0.965], mean action: 23.500 [1.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.350713, mean_absolute_error: 6.052421, mean_q: 6.877449
0 (array([48]),) False
  41760/500000: episode: 1044, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 26.206, mean reward: 0.655 [0.000, 1.000], mean action: 23.950 [2.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.329405, mean_absolute_error: 6.037676, mean_q: 6.895212
208 (array([22]),) False
  41800/500000: episode: 1045, duration: 30.034s, episode steps: 40, steps per second: 1, episode reward: 34.068, mean reward: 0.852 [0.321, 1.000], mean action: 20.725 [5.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.306013, mean_absolute_error: 6.043013, mean_q: 6.873553
441 (array([22]),) False
  41840/500000: episode: 1046, duration: 30.735s, episode steps: 40, steps per second: 1, episode reward: 30.297, mean reward: 0.757 [0.000, 1.000], mean action: 25.600 [7.000, 58.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.308597, mean_absolute_error: 6.056209, mean_q: 6.872771
766 (array([12]),) False
  41880/500000: episode: 1047, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 29.986, mean reward: 0.750 [0.046, 0.955], mean action: 19.325 [0.000, 51.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.311949, mean_absolute_error: 6.060099, mean_q: 6.889778
143 (array([12]),) False
  41920/500000: episode: 1048, duration: 30.834s, episode steps: 40, steps per second: 1, episode reward: 32.459, mean reward: 0.811 [0.404, 1.000], mean action: 17.650 [7.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.348792, mean_absolute_error: 6.017410, mean_q: 6.845542
219 (array([36]),) False
  41960/500000: episode: 1049, duration: 30.028s, episode steps: 40, steps per second: 1, episode reward: 10.790, mean reward: 0.270 [0.000, 0.764], mean action: 16.375 [4.000, 55.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.312499, mean_absolute_error: 6.008979, mean_q: 6.835922
603 (array([58]),) False
  42000/500000: episode: 1050, duration: 30.758s, episode steps: 40, steps per second: 1, episode reward: 20.202, mean reward: 0.505 [0.062, 0.880], mean action: 45.325 [0.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.320610, mean_absolute_error: 6.011879, mean_q: 6.843095
637 (array([12]),) False
  42040/500000: episode: 1051, duration: 30.759s, episode steps: 40, steps per second: 1, episode reward: 33.945, mean reward: 0.849 [0.042, 1.000], mean action: 14.375 [0.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.292185, mean_absolute_error: 5.983165, mean_q: 6.806574
176 (array([3]),) False
  42080/500000: episode: 1052, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 16.130, mean reward: 0.403 [0.039, 1.000], mean action: 27.775 [2.000, 58.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.316014, mean_absolute_error: 5.980477, mean_q: 6.801966
27 (array([22]),) False
  42120/500000: episode: 1053, duration: 29.962s, episode steps: 40, steps per second: 1, episode reward: 31.910, mean reward: 0.798 [0.000, 1.000], mean action: 23.600 [5.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.341299, mean_absolute_error: 6.019425, mean_q: 6.850462
0 (array([48]),) False
  42160/500000: episode: 1054, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 30.675, mean reward: 0.767 [0.014, 1.000], mean action: 23.075 [0.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.330325, mean_absolute_error: 6.011037, mean_q: 6.837875
449 (array([22]),) False
  42200/500000: episode: 1055, duration: 30.698s, episode steps: 40, steps per second: 1, episode reward: 28.079, mean reward: 0.702 [0.030, 1.000], mean action: 26.225 [2.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.305511, mean_absolute_error: 5.969051, mean_q: 6.789656
748 (array([22]),) False
  42240/500000: episode: 1056, duration: 30.821s, episode steps: 40, steps per second: 1, episode reward: 30.362, mean reward: 0.759 [0.107, 1.000], mean action: 16.925 [1.000, 54.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.300947, mean_absolute_error: 5.995022, mean_q: 6.812872
443 (array([22]),) False
  42280/500000: episode: 1057, duration: 29.958s, episode steps: 40, steps per second: 1, episode reward: 29.725, mean reward: 0.743 [0.010, 1.000], mean action: 23.875 [2.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.305357, mean_absolute_error: 5.969099, mean_q: 6.779910
801 (array([58]),) False
  42320/500000: episode: 1058, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 15.661, mean reward: 0.392 [0.002, 0.779], mean action: 19.400 [0.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.289210, mean_absolute_error: 5.999622, mean_q: 6.806775
712 (array([22]),) False
  42360/500000: episode: 1059, duration: 30.725s, episode steps: 40, steps per second: 1, episode reward: 29.363, mean reward: 0.734 [0.115, 0.832], mean action: 16.325 [12.000, 51.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.280398, mean_absolute_error: 6.018653, mean_q: 6.834460
723 (array([48]),) False
  42400/500000: episode: 1060, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 26.394, mean reward: 0.660 [0.070, 1.000], mean action: 21.525 [4.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.291876, mean_absolute_error: 6.051053, mean_q: 6.845006
754 (array([52]),) False
  42440/500000: episode: 1061, duration: 29.965s, episode steps: 40, steps per second: 1, episode reward: 34.618, mean reward: 0.865 [0.213, 0.986], mean action: 15.975 [1.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.387822, mean_absolute_error: 6.031172, mean_q: 6.863525
568 (array([22]),) False
  42480/500000: episode: 1062, duration: 30.714s, episode steps: 40, steps per second: 1, episode reward: 31.394, mean reward: 0.785 [0.011, 1.000], mean action: 17.000 [3.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.295167, mean_absolute_error: 5.975685, mean_q: 6.803729
815 (array([22]),) False
  42520/500000: episode: 1063, duration: 30.799s, episode steps: 40, steps per second: 1, episode reward: 30.444, mean reward: 0.761 [0.119, 1.000], mean action: 19.775 [2.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.318561, mean_absolute_error: 5.993569, mean_q: 6.811409
306 (array([22]),) False
  42560/500000: episode: 1064, duration: 30.767s, episode steps: 40, steps per second: 1, episode reward: 31.314, mean reward: 0.783 [0.135, 1.000], mean action: 25.050 [5.000, 50.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.328917, mean_absolute_error: 6.015537, mean_q: 6.838046
802 (array([22]),) False
  42600/500000: episode: 1065, duration: 29.956s, episode steps: 40, steps per second: 1, episode reward: 23.043, mean reward: 0.576 [0.150, 1.000], mean action: 21.525 [0.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.291864, mean_absolute_error: 5.972587, mean_q: 6.784995
149 (array([8]),) False
  42640/500000: episode: 1066, duration: 30.717s, episode steps: 40, steps per second: 1, episode reward: 14.617, mean reward: 0.365 [0.156, 0.734], mean action: 25.175 [5.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.297797, mean_absolute_error: 5.984910, mean_q: 6.790643
741 (array([22]),) False
  42680/500000: episode: 1067, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 31.313, mean reward: 0.783 [0.142, 1.000], mean action: 17.825 [1.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.320444, mean_absolute_error: 6.012010, mean_q: 6.813894
614 (array([22]),) False
  42720/500000: episode: 1068, duration: 31.275s, episode steps: 40, steps per second: 1, episode reward: 26.649, mean reward: 0.666 [0.058, 1.000], mean action: 18.750 [0.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.357706, mean_absolute_error: 5.957421, mean_q: 6.763124
561 (array([22]),) False
  42760/500000: episode: 1069, duration: 30.240s, episode steps: 40, steps per second: 1, episode reward: 27.292, mean reward: 0.682 [0.146, 1.000], mean action: 18.125 [11.000, 45.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.334901, mean_absolute_error: 5.963805, mean_q: 6.765251
838 (array([21]),) False
  42800/500000: episode: 1070, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 29.153, mean reward: 0.729 [0.134, 1.000], mean action: 24.550 [11.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.267908, mean_absolute_error: 6.004373, mean_q: 6.826120
614 (array([22]),) False
  42840/500000: episode: 1071, duration: 31.234s, episode steps: 40, steps per second: 1, episode reward: 25.491, mean reward: 0.637 [0.152, 1.000], mean action: 17.625 [0.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.309194, mean_absolute_error: 6.003448, mean_q: 6.821609
553 (array([22]),) False
  42880/500000: episode: 1072, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 30.252, mean reward: 0.756 [0.020, 1.000], mean action: 18.825 [2.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.320699, mean_absolute_error: 6.002412, mean_q: 6.824713
293 (array([22]),) False
  42920/500000: episode: 1073, duration: 30.215s, episode steps: 40, steps per second: 1, episode reward: 33.498, mean reward: 0.837 [0.041, 1.000], mean action: 20.900 [3.000, 53.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.345277, mean_absolute_error: 5.995086, mean_q: 6.826379
375 (array([22]),) False
  42960/500000: episode: 1074, duration: 30.962s, episode steps: 40, steps per second: 1, episode reward: 25.621, mean reward: 0.641 [0.074, 1.000], mean action: 20.100 [0.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.315404, mean_absolute_error: 6.034359, mean_q: 6.862292
722 (array([22]),) False
  43000/500000: episode: 1075, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 32.869, mean reward: 0.822 [0.119, 0.980], mean action: 15.875 [0.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.313246, mean_absolute_error: 6.007493, mean_q: 6.825055
499 (array([8]),) False
  43040/500000: episode: 1076, duration: 31.176s, episode steps: 40, steps per second: 1, episode reward: 18.596, mean reward: 0.465 [0.288, 0.967], mean action: 25.000 [9.000, 55.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.295483, mean_absolute_error: 6.040283, mean_q: 6.854581
709 (array([41]),) False
  43080/500000: episode: 1077, duration: 30.709s, episode steps: 40, steps per second: 1, episode reward: 20.587, mean reward: 0.515 [0.000, 0.765], mean action: 16.400 [0.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.302112, mean_absolute_error: 6.008285, mean_q: 6.837549
835 (array([50]),) False
  43120/500000: episode: 1078, duration: 31.464s, episode steps: 40, steps per second: 1, episode reward: 30.039, mean reward: 0.751 [0.000, 0.979], mean action: 16.925 [4.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.294113, mean_absolute_error: 6.052216, mean_q: 6.864221
476 (array([48]),) False
  43160/500000: episode: 1079, duration: 31.173s, episode steps: 40, steps per second: 1, episode reward: 30.949, mean reward: 0.774 [0.009, 1.000], mean action: 24.575 [3.000, 57.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.320057, mean_absolute_error: 6.033632, mean_q: 6.836273
162 (array([22]),) False
  43200/500000: episode: 1080, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 29.301, mean reward: 0.733 [0.263, 0.906], mean action: 17.475 [1.000, 53.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.322416, mean_absolute_error: 6.005473, mean_q: 6.818594
373 (array([22]),) False
  43240/500000: episode: 1081, duration: 30.263s, episode steps: 40, steps per second: 1, episode reward: 25.670, mean reward: 0.642 [0.000, 1.000], mean action: 19.175 [0.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.308942, mean_absolute_error: 5.992469, mean_q: 6.812003
189 (array([12]),) False
  43280/500000: episode: 1082, duration: 30.788s, episode steps: 40, steps per second: 1, episode reward: 31.444, mean reward: 0.786 [0.062, 1.000], mean action: 19.625 [5.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.320233, mean_absolute_error: 5.974989, mean_q: 6.788764
442 (array([22]),) False
  43320/500000: episode: 1083, duration: 31.165s, episode steps: 40, steps per second: 1, episode reward: 32.365, mean reward: 0.809 [0.000, 1.000], mean action: 21.625 [5.000, 50.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.338638, mean_absolute_error: 5.971490, mean_q: 6.789963
205 (array([22]),) False
  43360/500000: episode: 1084, duration: 31.136s, episode steps: 40, steps per second: 1, episode reward: 26.165, mean reward: 0.654 [0.166, 0.788], mean action: 22.550 [4.000, 53.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.305640, mean_absolute_error: 5.979669, mean_q: 6.798538
532 (array([25]),) False
  43400/500000: episode: 1085, duration: 30.150s, episode steps: 40, steps per second: 1, episode reward: 25.181, mean reward: 0.630 [0.077, 0.957], mean action: 25.875 [7.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.303363, mean_absolute_error: 5.995039, mean_q: 6.814420
672 (array([44]),) False
  43440/500000: episode: 1086, duration: 31.066s, episode steps: 40, steps per second: 1, episode reward: 30.080, mean reward: 0.752 [0.204, 1.000], mean action: 38.225 [3.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.275772, mean_absolute_error: 6.015481, mean_q: 6.840304
387 (array([22]),) False
  43480/500000: episode: 1087, duration: 31.223s, episode steps: 40, steps per second: 1, episode reward: 31.780, mean reward: 0.794 [0.034, 1.000], mean action: 29.075 [3.000, 55.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.309127, mean_absolute_error: 6.054444, mean_q: 6.867476
229 (array([48]),) False
  43520/500000: episode: 1088, duration: 31.729s, episode steps: 40, steps per second: 1, episode reward: 27.001, mean reward: 0.675 [0.205, 1.000], mean action: 20.950 [7.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.296533, mean_absolute_error: 6.082705, mean_q: 6.906570
16 (array([22]),) False
  43560/500000: episode: 1089, duration: 30.061s, episode steps: 40, steps per second: 1, episode reward: 31.311, mean reward: 0.783 [0.115, 1.000], mean action: 25.925 [5.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.309737, mean_absolute_error: 6.082642, mean_q: 6.898413
282 (array([22]),) False
  43600/500000: episode: 1090, duration: 30.846s, episode steps: 40, steps per second: 1, episode reward: 34.699, mean reward: 0.867 [0.300, 1.000], mean action: 25.525 [0.000, 60.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.326461, mean_absolute_error: 6.085362, mean_q: 6.921754
230 (array([22]),) False
  43640/500000: episode: 1091, duration: 30.778s, episode steps: 40, steps per second: 1, episode reward: 35.748, mean reward: 0.894 [0.034, 1.000], mean action: 18.650 [8.000, 55.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.291934, mean_absolute_error: 6.090848, mean_q: 6.908220
369 (array([48]),) False
  43680/500000: episode: 1092, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 34.715, mean reward: 0.868 [0.066, 0.973], mean action: 22.600 [1.000, 60.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.322853, mean_absolute_error: 6.081296, mean_q: 6.904689
336 (array([12]),) False
  43720/500000: episode: 1093, duration: 30.016s, episode steps: 40, steps per second: 1, episode reward: 30.506, mean reward: 0.763 [0.000, 1.000], mean action: 15.925 [0.000, 51.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.327461, mean_absolute_error: 6.077367, mean_q: 6.894168
727 (array([12]),) False
  43760/500000: episode: 1094, duration: 30.830s, episode steps: 40, steps per second: 1, episode reward: 29.014, mean reward: 0.725 [0.000, 1.000], mean action: 22.550 [4.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.299850, mean_absolute_error: 6.115573, mean_q: 6.917281
515 (array([22]),) False
  43800/500000: episode: 1095, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 31.688, mean reward: 0.792 [0.137, 1.000], mean action: 25.250 [7.000, 58.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.377462, mean_absolute_error: 6.076790, mean_q: 6.891703
117 (array([44]),) False
  43840/500000: episode: 1096, duration: 31.325s, episode steps: 40, steps per second: 1, episode reward: 27.110, mean reward: 0.678 [0.070, 0.826], mean action: 18.950 [5.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.294370, mean_absolute_error: 6.074821, mean_q: 6.879181
214 (array([22]),) False
  43880/500000: episode: 1097, duration: 30.289s, episode steps: 40, steps per second: 1, episode reward: 33.700, mean reward: 0.843 [0.263, 1.000], mean action: 24.900 [8.000, 54.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.338189, mean_absolute_error: 6.065005, mean_q: 6.884769
744 (array([22]),) False
  43920/500000: episode: 1098, duration: 31.286s, episode steps: 40, steps per second: 1, episode reward: 27.528, mean reward: 0.688 [0.085, 0.888], mean action: 16.575 [2.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.304912, mean_absolute_error: 6.033868, mean_q: 6.858176
570 (array([47]),) False
  43960/500000: episode: 1099, duration: 31.389s, episode steps: 40, steps per second: 1, episode reward: 27.784, mean reward: 0.695 [0.146, 1.000], mean action: 21.100 [6.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.260805, mean_absolute_error: 6.039417, mean_q: 6.851807
96 (array([22]),) False
  44000/500000: episode: 1100, duration: 31.559s, episode steps: 40, steps per second: 1, episode reward: 35.914, mean reward: 0.898 [0.072, 1.000], mean action: 22.825 [2.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.301736, mean_absolute_error: 6.022269, mean_q: 6.843025
110 (array([22]),) False
  44040/500000: episode: 1101, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 30.842, mean reward: 0.771 [0.150, 1.000], mean action: 22.125 [1.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.320598, mean_absolute_error: 6.020293, mean_q: 6.831010
681 (array([12]),) False
  44080/500000: episode: 1102, duration: 31.383s, episode steps: 40, steps per second: 1, episode reward: 32.956, mean reward: 0.824 [0.027, 1.000], mean action: 17.600 [4.000, 59.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.309341, mean_absolute_error: 6.027759, mean_q: 6.846460
785 (array([22]),) False
  44120/500000: episode: 1103, duration: 31.363s, episode steps: 40, steps per second: 1, episode reward: 27.619, mean reward: 0.690 [0.137, 0.829], mean action: 23.650 [3.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.301375, mean_absolute_error: 6.028706, mean_q: 6.838146
38 (array([22]),) False
  44160/500000: episode: 1104, duration: 31.326s, episode steps: 40, steps per second: 1, episode reward: 34.337, mean reward: 0.858 [0.079, 1.000], mean action: 24.825 [10.000, 59.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.329390, mean_absolute_error: 6.022691, mean_q: 6.833005
265 (array([22]),) False
  44200/500000: episode: 1105, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 31.700, mean reward: 0.793 [0.000, 1.000], mean action: 21.400 [6.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.274509, mean_absolute_error: 6.007591, mean_q: 6.812145
682 (array([22]),) False
  44240/500000: episode: 1106, duration: 31.378s, episode steps: 40, steps per second: 1, episode reward: 29.875, mean reward: 0.747 [0.112, 1.000], mean action: 24.750 [3.000, 60.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.269675, mean_absolute_error: 6.046484, mean_q: 6.852810
452 (array([22]),) False
  44280/500000: episode: 1107, duration: 31.346s, episode steps: 40, steps per second: 1, episode reward: 29.828, mean reward: 0.746 [0.000, 1.000], mean action: 24.750 [7.000, 54.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.316599, mean_absolute_error: 6.042243, mean_q: 6.854584
598 (array([22]),) False
  44320/500000: episode: 1108, duration: 31.304s, episode steps: 40, steps per second: 1, episode reward: 32.207, mean reward: 0.805 [0.285, 0.956], mean action: 16.025 [0.000, 53.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.292916, mean_absolute_error: 6.049417, mean_q: 6.849086
547 (array([21]),) False
  44360/500000: episode: 1109, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 27.458, mean reward: 0.686 [0.271, 1.000], mean action: 23.600 [0.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.287157, mean_absolute_error: 6.066161, mean_q: 6.863159
65 (array([48]),) False
  44400/500000: episode: 1110, duration: 31.304s, episode steps: 40, steps per second: 1, episode reward: 29.514, mean reward: 0.738 [0.116, 1.000], mean action: 22.625 [4.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.313600, mean_absolute_error: 6.082496, mean_q: 6.889494
569 (array([22]),) False
  44440/500000: episode: 1111, duration: 32.917s, episode steps: 40, steps per second: 1, episode reward: 27.851, mean reward: 0.696 [0.130, 1.000], mean action: 21.050 [2.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.280113, mean_absolute_error: 6.127412, mean_q: 6.931514
702 (array([22]),) False
  44480/500000: episode: 1112, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 31.619, mean reward: 0.790 [0.133, 1.000], mean action: 24.750 [10.000, 56.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.324395, mean_absolute_error: 6.095918, mean_q: 6.902535
251 (array([3]),) False
  44520/500000: episode: 1113, duration: 32.307s, episode steps: 40, steps per second: 1, episode reward: 13.203, mean reward: 0.330 [0.000, 1.000], mean action: 27.425 [0.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.284405, mean_absolute_error: 6.096231, mean_q: 6.910943
513 (array([12]),) False
  44560/500000: episode: 1114, duration: 33.201s, episode steps: 40, steps per second: 1, episode reward: 31.885, mean reward: 0.797 [0.068, 1.000], mean action: 17.900 [0.000, 56.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.329421, mean_absolute_error: 6.072596, mean_q: 6.888272
370 (array([58]),) False
  44600/500000: episode: 1115, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 20.608, mean reward: 0.515 [0.000, 1.000], mean action: 26.100 [5.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.282272, mean_absolute_error: 6.089675, mean_q: 6.895908
775 (array([58]),) False
  44640/500000: episode: 1116, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 31.562, mean reward: 0.789 [0.036, 0.915], mean action: 45.550 [0.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.330172, mean_absolute_error: 6.022743, mean_q: 6.849173
185 (array([22]),) False
  44680/500000: episode: 1117, duration: 32.299s, episode steps: 40, steps per second: 1, episode reward: 28.494, mean reward: 0.712 [0.232, 0.869], mean action: 20.450 [0.000, 56.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.322260, mean_absolute_error: 6.063516, mean_q: 6.875574
195 (array([22]),) False
  44720/500000: episode: 1118, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 32.815, mean reward: 0.820 [0.198, 1.000], mean action: 18.225 [1.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.317023, mean_absolute_error: 6.042385, mean_q: 6.832049
55 (array([22]),) False
  44760/500000: episode: 1119, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 30.250, mean reward: 0.756 [0.098, 1.000], mean action: 25.100 [2.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.314434, mean_absolute_error: 6.013771, mean_q: 6.819903
333 (array([12]),) False
  44800/500000: episode: 1120, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 33.271, mean reward: 0.832 [0.020, 1.000], mean action: 19.725 [6.000, 51.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.319132, mean_absolute_error: 6.038878, mean_q: 6.855086
436 (array([22]),) False
  44840/500000: episode: 1121, duration: 32.292s, episode steps: 40, steps per second: 1, episode reward: 30.484, mean reward: 0.762 [0.025, 1.000], mean action: 22.575 [0.000, 58.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.318493, mean_absolute_error: 6.029341, mean_q: 6.835575
838 (array([21]),) False
  44880/500000: episode: 1122, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 30.631, mean reward: 0.766 [0.269, 1.000], mean action: 16.675 [5.000, 49.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.347710, mean_absolute_error: 6.004833, mean_q: 6.817467
568 (array([22]),) False
  44920/500000: episode: 1123, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 33.287, mean reward: 0.832 [0.117, 1.000], mean action: 20.650 [12.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.291800, mean_absolute_error: 6.032369, mean_q: 6.828321
106 (array([22]),) False
  44960/500000: episode: 1124, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 28.554, mean reward: 0.714 [0.255, 1.000], mean action: 19.200 [1.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.325143, mean_absolute_error: 5.982456, mean_q: 6.777055
323 (array([55]),) False
  45000/500000: episode: 1125, duration: 32.287s, episode steps: 40, steps per second: 1, episode reward: 25.522, mean reward: 0.638 [0.020, 0.830], mean action: 25.225 [3.000, 52.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.298613, mean_absolute_error: 5.985000, mean_q: 6.774759
406 (array([48]),) False
  45040/500000: episode: 1126, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 32.385, mean reward: 0.810 [0.020, 1.000], mean action: 26.600 [5.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.302869, mean_absolute_error: 5.996747, mean_q: 6.793428
452 (array([22]),) False
  45080/500000: episode: 1127, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 30.758, mean reward: 0.769 [0.390, 1.000], mean action: 23.775 [4.000, 60.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.303145, mean_absolute_error: 5.964286, mean_q: 6.766856
803 (array([58]),) False
  45120/500000: episode: 1128, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 21.007, mean reward: 0.525 [0.188, 1.000], mean action: 25.575 [3.000, 51.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.288954, mean_absolute_error: 5.987079, mean_q: 6.794894
194 (array([44]),) False
  45160/500000: episode: 1129, duration: 32.234s, episode steps: 40, steps per second: 1, episode reward: 26.486, mean reward: 0.662 [0.060, 0.929], mean action: 23.750 [3.000, 58.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.299454, mean_absolute_error: 5.976088, mean_q: 6.785964
283 (array([34]),) False
  45200/500000: episode: 1130, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 16.263, mean reward: 0.407 [0.000, 1.000], mean action: 30.225 [5.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.289716, mean_absolute_error: 6.003965, mean_q: 6.786935
603 (array([58]),) False
  45240/500000: episode: 1131, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 21.435, mean reward: 0.536 [0.046, 1.000], mean action: 38.350 [1.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.311611, mean_absolute_error: 5.963042, mean_q: 6.763706
431 (array([22]),) False
  45280/500000: episode: 1132, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 34.313, mean reward: 0.858 [0.101, 1.000], mean action: 21.100 [0.000, 46.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.276094, mean_absolute_error: 5.934011, mean_q: 6.732753
788 (array([3]),) False
  45320/500000: episode: 1133, duration: 32.278s, episode steps: 40, steps per second: 1, episode reward: 19.790, mean reward: 0.495 [0.000, 0.891], mean action: 36.625 [0.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.303452, mean_absolute_error: 5.918610, mean_q: 6.723348
708 (array([40]),) False
  45360/500000: episode: 1134, duration: 32.950s, episode steps: 40, steps per second: 1, episode reward: 26.254, mean reward: 0.656 [0.009, 1.000], mean action: 19.725 [5.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.318263, mean_absolute_error: 5.906698, mean_q: 6.693517
715 (array([22]),) False
  45400/500000: episode: 1135, duration: 31.405s, episode steps: 40, steps per second: 1, episode reward: 31.573, mean reward: 0.789 [0.229, 0.940], mean action: 20.375 [5.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.278258, mean_absolute_error: 5.891956, mean_q: 6.684793
136 (array([12]),) False
  45440/500000: episode: 1136, duration: 31.338s, episode steps: 40, steps per second: 1, episode reward: 35.342, mean reward: 0.884 [0.229, 1.000], mean action: 17.675 [10.000, 53.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.299720, mean_absolute_error: 5.889422, mean_q: 6.664430
820 (array([48]),) False
  45480/500000: episode: 1137, duration: 30.994s, episode steps: 40, steps per second: 1, episode reward: 25.046, mean reward: 0.626 [0.000, 0.855], mean action: 20.875 [0.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.253862, mean_absolute_error: 5.918976, mean_q: 6.699429
703 (array([3]),) False
  45520/500000: episode: 1138, duration: 31.310s, episode steps: 40, steps per second: 1, episode reward: 20.105, mean reward: 0.503 [0.024, 1.000], mean action: 28.450 [1.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.272051, mean_absolute_error: 5.893382, mean_q: 6.666621
262 (array([22]),) False
  45560/500000: episode: 1139, duration: 31.340s, episode steps: 40, steps per second: 1, episode reward: 27.977, mean reward: 0.699 [0.107, 1.000], mean action: 28.500 [13.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.280713, mean_absolute_error: 5.905876, mean_q: 6.698810
27 (array([22]),) False
  45600/500000: episode: 1140, duration: 31.323s, episode steps: 40, steps per second: 1, episode reward: 35.161, mean reward: 0.879 [0.000, 1.000], mean action: 22.675 [6.000, 44.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.274193, mean_absolute_error: 5.905395, mean_q: 6.681247
272 (array([12]),) False
  45640/500000: episode: 1141, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 30.071, mean reward: 0.752 [0.026, 1.000], mean action: 18.750 [2.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.304984, mean_absolute_error: 5.873016, mean_q: 6.653797
609 (array([22]),) False
  45680/500000: episode: 1142, duration: 31.381s, episode steps: 40, steps per second: 1, episode reward: 29.745, mean reward: 0.744 [0.239, 1.000], mean action: 19.525 [5.000, 49.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.292292, mean_absolute_error: 5.925661, mean_q: 6.711017
447 (array([44]),) False
  45720/500000: episode: 1143, duration: 31.335s, episode steps: 40, steps per second: 1, episode reward: 25.532, mean reward: 0.638 [0.061, 1.000], mean action: 23.100 [0.000, 59.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.298713, mean_absolute_error: 5.879085, mean_q: 6.659309
619 (array([3]),) False
  45760/500000: episode: 1144, duration: 31.395s, episode steps: 40, steps per second: 1, episode reward: 12.956, mean reward: 0.324 [0.007, 1.000], mean action: 31.225 [3.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.271737, mean_absolute_error: 5.920862, mean_q: 6.695066
357 (array([22]),) False
  45800/500000: episode: 1145, duration: 31.136s, episode steps: 40, steps per second: 1, episode reward: 29.506, mean reward: 0.738 [0.061, 1.000], mean action: 27.125 [0.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.297152, mean_absolute_error: 5.935496, mean_q: 6.700589
777 (array([48]),) False
  45840/500000: episode: 1146, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 29.049, mean reward: 0.726 [0.072, 1.000], mean action: 17.225 [2.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.294204, mean_absolute_error: 5.898101, mean_q: 6.667665
316 (array([12]),) False
  45880/500000: episode: 1147, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 30.182, mean reward: 0.755 [0.101, 1.000], mean action: 22.300 [8.000, 58.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.297808, mean_absolute_error: 5.891326, mean_q: 6.675795
718 (array([12]),) False
  45920/500000: episode: 1148, duration: 32.335s, episode steps: 40, steps per second: 1, episode reward: 36.349, mean reward: 0.909 [0.366, 1.000], mean action: 17.850 [12.000, 52.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.290823, mean_absolute_error: 5.907912, mean_q: 6.682899
511 (array([22]),) False
  45960/500000: episode: 1149, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 33.637, mean reward: 0.841 [0.253, 1.000], mean action: 18.950 [1.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.333447, mean_absolute_error: 5.876143, mean_q: 6.660045
486 (array([22]),) False
  46000/500000: episode: 1150, duration: 31.358s, episode steps: 40, steps per second: 1, episode reward: 30.935, mean reward: 0.773 [0.138, 1.000], mean action: 14.600 [1.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.286348, mean_absolute_error: 5.888681, mean_q: 6.669420
665 (array([12]),) False
  46040/500000: episode: 1151, duration: 31.287s, episode steps: 40, steps per second: 1, episode reward: 23.909, mean reward: 0.598 [0.000, 1.000], mean action: 24.550 [0.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.313972, mean_absolute_error: 5.892425, mean_q: 6.678754
796 (array([38]),) False
  46080/500000: episode: 1152, duration: 31.443s, episode steps: 40, steps per second: 1, episode reward: 32.471, mean reward: 0.812 [0.142, 0.995], mean action: 17.800 [0.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.301932, mean_absolute_error: 5.882418, mean_q: 6.655751
559 (array([59]),) False
  46120/500000: episode: 1153, duration: 31.090s, episode steps: 40, steps per second: 1, episode reward: 25.124, mean reward: 0.628 [0.089, 1.000], mean action: 25.625 [2.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.298948, mean_absolute_error: 5.898921, mean_q: 6.679277
5 (array([37]),) False
  46160/500000: episode: 1154, duration: 31.333s, episode steps: 40, steps per second: 1, episode reward: 33.093, mean reward: 0.827 [0.035, 0.961], mean action: 17.450 [9.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.303604, mean_absolute_error: 5.886699, mean_q: 6.683596
835 (array([50]),) False
  46200/500000: episode: 1155, duration: 31.428s, episode steps: 40, steps per second: 1, episode reward: 31.004, mean reward: 0.775 [0.275, 0.941], mean action: 19.200 [2.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.287385, mean_absolute_error: 5.845950, mean_q: 6.628442
63 (array([18]),) False
  46240/500000: episode: 1156, duration: 31.314s, episode steps: 40, steps per second: 1, episode reward: 34.017, mean reward: 0.850 [0.014, 0.990], mean action: 18.750 [3.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.288270, mean_absolute_error: 5.819941, mean_q: 6.609675
480 (array([22]),) False
  46280/500000: episode: 1157, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 19.844, mean reward: 0.496 [0.083, 1.000], mean action: 18.800 [1.000, 53.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.276834, mean_absolute_error: 5.869960, mean_q: 6.655760
680 (array([22]),) False
  46320/500000: episode: 1158, duration: 31.393s, episode steps: 40, steps per second: 1, episode reward: 30.346, mean reward: 0.759 [0.000, 1.000], mean action: 20.150 [4.000, 60.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.237327, mean_absolute_error: 5.888036, mean_q: 6.669797
578 (array([22]),) False
  46360/500000: episode: 1159, duration: 31.337s, episode steps: 40, steps per second: 1, episode reward: 29.637, mean reward: 0.741 [0.085, 1.000], mean action: 22.750 [0.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.274902, mean_absolute_error: 5.913565, mean_q: 6.702773
94 (array([44]),) False
  46400/500000: episode: 1160, duration: 31.332s, episode steps: 40, steps per second: 1, episode reward: 31.469, mean reward: 0.787 [0.219, 1.000], mean action: 24.450 [0.000, 52.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.264702, mean_absolute_error: 5.883335, mean_q: 6.677455
341 (array([22]),) False
  46440/500000: episode: 1161, duration: 30.892s, episode steps: 40, steps per second: 1, episode reward: 32.138, mean reward: 0.803 [0.127, 1.000], mean action: 24.875 [12.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.287789, mean_absolute_error: 5.888658, mean_q: 6.679923
8 (array([22]),) False
  46480/500000: episode: 1162, duration: 31.428s, episode steps: 40, steps per second: 1, episode reward: 29.038, mean reward: 0.726 [0.017, 1.000], mean action: 29.175 [8.000, 60.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.261459, mean_absolute_error: 5.907919, mean_q: 6.691907
622 (array([36]),) False
  46520/500000: episode: 1163, duration: 31.331s, episode steps: 40, steps per second: 1, episode reward: 16.776, mean reward: 0.419 [0.178, 1.000], mean action: 31.050 [4.000, 58.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.271091, mean_absolute_error: 5.912885, mean_q: 6.687128
485 (array([22]),) False
  46560/500000: episode: 1164, duration: 31.358s, episode steps: 40, steps per second: 1, episode reward: 30.083, mean reward: 0.752 [0.065, 0.942], mean action: 18.400 [1.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.269482, mean_absolute_error: 5.930414, mean_q: 6.704535
424 (array([22]),) False
  46600/500000: episode: 1165, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 28.858, mean reward: 0.721 [0.000, 1.000], mean action: 23.650 [1.000, 54.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.304402, mean_absolute_error: 5.931764, mean_q: 6.709233
494 (array([48]),) False
  46640/500000: episode: 1166, duration: 31.366s, episode steps: 40, steps per second: 1, episode reward: 26.999, mean reward: 0.675 [0.077, 0.808], mean action: 15.125 [1.000, 51.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.290892, mean_absolute_error: 5.940825, mean_q: 6.718643
608 (array([36]),) False
  46680/500000: episode: 1167, duration: 31.343s, episode steps: 40, steps per second: 1, episode reward: 18.066, mean reward: 0.452 [0.000, 0.926], mean action: 32.825 [9.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.327401, mean_absolute_error: 5.927562, mean_q: 6.704213
459 (array([22]),) False
  46720/500000: episode: 1168, duration: 31.376s, episode steps: 40, steps per second: 1, episode reward: 29.819, mean reward: 0.745 [0.090, 1.000], mean action: 24.725 [4.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.300778, mean_absolute_error: 5.870643, mean_q: 6.655562
180 (array([48]),) False
  46760/500000: episode: 1169, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 34.307, mean reward: 0.858 [0.067, 0.981], mean action: 18.050 [0.000, 54.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.283507, mean_absolute_error: 5.891387, mean_q: 6.665784
336 (array([12]),) False
  46800/500000: episode: 1170, duration: 31.464s, episode steps: 40, steps per second: 1, episode reward: 31.722, mean reward: 0.793 [0.165, 1.000], mean action: 21.575 [1.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.298710, mean_absolute_error: 5.919700, mean_q: 6.702795
51 (array([22]),) False
  46840/500000: episode: 1171, duration: 31.403s, episode steps: 40, steps per second: 1, episode reward: 31.615, mean reward: 0.790 [0.052, 1.000], mean action: 24.575 [3.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.304530, mean_absolute_error: 5.896373, mean_q: 6.681567
561 (array([22]),) False
  46880/500000: episode: 1172, duration: 31.374s, episode steps: 40, steps per second: 1, episode reward: 27.594, mean reward: 0.690 [0.000, 1.000], mean action: 18.875 [1.000, 56.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.282577, mean_absolute_error: 5.874670, mean_q: 6.665477
3 (array([48]),) False
  46920/500000: episode: 1173, duration: 31.013s, episode steps: 40, steps per second: 1, episode reward: 28.013, mean reward: 0.700 [0.000, 1.000], mean action: 24.700 [3.000, 58.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.271577, mean_absolute_error: 5.886120, mean_q: 6.666233
760 (array([22]),) False
  46960/500000: episode: 1174, duration: 31.473s, episode steps: 40, steps per second: 1, episode reward: 26.554, mean reward: 0.664 [0.160, 1.000], mean action: 23.625 [9.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.306307, mean_absolute_error: 5.876567, mean_q: 6.657786
479 (array([22]),) False
  47000/500000: episode: 1175, duration: 31.414s, episode steps: 40, steps per second: 1, episode reward: 30.530, mean reward: 0.763 [0.032, 1.000], mean action: 19.400 [0.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.261665, mean_absolute_error: 5.923316, mean_q: 6.699203
672 (array([44]),) False
  47040/500000: episode: 1176, duration: 31.438s, episode steps: 40, steps per second: 1, episode reward: 30.027, mean reward: 0.751 [0.243, 1.000], mean action: 34.475 [2.000, 58.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.279468, mean_absolute_error: 5.885372, mean_q: 6.652812
254 (array([22]),) False
  47080/500000: episode: 1177, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 31.434, mean reward: 0.786 [0.000, 1.000], mean action: 16.975 [8.000, 46.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.300206, mean_absolute_error: 5.897767, mean_q: 6.674779
137 (array([22]),) False
  47120/500000: episode: 1178, duration: 31.437s, episode steps: 40, steps per second: 1, episode reward: 32.910, mean reward: 0.823 [0.212, 1.000], mean action: 15.675 [1.000, 43.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.322546, mean_absolute_error: 5.917363, mean_q: 6.686912
99 (array([22]),) False
  47160/500000: episode: 1179, duration: 31.188s, episode steps: 40, steps per second: 1, episode reward: 34.222, mean reward: 0.856 [0.103, 1.000], mean action: 22.525 [4.000, 50.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.311808, mean_absolute_error: 5.922368, mean_q: 6.716156
314 (array([22]),) False
  47200/500000: episode: 1180, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 32.793, mean reward: 0.820 [0.224, 1.000], mean action: 17.875 [3.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.291940, mean_absolute_error: 5.856909, mean_q: 6.646657
328 (array([12]),) False
  47240/500000: episode: 1181, duration: 30.211s, episode steps: 40, steps per second: 1, episode reward: 28.965, mean reward: 0.724 [0.070, 1.000], mean action: 20.975 [7.000, 58.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.302827, mean_absolute_error: 5.905419, mean_q: 6.686852
225 (array([48]),) False
  47280/500000: episode: 1182, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 34.020, mean reward: 0.851 [0.082, 1.000], mean action: 17.475 [9.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.322346, mean_absolute_error: 5.875614, mean_q: 6.671992
746 (array([37]),) False
  47320/500000: episode: 1183, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 31.153, mean reward: 0.779 [0.051, 0.964], mean action: 17.925 [0.000, 51.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.295861, mean_absolute_error: 5.897194, mean_q: 6.675133
55 (array([22]),) False
  47360/500000: episode: 1184, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 29.001, mean reward: 0.725 [0.164, 1.000], mean action: 26.375 [11.000, 55.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.286108, mean_absolute_error: 5.895712, mean_q: 6.684553
409 (array([22]),) False
  47400/500000: episode: 1185, duration: 30.129s, episode steps: 40, steps per second: 1, episode reward: 33.916, mean reward: 0.848 [0.051, 1.000], mean action: 24.025 [2.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.274309, mean_absolute_error: 5.916252, mean_q: 6.695570
703 (array([3]),) False
  47440/500000: episode: 1186, duration: 30.871s, episode steps: 40, steps per second: 1, episode reward: 14.484, mean reward: 0.362 [0.000, 1.000], mean action: 25.150 [1.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.297830, mean_absolute_error: 5.935439, mean_q: 6.721612
626 (array([22]),) False
  47480/500000: episode: 1187, duration: 30.876s, episode steps: 40, steps per second: 1, episode reward: 28.465, mean reward: 0.712 [0.123, 0.905], mean action: 24.950 [1.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.264973, mean_absolute_error: 5.965407, mean_q: 6.757681
670 (array([22]),) False
  47520/500000: episode: 1188, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 26.452, mean reward: 0.661 [0.000, 1.000], mean action: 20.625 [3.000, 49.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.304937, mean_absolute_error: 5.964268, mean_q: 6.749454
641 (array([22]),) False
  47560/500000: episode: 1189, duration: 30.096s, episode steps: 40, steps per second: 1, episode reward: 30.649, mean reward: 0.766 [0.156, 1.000], mean action: 25.175 [1.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.285227, mean_absolute_error: 5.999890, mean_q: 6.788851
290 (array([22]),) False
  47600/500000: episode: 1190, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 29.923, mean reward: 0.748 [0.159, 0.909], mean action: 17.150 [0.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.324328, mean_absolute_error: 5.961416, mean_q: 6.746024
442 (array([22]),) False
  47640/500000: episode: 1191, duration: 30.845s, episode steps: 40, steps per second: 1, episode reward: 28.658, mean reward: 0.716 [0.117, 1.000], mean action: 24.000 [1.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.305489, mean_absolute_error: 5.963839, mean_q: 6.752594
838 (array([21]),) False
  47680/500000: episode: 1192, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 32.703, mean reward: 0.818 [0.211, 1.000], mean action: 22.825 [7.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.253404, mean_absolute_error: 5.930129, mean_q: 6.711694
860 (array([12]),) False
  47720/500000: episode: 1193, duration: 30.192s, episode steps: 40, steps per second: 1, episode reward: 30.847, mean reward: 0.771 [0.000, 1.000], mean action: 18.400 [2.000, 57.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.299511, mean_absolute_error: 5.944394, mean_q: 6.730778
840 (array([12]),) False
  47760/500000: episode: 1194, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 30.420, mean reward: 0.760 [0.067, 1.000], mean action: 20.350 [9.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.329802, mean_absolute_error: 5.945231, mean_q: 6.723867
627 (array([48]),) False
  47800/500000: episode: 1195, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 30.595, mean reward: 0.765 [0.188, 1.000], mean action: 23.075 [12.000, 59.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.300342, mean_absolute_error: 5.932303, mean_q: 6.728095
260 (array([22]),) False
  47840/500000: episode: 1196, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 31.128, mean reward: 0.778 [0.040, 1.000], mean action: 26.475 [12.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.294802, mean_absolute_error: 5.913790, mean_q: 6.694951
847 (array([21]),) False
  47880/500000: episode: 1197, duration: 30.272s, episode steps: 40, steps per second: 1, episode reward: 31.452, mean reward: 0.786 [0.318, 1.000], mean action: 18.650 [0.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.303433, mean_absolute_error: 5.897501, mean_q: 6.670841
230 (array([22]),) False
  47920/500000: episode: 1198, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 32.427, mean reward: 0.811 [0.045, 1.000], mean action: 19.200 [1.000, 59.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.252202, mean_absolute_error: 5.918038, mean_q: 6.709129
665 (array([12]),) False
  47960/500000: episode: 1199, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 29.250, mean reward: 0.731 [0.170, 1.000], mean action: 24.525 [12.000, 52.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.291094, mean_absolute_error: 5.908655, mean_q: 6.699088
39 (array([22]),) False
  48000/500000: episode: 1200, duration: 30.987s, episode steps: 40, steps per second: 1, episode reward: 32.316, mean reward: 0.808 [0.131, 1.000], mean action: 24.525 [0.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.313208, mean_absolute_error: 5.955781, mean_q: 6.728712
269 (array([36]),) False
  48040/500000: episode: 1201, duration: 30.146s, episode steps: 40, steps per second: 1, episode reward: 21.742, mean reward: 0.544 [0.113, 1.000], mean action: 23.825 [12.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.314368, mean_absolute_error: 5.940550, mean_q: 6.715583
469 (array([22]),) False
  48080/500000: episode: 1202, duration: 30.851s, episode steps: 40, steps per second: 1, episode reward: 33.036, mean reward: 0.826 [0.082, 1.000], mean action: 23.875 [1.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.279106, mean_absolute_error: 5.945491, mean_q: 6.710716
166 (array([22]),) False
  48120/500000: episode: 1203, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 27.367, mean reward: 0.684 [0.221, 1.000], mean action: 16.325 [1.000, 51.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.301914, mean_absolute_error: 5.937734, mean_q: 6.703630
546 (array([22]),) False
  48160/500000: episode: 1204, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 33.998, mean reward: 0.850 [0.032, 1.000], mean action: 23.550 [0.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.292689, mean_absolute_error: 5.889319, mean_q: 6.660228
312 (array([12]),) False
  48200/500000: episode: 1205, duration: 30.189s, episode steps: 40, steps per second: 1, episode reward: 32.899, mean reward: 0.822 [0.000, 1.000], mean action: 18.225 [1.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.291125, mean_absolute_error: 5.873023, mean_q: 6.658233
727 (array([12]),) False
  48240/500000: episode: 1206, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 36.563, mean reward: 0.914 [0.255, 1.000], mean action: 16.550 [12.000, 46.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.283179, mean_absolute_error: 5.873156, mean_q: 6.656489
223 (array([48]),) False
  48280/500000: episode: 1207, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 27.087, mean reward: 0.677 [0.000, 1.000], mean action: 17.300 [1.000, 58.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.274156, mean_absolute_error: 5.876315, mean_q: 6.664268
296 (array([22]),) False
  48320/500000: episode: 1208, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 32.077, mean reward: 0.802 [0.054, 1.000], mean action: 28.750 [6.000, 49.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.285929, mean_absolute_error: 5.888550, mean_q: 6.662833
291 (array([22]),) False
  48360/500000: episode: 1209, duration: 30.190s, episode steps: 40, steps per second: 1, episode reward: 29.732, mean reward: 0.743 [0.040, 1.000], mean action: 19.025 [1.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.281427, mean_absolute_error: 5.861447, mean_q: 6.638878
333 (array([12]),) False
  48400/500000: episode: 1210, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 32.904, mean reward: 0.823 [0.053, 1.000], mean action: 18.300 [2.000, 58.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.294483, mean_absolute_error: 5.888246, mean_q: 6.668629
604 (array([40]),) False
  48440/500000: episode: 1211, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 32.249, mean reward: 0.806 [0.000, 1.000], mean action: 22.775 [7.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.286279, mean_absolute_error: 5.855307, mean_q: 6.630713
112 (array([12]),) False
  48480/500000: episode: 1212, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 32.214, mean reward: 0.805 [0.050, 1.000], mean action: 16.050 [0.000, 47.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.276351, mean_absolute_error: 5.882945, mean_q: 6.668982
576 (array([58]),) False
  48520/500000: episode: 1213, duration: 30.164s, episode steps: 40, steps per second: 1, episode reward: 23.998, mean reward: 0.600 [0.000, 0.804], mean action: 30.950 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.302652, mean_absolute_error: 5.869097, mean_q: 6.659282
506 (array([8]),) False
  48560/500000: episode: 1214, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 12.364, mean reward: 0.309 [0.061, 0.981], mean action: 21.650 [0.000, 53.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.300204, mean_absolute_error: 5.840372, mean_q: 6.629343
858 (array([12]),) False
  48600/500000: episode: 1215, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 32.188, mean reward: 0.805 [0.036, 1.000], mean action: 20.375 [4.000, 57.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.270038, mean_absolute_error: 5.898599, mean_q: 6.683945
148 (array([22]),) False
  48640/500000: episode: 1216, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 31.950, mean reward: 0.799 [0.210, 1.000], mean action: 19.450 [7.000, 53.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.293560, mean_absolute_error: 5.850001, mean_q: 6.623940
45 (array([22]),) False
  48680/500000: episode: 1217, duration: 30.093s, episode steps: 40, steps per second: 1, episode reward: 28.532, mean reward: 0.713 [0.003, 1.000], mean action: 21.925 [5.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.246756, mean_absolute_error: 5.911469, mean_q: 6.689265
539 (array([22]),) False
  48720/500000: episode: 1218, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 32.623, mean reward: 0.816 [0.002, 1.000], mean action: 26.125 [12.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.283629, mean_absolute_error: 5.897663, mean_q: 6.686324
597 (array([22]),) False
  48760/500000: episode: 1219, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 30.464, mean reward: 0.762 [0.137, 1.000], mean action: 20.050 [0.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.290390, mean_absolute_error: 5.895255, mean_q: 6.677565
732 (array([12]),) False
  48800/500000: episode: 1220, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 33.996, mean reward: 0.850 [0.106, 1.000], mean action: 15.950 [4.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.264142, mean_absolute_error: 5.947703, mean_q: 6.742537
349 (array([48]),) False
  48840/500000: episode: 1221, duration: 31.014s, episode steps: 40, steps per second: 1, episode reward: 32.009, mean reward: 0.800 [0.159, 1.000], mean action: 27.075 [10.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.299623, mean_absolute_error: 5.900294, mean_q: 6.695793
776 (array([22]),) False
  48880/500000: episode: 1222, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 27.608, mean reward: 0.690 [0.259, 1.000], mean action: 22.500 [2.000, 55.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.291395, mean_absolute_error: 5.929634, mean_q: 6.719153
671 (array([57]),) False
  48920/500000: episode: 1223, duration: 30.116s, episode steps: 40, steps per second: 1, episode reward: 19.438, mean reward: 0.486 [0.003, 0.959], mean action: 40.275 [10.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.263609, mean_absolute_error: 5.911710, mean_q: 6.698018
748 (array([22]),) False
  48960/500000: episode: 1224, duration: 31.040s, episode steps: 40, steps per second: 1, episode reward: 33.353, mean reward: 0.834 [0.348, 1.000], mean action: 22.650 [8.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.265754, mean_absolute_error: 5.932425, mean_q: 6.724524
736 (array([22]),) False
  49000/500000: episode: 1225, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 29.967, mean reward: 0.749 [0.135, 0.928], mean action: 15.950 [0.000, 51.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.303504, mean_absolute_error: 5.945792, mean_q: 6.728248
645 (array([48]),) False
  49040/500000: episode: 1226, duration: 30.958s, episode steps: 40, steps per second: 1, episode reward: 31.390, mean reward: 0.785 [0.064, 1.000], mean action: 18.700 [0.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.284107, mean_absolute_error: 5.924877, mean_q: 6.706316
608 (array([36]),) False
  49080/500000: episode: 1227, duration: 30.099s, episode steps: 40, steps per second: 1, episode reward: 15.654, mean reward: 0.391 [0.015, 0.792], mean action: 24.425 [1.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.293168, mean_absolute_error: 5.851935, mean_q: 6.636579
548 (array([22]),) False
  49120/500000: episode: 1228, duration: 31.004s, episode steps: 40, steps per second: 1, episode reward: 26.858, mean reward: 0.671 [0.021, 1.000], mean action: 22.675 [3.000, 58.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.261855, mean_absolute_error: 5.859174, mean_q: 6.635837
318 (array([48]),) False
  49160/500000: episode: 1229, duration: 30.959s, episode steps: 40, steps per second: 1, episode reward: 35.089, mean reward: 0.877 [0.000, 1.000], mean action: 25.950 [12.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.290242, mean_absolute_error: 5.803262, mean_q: 6.589942
459 (array([22]),) False
  49200/500000: episode: 1230, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 31.400, mean reward: 0.785 [0.130, 1.000], mean action: 24.125 [11.000, 57.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.229712, mean_absolute_error: 5.796079, mean_q: 6.582118
200 (array([22]),) False
  49240/500000: episode: 1231, duration: 30.109s, episode steps: 40, steps per second: 1, episode reward: 22.017, mean reward: 0.550 [0.020, 1.000], mean action: 16.575 [2.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.234959, mean_absolute_error: 5.840620, mean_q: 6.622678
452 (array([22]),) False
  49280/500000: episode: 1232, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 32.498, mean reward: 0.812 [0.000, 1.000], mean action: 24.450 [1.000, 60.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.262809, mean_absolute_error: 5.850636, mean_q: 6.635015
856 (array([48]),) False
  49320/500000: episode: 1233, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 31.657, mean reward: 0.791 [0.000, 0.973], mean action: 17.950 [8.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.274565, mean_absolute_error: 5.824910, mean_q: 6.600104
399 (array([22]),) False
  49360/500000: episode: 1234, duration: 30.991s, episode steps: 40, steps per second: 1, episode reward: 28.715, mean reward: 0.718 [0.000, 1.000], mean action: 23.975 [4.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.298946, mean_absolute_error: 5.872588, mean_q: 6.634863
807 (array([22]),) False
  49400/500000: episode: 1235, duration: 30.131s, episode steps: 40, steps per second: 1, episode reward: 33.757, mean reward: 0.844 [0.067, 1.000], mean action: 19.075 [6.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.312712, mean_absolute_error: 5.852663, mean_q: 6.627607
354 (array([12]),) False
  49440/500000: episode: 1236, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 25.547, mean reward: 0.639 [0.219, 1.000], mean action: 23.975 [5.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.301162, mean_absolute_error: 5.775610, mean_q: 6.558419
330 (array([38]),) False
  49480/500000: episode: 1237, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 32.075, mean reward: 0.802 [0.189, 1.000], mean action: 19.100 [0.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.306585, mean_absolute_error: 5.795175, mean_q: 6.573851
23 (array([48]),) False
  49520/500000: episode: 1238, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 32.998, mean reward: 0.825 [0.024, 1.000], mean action: 24.625 [8.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.254904, mean_absolute_error: 5.848034, mean_q: 6.625075
752 (array([3]),) False
  49560/500000: episode: 1239, duration: 30.109s, episode steps: 40, steps per second: 1, episode reward: 24.927, mean reward: 0.623 [0.140, 1.000], mean action: 15.475 [3.000, 49.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.295469, mean_absolute_error: 5.832938, mean_q: 6.624228
60 (array([22]),) False
  49600/500000: episode: 1240, duration: 31.050s, episode steps: 40, steps per second: 1, episode reward: 32.417, mean reward: 0.810 [0.000, 1.000], mean action: 23.800 [3.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.298080, mean_absolute_error: 5.795356, mean_q: 6.564832
783 (array([22]),) False
  49640/500000: episode: 1241, duration: 31.028s, episode steps: 40, steps per second: 1, episode reward: 31.030, mean reward: 0.776 [0.054, 1.000], mean action: 21.025 [5.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.282369, mean_absolute_error: 5.821804, mean_q: 6.593865
766 (array([12]),) False
  49680/500000: episode: 1242, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 32.809, mean reward: 0.820 [0.131, 1.000], mean action: 21.825 [12.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.266165, mean_absolute_error: 5.829934, mean_q: 6.599953
138 (array([3]),) False
  49720/500000: episode: 1243, duration: 30.151s, episode steps: 40, steps per second: 1, episode reward: 19.177, mean reward: 0.479 [0.149, 0.994], mean action: 30.825 [5.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.243190, mean_absolute_error: 5.780888, mean_q: 6.554471
163 (array([44]),) False
  49760/500000: episode: 1244, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 33.531, mean reward: 0.838 [0.232, 0.999], mean action: 22.300 [2.000, 54.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.281683, mean_absolute_error: 5.801181, mean_q: 6.577480
775 (array([58]),) False
  49800/500000: episode: 1245, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 31.039, mean reward: 0.776 [0.022, 0.915], mean action: 45.300 [4.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.264650, mean_absolute_error: 5.756736, mean_q: 6.525756
745 (array([22]),) False
  49840/500000: episode: 1246, duration: 30.935s, episode steps: 40, steps per second: 1, episode reward: 30.112, mean reward: 0.753 [0.253, 0.956], mean action: 17.950 [1.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.286147, mean_absolute_error: 5.766450, mean_q: 6.532079
231 (array([22]),) False
  49880/500000: episode: 1247, duration: 30.118s, episode steps: 40, steps per second: 1, episode reward: 35.517, mean reward: 0.888 [0.070, 0.977], mean action: 14.925 [2.000, 49.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.282154, mean_absolute_error: 5.740426, mean_q: 6.503305
581 (array([22]),) False
  49920/500000: episode: 1248, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 27.769, mean reward: 0.694 [0.092, 1.000], mean action: 25.875 [2.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.246954, mean_absolute_error: 5.775163, mean_q: 6.551252
755 (array([22]),) False
  49960/500000: episode: 1249, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 26.470, mean reward: 0.662 [0.086, 1.000], mean action: 21.225 [9.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.273165, mean_absolute_error: 5.708337, mean_q: 6.473727
797 (array([22]),) False
  50000/500000: episode: 1250, duration: 31.061s, episode steps: 40, steps per second: 1, episode reward: 31.673, mean reward: 0.792 [0.132, 0.916], mean action: 18.150 [0.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.281518, mean_absolute_error: 5.723178, mean_q: 6.490915
104 (array([22]),) False
  50040/500000: episode: 1251, duration: 30.098s, episode steps: 40, steps per second: 1, episode reward: 29.882, mean reward: 0.747 [0.000, 1.000], mean action: 16.650 [0.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.272472, mean_absolute_error: 5.741533, mean_q: 6.500437
137 (array([22]),) False
  50080/500000: episode: 1252, duration: 31.048s, episode steps: 40, steps per second: 1, episode reward: 31.834, mean reward: 0.796 [0.122, 0.927], mean action: 14.375 [0.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.271108, mean_absolute_error: 5.727221, mean_q: 6.473155
645 (array([48]),) False
  50120/500000: episode: 1253, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 35.071, mean reward: 0.877 [0.074, 1.000], mean action: 15.825 [8.000, 49.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.245888, mean_absolute_error: 5.744413, mean_q: 6.497838
662 (array([12]),) False
  50160/500000: episode: 1254, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 35.160, mean reward: 0.879 [0.119, 1.000], mean action: 16.000 [0.000, 53.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.253708, mean_absolute_error: 5.771140, mean_q: 6.534963
669 (array([15]),) False
  50200/500000: episode: 1255, duration: 30.163s, episode steps: 40, steps per second: 1, episode reward: 34.285, mean reward: 0.857 [0.218, 0.916], mean action: 16.325 [2.000, 57.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.253822, mean_absolute_error: 5.787370, mean_q: 6.545268
176 (array([3]),) False
  50240/500000: episode: 1256, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 11.571, mean reward: 0.289 [0.002, 0.750], mean action: 25.975 [8.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.269792, mean_absolute_error: 5.784454, mean_q: 6.555355
112 (array([12]),) False
  50280/500000: episode: 1257, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 32.481, mean reward: 0.812 [0.156, 1.000], mean action: 17.300 [0.000, 52.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.261632, mean_absolute_error: 5.825301, mean_q: 6.594809
254 (array([22]),) False
  50320/500000: episode: 1258, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 30.673, mean reward: 0.767 [0.038, 1.000], mean action: 20.225 [2.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.267698, mean_absolute_error: 5.833343, mean_q: 6.609972
182 (array([54]),) False
  50360/500000: episode: 1259, duration: 30.101s, episode steps: 40, steps per second: 1, episode reward: 25.512, mean reward: 0.638 [0.284, 1.000], mean action: 29.125 [0.000, 58.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.252554, mean_absolute_error: 5.824735, mean_q: 6.591205
729 (array([22]),) False
  50400/500000: episode: 1260, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 26.930, mean reward: 0.673 [0.206, 0.930], mean action: 16.900 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.258408, mean_absolute_error: 5.794194, mean_q: 6.555765
208 (array([22]),) False
  50440/500000: episode: 1261, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 30.242, mean reward: 0.756 [0.043, 1.000], mean action: 18.550 [6.000, 55.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.273792, mean_absolute_error: 5.785079, mean_q: 6.542460
610 (array([48]),) False
  50480/500000: episode: 1262, duration: 30.845s, episode steps: 40, steps per second: 1, episode reward: 31.730, mean reward: 0.793 [0.026, 1.000], mean action: 18.875 [9.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.274368, mean_absolute_error: 5.798038, mean_q: 6.555385
796 (array([38]),) False
  50520/500000: episode: 1263, duration: 30.066s, episode steps: 40, steps per second: 1, episode reward: 35.015, mean reward: 0.875 [0.000, 0.995], mean action: 16.675 [4.000, 45.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.260654, mean_absolute_error: 5.810566, mean_q: 6.586137
453 (array([22]),) False
  50560/500000: episode: 1264, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 31.469, mean reward: 0.787 [0.000, 1.000], mean action: 22.200 [7.000, 57.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.257770, mean_absolute_error: 5.784253, mean_q: 6.555011
600 (array([48]),) False
  50600/500000: episode: 1265, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 30.546, mean reward: 0.764 [0.156, 1.000], mean action: 20.350 [12.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.273840, mean_absolute_error: 5.781867, mean_q: 6.555376
190 (array([3]),) False
  50640/500000: episode: 1266, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 18.045, mean reward: 0.451 [0.147, 1.000], mean action: 21.400 [3.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.294637, mean_absolute_error: 5.735617, mean_q: 6.500897
538 (array([12]),) False
  50680/500000: episode: 1267, duration: 30.117s, episode steps: 40, steps per second: 1, episode reward: 32.665, mean reward: 0.817 [0.000, 1.000], mean action: 20.900 [0.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.262143, mean_absolute_error: 5.821892, mean_q: 6.592550
544 (array([22]),) False
  50720/500000: episode: 1268, duration: 31.018s, episode steps: 40, steps per second: 1, episode reward: 33.204, mean reward: 0.830 [0.122, 1.000], mean action: 20.000 [4.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.272894, mean_absolute_error: 5.790811, mean_q: 6.547202
414 (array([48]),) False
  50760/500000: episode: 1269, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 29.874, mean reward: 0.747 [0.277, 1.000], mean action: 25.500 [0.000, 52.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.277878, mean_absolute_error: 5.783124, mean_q: 6.543031
681 (array([12]),) False
  50800/500000: episode: 1270, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 33.908, mean reward: 0.848 [0.227, 1.000], mean action: 17.725 [9.000, 55.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.294290, mean_absolute_error: 5.771905, mean_q: 6.537179
36 (array([22]),) False
  50840/500000: episode: 1271, duration: 30.074s, episode steps: 40, steps per second: 1, episode reward: 30.993, mean reward: 0.775 [0.000, 1.000], mean action: 23.975 [4.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.241267, mean_absolute_error: 5.774615, mean_q: 6.536536
247 (array([14]),) False
  50880/500000: episode: 1272, duration: 31.080s, episode steps: 40, steps per second: 1, episode reward: 30.332, mean reward: 0.758 [0.166, 1.000], mean action: 25.675 [2.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.272753, mean_absolute_error: 5.771945, mean_q: 6.533659
477 (array([22]),) False
  50920/500000: episode: 1273, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 30.236, mean reward: 0.756 [0.000, 1.000], mean action: 17.425 [5.000, 47.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.267537, mean_absolute_error: 5.797694, mean_q: 6.576415
17 (array([22]),) False
  50960/500000: episode: 1274, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 33.130, mean reward: 0.828 [0.000, 1.000], mean action: 24.050 [1.000, 52.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.250307, mean_absolute_error: 5.840010, mean_q: 6.617980
320 (array([22]),) False
  51000/500000: episode: 1275, duration: 30.065s, episode steps: 40, steps per second: 1, episode reward: 31.281, mean reward: 0.782 [0.020, 1.000], mean action: 18.575 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.279373, mean_absolute_error: 5.806690, mean_q: 6.575489
705 (array([22]),) False
  51040/500000: episode: 1276, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 27.150, mean reward: 0.679 [0.000, 0.915], mean action: 16.950 [3.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.254692, mean_absolute_error: 5.787787, mean_q: 6.561444
807 (array([22]),) False
  51080/500000: episode: 1277, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 31.196, mean reward: 0.780 [0.079, 1.000], mean action: 21.375 [3.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.264283, mean_absolute_error: 5.791110, mean_q: 6.566124
372 (array([22]),) False
  51120/500000: episode: 1278, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 30.907, mean reward: 0.773 [0.106, 1.000], mean action: 23.475 [12.000, 56.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.268105, mean_absolute_error: 5.787700, mean_q: 6.551103
723 (array([48]),) False
  51160/500000: episode: 1279, duration: 30.103s, episode steps: 40, steps per second: 1, episode reward: 31.004, mean reward: 0.775 [0.114, 1.000], mean action: 16.675 [1.000, 52.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.280643, mean_absolute_error: 5.781692, mean_q: 6.549779
306 (array([22]),) False
  51200/500000: episode: 1280, duration: 31.070s, episode steps: 40, steps per second: 1, episode reward: 33.333, mean reward: 0.833 [0.085, 1.000], mean action: 22.825 [1.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.257235, mean_absolute_error: 5.775762, mean_q: 6.546113
656 (array([48]),) False
  51240/500000: episode: 1281, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 30.566, mean reward: 0.764 [0.062, 1.000], mean action: 35.475 [2.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.244861, mean_absolute_error: 5.767688, mean_q: 6.527989
237 (array([22]),) False
  51280/500000: episode: 1282, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 31.505, mean reward: 0.788 [0.170, 1.000], mean action: 24.150 [5.000, 53.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.306282, mean_absolute_error: 5.791531, mean_q: 6.550941
77 (array([22]),) False
  51320/500000: episode: 1283, duration: 30.088s, episode steps: 40, steps per second: 1, episode reward: 25.081, mean reward: 0.627 [0.000, 1.000], mean action: 21.200 [0.000, 56.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.301370, mean_absolute_error: 5.713491, mean_q: 6.478537
64 (array([12]),) False
  51360/500000: episode: 1284, duration: 31.024s, episode steps: 40, steps per second: 1, episode reward: 34.350, mean reward: 0.859 [0.119, 1.000], mean action: 21.400 [2.000, 52.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.276447, mean_absolute_error: 5.758091, mean_q: 6.524296
86 (array([22]),) False
  51400/500000: episode: 1285, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 35.892, mean reward: 0.897 [0.000, 1.000], mean action: 20.800 [6.000, 51.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.249444, mean_absolute_error: 5.736098, mean_q: 6.491171
140 (array([12]),) False
  51440/500000: episode: 1286, duration: 30.996s, episode steps: 40, steps per second: 1, episode reward: 36.091, mean reward: 0.902 [0.339, 1.000], mean action: 15.150 [1.000, 51.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.259382, mean_absolute_error: 5.702177, mean_q: 6.446947
665 (array([12]),) False
  51480/500000: episode: 1287, duration: 30.112s, episode steps: 40, steps per second: 1, episode reward: 29.158, mean reward: 0.729 [0.000, 1.000], mean action: 23.725 [3.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.287851, mean_absolute_error: 5.717561, mean_q: 6.474626
637 (array([12]),) False
  51520/500000: episode: 1288, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 33.515, mean reward: 0.838 [0.056, 1.000], mean action: 18.850 [0.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.256011, mean_absolute_error: 5.714078, mean_q: 6.480741
541 (array([57]),) False
  51560/500000: episode: 1289, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 21.686, mean reward: 0.542 [0.174, 1.000], mean action: 24.200 [6.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.247022, mean_absolute_error: 5.696823, mean_q: 6.464059
133 (array([22]),) False
  51600/500000: episode: 1290, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 28.436, mean reward: 0.711 [0.074, 1.000], mean action: 20.925 [3.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.248055, mean_absolute_error: 5.709230, mean_q: 6.470200
107 (array([22]),) False
  51640/500000: episode: 1291, duration: 30.112s, episode steps: 40, steps per second: 1, episode reward: 29.933, mean reward: 0.748 [0.103, 1.000], mean action: 21.950 [12.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.227184, mean_absolute_error: 5.668087, mean_q: 6.428089
110 (array([22]),) False
  51680/500000: episode: 1292, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 26.970, mean reward: 0.674 [0.159, 1.000], mean action: 23.875 [3.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.246736, mean_absolute_error: 5.672825, mean_q: 6.427348
229 (array([48]),) False
  51720/500000: episode: 1293, duration: 31.009s, episode steps: 40, steps per second: 1, episode reward: 25.566, mean reward: 0.639 [0.000, 0.867], mean action: 19.025 [4.000, 52.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.250479, mean_absolute_error: 5.703151, mean_q: 6.461822
555 (array([22]),) False
  51760/500000: episode: 1294, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 30.376, mean reward: 0.759 [0.090, 0.915], mean action: 16.550 [0.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.269166, mean_absolute_error: 5.682779, mean_q: 6.453217
636 (array([12]),) False
  51800/500000: episode: 1295, duration: 30.110s, episode steps: 40, steps per second: 1, episode reward: 32.351, mean reward: 0.809 [0.080, 1.000], mean action: 21.050 [1.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.238622, mean_absolute_error: 5.718332, mean_q: 6.490678
450 (array([8]),) False
  51840/500000: episode: 1296, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 26.390, mean reward: 0.660 [0.257, 1.000], mean action: 28.725 [0.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.310453, mean_absolute_error: 5.706328, mean_q: 6.456778
481 (array([22]),) False
  51880/500000: episode: 1297, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 35.016, mean reward: 0.875 [0.006, 1.000], mean action: 18.975 [6.000, 55.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.253347, mean_absolute_error: 5.678659, mean_q: 6.436703
689 (array([12]),) False
  51920/500000: episode: 1298, duration: 30.872s, episode steps: 40, steps per second: 1, episode reward: 35.023, mean reward: 0.876 [0.000, 1.000], mean action: 19.300 [12.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.265774, mean_absolute_error: 5.669405, mean_q: 6.418919
12 (array([22]),) False
  51960/500000: episode: 1299, duration: 30.113s, episode steps: 40, steps per second: 1, episode reward: 35.947, mean reward: 0.899 [0.134, 1.000], mean action: 23.300 [7.000, 60.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.263880, mean_absolute_error: 5.661524, mean_q: 6.414592
709 (array([41]),) False
  52000/500000: episode: 1300, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 21.813, mean reward: 0.545 [0.059, 0.976], mean action: 19.325 [6.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.241266, mean_absolute_error: 5.686946, mean_q: 6.443391
534 (array([22]),) False
  52040/500000: episode: 1301, duration: 30.958s, episode steps: 40, steps per second: 1, episode reward: 34.668, mean reward: 0.867 [0.288, 1.000], mean action: 23.725 [4.000, 53.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.255846, mean_absolute_error: 5.657390, mean_q: 6.415491
226 (array([22]),) False
  52080/500000: episode: 1302, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 31.470, mean reward: 0.787 [0.197, 1.000], mean action: 16.800 [0.000, 58.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.277710, mean_absolute_error: 5.674838, mean_q: 6.430898
443 (array([22]),) False
  52120/500000: episode: 1303, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 31.300, mean reward: 0.783 [0.000, 1.000], mean action: 23.625 [1.000, 50.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.227892, mean_absolute_error: 5.696879, mean_q: 6.447895
310 (array([12]),) False
  52160/500000: episode: 1304, duration: 31.104s, episode steps: 40, steps per second: 1, episode reward: 26.630, mean reward: 0.666 [0.000, 1.000], mean action: 21.575 [6.000, 59.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.281674, mean_absolute_error: 5.715922, mean_q: 6.471147
420 (array([22]),) False
  52200/500000: episode: 1305, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 31.282, mean reward: 0.782 [0.080, 1.000], mean action: 25.500 [3.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.232815, mean_absolute_error: 5.699460, mean_q: 6.450761
643 (array([44]),) False
  52240/500000: episode: 1306, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 33.580, mean reward: 0.840 [0.300, 0.988], mean action: 27.075 [2.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.230028, mean_absolute_error: 5.660174, mean_q: 6.413275
280 (array([48]),) False
  52280/500000: episode: 1307, duration: 30.125s, episode steps: 40, steps per second: 1, episode reward: 31.244, mean reward: 0.781 [0.083, 1.000], mean action: 18.575 [1.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.219651, mean_absolute_error: 5.670552, mean_q: 6.423238
126 (array([22]),) False
  52320/500000: episode: 1308, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 26.151, mean reward: 0.654 [0.079, 1.000], mean action: 18.250 [2.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.214431, mean_absolute_error: 5.701030, mean_q: 6.449783
829 (array([21]),) False
  52360/500000: episode: 1309, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 30.653, mean reward: 0.766 [0.148, 0.917], mean action: 19.025 [8.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.277762, mean_absolute_error: 5.659910, mean_q: 6.397187
627 (array([48]),) False
  52400/500000: episode: 1310, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 31.330, mean reward: 0.783 [0.012, 0.952], mean action: 15.850 [0.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.234652, mean_absolute_error: 5.715512, mean_q: 6.472025
780 (array([22]),) False
  52440/500000: episode: 1311, duration: 30.052s, episode steps: 40, steps per second: 1, episode reward: 29.140, mean reward: 0.729 [0.152, 1.000], mean action: 22.700 [3.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.259027, mean_absolute_error: 5.698451, mean_q: 6.452423
656 (array([48]),) False
  52480/500000: episode: 1312, duration: 31.028s, episode steps: 40, steps per second: 1, episode reward: 31.653, mean reward: 0.791 [0.037, 1.000], mean action: 33.425 [6.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.243919, mean_absolute_error: 5.706057, mean_q: 6.450925
547 (array([21]),) False
  52520/500000: episode: 1313, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 26.678, mean reward: 0.667 [0.000, 1.000], mean action: 23.175 [3.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.286528, mean_absolute_error: 5.681695, mean_q: 6.420530
18 (array([22]),) False
  52560/500000: episode: 1314, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 32.333, mean reward: 0.808 [0.109, 1.000], mean action: 25.925 [1.000, 57.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.286280, mean_absolute_error: 5.687362, mean_q: 6.435047
75 (array([22]),) False
  52600/500000: episode: 1315, duration: 30.093s, episode steps: 40, steps per second: 1, episode reward: 31.923, mean reward: 0.798 [0.226, 1.000], mean action: 24.275 [9.000, 47.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.277394, mean_absolute_error: 5.665044, mean_q: 6.420615
851 (array([48]),) False
  52640/500000: episode: 1316, duration: 31.018s, episode steps: 40, steps per second: 1, episode reward: 27.538, mean reward: 0.688 [0.000, 0.950], mean action: 20.625 [1.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.278473, mean_absolute_error: 5.685066, mean_q: 6.423293
257 (array([22]),) False
  52680/500000: episode: 1317, duration: 31.033s, episode steps: 40, steps per second: 1, episode reward: 28.864, mean reward: 0.722 [0.000, 1.000], mean action: 26.250 [5.000, 52.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.265515, mean_absolute_error: 5.648095, mean_q: 6.397839
755 (array([22]),) False
  52720/500000: episode: 1318, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 25.444, mean reward: 0.636 [0.082, 0.849], mean action: 18.850 [2.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.239731, mean_absolute_error: 5.608476, mean_q: 6.356269
282 (array([22]),) False
  52760/500000: episode: 1319, duration: 30.102s, episode steps: 40, steps per second: 1, episode reward: 35.932, mean reward: 0.898 [0.085, 1.000], mean action: 22.850 [1.000, 52.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.239760, mean_absolute_error: 5.632547, mean_q: 6.387771
129 (array([22]),) False
  52800/500000: episode: 1320, duration: 30.935s, episode steps: 40, steps per second: 1, episode reward: 31.510, mean reward: 0.788 [0.066, 1.000], mean action: 21.750 [2.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.244692, mean_absolute_error: 5.634004, mean_q: 6.385071
755 (array([22]),) False
  52840/500000: episode: 1321, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 27.898, mean reward: 0.697 [0.086, 1.000], mean action: 17.700 [1.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.266982, mean_absolute_error: 5.673414, mean_q: 6.416898
608 (array([36]),) False
  52880/500000: episode: 1322, duration: 30.925s, episode steps: 40, steps per second: 1, episode reward: 18.796, mean reward: 0.470 [0.169, 1.000], mean action: 19.275 [0.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.254262, mean_absolute_error: 5.633681, mean_q: 6.375472
245 (array([22]),) False
  52920/500000: episode: 1323, duration: 30.174s, episode steps: 40, steps per second: 1, episode reward: 25.574, mean reward: 0.639 [0.042, 1.000], mean action: 17.375 [4.000, 56.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.244576, mean_absolute_error: 5.661965, mean_q: 6.412364
416 (array([22]),) False
  52960/500000: episode: 1324, duration: 30.966s, episode steps: 40, steps per second: 1, episode reward: 32.421, mean reward: 0.811 [0.025, 1.000], mean action: 24.175 [0.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.261967, mean_absolute_error: 5.671056, mean_q: 6.418040
118 (array([22]),) False
  53000/500000: episode: 1325, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 30.217, mean reward: 0.755 [0.236, 1.000], mean action: 21.100 [1.000, 52.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.266185, mean_absolute_error: 5.691424, mean_q: 6.439188
462 (array([12]),) False
  53040/500000: episode: 1326, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 35.203, mean reward: 0.880 [0.251, 1.000], mean action: 16.775 [2.000, 49.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.248067, mean_absolute_error: 5.655007, mean_q: 6.399587
438 (array([22]),) False
  53080/500000: episode: 1327, duration: 30.084s, episode steps: 40, steps per second: 1, episode reward: 35.386, mean reward: 0.885 [0.096, 1.000], mean action: 22.525 [6.000, 50.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.266463, mean_absolute_error: 5.633424, mean_q: 6.377933
110 (array([22]),) False
  53120/500000: episode: 1328, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 29.651, mean reward: 0.741 [0.217, 1.000], mean action: 21.050 [3.000, 49.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.242743, mean_absolute_error: 5.662239, mean_q: 6.402174
27 (array([22]),) False
  53160/500000: episode: 1329, duration: 30.926s, episode steps: 40, steps per second: 1, episode reward: 31.828, mean reward: 0.796 [0.064, 1.000], mean action: 23.350 [3.000, 59.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.254599, mean_absolute_error: 5.672908, mean_q: 6.420236
251 (array([3]),) False
  53200/500000: episode: 1330, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 12.988, mean reward: 0.325 [0.002, 1.000], mean action: 25.100 [1.000, 51.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.265008, mean_absolute_error: 5.609065, mean_q: 6.341667
249 (array([22]),) False
  53240/500000: episode: 1331, duration: 30.133s, episode steps: 40, steps per second: 1, episode reward: 32.366, mean reward: 0.809 [0.163, 1.000], mean action: 22.250 [3.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.254280, mean_absolute_error: 5.657158, mean_q: 6.385749
494 (array([48]),) False
  53280/500000: episode: 1332, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 29.400, mean reward: 0.735 [0.077, 0.808], mean action: 12.875 [0.000, 29.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.248878, mean_absolute_error: 5.611461, mean_q: 6.341053
132 (array([22]),) False
  53320/500000: episode: 1333, duration: 30.925s, episode steps: 40, steps per second: 1, episode reward: 29.703, mean reward: 0.743 [0.113, 1.000], mean action: 18.925 [1.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.235638, mean_absolute_error: 5.605691, mean_q: 6.346038
749 (array([22]),) False
  53360/500000: episode: 1334, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 33.071, mean reward: 0.827 [0.003, 1.000], mean action: 21.700 [2.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.251806, mean_absolute_error: 5.569626, mean_q: 6.294666
697 (array([22]),) False
  53400/500000: episode: 1335, duration: 30.103s, episode steps: 40, steps per second: 1, episode reward: 32.488, mean reward: 0.812 [0.063, 1.000], mean action: 18.675 [7.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.231052, mean_absolute_error: 5.603086, mean_q: 6.323432
562 (array([22]),) False
  53440/500000: episode: 1336, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 28.982, mean reward: 0.725 [0.066, 1.000], mean action: 19.525 [1.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.239976, mean_absolute_error: 5.628455, mean_q: 6.358598
593 (array([37]),) False
  53480/500000: episode: 1337, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 33.026, mean reward: 0.826 [0.301, 1.000], mean action: 18.675 [0.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.248004, mean_absolute_error: 5.613441, mean_q: 6.334774
590 (array([22]),) False
  53520/500000: episode: 1338, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 28.080, mean reward: 0.702 [0.132, 0.917], mean action: 19.075 [1.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.228633, mean_absolute_error: 5.629560, mean_q: 6.357893
363 (array([36]),) False
  53560/500000: episode: 1339, duration: 30.117s, episode steps: 40, steps per second: 1, episode reward: 31.602, mean reward: 0.790 [0.210, 1.000], mean action: 28.650 [3.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.257839, mean_absolute_error: 5.650538, mean_q: 6.393374
654 (array([22]),) False
  53600/500000: episode: 1340, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 29.016, mean reward: 0.725 [0.000, 1.000], mean action: 30.325 [9.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.249591, mean_absolute_error: 5.608586, mean_q: 6.351947
670 (array([22]),) False
  53640/500000: episode: 1341, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 30.718, mean reward: 0.768 [0.203, 1.000], mean action: 18.650 [0.000, 57.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.251282, mean_absolute_error: 5.614713, mean_q: 6.347857
712 (array([22]),) False
  53680/500000: episode: 1342, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 28.033, mean reward: 0.701 [0.034, 0.832], mean action: 15.925 [9.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.255833, mean_absolute_error: 5.632371, mean_q: 6.356389
733 (array([22]),) False
  53720/500000: episode: 1343, duration: 30.102s, episode steps: 40, steps per second: 1, episode reward: 31.855, mean reward: 0.796 [0.078, 0.998], mean action: 20.225 [12.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.245021, mean_absolute_error: 5.659932, mean_q: 6.389007
419 (array([40]),) False
  53760/500000: episode: 1344, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 35.680, mean reward: 0.892 [0.075, 1.000], mean action: 23.700 [7.000, 50.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.240318, mean_absolute_error: 5.639089, mean_q: 6.374578
379 (array([22]),) False
  53800/500000: episode: 1345, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 29.671, mean reward: 0.742 [0.013, 1.000], mean action: 27.325 [5.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.239373, mean_absolute_error: 5.689460, mean_q: 6.432380
206 (array([22]),) False
  53840/500000: episode: 1346, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 27.628, mean reward: 0.691 [0.000, 1.000], mean action: 14.775 [3.000, 47.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.248911, mean_absolute_error: 5.642074, mean_q: 6.374623
763 (array([48]),) False
  53880/500000: episode: 1347, duration: 30.170s, episode steps: 40, steps per second: 1, episode reward: 31.002, mean reward: 0.775 [0.036, 1.000], mean action: 24.725 [3.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.248680, mean_absolute_error: 5.638232, mean_q: 6.377615
257 (array([22]),) False
  53920/500000: episode: 1348, duration: 31.034s, episode steps: 40, steps per second: 1, episode reward: 32.181, mean reward: 0.805 [0.258, 1.000], mean action: 21.350 [5.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.246793, mean_absolute_error: 5.662027, mean_q: 6.405464
470 (array([22]),) False
  53960/500000: episode: 1349, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 32.796, mean reward: 0.820 [0.150, 1.000], mean action: 21.475 [0.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.252156, mean_absolute_error: 5.674316, mean_q: 6.410533
263 (array([8]),) False
  54000/500000: episode: 1350, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 21.061, mean reward: 0.527 [0.000, 0.815], mean action: 34.100 [7.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.267259, mean_absolute_error: 5.683514, mean_q: 6.420470
312 (array([12]),) False
  54040/500000: episode: 1351, duration: 30.124s, episode steps: 40, steps per second: 1, episode reward: 33.942, mean reward: 0.849 [0.251, 1.000], mean action: 19.175 [12.000, 54.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.250598, mean_absolute_error: 5.659757, mean_q: 6.398702
511 (array([22]),) False
  54080/500000: episode: 1352, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 33.656, mean reward: 0.841 [0.102, 1.000], mean action: 18.475 [5.000, 56.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.245574, mean_absolute_error: 5.661305, mean_q: 6.393243
238 (array([22]),) False
  54120/500000: episode: 1353, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 34.521, mean reward: 0.863 [0.068, 1.000], mean action: 23.000 [3.000, 53.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.232733, mean_absolute_error: 5.660405, mean_q: 6.406781
148 (array([22]),) False
  54160/500000: episode: 1354, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 31.284, mean reward: 0.782 [0.129, 1.000], mean action: 17.775 [11.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.246479, mean_absolute_error: 5.655931, mean_q: 6.396521
488 (array([22]),) False
  54200/500000: episode: 1355, duration: 30.086s, episode steps: 40, steps per second: 1, episode reward: 30.625, mean reward: 0.766 [0.099, 1.000], mean action: 19.325 [5.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.266189, mean_absolute_error: 5.664474, mean_q: 6.406165
489 (array([22]),) False
  54240/500000: episode: 1356, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 28.959, mean reward: 0.724 [0.058, 1.000], mean action: 21.525 [6.000, 54.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.256682, mean_absolute_error: 5.646975, mean_q: 6.386615
213 (array([22]),) False
  54280/500000: episode: 1357, duration: 30.996s, episode steps: 40, steps per second: 1, episode reward: 33.606, mean reward: 0.840 [0.000, 1.000], mean action: 21.675 [0.000, 53.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.264324, mean_absolute_error: 5.659523, mean_q: 6.406026
498 (array([12]),) False
  54320/500000: episode: 1358, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 21.478, mean reward: 0.537 [0.000, 0.981], mean action: 23.200 [2.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.223097, mean_absolute_error: 5.646025, mean_q: 6.389888
157 (array([48]),) False
  54360/500000: episode: 1359, duration: 30.202s, episode steps: 40, steps per second: 1, episode reward: 29.281, mean reward: 0.732 [0.033, 0.934], mean action: 22.700 [4.000, 56.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.254209, mean_absolute_error: 5.707028, mean_q: 6.443124
555 (array([22]),) False
  54400/500000: episode: 1360, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 30.253, mean reward: 0.756 [0.000, 1.000], mean action: 16.825 [3.000, 51.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.225486, mean_absolute_error: 5.719311, mean_q: 6.458087
108 (array([48]),) False
  54440/500000: episode: 1361, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 28.032, mean reward: 0.701 [0.000, 0.934], mean action: 21.450 [1.000, 49.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.230288, mean_absolute_error: 5.677558, mean_q: 6.409513
178 (array([38]),) False
  54480/500000: episode: 1362, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 28.997, mean reward: 0.725 [0.251, 1.000], mean action: 18.125 [7.000, 51.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.246196, mean_absolute_error: 5.739600, mean_q: 6.476266
258 (array([22]),) False
  54520/500000: episode: 1363, duration: 30.081s, episode steps: 40, steps per second: 1, episode reward: 34.167, mean reward: 0.854 [0.167, 1.000], mean action: 16.075 [4.000, 52.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.244821, mean_absolute_error: 5.715760, mean_q: 6.463681
269 (array([36]),) False
  54560/500000: episode: 1364, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 23.180, mean reward: 0.580 [0.113, 1.000], mean action: 23.675 [0.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.262617, mean_absolute_error: 5.718663, mean_q: 6.470217
10 (array([3]),) False
  54600/500000: episode: 1365, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 22.077, mean reward: 0.552 [0.000, 1.000], mean action: 27.300 [4.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.274203, mean_absolute_error: 5.682315, mean_q: 6.423480
723 (array([48]),) False
  54640/500000: episode: 1366, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 29.577, mean reward: 0.739 [0.000, 1.000], mean action: 17.625 [4.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.218981, mean_absolute_error: 5.713800, mean_q: 6.467130
7 (array([22]),) False
  54680/500000: episode: 1367, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 33.097, mean reward: 0.827 [0.131, 1.000], mean action: 24.600 [4.000, 58.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.207864, mean_absolute_error: 5.730193, mean_q: 6.482566
325 (array([22]),) False
  54720/500000: episode: 1368, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 33.126, mean reward: 0.828 [0.000, 1.000], mean action: 22.075 [2.000, 50.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.251559, mean_absolute_error: 5.708524, mean_q: 6.451536
684 (array([22]),) False
  54760/500000: episode: 1369, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 31.780, mean reward: 0.795 [0.339, 1.000], mean action: 18.700 [8.000, 48.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.255630, mean_absolute_error: 5.688910, mean_q: 6.425574
316 (array([12]),) False
  54800/500000: episode: 1370, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 31.973, mean reward: 0.799 [0.000, 1.000], mean action: 19.725 [0.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.265541, mean_absolute_error: 5.776703, mean_q: 6.510370
349 (array([48]),) False
  54840/500000: episode: 1371, duration: 30.089s, episode steps: 40, steps per second: 1, episode reward: 31.457, mean reward: 0.786 [0.123, 1.000], mean action: 23.550 [12.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.284201, mean_absolute_error: 5.727222, mean_q: 6.468053
189 (array([12]),) False
  54880/500000: episode: 1372, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 34.601, mean reward: 0.865 [0.128, 1.000], mean action: 15.175 [1.000, 54.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.265163, mean_absolute_error: 5.661233, mean_q: 6.403416
678 (array([22]),) False
  54920/500000: episode: 1373, duration: 30.141s, episode steps: 40, steps per second: 1, episode reward: 30.247, mean reward: 0.756 [0.133, 1.000], mean action: 19.650 [12.000, 56.000], mean observation: -0.107 [-1.000, 1.000], loss: 0.262379, mean_absolute_error: 5.633071, mean_q: 6.389709
149 (array([8]),) False
  54960/500000: episode: 1374, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 19.956, mean reward: 0.499 [0.000, 0.778], mean action: 34.625 [0.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.261598, mean_absolute_error: 5.567587, mean_q: 6.320956
498 (array([12]),) False
  55000/500000: episode: 1375, duration: 30.111s, episode steps: 40, steps per second: 1, episode reward: 23.651, mean reward: 0.591 [0.136, 1.000], mean action: 25.100 [2.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.249236, mean_absolute_error: 5.619937, mean_q: 6.364231
75 (array([22]),) False
  55040/500000: episode: 1376, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 33.722, mean reward: 0.843 [0.099, 1.000], mean action: 24.900 [1.000, 59.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.233159, mean_absolute_error: 5.636384, mean_q: 6.377669
657 (array([48]),) False
  55080/500000: episode: 1377, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 32.509, mean reward: 0.813 [0.055, 1.000], mean action: 32.150 [0.000, 49.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.238568, mean_absolute_error: 5.604934, mean_q: 6.334638
800 (array([22]),) False
  55120/500000: episode: 1378, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 27.854, mean reward: 0.696 [0.192, 0.848], mean action: 15.925 [4.000, 39.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.241022, mean_absolute_error: 5.648636, mean_q: 6.395382
814 (array([22]),) False
  55160/500000: episode: 1379, duration: 30.890s, episode steps: 40, steps per second: 1, episode reward: 30.925, mean reward: 0.773 [0.056, 1.000], mean action: 19.625 [1.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.261820, mean_absolute_error: 5.672527, mean_q: 6.424342
468 (array([22]),) False
  55200/500000: episode: 1380, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 28.369, mean reward: 0.709 [0.000, 1.000], mean action: 21.700 [2.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.273208, mean_absolute_error: 5.669725, mean_q: 6.424901
235 (array([14]),) False
  55240/500000: episode: 1381, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 32.233, mean reward: 0.806 [0.039, 1.000], mean action: 27.400 [5.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.278751, mean_absolute_error: 5.633622, mean_q: 6.382638
742 (array([33]),) False
  55280/500000: episode: 1382, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 24.132, mean reward: 0.603 [0.142, 1.000], mean action: 18.725 [1.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.250134, mean_absolute_error: 5.619390, mean_q: 6.369533
544 (array([22]),) False
  55320/500000: episode: 1383, duration: 30.072s, episode steps: 40, steps per second: 1, episode reward: 29.715, mean reward: 0.743 [0.000, 1.000], mean action: 20.200 [0.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.294214, mean_absolute_error: 5.582706, mean_q: 6.334025
142 (array([12]),) False
  55360/500000: episode: 1384, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 35.568, mean reward: 0.889 [0.308, 1.000], mean action: 18.300 [6.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.232996, mean_absolute_error: 5.619622, mean_q: 6.370111
625 (array([22]),) False
  55400/500000: episode: 1385, duration: 30.149s, episode steps: 40, steps per second: 1, episode reward: 32.366, mean reward: 0.809 [0.134, 1.000], mean action: 40.950 [12.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.236054, mean_absolute_error: 5.611861, mean_q: 6.360005
829 (array([21]),) False
  55440/500000: episode: 1386, duration: 31.040s, episode steps: 40, steps per second: 1, episode reward: 30.571, mean reward: 0.764 [0.370, 1.000], mean action: 21.425 [8.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.235016, mean_absolute_error: 5.614727, mean_q: 6.358294
806 (array([22]),) False
  55480/500000: episode: 1387, duration: 30.253s, episode steps: 40, steps per second: 1, episode reward: 34.571, mean reward: 0.864 [0.128, 1.000], mean action: 35.025 [2.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.232696, mean_absolute_error: 5.608243, mean_q: 6.359900
234 (array([22]),) False
  55520/500000: episode: 1388, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 31.696, mean reward: 0.792 [0.129, 0.890], mean action: 17.400 [12.000, 56.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.251108, mean_absolute_error: 5.580218, mean_q: 6.327760
336 (array([12]),) False
  55560/500000: episode: 1389, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 30.199, mean reward: 0.755 [0.102, 1.000], mean action: 18.150 [0.000, 55.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.259050, mean_absolute_error: 5.557583, mean_q: 6.297176
264 (array([12]),) False
  55600/500000: episode: 1390, duration: 31.052s, episode steps: 40, steps per second: 1, episode reward: 28.723, mean reward: 0.718 [0.117, 1.000], mean action: 23.725 [1.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.256904, mean_absolute_error: 5.550157, mean_q: 6.280201
617 (array([22]),) False
  55640/500000: episode: 1391, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 31.317, mean reward: 0.783 [0.000, 1.000], mean action: 17.675 [8.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.216921, mean_absolute_error: 5.574061, mean_q: 6.321676
366 (array([22]),) False
  55680/500000: episode: 1392, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 32.941, mean reward: 0.824 [0.000, 1.000], mean action: 26.750 [1.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.209496, mean_absolute_error: 5.587235, mean_q: 6.331863
164 (array([22]),) False
  55720/500000: episode: 1393, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 27.480, mean reward: 0.687 [0.075, 1.000], mean action: 29.150 [5.000, 59.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.231431, mean_absolute_error: 5.577058, mean_q: 6.321791
181 (array([22]),) False
  55760/500000: episode: 1394, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 25.710, mean reward: 0.643 [0.146, 1.000], mean action: 18.575 [7.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.236727, mean_absolute_error: 5.588573, mean_q: 6.323883
159 (array([48]),) False
  55800/500000: episode: 1395, duration: 30.087s, episode steps: 40, steps per second: 1, episode reward: 28.533, mean reward: 0.713 [0.040, 1.000], mean action: 21.375 [4.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.246619, mean_absolute_error: 5.606744, mean_q: 6.354875
557 (array([22]),) False
  55840/500000: episode: 1396, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 26.692, mean reward: 0.667 [0.173, 1.000], mean action: 23.325 [12.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.234026, mean_absolute_error: 5.572127, mean_q: 6.327035
265 (array([22]),) False
  55880/500000: episode: 1397, duration: 30.068s, episode steps: 40, steps per second: 1, episode reward: 31.478, mean reward: 0.787 [0.134, 1.000], mean action: 23.675 [1.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.207354, mean_absolute_error: 5.586172, mean_q: 6.331313
822 (array([22]),) False
  55920/500000: episode: 1398, duration: 30.917s, episode steps: 40, steps per second: 1, episode reward: 31.233, mean reward: 0.781 [0.058, 1.000], mean action: 16.725 [2.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.241891, mean_absolute_error: 5.558347, mean_q: 6.309945
800 (array([22]),) False
  55960/500000: episode: 1399, duration: 30.141s, episode steps: 40, steps per second: 1, episode reward: 30.142, mean reward: 0.754 [0.000, 0.848], mean action: 17.000 [3.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.219889, mean_absolute_error: 5.547582, mean_q: 6.301369
769 (array([12]),) False
  56000/500000: episode: 1400, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 29.334, mean reward: 0.733 [0.097, 1.000], mean action: 18.225 [7.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.257642, mean_absolute_error: 5.526351, mean_q: 6.259650
472 (array([22]),) False
  56040/500000: episode: 1401, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 32.748, mean reward: 0.819 [0.030, 1.000], mean action: 23.875 [9.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.232911, mean_absolute_error: 5.494064, mean_q: 6.228115
535 (array([22]),) False
  56080/500000: episode: 1402, duration: 31.055s, episode steps: 40, steps per second: 1, episode reward: 30.741, mean reward: 0.769 [0.020, 1.000], mean action: 18.575 [10.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.217962, mean_absolute_error: 5.532838, mean_q: 6.271000
676 (array([40]),) False
  56120/500000: episode: 1403, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 24.386, mean reward: 0.610 [0.055, 1.000], mean action: 18.950 [3.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.215576, mean_absolute_error: 5.519263, mean_q: 6.257744
283 (array([34]),) False
  56160/500000: episode: 1404, duration: 30.925s, episode steps: 40, steps per second: 1, episode reward: 19.512, mean reward: 0.488 [0.000, 1.000], mean action: 25.225 [12.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.258435, mean_absolute_error: 5.507995, mean_q: 6.248116
336 (array([12]),) False
  56200/500000: episode: 1405, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 32.329, mean reward: 0.808 [0.129, 1.000], mean action: 18.175 [2.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.249259, mean_absolute_error: 5.489604, mean_q: 6.232159
372 (array([22]),) False
  56240/500000: episode: 1406, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 29.367, mean reward: 0.734 [0.049, 1.000], mean action: 23.850 [1.000, 56.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.204676, mean_absolute_error: 5.560749, mean_q: 6.307548
436 (array([22]),) False
  56280/500000: episode: 1407, duration: 30.143s, episode steps: 40, steps per second: 1, episode reward: 35.053, mean reward: 0.876 [0.074, 1.000], mean action: 23.150 [0.000, 54.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.240898, mean_absolute_error: 5.536422, mean_q: 6.269305
459 (array([22]),) False
  56320/500000: episode: 1408, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 33.895, mean reward: 0.847 [0.000, 1.000], mean action: 23.300 [2.000, 57.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.275732, mean_absolute_error: 5.509663, mean_q: 6.242283
720 (array([22]),) False
  56360/500000: episode: 1409, duration: 30.107s, episode steps: 40, steps per second: 1, episode reward: 31.385, mean reward: 0.785 [0.071, 0.940], mean action: 16.275 [3.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.274206, mean_absolute_error: 5.512910, mean_q: 6.248601
387 (array([22]),) False
  56400/500000: episode: 1410, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 33.571, mean reward: 0.839 [0.000, 1.000], mean action: 24.650 [5.000, 58.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.222235, mean_absolute_error: 5.539552, mean_q: 6.264329
296 (array([22]),) False
  56440/500000: episode: 1411, duration: 30.064s, episode steps: 40, steps per second: 1, episode reward: 33.310, mean reward: 0.833 [0.280, 1.000], mean action: 26.475 [13.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.274454, mean_absolute_error: 5.544121, mean_q: 6.266917
806 (array([22]),) False
  56480/500000: episode: 1412, duration: 31.022s, episode steps: 40, steps per second: 1, episode reward: 30.896, mean reward: 0.772 [0.045, 1.000], mean action: 23.050 [8.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.236134, mean_absolute_error: 5.514723, mean_q: 6.245226
480 (array([22]),) False
  56520/500000: episode: 1413, duration: 31.006s, episode steps: 40, steps per second: 1, episode reward: 19.489, mean reward: 0.487 [0.000, 1.000], mean action: 19.000 [2.000, 54.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.229104, mean_absolute_error: 5.525860, mean_q: 6.243553
563 (array([22]),) False
  56560/500000: episode: 1414, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 32.066, mean reward: 0.802 [0.142, 1.000], mean action: 19.100 [4.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.248854, mean_absolute_error: 5.530583, mean_q: 6.260153
559 (array([59]),) False
  56600/500000: episode: 1415, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 24.925, mean reward: 0.623 [0.068, 1.000], mean action: 21.975 [3.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.197491, mean_absolute_error: 5.528988, mean_q: 6.263815
800 (array([22]),) False
  56640/500000: episode: 1416, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 30.275, mean reward: 0.757 [0.285, 0.940], mean action: 15.000 [0.000, 52.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.235477, mean_absolute_error: 5.585973, mean_q: 6.326472
493 (array([22]),) False
  56680/500000: episode: 1417, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 32.044, mean reward: 0.801 [0.095, 0.918], mean action: 14.400 [11.000, 59.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.283681, mean_absolute_error: 5.539869, mean_q: 6.269713
391 (array([22]),) False
  56720/500000: episode: 1418, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 36.714, mean reward: 0.918 [0.125, 1.000], mean action: 23.725 [10.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.258905, mean_absolute_error: 5.528680, mean_q: 6.251985
127 (array([22]),) False
  56760/500000: episode: 1419, duration: 30.070s, episode steps: 40, steps per second: 1, episode reward: 27.087, mean reward: 0.677 [0.161, 1.000], mean action: 16.925 [3.000, 53.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.209957, mean_absolute_error: 5.565536, mean_q: 6.288768
81 (array([22]),) False
  56800/500000: episode: 1420, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 32.250, mean reward: 0.806 [0.081, 1.000], mean action: 24.025 [5.000, 57.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.220906, mean_absolute_error: 5.584929, mean_q: 6.325435
678 (array([22]),) False
  56840/500000: episode: 1421, duration: 30.103s, episode steps: 40, steps per second: 1, episode reward: 29.492, mean reward: 0.737 [0.108, 1.000], mean action: 15.625 [0.000, 44.000], mean observation: -0.107 [-1.000, 1.000], loss: 0.265192, mean_absolute_error: 5.588816, mean_q: 6.320399
118 (array([22]),) False
  56880/500000: episode: 1422, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 30.819, mean reward: 0.770 [0.092, 1.000], mean action: 23.325 [12.000, 57.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.218681, mean_absolute_error: 5.567244, mean_q: 6.297772
642 (array([22]),) False
  56920/500000: episode: 1423, duration: 30.116s, episode steps: 40, steps per second: 1, episode reward: 34.982, mean reward: 0.875 [0.053, 1.000], mean action: 20.450 [3.000, 49.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.260919, mean_absolute_error: 5.590393, mean_q: 6.320065
801 (array([58]),) False
  56960/500000: episode: 1424, duration: 30.973s, episode steps: 40, steps per second: 1, episode reward: 19.263, mean reward: 0.482 [0.031, 1.000], mean action: 32.350 [6.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.230890, mean_absolute_error: 5.589198, mean_q: 6.319298
536 (array([22]),) False
  57000/500000: episode: 1425, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 31.712, mean reward: 0.793 [0.032, 1.000], mean action: 21.975 [4.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.244044, mean_absolute_error: 5.583608, mean_q: 6.319661
278 (array([48]),) False
  57040/500000: episode: 1426, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 33.163, mean reward: 0.829 [0.279, 1.000], mean action: 21.300 [5.000, 40.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.253952, mean_absolute_error: 5.639232, mean_q: 6.379702
862 (array([14]),) False
  57080/500000: episode: 1427, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 33.487, mean reward: 0.837 [0.000, 1.000], mean action: 17.850 [7.000, 32.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.250347, mean_absolute_error: 5.589366, mean_q: 6.319284
712 (array([22]),) False
  57120/500000: episode: 1428, duration: 31.013s, episode steps: 40, steps per second: 1, episode reward: 25.696, mean reward: 0.642 [0.000, 0.832], mean action: 21.025 [9.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.231618, mean_absolute_error: 5.612446, mean_q: 6.355992
455 (array([22]),) False
  57160/500000: episode: 1429, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 31.102, mean reward: 0.778 [0.103, 1.000], mean action: 25.575 [1.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.226417, mean_absolute_error: 5.585767, mean_q: 6.322626
540 (array([22]),) False
  57200/500000: episode: 1430, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 30.161, mean reward: 0.754 [0.004, 1.000], mean action: 31.375 [0.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.271695, mean_absolute_error: 5.559449, mean_q: 6.297675
156 (array([22]),) False
  57240/500000: episode: 1431, duration: 30.132s, episode steps: 40, steps per second: 1, episode reward: 27.385, mean reward: 0.685 [0.033, 1.000], mean action: 21.250 [0.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.283085, mean_absolute_error: 5.591863, mean_q: 6.332330
215 (array([22]),) False
  57280/500000: episode: 1432, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 31.437, mean reward: 0.786 [0.222, 1.000], mean action: 20.900 [12.000, 59.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.270582, mean_absolute_error: 5.538311, mean_q: 6.271873
269 (array([36]),) False
  57320/500000: episode: 1433, duration: 30.131s, episode steps: 40, steps per second: 1, episode reward: 23.983, mean reward: 0.600 [0.047, 0.978], mean action: 20.850 [0.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.238541, mean_absolute_error: 5.534693, mean_q: 6.266502
506 (array([8]),) False
  57360/500000: episode: 1434, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 11.425, mean reward: 0.286 [0.000, 0.953], mean action: 19.675 [7.000, 58.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.232593, mean_absolute_error: 5.504676, mean_q: 6.241914
787 (array([3]),) False
  57400/500000: episode: 1435, duration: 30.106s, episode steps: 40, steps per second: 1, episode reward: 19.795, mean reward: 0.495 [0.000, 0.968], mean action: 17.725 [2.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.247007, mean_absolute_error: 5.512439, mean_q: 6.246324
324 (array([12]),) False
  57440/500000: episode: 1436, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 33.570, mean reward: 0.839 [0.000, 1.000], mean action: 21.300 [0.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.248770, mean_absolute_error: 5.502264, mean_q: 6.231551
682 (array([22]),) False
  57480/500000: episode: 1437, duration: 30.994s, episode steps: 40, steps per second: 1, episode reward: 34.632, mean reward: 0.866 [0.221, 1.000], mean action: 16.100 [0.000, 54.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.219880, mean_absolute_error: 5.466400, mean_q: 6.194577
767 (array([48]),) False
  57520/500000: episode: 1438, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 25.350, mean reward: 0.634 [0.000, 0.827], mean action: 21.400 [4.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.210829, mean_absolute_error: 5.469203, mean_q: 6.195254
339 (array([22]),) False
  57560/500000: episode: 1439, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 31.432, mean reward: 0.786 [0.048, 1.000], mean action: 20.000 [3.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.269006, mean_absolute_error: 5.472826, mean_q: 6.192659
768 (array([22]),) False
  57600/500000: episode: 1440, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 27.975, mean reward: 0.699 [0.000, 1.000], mean action: 19.650 [0.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.206053, mean_absolute_error: 5.493978, mean_q: 6.214554
252 (array([22]),) False
  57640/500000: episode: 1441, duration: 30.991s, episode steps: 40, steps per second: 1, episode reward: 32.782, mean reward: 0.820 [0.051, 1.000], mean action: 22.900 [0.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.215256, mean_absolute_error: 5.468749, mean_q: 6.190871
621 (array([22]),) False
  57680/500000: episode: 1442, duration: 30.991s, episode steps: 40, steps per second: 1, episode reward: 28.678, mean reward: 0.717 [0.081, 1.000], mean action: 21.625 [0.000, 52.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.238298, mean_absolute_error: 5.543408, mean_q: 6.264979
589 (array([22]),) False
  57720/500000: episode: 1443, duration: 30.099s, episode steps: 40, steps per second: 1, episode reward: 27.494, mean reward: 0.687 [0.166, 1.000], mean action: 18.425 [5.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.239495, mean_absolute_error: 5.545030, mean_q: 6.271236
775 (array([58]),) False
  57760/500000: episode: 1444, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 26.380, mean reward: 0.660 [0.000, 0.913], mean action: 42.725 [7.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.262117, mean_absolute_error: 5.555743, mean_q: 6.280908
372 (array([22]),) False
  57800/500000: episode: 1445, duration: 30.101s, episode steps: 40, steps per second: 1, episode reward: 32.912, mean reward: 0.823 [0.117, 1.000], mean action: 22.875 [2.000, 57.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.236150, mean_absolute_error: 5.522023, mean_q: 6.251733
228 (array([44]),) False
  57840/500000: episode: 1446, duration: 31.048s, episode steps: 40, steps per second: 1, episode reward: 33.923, mean reward: 0.848 [0.458, 0.957], mean action: 14.550 [5.000, 47.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.217310, mean_absolute_error: 5.580844, mean_q: 6.321008
573 (array([22]),) False
  57880/500000: episode: 1447, duration: 30.130s, episode steps: 40, steps per second: 1, episode reward: 33.541, mean reward: 0.839 [0.136, 1.000], mean action: 23.875 [7.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.250550, mean_absolute_error: 5.532059, mean_q: 6.251903
68 (array([22]),) False
  57920/500000: episode: 1448, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 33.303, mean reward: 0.833 [0.150, 1.000], mean action: 23.550 [12.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.232601, mean_absolute_error: 5.592360, mean_q: 6.307979
488 (array([22]),) False
  57960/500000: episode: 1449, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 33.092, mean reward: 0.827 [0.064, 1.000], mean action: 15.125 [7.000, 54.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.253529, mean_absolute_error: 5.551377, mean_q: 6.273867
157 (array([48]),) False
  58000/500000: episode: 1450, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 33.245, mean reward: 0.831 [0.146, 1.000], mean action: 18.525 [2.000, 49.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.272638, mean_absolute_error: 5.588949, mean_q: 6.323233
126 (array([22]),) False
  58040/500000: episode: 1451, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 28.952, mean reward: 0.724 [0.089, 1.000], mean action: 17.100 [2.000, 45.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.213385, mean_absolute_error: 5.592728, mean_q: 6.326108
50 (array([22]),) False
  58080/500000: episode: 1452, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 32.744, mean reward: 0.819 [0.157, 1.000], mean action: 22.450 [1.000, 49.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.243138, mean_absolute_error: 5.657874, mean_q: 6.384537
167 (array([22]),) False
  58120/500000: episode: 1453, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 30.261, mean reward: 0.757 [0.040, 0.916], mean action: 17.000 [1.000, 52.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.253219, mean_absolute_error: 5.569468, mean_q: 6.299555
349 (array([48]),) False
  58160/500000: episode: 1454, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 34.467, mean reward: 0.862 [0.069, 1.000], mean action: 23.950 [1.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.253771, mean_absolute_error: 5.613914, mean_q: 6.335891
753 (array([22]),) False
  58200/500000: episode: 1455, duration: 30.059s, episode steps: 40, steps per second: 1, episode reward: 35.726, mean reward: 0.893 [0.160, 1.000], mean action: 20.000 [0.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.248711, mean_absolute_error: 5.576649, mean_q: 6.297757
630 (array([22]),) False
  58240/500000: episode: 1456, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 32.738, mean reward: 0.818 [0.118, 1.000], mean action: 20.050 [0.000, 53.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.244597, mean_absolute_error: 5.556540, mean_q: 6.282753
497 (array([33]),) False
  58280/500000: episode: 1457, duration: 30.122s, episode steps: 40, steps per second: 1, episode reward: 19.488, mean reward: 0.487 [0.076, 1.000], mean action: 25.900 [4.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.210655, mean_absolute_error: 5.599560, mean_q: 6.326898
562 (array([22]),) False
  58320/500000: episode: 1458, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 33.856, mean reward: 0.846 [0.200, 1.000], mean action: 20.725 [5.000, 49.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.248727, mean_absolute_error: 5.549281, mean_q: 6.277810
261 (array([44]),) False
  58360/500000: episode: 1459, duration: 30.182s, episode steps: 40, steps per second: 1, episode reward: 27.929, mean reward: 0.698 [0.215, 1.000], mean action: 26.800 [12.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.273332, mean_absolute_error: 5.564758, mean_q: 6.290454
228 (array([44]),) False
  58400/500000: episode: 1460, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 28.163, mean reward: 0.704 [0.012, 0.956], mean action: 18.425 [5.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.233715, mean_absolute_error: 5.592933, mean_q: 6.320518
200 (array([22]),) False
  58440/500000: episode: 1461, duration: 30.903s, episode steps: 40, steps per second: 1, episode reward: 23.080, mean reward: 0.577 [0.073, 0.861], mean action: 16.150 [7.000, 51.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.282008, mean_absolute_error: 5.555217, mean_q: 6.275111
14 (array([48]),) False
  58480/500000: episode: 1462, duration: 30.984s, episode steps: 40, steps per second: 1, episode reward: 33.220, mean reward: 0.831 [0.000, 1.000], mean action: 25.375 [7.000, 53.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.235744, mean_absolute_error: 5.609814, mean_q: 6.333884
357 (array([22]),) False
  58520/500000: episode: 1463, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 28.786, mean reward: 0.720 [0.016, 1.000], mean action: 27.225 [1.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.244790, mean_absolute_error: 5.570742, mean_q: 6.283910
247 (array([14]),) False
  58560/500000: episode: 1464, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 32.193, mean reward: 0.805 [0.210, 1.000], mean action: 24.950 [2.000, 60.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.251895, mean_absolute_error: 5.573821, mean_q: 6.294071
842 (array([22]),) False
  58600/500000: episode: 1465, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 28.068, mean reward: 0.702 [0.082, 1.000], mean action: 19.950 [3.000, 58.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.205362, mean_absolute_error: 5.568467, mean_q: 6.291356
285 (array([58]),) False
  58640/500000: episode: 1466, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 18.347, mean reward: 0.459 [0.014, 1.000], mean action: 28.325 [6.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.229664, mean_absolute_error: 5.560496, mean_q: 6.284075
544 (array([22]),) False
  58680/500000: episode: 1467, duration: 30.157s, episode steps: 40, steps per second: 1, episode reward: 30.113, mean reward: 0.753 [0.000, 1.000], mean action: 24.450 [6.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.241207, mean_absolute_error: 5.555323, mean_q: 6.279710
695 (array([22]),) False
  58720/500000: episode: 1468, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 31.834, mean reward: 0.796 [0.017, 1.000], mean action: 19.025 [6.000, 49.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.233937, mean_absolute_error: 5.552030, mean_q: 6.276375
28 (array([58]),) False
  58760/500000: episode: 1469, duration: 30.079s, episode steps: 40, steps per second: 1, episode reward: 18.895, mean reward: 0.472 [0.000, 1.000], mean action: 21.900 [0.000, 55.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.255845, mean_absolute_error: 5.557793, mean_q: 6.282946
377 (array([22]),) False
  58800/500000: episode: 1470, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 35.404, mean reward: 0.885 [0.162, 1.000], mean action: 19.600 [1.000, 37.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.235181, mean_absolute_error: 5.596255, mean_q: 6.322725
558 (array([40]),) False
  58840/500000: episode: 1471, duration: 30.146s, episode steps: 40, steps per second: 1, episode reward: 26.951, mean reward: 0.674 [0.145, 1.000], mean action: 14.750 [1.000, 50.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.245571, mean_absolute_error: 5.566887, mean_q: 6.297795
279 (array([22]),) False
  58880/500000: episode: 1472, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 31.747, mean reward: 0.794 [0.408, 1.000], mean action: 23.500 [1.000, 49.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.267680, mean_absolute_error: 5.570374, mean_q: 6.305789
762 (array([22]),) False
  58920/500000: episode: 1473, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 32.303, mean reward: 0.808 [0.193, 1.000], mean action: 25.650 [10.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.275574, mean_absolute_error: 5.595530, mean_q: 6.326385
465 (array([48]),) False
  58960/500000: episode: 1474, duration: 31.100s, episode steps: 40, steps per second: 1, episode reward: 32.789, mean reward: 0.820 [0.091, 1.000], mean action: 28.200 [10.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.254829, mean_absolute_error: 5.600765, mean_q: 6.321814
433 (array([22]),) False
  59000/500000: episode: 1475, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 35.726, mean reward: 0.893 [0.206, 1.000], mean action: 25.475 [12.000, 54.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.247434, mean_absolute_error: 5.612778, mean_q: 6.336615
10 (array([3]),) False
  59040/500000: episode: 1476, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 22.039, mean reward: 0.551 [0.000, 1.000], mean action: 23.325 [0.000, 53.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.247017, mean_absolute_error: 5.591998, mean_q: 6.320600
481 (array([22]),) False
  59080/500000: episode: 1477, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 30.515, mean reward: 0.763 [0.027, 1.000], mean action: 28.275 [5.000, 58.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.248001, mean_absolute_error: 5.570276, mean_q: 6.295631
726 (array([12]),) False
  59120/500000: episode: 1478, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 32.820, mean reward: 0.821 [0.092, 1.000], mean action: 16.375 [3.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.222875, mean_absolute_error: 5.601770, mean_q: 6.331717
243 (array([12]),) False
  59160/500000: episode: 1479, duration: 30.062s, episode steps: 40, steps per second: 1, episode reward: 35.760, mean reward: 0.894 [0.242, 1.000], mean action: 21.975 [11.000, 56.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.240206, mean_absolute_error: 5.575288, mean_q: 6.295930
710 (array([12]),) False
  59200/500000: episode: 1480, duration: 30.881s, episode steps: 40, steps per second: 1, episode reward: 31.139, mean reward: 0.778 [0.296, 1.000], mean action: 20.525 [10.000, 59.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.236039, mean_absolute_error: 5.558936, mean_q: 6.281843
293 (array([22]),) False
  59240/500000: episode: 1481, duration: 30.093s, episode steps: 40, steps per second: 1, episode reward: 31.209, mean reward: 0.780 [0.121, 1.000], mean action: 24.100 [3.000, 57.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.228542, mean_absolute_error: 5.628162, mean_q: 6.365492
340 (array([12]),) False
  59280/500000: episode: 1482, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 33.876, mean reward: 0.847 [0.161, 1.000], mean action: 17.925 [0.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.238152, mean_absolute_error: 5.617672, mean_q: 6.360692
787 (array([3]),) False
  59320/500000: episode: 1483, duration: 30.091s, episode steps: 40, steps per second: 1, episode reward: 20.461, mean reward: 0.512 [0.000, 1.000], mean action: 20.325 [0.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.227476, mean_absolute_error: 5.605750, mean_q: 6.347224
429 (array([22]),) False
  59360/500000: episode: 1484, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 34.124, mean reward: 0.853 [0.303, 1.000], mean action: 24.875 [5.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.235528, mean_absolute_error: 5.613873, mean_q: 6.353992
133 (array([22]),) False
  59400/500000: episode: 1485, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 29.470, mean reward: 0.737 [0.027, 1.000], mean action: 19.875 [5.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.213170, mean_absolute_error: 5.601271, mean_q: 6.343914
19 (array([12]),) False
  59440/500000: episode: 1486, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 36.628, mean reward: 0.916 [0.260, 1.000], mean action: 25.625 [22.000, 53.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.269290, mean_absolute_error: 5.587361, mean_q: 6.325184
604 (array([40]),) False
  59480/500000: episode: 1487, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 32.941, mean reward: 0.824 [0.043, 0.951], mean action: 22.000 [4.000, 53.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.264850, mean_absolute_error: 5.568178, mean_q: 6.318548
776 (array([22]),) False
  59520/500000: episode: 1488, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 27.904, mean reward: 0.698 [0.072, 0.816], mean action: 19.100 [5.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.244875, mean_absolute_error: 5.561657, mean_q: 6.308594
291 (array([22]),) False
  59560/500000: episode: 1489, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 30.542, mean reward: 0.764 [0.078, 1.000], mean action: 20.350 [1.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.278868, mean_absolute_error: 5.587739, mean_q: 6.327453
386 (array([12]),) False
  59600/500000: episode: 1490, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 31.836, mean reward: 0.796 [0.000, 1.000], mean action: 25.575 [2.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.236841, mean_absolute_error: 5.596674, mean_q: 6.339315
91 (array([48]),) False
  59640/500000: episode: 1491, duration: 30.084s, episode steps: 40, steps per second: 1, episode reward: 31.434, mean reward: 0.786 [0.174, 0.951], mean action: 24.275 [2.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.257407, mean_absolute_error: 5.599935, mean_q: 6.340463
578 (array([22]),) False
  59680/500000: episode: 1492, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 33.908, mean reward: 0.848 [0.047, 1.000], mean action: 28.675 [12.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.259403, mean_absolute_error: 5.602891, mean_q: 6.341384
117 (array([44]),) False
  59720/500000: episode: 1493, duration: 30.110s, episode steps: 40, steps per second: 1, episode reward: 28.462, mean reward: 0.712 [0.000, 0.906], mean action: 19.000 [0.000, 50.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.231007, mean_absolute_error: 5.573465, mean_q: 6.303861
322 (array([12]),) False
  59760/500000: episode: 1494, duration: 31.009s, episode steps: 40, steps per second: 1, episode reward: 34.155, mean reward: 0.854 [0.152, 1.000], mean action: 22.725 [7.000, 58.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.249447, mean_absolute_error: 5.559369, mean_q: 6.279059
553 (array([22]),) False
  59800/500000: episode: 1495, duration: 30.131s, episode steps: 40, steps per second: 1, episode reward: 33.807, mean reward: 0.845 [0.000, 0.953], mean action: 15.425 [10.000, 52.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.242184, mean_absolute_error: 5.571409, mean_q: 6.309440
747 (array([22]),) False
  59840/500000: episode: 1496, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 33.090, mean reward: 0.827 [0.235, 1.000], mean action: 22.825 [5.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.236752, mean_absolute_error: 5.590497, mean_q: 6.329723
125 (array([58]),) False
  59880/500000: episode: 1497, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 11.122, mean reward: 0.278 [0.000, 0.620], mean action: 24.450 [3.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.195951, mean_absolute_error: 5.612006, mean_q: 6.350186
247 (array([14]),) False
  59920/500000: episode: 1498, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 31.608, mean reward: 0.790 [0.025, 1.000], mean action: 24.150 [5.000, 60.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.232155, mean_absolute_error: 5.594122, mean_q: 6.328116
277 (array([56]),) False
  59960/500000: episode: 1499, duration: 30.892s, episode steps: 40, steps per second: 1, episode reward: 25.443, mean reward: 0.636 [0.000, 0.873], mean action: 24.000 [0.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.227466, mean_absolute_error: 5.595918, mean_q: 6.331254
608 (array([36]),) False
  60000/500000: episode: 1500, duration: 30.886s, episode steps: 40, steps per second: 1, episode reward: 20.083, mean reward: 0.502 [0.054, 1.000], mean action: 26.500 [3.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.229607, mean_absolute_error: 5.563727, mean_q: 6.299957
9 (array([14]),) False
  60040/500000: episode: 1501, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 29.444, mean reward: 0.736 [0.000, 1.000], mean action: 21.925 [3.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.209401, mean_absolute_error: 5.562787, mean_q: 6.293732
135 (array([22]),) False
  60080/500000: episode: 1502, duration: 30.808s, episode steps: 40, steps per second: 1, episode reward: 31.583, mean reward: 0.790 [0.139, 1.000], mean action: 21.325 [9.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.240571, mean_absolute_error: 5.585980, mean_q: 6.305379
30 (array([22]),) False
  60120/500000: episode: 1503, duration: 30.125s, episode steps: 40, steps per second: 1, episode reward: 32.895, mean reward: 0.822 [0.064, 1.000], mean action: 24.675 [9.000, 54.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.230137, mean_absolute_error: 5.601645, mean_q: 6.317719
680 (array([22]),) False
  60160/500000: episode: 1504, duration: 30.987s, episode steps: 40, steps per second: 1, episode reward: 31.789, mean reward: 0.795 [0.044, 1.000], mean action: 15.575 [6.000, 60.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.242290, mean_absolute_error: 5.611815, mean_q: 6.339246
4 (array([22]),) False
  60200/500000: episode: 1505, duration: 30.157s, episode steps: 40, steps per second: 1, episode reward: 28.870, mean reward: 0.722 [0.115, 1.000], mean action: 23.450 [3.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.239664, mean_absolute_error: 5.549400, mean_q: 6.275656
668 (array([22]),) False
  60240/500000: episode: 1506, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 28.148, mean reward: 0.704 [0.117, 1.000], mean action: 25.725 [4.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.246004, mean_absolute_error: 5.605172, mean_q: 6.330533
333 (array([12]),) False
  60280/500000: episode: 1507, duration: 30.151s, episode steps: 40, steps per second: 1, episode reward: 37.341, mean reward: 0.934 [0.518, 1.000], mean action: 17.275 [12.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.249441, mean_absolute_error: 5.573837, mean_q: 6.298846
731 (array([21]),) False
  60320/500000: episode: 1508, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 30.979, mean reward: 0.774 [0.138, 1.000], mean action: 18.325 [5.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.245221, mean_absolute_error: 5.546626, mean_q: 6.256776
453 (array([22]),) False
  60360/500000: episode: 1509, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 29.020, mean reward: 0.725 [0.175, 1.000], mean action: 27.150 [6.000, 56.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.245131, mean_absolute_error: 5.586844, mean_q: 6.308057
444 (array([22]),) False
  60400/500000: episode: 1510, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 29.171, mean reward: 0.729 [0.022, 1.000], mean action: 23.450 [3.000, 43.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.242362, mean_absolute_error: 5.538369, mean_q: 6.258148
456 (array([22]),) False
  60440/500000: episode: 1511, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 32.017, mean reward: 0.800 [0.096, 1.000], mean action: 26.550 [9.000, 59.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.219674, mean_absolute_error: 5.577876, mean_q: 6.299126
204 (array([22]),) False
  60480/500000: episode: 1512, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 26.562, mean reward: 0.664 [0.175, 0.863], mean action: 15.325 [5.000, 56.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.229856, mean_absolute_error: 5.542852, mean_q: 6.268117
841 (array([21]),) False
  60520/500000: episode: 1513, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 30.333, mean reward: 0.758 [0.160, 0.964], mean action: 15.875 [12.000, 43.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.256111, mean_absolute_error: 5.503062, mean_q: 6.229793
67 (array([8]),) False
  60560/500000: episode: 1514, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 16.733, mean reward: 0.418 [0.242, 1.000], mean action: 25.325 [8.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.247603, mean_absolute_error: 5.515769, mean_q: 6.241468
738 (array([12]),) False
  60600/500000: episode: 1515, duration: 30.051s, episode steps: 40, steps per second: 1, episode reward: 34.028, mean reward: 0.851 [0.202, 1.000], mean action: 15.900 [0.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.249260, mean_absolute_error: 5.565003, mean_q: 6.294349
96 (array([22]),) False
  60640/500000: episode: 1516, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 36.726, mean reward: 0.918 [0.296, 1.000], mean action: 21.700 [0.000, 47.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.235542, mean_absolute_error: 5.533480, mean_q: 6.252168
570 (array([47]),) False
  60680/500000: episode: 1517, duration: 30.137s, episode steps: 40, steps per second: 1, episode reward: 25.323, mean reward: 0.633 [0.011, 1.000], mean action: 21.625 [0.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.229223, mean_absolute_error: 5.576739, mean_q: 6.306993
404 (array([12]),) False
  60720/500000: episode: 1518, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 28.011, mean reward: 0.700 [0.000, 1.000], mean action: 21.775 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.246424, mean_absolute_error: 5.586322, mean_q: 6.322027
163 (array([44]),) False
  60760/500000: episode: 1519, duration: 30.137s, episode steps: 40, steps per second: 1, episode reward: 34.722, mean reward: 0.868 [0.190, 0.999], mean action: 22.400 [1.000, 59.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.257885, mean_absolute_error: 5.572406, mean_q: 6.300159
197 (array([22]),) False
  60800/500000: episode: 1520, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 31.630, mean reward: 0.791 [0.118, 0.938], mean action: 18.150 [10.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.235105, mean_absolute_error: 5.582549, mean_q: 6.307519
853 (array([22]),) False
  60840/500000: episode: 1521, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 27.172, mean reward: 0.679 [0.196, 1.000], mean action: 22.250 [4.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.236793, mean_absolute_error: 5.525449, mean_q: 6.250020
641 (array([22]),) False
  60880/500000: episode: 1522, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 37.048, mean reward: 0.926 [0.139, 1.000], mean action: 21.975 [9.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.220436, mean_absolute_error: 5.510154, mean_q: 6.229098
369 (array([48]),) False
  60920/500000: episode: 1523, duration: 31.076s, episode steps: 40, steps per second: 1, episode reward: 34.866, mean reward: 0.872 [0.019, 0.973], mean action: 24.625 [6.000, 57.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.234650, mean_absolute_error: 5.550768, mean_q: 6.283848
315 (array([12]),) False
  60960/500000: episode: 1524, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 31.155, mean reward: 0.779 [0.000, 1.000], mean action: 23.475 [0.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.228534, mean_absolute_error: 5.548655, mean_q: 6.266983
573 (array([22]),) False
  61000/500000: episode: 1525, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 32.673, mean reward: 0.817 [0.059, 1.000], mean action: 25.025 [3.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.219752, mean_absolute_error: 5.550957, mean_q: 6.264200
353 (array([22]),) False
  61040/500000: episode: 1526, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 32.767, mean reward: 0.819 [0.208, 1.000], mean action: 24.975 [6.000, 53.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.249640, mean_absolute_error: 5.535826, mean_q: 6.258620
165 (array([34]),) False
  61080/500000: episode: 1527, duration: 30.152s, episode steps: 40, steps per second: 1, episode reward: 25.985, mean reward: 0.650 [0.109, 1.000], mean action: 19.700 [1.000, 56.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.234834, mean_absolute_error: 5.555035, mean_q: 6.287891
500 (array([22]),) False
  61120/500000: episode: 1528, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 31.695, mean reward: 0.792 [0.000, 1.000], mean action: 19.000 [1.000, 54.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.269004, mean_absolute_error: 5.511237, mean_q: 6.243480
815 (array([22]),) False
  61160/500000: episode: 1529, duration: 30.109s, episode steps: 40, steps per second: 1, episode reward: 31.954, mean reward: 0.799 [0.032, 1.000], mean action: 21.975 [0.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.227344, mean_absolute_error: 5.547793, mean_q: 6.286714
261 (array([44]),) False
  61200/500000: episode: 1530, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 28.717, mean reward: 0.718 [0.022, 0.934], mean action: 22.925 [0.000, 53.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.257792, mean_absolute_error: 5.540002, mean_q: 6.269953
833 (array([22]),) False
  61240/500000: episode: 1531, duration: 30.087s, episode steps: 40, steps per second: 1, episode reward: 30.468, mean reward: 0.762 [0.000, 1.000], mean action: 18.575 [0.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.235223, mean_absolute_error: 5.524301, mean_q: 6.245871
693 (array([22]),) False
  61280/500000: episode: 1532, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 32.838, mean reward: 0.821 [0.136, 1.000], mean action: 24.875 [0.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.205453, mean_absolute_error: 5.575623, mean_q: 6.303614
130 (array([22]),) False
  61320/500000: episode: 1533, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 30.798, mean reward: 0.770 [0.000, 0.999], mean action: 15.725 [3.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.237294, mean_absolute_error: 5.540995, mean_q: 6.266430
220 (array([22]),) False
  61360/500000: episode: 1534, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 33.882, mean reward: 0.847 [0.053, 0.981], mean action: 16.750 [1.000, 56.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.227157, mean_absolute_error: 5.551254, mean_q: 6.282980
51 (array([22]),) False
  61400/500000: episode: 1535, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 34.248, mean reward: 0.856 [0.169, 1.000], mean action: 23.750 [5.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.213893, mean_absolute_error: 5.544788, mean_q: 6.271256
670 (array([22]),) False
  61440/500000: episode: 1536, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 30.885, mean reward: 0.772 [0.250, 1.000], mean action: 21.425 [11.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.234663, mean_absolute_error: 5.557317, mean_q: 6.291483
193 (array([36]),) False
  61480/500000: episode: 1537, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 23.632, mean reward: 0.591 [0.291, 0.975], mean action: 18.775 [2.000, 54.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.216649, mean_absolute_error: 5.553882, mean_q: 6.297536
268 (array([22]),) False
  61520/500000: episode: 1538, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 29.456, mean reward: 0.736 [0.103, 1.000], mean action: 20.825 [0.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.235571, mean_absolute_error: 5.546130, mean_q: 6.286130
19 (array([12]),) False
  61560/500000: episode: 1539, duration: 30.131s, episode steps: 40, steps per second: 1, episode reward: 33.215, mean reward: 0.830 [0.160, 1.000], mean action: 24.100 [13.000, 55.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.226039, mean_absolute_error: 5.540752, mean_q: 6.277652
505 (array([22]),) False
  61600/500000: episode: 1540, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 33.710, mean reward: 0.843 [0.260, 1.000], mean action: 21.275 [5.000, 50.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.241587, mean_absolute_error: 5.536841, mean_q: 6.275121
143 (array([12]),) False
  61640/500000: episode: 1541, duration: 30.179s, episode steps: 40, steps per second: 1, episode reward: 30.638, mean reward: 0.766 [0.000, 1.000], mean action: 19.950 [3.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.229995, mean_absolute_error: 5.555097, mean_q: 6.290277
417 (array([12]),) False
  61680/500000: episode: 1542, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 28.810, mean reward: 0.720 [0.116, 1.000], mean action: 27.825 [12.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.233267, mean_absolute_error: 5.520024, mean_q: 6.246023
67 (array([8]),) False
  61720/500000: episode: 1543, duration: 30.131s, episode steps: 40, steps per second: 1, episode reward: 17.646, mean reward: 0.441 [0.000, 1.000], mean action: 24.650 [1.000, 53.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.235801, mean_absolute_error: 5.492011, mean_q: 6.211883
687 (array([44]),) False
  61760/500000: episode: 1544, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 34.378, mean reward: 0.859 [0.162, 1.000], mean action: 21.075 [1.000, 44.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.226821, mean_absolute_error: 5.507014, mean_q: 6.226555
311 (array([22]),) False
  61800/500000: episode: 1545, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 34.662, mean reward: 0.867 [0.000, 1.000], mean action: 24.600 [3.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.242264, mean_absolute_error: 5.487667, mean_q: 6.218207
632 (array([22]),) False
  61840/500000: episode: 1546, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 36.314, mean reward: 0.908 [0.132, 1.000], mean action: 22.675 [11.000, 47.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.226551, mean_absolute_error: 5.523478, mean_q: 6.246951
16 (array([22]),) False
  61880/500000: episode: 1547, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 33.845, mean reward: 0.846 [0.000, 1.000], mean action: 23.675 [1.000, 52.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.247390, mean_absolute_error: 5.514709, mean_q: 6.237097
517 (array([22]),) False
  61920/500000: episode: 1548, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 32.572, mean reward: 0.814 [0.085, 1.000], mean action: 23.125 [3.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.238972, mean_absolute_error: 5.523028, mean_q: 6.246621
218 (array([22]),) False
  61960/500000: episode: 1549, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 29.529, mean reward: 0.738 [0.116, 1.000], mean action: 17.750 [6.000, 60.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.269853, mean_absolute_error: 5.497198, mean_q: 6.214852
771 (array([12]),) False
  62000/500000: episode: 1550, duration: 30.935s, episode steps: 40, steps per second: 1, episode reward: 34.419, mean reward: 0.860 [0.076, 1.000], mean action: 16.100 [6.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.227500, mean_absolute_error: 5.490505, mean_q: 6.207531
695 (array([22]),) False
  62040/500000: episode: 1551, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 33.557, mean reward: 0.839 [0.098, 1.000], mean action: 16.550 [5.000, 52.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.250408, mean_absolute_error: 5.517385, mean_q: 6.237271
549 (array([22]),) False
  62080/500000: episode: 1552, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 32.941, mean reward: 0.824 [0.204, 1.000], mean action: 25.175 [12.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.208953, mean_absolute_error: 5.487649, mean_q: 6.205991
149 (array([8]),) False
  62120/500000: episode: 1553, duration: 30.118s, episode steps: 40, steps per second: 1, episode reward: 23.232, mean reward: 0.581 [0.000, 1.000], mean action: 41.725 [3.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.243645, mean_absolute_error: 5.516695, mean_q: 6.218961
856 (array([48]),) False
  62160/500000: episode: 1554, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 28.330, mean reward: 0.708 [0.019, 0.973], mean action: 21.000 [0.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.239785, mean_absolute_error: 5.516300, mean_q: 6.215745
540 (array([22]),) False
  62200/500000: episode: 1555, duration: 30.054s, episode steps: 40, steps per second: 1, episode reward: 34.892, mean reward: 0.872 [0.305, 1.000], mean action: 39.625 [12.000, 49.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.231705, mean_absolute_error: 5.529965, mean_q: 6.241190
373 (array([22]),) False
  62240/500000: episode: 1556, duration: 31.064s, episode steps: 40, steps per second: 1, episode reward: 33.054, mean reward: 0.826 [0.064, 1.000], mean action: 23.600 [9.000, 51.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.212976, mean_absolute_error: 5.546704, mean_q: 6.262197
294 (array([22]),) False
  62280/500000: episode: 1557, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 31.016, mean reward: 0.775 [0.146, 1.000], mean action: 31.700 [7.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.220612, mean_absolute_error: 5.533910, mean_q: 6.254775
212 (array([36]),) False
  62320/500000: episode: 1558, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 21.827, mean reward: 0.546 [0.000, 0.997], mean action: 24.575 [2.000, 53.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.222148, mean_absolute_error: 5.560680, mean_q: 6.292929
837 (array([48]),) False
  62360/500000: episode: 1559, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 32.731, mean reward: 0.818 [0.240, 0.974], mean action: 26.225 [0.000, 56.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.237002, mean_absolute_error: 5.554915, mean_q: 6.277572
709 (array([41]),) False
  62400/500000: episode: 1560, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 21.210, mean reward: 0.530 [0.253, 0.763], mean action: 17.025 [6.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.223985, mean_absolute_error: 5.555713, mean_q: 6.272179
599 (array([48]),) False
  62440/500000: episode: 1561, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 26.804, mean reward: 0.670 [0.032, 0.974], mean action: 21.350 [0.000, 54.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.237753, mean_absolute_error: 5.518306, mean_q: 6.241173
28 (array([58]),) False
  62480/500000: episode: 1562, duration: 30.881s, episode steps: 40, steps per second: 1, episode reward: 20.460, mean reward: 0.512 [0.000, 1.000], mean action: 24.450 [5.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.246640, mean_absolute_error: 5.525399, mean_q: 6.239973
705 (array([22]),) False
  62520/500000: episode: 1563, duration: 30.079s, episode steps: 40, steps per second: 1, episode reward: 31.516, mean reward: 0.788 [0.178, 0.915], mean action: 14.150 [0.000, 45.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.230460, mean_absolute_error: 5.497870, mean_q: 6.209825
108 (array([48]),) False
  62560/500000: episode: 1564, duration: 30.957s, episode steps: 40, steps per second: 1, episode reward: 27.283, mean reward: 0.682 [0.111, 0.927], mean action: 24.425 [12.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.223689, mean_absolute_error: 5.503474, mean_q: 6.214122
772 (array([46]),) False
  62600/500000: episode: 1565, duration: 30.144s, episode steps: 40, steps per second: 1, episode reward: 23.036, mean reward: 0.576 [0.061, 0.939], mean action: 19.950 [7.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.213951, mean_absolute_error: 5.526604, mean_q: 6.234359
485 (array([22]),) False
  62640/500000: episode: 1566, duration: 31.004s, episode steps: 40, steps per second: 1, episode reward: 29.829, mean reward: 0.746 [0.023, 1.000], mean action: 20.975 [4.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.225620, mean_absolute_error: 5.466747, mean_q: 6.188653
679 (array([44]),) False
  62680/500000: episode: 1567, duration: 30.069s, episode steps: 40, steps per second: 1, episode reward: 26.669, mean reward: 0.667 [0.094, 1.000], mean action: 16.825 [0.000, 56.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.219849, mean_absolute_error: 5.477241, mean_q: 6.198746
624 (array([48]),) False
  62720/500000: episode: 1568, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 32.750, mean reward: 0.819 [0.084, 0.935], mean action: 15.850 [12.000, 44.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.230503, mean_absolute_error: 5.480401, mean_q: 6.187657
428 (array([22]),) False
  62760/500000: episode: 1569, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 34.596, mean reward: 0.865 [0.072, 1.000], mean action: 25.425 [11.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.230668, mean_absolute_error: 5.496737, mean_q: 6.218688
112 (array([12]),) False
  62800/500000: episode: 1570, duration: 31.013s, episode steps: 40, steps per second: 1, episode reward: 36.146, mean reward: 0.904 [0.120, 1.000], mean action: 17.800 [12.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.213478, mean_absolute_error: 5.441577, mean_q: 6.156499
508 (array([22]),) False
  62840/500000: episode: 1571, duration: 30.974s, episode steps: 40, steps per second: 1, episode reward: 32.635, mean reward: 0.816 [0.357, 1.000], mean action: 23.675 [7.000, 51.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.244610, mean_absolute_error: 5.456343, mean_q: 6.164495
276 (array([56]),) False
  62880/500000: episode: 1572, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 22.620, mean reward: 0.565 [0.010, 0.915], mean action: 22.925 [0.000, 60.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.248979, mean_absolute_error: 5.476351, mean_q: 6.190051
164 (array([22]),) False
  62920/500000: episode: 1573, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 26.574, mean reward: 0.664 [0.002, 1.000], mean action: 23.775 [5.000, 54.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.231189, mean_absolute_error: 5.467385, mean_q: 6.187515
530 (array([22]),) False
  62960/500000: episode: 1574, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 34.138, mean reward: 0.853 [0.108, 1.000], mean action: 23.300 [1.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.217336, mean_absolute_error: 5.498495, mean_q: 6.211081
436 (array([22]),) False
  63000/500000: episode: 1575, duration: 30.100s, episode steps: 40, steps per second: 1, episode reward: 31.435, mean reward: 0.786 [0.097, 1.000], mean action: 25.525 [1.000, 58.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.214072, mean_absolute_error: 5.474664, mean_q: 6.182585
286 (array([22]),) False
  63040/500000: episode: 1576, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 32.604, mean reward: 0.815 [0.142, 1.000], mean action: 24.925 [0.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.231924, mean_absolute_error: 5.482886, mean_q: 6.186963
144 (array([22]),) False
  63080/500000: episode: 1577, duration: 30.130s, episode steps: 40, steps per second: 1, episode reward: 29.946, mean reward: 0.749 [0.155, 1.000], mean action: 15.800 [10.000, 43.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.216629, mean_absolute_error: 5.461354, mean_q: 6.172573
602 (array([36]),) False
  63120/500000: episode: 1578, duration: 31.006s, episode steps: 40, steps per second: 1, episode reward: 17.680, mean reward: 0.442 [0.025, 1.000], mean action: 35.350 [0.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.210487, mean_absolute_error: 5.480308, mean_q: 6.190835
351 (array([22]),) False
  63160/500000: episode: 1579, duration: 30.177s, episode steps: 40, steps per second: 1, episode reward: 37.238, mean reward: 0.931 [0.293, 1.000], mean action: 22.925 [14.000, 53.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.219254, mean_absolute_error: 5.498946, mean_q: 6.212550
50 (array([22]),) False
  63200/500000: episode: 1580, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 34.419, mean reward: 0.860 [0.000, 1.000], mean action: 22.225 [0.000, 55.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.211872, mean_absolute_error: 5.445180, mean_q: 6.147685
641 (array([22]),) False
  63240/500000: episode: 1581, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 33.448, mean reward: 0.836 [0.055, 1.000], mean action: 22.700 [3.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.221841, mean_absolute_error: 5.496110, mean_q: 6.205467
526 (array([22]),) False
  63280/500000: episode: 1582, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 33.505, mean reward: 0.838 [0.142, 1.000], mean action: 22.550 [1.000, 56.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.224149, mean_absolute_error: 5.472975, mean_q: 6.177716
550 (array([12]),) False
  63320/500000: episode: 1583, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 31.987, mean reward: 0.800 [0.095, 1.000], mean action: 21.700 [3.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.221375, mean_absolute_error: 5.505817, mean_q: 6.209363
849 (array([3]),) False
  63360/500000: episode: 1584, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 19.283, mean reward: 0.482 [0.000, 0.782], mean action: 36.050 [3.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.221195, mean_absolute_error: 5.427450, mean_q: 6.133032
820 (array([48]),) False
  63400/500000: episode: 1585, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 29.158, mean reward: 0.729 [0.371, 1.000], mean action: 25.600 [12.000, 55.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.224091, mean_absolute_error: 5.480728, mean_q: 6.203691
716 (array([48]),) False
  63440/500000: episode: 1586, duration: 30.870s, episode steps: 40, steps per second: 1, episode reward: 28.548, mean reward: 0.714 [0.163, 0.992], mean action: 18.475 [12.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.218474, mean_absolute_error: 5.499185, mean_q: 6.214174
600 (array([48]),) False
  63480/500000: episode: 1587, duration: 30.077s, episode steps: 40, steps per second: 1, episode reward: 28.286, mean reward: 0.707 [0.050, 0.897], mean action: 17.575 [10.000, 51.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.233220, mean_absolute_error: 5.485271, mean_q: 6.199059
337 (array([22]),) False
  63520/500000: episode: 1588, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 32.702, mean reward: 0.818 [0.100, 1.000], mean action: 19.500 [4.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.215644, mean_absolute_error: 5.456383, mean_q: 6.165580
512 (array([48]),) False
  63560/500000: episode: 1589, duration: 30.160s, episode steps: 40, steps per second: 1, episode reward: 30.180, mean reward: 0.754 [0.023, 1.000], mean action: 23.450 [8.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.230293, mean_absolute_error: 5.504263, mean_q: 6.208208
523 (array([22]),) False
  63600/500000: episode: 1590, duration: 30.903s, episode steps: 40, steps per second: 1, episode reward: 30.250, mean reward: 0.756 [0.000, 1.000], mean action: 19.750 [4.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.238469, mean_absolute_error: 5.511102, mean_q: 6.224164
36 (array([22]),) False
  63640/500000: episode: 1591, duration: 30.154s, episode steps: 40, steps per second: 1, episode reward: 32.567, mean reward: 0.814 [0.221, 1.000], mean action: 27.750 [1.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.250558, mean_absolute_error: 5.506300, mean_q: 6.221347
249 (array([22]),) False
  63680/500000: episode: 1592, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 30.290, mean reward: 0.757 [0.001, 1.000], mean action: 24.100 [1.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.212252, mean_absolute_error: 5.504881, mean_q: 6.208976
36 (array([22]),) False
  63720/500000: episode: 1593, duration: 30.948s, episode steps: 40, steps per second: 1, episode reward: 31.427, mean reward: 0.786 [0.086, 1.000], mean action: 31.475 [10.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.216892, mean_absolute_error: 5.478068, mean_q: 6.184207
53 (array([22]),) False
  63760/500000: episode: 1594, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 34.655, mean reward: 0.866 [0.000, 1.000], mean action: 24.475 [19.000, 59.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.273084, mean_absolute_error: 5.522836, mean_q: 6.227287
600 (array([48]),) False
  63800/500000: episode: 1595, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 29.275, mean reward: 0.732 [0.000, 0.899], mean action: 19.575 [7.000, 49.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.222422, mean_absolute_error: 5.492719, mean_q: 6.205757
609 (array([22]),) False
  63840/500000: episode: 1596, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 28.349, mean reward: 0.709 [0.176, 1.000], mean action: 17.625 [1.000, 53.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.234045, mean_absolute_error: 5.528080, mean_q: 6.248641
408 (array([12]),) False
  63880/500000: episode: 1597, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 31.531, mean reward: 0.788 [0.022, 0.989], mean action: 21.450 [4.000, 47.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.267450, mean_absolute_error: 5.511256, mean_q: 6.221507
14 (array([48]),) False
  63920/500000: episode: 1598, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 36.170, mean reward: 0.904 [0.016, 1.000], mean action: 21.750 [3.000, 42.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.229485, mean_absolute_error: 5.545850, mean_q: 6.255527
48 (array([12]),) False
  63960/500000: episode: 1599, duration: 30.063s, episode steps: 40, steps per second: 1, episode reward: 36.007, mean reward: 0.900 [0.478, 0.952], mean action: 23.400 [13.000, 46.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.218243, mean_absolute_error: 5.561415, mean_q: 6.266131
655 (array([22]),) False
  64000/500000: episode: 1600, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 31.393, mean reward: 0.785 [0.032, 1.000], mean action: 21.725 [3.000, 40.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.244877, mean_absolute_error: 5.558091, mean_q: 6.260715
474 (array([22]),) False
  64040/500000: episode: 1601, duration: 30.150s, episode steps: 40, steps per second: 1, episode reward: 35.301, mean reward: 0.883 [0.163, 1.000], mean action: 14.825 [1.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.224631, mean_absolute_error: 5.590520, mean_q: 6.291904
82 (array([22]),) False
  64080/500000: episode: 1602, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 30.810, mean reward: 0.770 [0.005, 1.000], mean action: 25.875 [10.000, 60.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.228101, mean_absolute_error: 5.553612, mean_q: 6.258532
376 (array([22]),) False
  64120/500000: episode: 1603, duration: 30.620s, episode steps: 40, steps per second: 1, episode reward: 33.444, mean reward: 0.836 [0.025, 1.000], mean action: 23.875 [6.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.223393, mean_absolute_error: 5.582153, mean_q: 6.283883
229 (array([48]),) False
  64160/500000: episode: 1604, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 25.961, mean reward: 0.649 [0.192, 0.874], mean action: 15.400 [0.000, 49.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.241586, mean_absolute_error: 5.534554, mean_q: 6.242301
630 (array([22]),) False
  64200/500000: episode: 1605, duration: 31.295s, episode steps: 40, steps per second: 1, episode reward: 33.392, mean reward: 0.835 [0.000, 1.000], mean action: 20.500 [6.000, 52.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.221833, mean_absolute_error: 5.537681, mean_q: 6.239192
41 (array([12]),) False
  64240/500000: episode: 1606, duration: 31.481s, episode steps: 40, steps per second: 1, episode reward: 31.449, mean reward: 0.786 [0.053, 1.000], mean action: 24.850 [5.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.234810, mean_absolute_error: 5.527090, mean_q: 6.227749
582 (array([44]),) False
  64280/500000: episode: 1607, duration: 31.486s, episode steps: 40, steps per second: 1, episode reward: 32.128, mean reward: 0.803 [0.000, 1.000], mean action: 25.300 [6.000, 57.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.242586, mean_absolute_error: 5.526578, mean_q: 6.241693
403 (array([12]),) False
  64320/500000: episode: 1608, duration: 31.809s, episode steps: 40, steps per second: 1, episode reward: 32.583, mean reward: 0.815 [0.233, 1.000], mean action: 23.850 [0.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.263820, mean_absolute_error: 5.528991, mean_q: 6.244559
860 (array([12]),) False
  64360/500000: episode: 1609, duration: 31.650s, episode steps: 40, steps per second: 1, episode reward: 34.369, mean reward: 0.859 [0.139, 1.000], mean action: 19.325 [11.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.245116, mean_absolute_error: 5.528409, mean_q: 6.245971
278 (array([48]),) False
  64400/500000: episode: 1610, duration: 31.456s, episode steps: 40, steps per second: 1, episode reward: 29.709, mean reward: 0.743 [0.225, 1.000], mean action: 39.550 [17.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.248660, mean_absolute_error: 5.545588, mean_q: 6.262122
851 (array([48]),) False
  64440/500000: episode: 1611, duration: 30.842s, episode steps: 40, steps per second: 1, episode reward: 31.739, mean reward: 0.793 [0.109, 0.973], mean action: 34.050 [5.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.221742, mean_absolute_error: 5.489727, mean_q: 6.203707
390 (array([22]),) False
  64480/500000: episode: 1612, duration: 30.831s, episode steps: 40, steps per second: 1, episode reward: 32.721, mean reward: 0.818 [0.216, 1.000], mean action: 24.025 [5.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.291950, mean_absolute_error: 5.481785, mean_q: 6.186776
378 (array([22]),) False
  64520/500000: episode: 1613, duration: 30.072s, episode steps: 40, steps per second: 1, episode reward: 33.523, mean reward: 0.838 [0.303, 1.000], mean action: 30.350 [14.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.260543, mean_absolute_error: 5.457671, mean_q: 6.164458
22 (array([37]),) False
  64560/500000: episode: 1614, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 30.521, mean reward: 0.763 [0.342, 0.901], mean action: 23.075 [12.000, 51.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.227643, mean_absolute_error: 5.486242, mean_q: 6.199683
757 (array([48]),) False
  64600/500000: episode: 1615, duration: 30.098s, episode steps: 40, steps per second: 1, episode reward: 30.654, mean reward: 0.766 [0.000, 0.979], mean action: 25.075 [8.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.234000, mean_absolute_error: 5.438519, mean_q: 6.147891
111 (array([22]),) False
  64640/500000: episode: 1616, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 30.000, mean reward: 0.750 [0.068, 1.000], mean action: 24.575 [0.000, 53.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.242269, mean_absolute_error: 5.481057, mean_q: 6.193223
472 (array([22]),) False
  64680/500000: episode: 1617, duration: 30.855s, episode steps: 40, steps per second: 1, episode reward: 31.145, mean reward: 0.779 [0.050, 1.000], mean action: 24.575 [8.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.221446, mean_absolute_error: 5.458102, mean_q: 6.171966
223 (array([48]),) False
  64720/500000: episode: 1618, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 29.740, mean reward: 0.744 [0.000, 0.854], mean action: 20.775 [3.000, 55.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.226795, mean_absolute_error: 5.434206, mean_q: 6.139327
684 (array([22]),) False
  64760/500000: episode: 1619, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 30.664, mean reward: 0.767 [0.144, 1.000], mean action: 21.050 [0.000, 58.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.241790, mean_absolute_error: 5.411298, mean_q: 6.108489
824 (array([22]),) False
  64800/500000: episode: 1620, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 29.570, mean reward: 0.739 [0.025, 0.915], mean action: 17.725 [1.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.220181, mean_absolute_error: 5.426753, mean_q: 6.124726
28 (array([58]),) False
  64840/500000: episode: 1621, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 21.103, mean reward: 0.528 [0.000, 1.000], mean action: 25.800 [1.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.238767, mean_absolute_error: 5.439332, mean_q: 6.135280
856 (array([48]),) False
  64880/500000: episode: 1622, duration: 31.009s, episode steps: 40, steps per second: 1, episode reward: 28.995, mean reward: 0.725 [0.000, 0.976], mean action: 21.075 [0.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.225211, mean_absolute_error: 5.457253, mean_q: 6.159151
681 (array([12]),) False
  64920/500000: episode: 1623, duration: 30.118s, episode steps: 40, steps per second: 1, episode reward: 32.646, mean reward: 0.816 [0.010, 1.000], mean action: 19.575 [0.000, 58.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.210318, mean_absolute_error: 5.465078, mean_q: 6.174555
607 (array([12]),) False
  64960/500000: episode: 1624, duration: 31.051s, episode steps: 40, steps per second: 1, episode reward: 30.701, mean reward: 0.768 [0.000, 1.000], mean action: 17.975 [0.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.225481, mean_absolute_error: 5.434124, mean_q: 6.139062
640 (array([22]),) False
  65000/500000: episode: 1625, duration: 30.122s, episode steps: 40, steps per second: 1, episode reward: 33.908, mean reward: 0.848 [0.117, 1.000], mean action: 18.525 [2.000, 49.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.236541, mean_absolute_error: 5.462220, mean_q: 6.161530
201 (array([22]),) False
  65040/500000: episode: 1626, duration: 30.973s, episode steps: 40, steps per second: 1, episode reward: 30.150, mean reward: 0.754 [0.190, 1.000], mean action: 18.275 [0.000, 50.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.209696, mean_absolute_error: 5.504590, mean_q: 6.204419
339 (array([22]),) False
  65080/500000: episode: 1627, duration: 30.152s, episode steps: 40, steps per second: 1, episode reward: 33.204, mean reward: 0.830 [0.043, 1.000], mean action: 21.975 [1.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.220604, mean_absolute_error: 5.525497, mean_q: 6.232401
723 (array([48]),) False
  65120/500000: episode: 1628, duration: 31.083s, episode steps: 40, steps per second: 1, episode reward: 33.064, mean reward: 0.827 [0.223, 1.000], mean action: 19.875 [7.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.211140, mean_absolute_error: 5.563316, mean_q: 6.280275
73 (array([22]),) False
  65160/500000: episode: 1629, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 35.171, mean reward: 0.879 [0.238, 1.000], mean action: 20.500 [3.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.215894, mean_absolute_error: 5.556935, mean_q: 6.268691
727 (array([12]),) False
  65200/500000: episode: 1630, duration: 31.004s, episode steps: 40, steps per second: 1, episode reward: 36.483, mean reward: 0.912 [0.294, 1.000], mean action: 16.150 [12.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.256787, mean_absolute_error: 5.491408, mean_q: 6.207500
774 (array([57]),) False
  65240/500000: episode: 1631, duration: 31.020s, episode steps: 40, steps per second: 1, episode reward: 27.892, mean reward: 0.697 [0.303, 0.819], mean action: 20.500 [2.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.257201, mean_absolute_error: 5.578496, mean_q: 6.293274
21 (array([3]),) False
  65280/500000: episode: 1632, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 24.855, mean reward: 0.621 [0.047, 1.000], mean action: 23.400 [5.000, 56.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.236903, mean_absolute_error: 5.551103, mean_q: 6.255425
788 (array([3]),) False
  65320/500000: episode: 1633, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 18.375, mean reward: 0.459 [0.020, 0.801], mean action: 38.275 [2.000, 51.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.232186, mean_absolute_error: 5.568700, mean_q: 6.269557
57 (array([37]),) False
  65360/500000: episode: 1634, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 30.037, mean reward: 0.751 [0.252, 0.960], mean action: 25.825 [21.000, 54.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.213683, mean_absolute_error: 5.478673, mean_q: 6.180684
178 (array([38]),) False
  65400/500000: episode: 1635, duration: 30.120s, episode steps: 40, steps per second: 1, episode reward: 27.397, mean reward: 0.685 [0.247, 0.992], mean action: 18.375 [5.000, 54.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.232243, mean_absolute_error: 5.501018, mean_q: 6.204461
839 (array([22]),) False
  65440/500000: episode: 1636, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 28.008, mean reward: 0.700 [0.271, 1.000], mean action: 23.500 [7.000, 49.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.238188, mean_absolute_error: 5.492624, mean_q: 6.189671
662 (array([12]),) False
  65480/500000: episode: 1637, duration: 30.139s, episode steps: 40, steps per second: 1, episode reward: 36.179, mean reward: 0.904 [0.213, 1.000], mean action: 16.050 [0.000, 59.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.251354, mean_absolute_error: 5.500157, mean_q: 6.201983
277 (array([56]),) False
  65520/500000: episode: 1638, duration: 30.996s, episode steps: 40, steps per second: 1, episode reward: 27.743, mean reward: 0.694 [0.239, 0.873], mean action: 23.550 [5.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.245029, mean_absolute_error: 5.546448, mean_q: 6.253643
41 (array([12]),) False
  65560/500000: episode: 1639, duration: 30.111s, episode steps: 40, steps per second: 1, episode reward: 31.403, mean reward: 0.785 [0.066, 1.000], mean action: 23.975 [5.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.249842, mean_absolute_error: 5.504790, mean_q: 6.204494
31 (array([48]),) False
  65600/500000: episode: 1640, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 30.359, mean reward: 0.759 [0.029, 0.897], mean action: 25.225 [8.000, 60.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.249392, mean_absolute_error: 5.472528, mean_q: 6.175588
537 (array([22]),) False
  65640/500000: episode: 1641, duration: 31.033s, episode steps: 40, steps per second: 1, episode reward: 34.909, mean reward: 0.873 [0.105, 1.000], mean action: 24.175 [3.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.253584, mean_absolute_error: 5.520130, mean_q: 6.217865
802 (array([22]),) False
  65680/500000: episode: 1642, duration: 30.970s, episode steps: 40, steps per second: 1, episode reward: 27.278, mean reward: 0.682 [0.134, 1.000], mean action: 20.200 [0.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.253553, mean_absolute_error: 5.473020, mean_q: 6.165498
758 (array([38]),) False
  65720/500000: episode: 1643, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 35.565, mean reward: 0.889 [0.000, 0.990], mean action: 21.725 [2.000, 51.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.249655, mean_absolute_error: 5.479512, mean_q: 6.180738
623 (array([37]),) False
  65760/500000: episode: 1644, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 23.321, mean reward: 0.583 [0.012, 1.000], mean action: 19.750 [0.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.221110, mean_absolute_error: 5.507808, mean_q: 6.208961
176 (array([3]),) False
  65800/500000: episode: 1645, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 17.982, mean reward: 0.450 [0.151, 1.000], mean action: 29.325 [3.000, 58.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.237273, mean_absolute_error: 5.551588, mean_q: 6.261935
733 (array([22]),) False
  65840/500000: episode: 1646, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 32.441, mean reward: 0.811 [0.070, 1.000], mean action: 19.150 [3.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.212016, mean_absolute_error: 5.540349, mean_q: 6.242753
597 (array([22]),) False
  65880/500000: episode: 1647, duration: 30.074s, episode steps: 40, steps per second: 1, episode reward: 31.327, mean reward: 0.783 [0.137, 1.000], mean action: 22.775 [1.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.230934, mean_absolute_error: 5.538641, mean_q: 6.248147
414 (array([48]),) False
  65920/500000: episode: 1648, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 30.983, mean reward: 0.775 [0.150, 1.000], mean action: 30.825 [9.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.215412, mean_absolute_error: 5.462523, mean_q: 6.163100
122 (array([12]),) False
  65960/500000: episode: 1649, duration: 30.086s, episode steps: 40, steps per second: 1, episode reward: 31.410, mean reward: 0.785 [0.164, 1.000], mean action: 17.000 [4.000, 55.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.185563, mean_absolute_error: 5.539952, mean_q: 6.251241
177 (array([22]),) False
  66000/500000: episode: 1650, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 34.413, mean reward: 0.860 [0.052, 1.000], mean action: 18.400 [6.000, 59.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.243774, mean_absolute_error: 5.523198, mean_q: 6.235518
612 (array([22]),) False
  66040/500000: episode: 1651, duration: 30.134s, episode steps: 40, steps per second: 1, episode reward: 30.797, mean reward: 0.770 [0.144, 0.934], mean action: 16.150 [0.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.251649, mean_absolute_error: 5.501217, mean_q: 6.214399
452 (array([22]),) False
  66080/500000: episode: 1652, duration: 31.030s, episode steps: 40, steps per second: 1, episode reward: 33.190, mean reward: 0.830 [0.264, 1.000], mean action: 23.400 [4.000, 57.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.225440, mean_absolute_error: 5.563036, mean_q: 6.270665
1 (array([22]),) False
  66120/500000: episode: 1653, duration: 30.944s, episode steps: 40, steps per second: 1, episode reward: 28.859, mean reward: 0.721 [0.021, 1.000], mean action: 23.475 [4.000, 51.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.235383, mean_absolute_error: 5.524663, mean_q: 6.226411
255 (array([12]),) False
  66160/500000: episode: 1654, duration: 31.108s, episode steps: 40, steps per second: 1, episode reward: 24.205, mean reward: 0.605 [0.117, 1.000], mean action: 18.825 [0.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.283856, mean_absolute_error: 5.494618, mean_q: 6.194009
697 (array([22]),) False
  66200/500000: episode: 1655, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 34.814, mean reward: 0.870 [0.062, 1.000], mean action: 20.825 [1.000, 59.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.243515, mean_absolute_error: 5.501238, mean_q: 6.211507
754 (array([52]),) False
  66240/500000: episode: 1656, duration: 30.687s, episode steps: 40, steps per second: 1, episode reward: 28.734, mean reward: 0.718 [0.000, 0.986], mean action: 35.425 [3.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.221745, mean_absolute_error: 5.538551, mean_q: 6.252183
751 (array([22]),) False
  66280/500000: episode: 1657, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 34.703, mean reward: 0.868 [0.012, 1.000], mean action: 23.900 [2.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.250160, mean_absolute_error: 5.456256, mean_q: 6.170119
249 (array([22]),) False
  66320/500000: episode: 1658, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 33.447, mean reward: 0.836 [0.148, 1.000], mean action: 28.050 [22.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.233739, mean_absolute_error: 5.483617, mean_q: 6.192089
157 (array([48]),) False
  66360/500000: episode: 1659, duration: 30.115s, episode steps: 40, steps per second: 1, episode reward: 30.105, mean reward: 0.753 [0.018, 0.934], mean action: 17.275 [1.000, 59.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.228060, mean_absolute_error: 5.460236, mean_q: 6.169044
733 (array([22]),) False
  66400/500000: episode: 1660, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 35.286, mean reward: 0.882 [0.074, 1.000], mean action: 16.900 [5.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.225963, mean_absolute_error: 5.461656, mean_q: 6.177417
721 (array([22]),) False
  66440/500000: episode: 1661, duration: 30.162s, episode steps: 40, steps per second: 1, episode reward: 28.636, mean reward: 0.716 [0.086, 0.954], mean action: 16.600 [1.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.208974, mean_absolute_error: 5.460168, mean_q: 6.173508
581 (array([22]),) False
  66480/500000: episode: 1662, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 31.515, mean reward: 0.788 [0.000, 1.000], mean action: 25.750 [2.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.260367, mean_absolute_error: 5.474999, mean_q: 6.181614
275 (array([12]),) False
  66520/500000: episode: 1663, duration: 30.150s, episode steps: 40, steps per second: 1, episode reward: 32.046, mean reward: 0.801 [0.131, 1.000], mean action: 17.150 [2.000, 48.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.243277, mean_absolute_error: 5.458537, mean_q: 6.158916
77 (array([22]),) False
  66560/500000: episode: 1664, duration: 31.009s, episode steps: 40, steps per second: 1, episode reward: 31.612, mean reward: 0.790 [0.097, 1.000], mean action: 19.200 [7.000, 49.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.225346, mean_absolute_error: 5.470142, mean_q: 6.168644
190 (array([3]),) False
  66600/500000: episode: 1665, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 20.376, mean reward: 0.509 [0.047, 1.000], mean action: 19.450 [3.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.232109, mean_absolute_error: 5.481221, mean_q: 6.173421
86 (array([22]),) False
  66640/500000: episode: 1666, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 36.340, mean reward: 0.909 [0.468, 1.000], mean action: 23.000 [12.000, 53.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.214356, mean_absolute_error: 5.469641, mean_q: 6.170924
649 (array([22]),) False
  66680/500000: episode: 1667, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 30.118, mean reward: 0.753 [0.029, 1.000], mean action: 21.275 [9.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.219955, mean_absolute_error: 5.485333, mean_q: 6.178972
164 (array([22]),) False
  66720/500000: episode: 1668, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 29.409, mean reward: 0.735 [0.006, 1.000], mean action: 18.350 [5.000, 52.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.224928, mean_absolute_error: 5.482261, mean_q: 6.181194
454 (array([12]),) False
  66760/500000: episode: 1669, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 30.425, mean reward: 0.761 [0.000, 1.000], mean action: 22.500 [0.000, 56.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.217094, mean_absolute_error: 5.469234, mean_q: 6.163894
501 (array([12]),) False
  66800/500000: episode: 1670, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 34.621, mean reward: 0.866 [0.173, 1.000], mean action: 23.225 [9.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.228227, mean_absolute_error: 5.483573, mean_q: 6.181509
701 (array([48]),) False
  66840/500000: episode: 1671, duration: 30.033s, episode steps: 40, steps per second: 1, episode reward: 33.255, mean reward: 0.831 [0.119, 1.000], mean action: 26.425 [0.000, 59.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.235914, mean_absolute_error: 5.492248, mean_q: 6.193266
524 (array([22]),) False
  66880/500000: episode: 1672, duration: 30.958s, episode steps: 40, steps per second: 1, episode reward: 35.214, mean reward: 0.880 [0.259, 1.000], mean action: 14.525 [5.000, 33.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.213550, mean_absolute_error: 5.500813, mean_q: 6.204455
785 (array([22]),) False
  66920/500000: episode: 1673, duration: 30.110s, episode steps: 40, steps per second: 1, episode reward: 26.373, mean reward: 0.659 [0.051, 0.824], mean action: 17.750 [1.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.232962, mean_absolute_error: 5.495495, mean_q: 6.200004
687 (array([44]),) False
  66960/500000: episode: 1674, duration: 31.018s, episode steps: 40, steps per second: 1, episode reward: 35.343, mean reward: 0.884 [0.162, 0.953], mean action: 23.225 [1.000, 51.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.199768, mean_absolute_error: 5.511586, mean_q: 6.227617
661 (array([48]),) False
  67000/500000: episode: 1675, duration: 30.140s, episode steps: 40, steps per second: 1, episode reward: 35.121, mean reward: 0.878 [0.307, 1.000], mean action: 25.025 [17.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.207631, mean_absolute_error: 5.552897, mean_q: 6.266579
33 (array([48]),) False
  67040/500000: episode: 1676, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 34.190, mean reward: 0.855 [0.000, 1.000], mean action: 26.075 [10.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.213683, mean_absolute_error: 5.502604, mean_q: 6.214900
410 (array([22]),) False
  67080/500000: episode: 1677, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 35.465, mean reward: 0.887 [0.223, 1.000], mean action: 24.425 [4.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.262136, mean_absolute_error: 5.533864, mean_q: 6.249636
145 (array([19]),) False
  67120/500000: episode: 1678, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 25.424, mean reward: 0.636 [0.294, 0.959], mean action: 17.750 [2.000, 55.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.231342, mean_absolute_error: 5.529399, mean_q: 6.243081
492 (array([22]),) False
  67160/500000: episode: 1679, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 29.606, mean reward: 0.740 [0.131, 0.877], mean action: 18.850 [12.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.242639, mean_absolute_error: 5.545620, mean_q: 6.257509
748 (array([22]),) False
  67200/500000: episode: 1680, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 33.804, mean reward: 0.845 [0.194, 1.000], mean action: 27.450 [11.000, 51.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.247512, mean_absolute_error: 5.452620, mean_q: 6.157511
856 (array([48]),) False
  67240/500000: episode: 1681, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 31.429, mean reward: 0.786 [0.033, 1.000], mean action: 19.450 [0.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.248328, mean_absolute_error: 5.477153, mean_q: 6.183058
758 (array([38]),) False
  67280/500000: episode: 1682, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 34.698, mean reward: 0.867 [0.339, 0.990], mean action: 19.500 [4.000, 54.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.207801, mean_absolute_error: 5.466689, mean_q: 6.184249
533 (array([22]),) False
  67320/500000: episode: 1683, duration: 30.123s, episode steps: 40, steps per second: 1, episode reward: 33.716, mean reward: 0.843 [0.235, 1.000], mean action: 24.950 [2.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.227557, mean_absolute_error: 5.524426, mean_q: 6.248983
586 (array([12]),) False
  67360/500000: episode: 1684, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 31.390, mean reward: 0.785 [0.128, 1.000], mean action: 25.325 [5.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.228267, mean_absolute_error: 5.498164, mean_q: 6.211052
225 (array([48]),) False
  67400/500000: episode: 1685, duration: 30.129s, episode steps: 40, steps per second: 1, episode reward: 33.421, mean reward: 0.836 [0.069, 1.000], mean action: 18.750 [9.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.236829, mean_absolute_error: 5.515706, mean_q: 6.219928
159 (array([48]),) False
  67440/500000: episode: 1686, duration: 31.030s, episode steps: 40, steps per second: 1, episode reward: 33.555, mean reward: 0.839 [0.000, 1.000], mean action: 22.575 [2.000, 50.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.282652, mean_absolute_error: 5.504763, mean_q: 6.204875
19 (array([12]),) False
  67480/500000: episode: 1687, duration: 30.090s, episode steps: 40, steps per second: 1, episode reward: 34.609, mean reward: 0.865 [0.245, 1.000], mean action: 24.250 [7.000, 55.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.240915, mean_absolute_error: 5.477302, mean_q: 6.173625
564 (array([22]),) False
  67520/500000: episode: 1688, duration: 31.056s, episode steps: 40, steps per second: 1, episode reward: 30.691, mean reward: 0.767 [0.000, 1.000], mean action: 22.025 [2.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.223186, mean_absolute_error: 5.482535, mean_q: 6.183675
444 (array([22]),) False
  67560/500000: episode: 1689, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 34.461, mean reward: 0.862 [0.071, 1.000], mean action: 22.350 [0.000, 55.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.242926, mean_absolute_error: 5.535469, mean_q: 6.253078
61 (array([48]),) False
  67600/500000: episode: 1690, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 32.155, mean reward: 0.804 [0.001, 1.000], mean action: 24.225 [5.000, 55.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.216945, mean_absolute_error: 5.519443, mean_q: 6.238932
162 (array([22]),) False
  67640/500000: episode: 1691, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 31.568, mean reward: 0.789 [0.176, 1.000], mean action: 21.550 [7.000, 55.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.239896, mean_absolute_error: 5.505856, mean_q: 6.219625
420 (array([22]),) False
  67680/500000: episode: 1692, duration: 31.006s, episode steps: 40, steps per second: 1, episode reward: 31.741, mean reward: 0.794 [0.000, 1.000], mean action: 25.675 [3.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.245495, mean_absolute_error: 5.524302, mean_q: 6.233593
29 (array([22]),) False
  67720/500000: episode: 1693, duration: 30.995s, episode steps: 40, steps per second: 1, episode reward: 32.818, mean reward: 0.820 [0.000, 1.000], mean action: 24.600 [3.000, 57.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.239279, mean_absolute_error: 5.468699, mean_q: 6.182345
574 (array([8]),) False
  67760/500000: episode: 1694, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 30.925, mean reward: 0.773 [0.000, 1.000], mean action: 23.225 [2.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.269722, mean_absolute_error: 5.503331, mean_q: 6.213275
336 (array([12]),) False
  67800/500000: episode: 1695, duration: 30.092s, episode steps: 40, steps per second: 1, episode reward: 31.974, mean reward: 0.799 [0.151, 1.000], mean action: 19.150 [6.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.232705, mean_absolute_error: 5.497485, mean_q: 6.207945
472 (array([22]),) False
  67840/500000: episode: 1696, duration: 31.004s, episode steps: 40, steps per second: 1, episode reward: 33.996, mean reward: 0.850 [0.095, 1.000], mean action: 22.600 [10.000, 40.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.227849, mean_absolute_error: 5.491717, mean_q: 6.201643
583 (array([22]),) False
  67880/500000: episode: 1697, duration: 30.083s, episode steps: 40, steps per second: 1, episode reward: 35.276, mean reward: 0.882 [0.188, 1.000], mean action: 20.700 [7.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.237228, mean_absolute_error: 5.441314, mean_q: 6.146598
388 (array([22]),) False
  67920/500000: episode: 1698, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 33.592, mean reward: 0.840 [0.227, 1.000], mean action: 27.900 [22.000, 54.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.235392, mean_absolute_error: 5.479108, mean_q: 6.170537
212 (array([36]),) False
  67960/500000: episode: 1699, duration: 30.109s, episode steps: 40, steps per second: 1, episode reward: 20.954, mean reward: 0.524 [0.000, 1.000], mean action: 22.775 [2.000, 56.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.212386, mean_absolute_error: 5.451661, mean_q: 6.149240
130 (array([22]),) False
  68000/500000: episode: 1700, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 35.381, mean reward: 0.885 [0.174, 1.000], mean action: 19.925 [7.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.222613, mean_absolute_error: 5.476411, mean_q: 6.180266
173 (array([3]),) False
  68040/500000: episode: 1701, duration: 30.954s, episode steps: 40, steps per second: 1, episode reward: 11.550, mean reward: 0.289 [0.062, 1.000], mean action: 21.600 [0.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.238264, mean_absolute_error: 5.479709, mean_q: 6.183490
290 (array([22]),) False
  68080/500000: episode: 1702, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 34.559, mean reward: 0.864 [0.000, 1.000], mean action: 21.300 [5.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.217651, mean_absolute_error: 5.473396, mean_q: 6.182808
554 (array([22]),) False
  68120/500000: episode: 1703, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 32.057, mean reward: 0.801 [0.166, 1.000], mean action: 15.000 [1.000, 36.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.221206, mean_absolute_error: 5.468377, mean_q: 6.170802
392 (array([40]),) False
  68160/500000: episode: 1704, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 26.780, mean reward: 0.669 [0.160, 1.000], mean action: 20.375 [1.000, 53.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.248181, mean_absolute_error: 5.525714, mean_q: 6.235998
299 (array([12]),) False
  68200/500000: episode: 1705, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 32.332, mean reward: 0.808 [0.254, 1.000], mean action: 27.825 [8.000, 54.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.228352, mean_absolute_error: 5.471063, mean_q: 6.177289
750 (array([22]),) False
  68240/500000: episode: 1706, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 34.988, mean reward: 0.875 [0.112, 1.000], mean action: 21.875 [12.000, 58.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.227481, mean_absolute_error: 5.471254, mean_q: 6.179294
770 (array([22]),) False
  68280/500000: episode: 1707, duration: 30.078s, episode steps: 40, steps per second: 1, episode reward: 33.649, mean reward: 0.841 [0.105, 1.000], mean action: 15.750 [1.000, 52.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.228024, mean_absolute_error: 5.505477, mean_q: 6.217603
430 (array([22]),) False
  68320/500000: episode: 1708, duration: 31.054s, episode steps: 40, steps per second: 1, episode reward: 34.746, mean reward: 0.869 [0.040, 1.000], mean action: 25.975 [11.000, 60.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.236097, mean_absolute_error: 5.504187, mean_q: 6.200754
338 (array([12]),) False
  68360/500000: episode: 1709, duration: 30.113s, episode steps: 40, steps per second: 1, episode reward: 32.091, mean reward: 0.802 [0.000, 1.000], mean action: 18.650 [1.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.200372, mean_absolute_error: 5.480365, mean_q: 6.186349
650 (array([22]),) False
  68400/500000: episode: 1710, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 33.143, mean reward: 0.829 [0.239, 1.000], mean action: 18.225 [12.000, 55.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.229770, mean_absolute_error: 5.503938, mean_q: 6.201040
634 (array([57]),) False
  68440/500000: episode: 1711, duration: 30.103s, episode steps: 40, steps per second: 1, episode reward: 32.983, mean reward: 0.825 [0.084, 1.000], mean action: 24.975 [15.000, 57.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.236415, mean_absolute_error: 5.511446, mean_q: 6.208817
323 (array([55]),) False
  68480/500000: episode: 1712, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 23.383, mean reward: 0.585 [0.108, 0.809], mean action: 27.075 [8.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.236225, mean_absolute_error: 5.529638, mean_q: 6.234231
257 (array([22]),) False
  68520/500000: episode: 1713, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 30.816, mean reward: 0.770 [0.362, 1.000], mean action: 24.250 [1.000, 50.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.247266, mean_absolute_error: 5.536380, mean_q: 6.245100
96 (array([22]),) False
  68560/500000: episode: 1714, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 32.128, mean reward: 0.803 [0.055, 1.000], mean action: 24.900 [12.000, 59.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.202953, mean_absolute_error: 5.524593, mean_q: 6.237060
400 (array([22]),) False
  68600/500000: episode: 1715, duration: 30.913s, episode steps: 40, steps per second: 1, episode reward: 33.037, mean reward: 0.826 [0.205, 1.000], mean action: 22.400 [12.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.223625, mean_absolute_error: 5.482045, mean_q: 6.186692
824 (array([22]),) False
  68640/500000: episode: 1716, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 33.618, mean reward: 0.840 [0.091, 1.000], mean action: 16.825 [12.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.235483, mean_absolute_error: 5.505712, mean_q: 6.208946
65 (array([48]),) False
  68680/500000: episode: 1717, duration: 30.883s, episode steps: 40, steps per second: 1, episode reward: 32.685, mean reward: 0.817 [0.265, 1.000], mean action: 25.650 [12.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.213439, mean_absolute_error: 5.562712, mean_q: 6.269973
144 (array([22]),) False
  68720/500000: episode: 1718, duration: 30.873s, episode steps: 40, steps per second: 1, episode reward: 27.181, mean reward: 0.680 [0.072, 0.810], mean action: 19.600 [10.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.255731, mean_absolute_error: 5.519030, mean_q: 6.216940
749 (array([22]),) False
  68760/500000: episode: 1719, duration: 30.385s, episode steps: 40, steps per second: 1, episode reward: 31.962, mean reward: 0.799 [0.000, 1.000], mean action: 28.125 [6.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.224641, mean_absolute_error: 5.576357, mean_q: 6.279290
314 (array([22]),) False
  68800/500000: episode: 1720, duration: 31.407s, episode steps: 40, steps per second: 1, episode reward: 31.359, mean reward: 0.784 [0.190, 0.935], mean action: 18.775 [0.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.244736, mean_absolute_error: 5.552182, mean_q: 6.247201
350 (array([12]),) False
  68840/500000: episode: 1721, duration: 31.033s, episode steps: 40, steps per second: 1, episode reward: 23.674, mean reward: 0.592 [0.000, 0.899], mean action: 24.250 [1.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.246248, mean_absolute_error: 5.588202, mean_q: 6.288882
343 (array([22]),) False
  68880/500000: episode: 1722, duration: 31.324s, episode steps: 40, steps per second: 1, episode reward: 30.224, mean reward: 0.756 [0.056, 1.000], mean action: 21.975 [1.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.252130, mean_absolute_error: 5.567554, mean_q: 6.275359
391 (array([22]),) False
  68920/500000: episode: 1723, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 36.211, mean reward: 0.905 [0.133, 1.000], mean action: 26.300 [18.000, 57.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.242674, mean_absolute_error: 5.566487, mean_q: 6.268314
291 (array([22]),) False
  68960/500000: episode: 1724, duration: 31.516s, episode steps: 40, steps per second: 1, episode reward: 34.946, mean reward: 0.874 [0.308, 1.000], mean action: 24.100 [5.000, 44.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.218990, mean_absolute_error: 5.602753, mean_q: 6.301496
318 (array([48]),) False
  69000/500000: episode: 1725, duration: 31.360s, episode steps: 40, steps per second: 1, episode reward: 30.878, mean reward: 0.772 [0.000, 1.000], mean action: 19.225 [4.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.278178, mean_absolute_error: 5.579147, mean_q: 6.274515
112 (array([12]),) False
  69040/500000: episode: 1726, duration: 31.367s, episode steps: 40, steps per second: 1, episode reward: 31.517, mean reward: 0.788 [0.000, 1.000], mean action: 13.950 [1.000, 34.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.215023, mean_absolute_error: 5.565572, mean_q: 6.266141
205 (array([22]),) False
  69080/500000: episode: 1727, duration: 31.416s, episode steps: 40, steps per second: 1, episode reward: 27.879, mean reward: 0.697 [0.268, 1.000], mean action: 17.225 [12.000, 57.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.219402, mean_absolute_error: 5.564552, mean_q: 6.266305
282 (array([22]),) False
  69120/500000: episode: 1728, duration: 31.356s, episode steps: 40, steps per second: 1, episode reward: 34.902, mean reward: 0.873 [0.085, 1.000], mean action: 24.075 [2.000, 58.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.243898, mean_absolute_error: 5.514033, mean_q: 6.221408
445 (array([22]),) False
  69160/500000: episode: 1729, duration: 31.406s, episode steps: 40, steps per second: 1, episode reward: 36.468, mean reward: 0.912 [0.047, 1.000], mean action: 23.425 [13.000, 55.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.225523, mean_absolute_error: 5.536283, mean_q: 6.244586
586 (array([12]),) False
  69200/500000: episode: 1730, duration: 31.404s, episode steps: 40, steps per second: 1, episode reward: 35.448, mean reward: 0.886 [0.180, 1.000], mean action: 17.425 [4.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.247412, mean_absolute_error: 5.520228, mean_q: 6.223569
139 (array([48]),) False
  69240/500000: episode: 1731, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 32.870, mean reward: 0.822 [0.143, 1.000], mean action: 14.700 [0.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.232410, mean_absolute_error: 5.514814, mean_q: 6.211114
258 (array([22]),) False
  69280/500000: episode: 1732, duration: 31.486s, episode steps: 40, steps per second: 1, episode reward: 33.632, mean reward: 0.841 [0.090, 1.000], mean action: 17.325 [7.000, 54.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.256376, mean_absolute_error: 5.514052, mean_q: 6.207576
498 (array([12]),) False
  69320/500000: episode: 1733, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 21.943, mean reward: 0.549 [0.136, 1.000], mean action: 22.550 [0.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.220655, mean_absolute_error: 5.497917, mean_q: 6.195945
582 (array([44]),) False
  69360/500000: episode: 1734, duration: 31.366s, episode steps: 40, steps per second: 1, episode reward: 30.695, mean reward: 0.767 [0.000, 1.000], mean action: 28.125 [2.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.221514, mean_absolute_error: 5.485199, mean_q: 6.175797
239 (array([22]),) False
  69400/500000: episode: 1735, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 32.413, mean reward: 0.810 [0.307, 1.000], mean action: 24.275 [0.000, 47.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.217733, mean_absolute_error: 5.471503, mean_q: 6.166928
544 (array([22]),) False
  69440/500000: episode: 1736, duration: 31.400s, episode steps: 40, steps per second: 1, episode reward: 32.412, mean reward: 0.810 [0.216, 1.000], mean action: 22.125 [12.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.252870, mean_absolute_error: 5.469947, mean_q: 6.156531
422 (array([48]),) False
  69480/500000: episode: 1737, duration: 31.358s, episode steps: 40, steps per second: 1, episode reward: 33.788, mean reward: 0.845 [0.000, 1.000], mean action: 29.800 [5.000, 59.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.244790, mean_absolute_error: 5.471748, mean_q: 6.161044
39 (array([22]),) False
  69520/500000: episode: 1738, duration: 31.379s, episode steps: 40, steps per second: 1, episode reward: 32.996, mean reward: 0.825 [0.138, 1.000], mean action: 16.400 [7.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.254315, mean_absolute_error: 5.436646, mean_q: 6.126157
96 (array([22]),) False
  69560/500000: episode: 1739, duration: 31.477s, episode steps: 40, steps per second: 1, episode reward: 33.748, mean reward: 0.844 [0.053, 1.000], mean action: 21.650 [1.000, 55.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.220094, mean_absolute_error: 5.483525, mean_q: 6.175442
803 (array([58]),) False
  69600/500000: episode: 1740, duration: 31.478s, episode steps: 40, steps per second: 1, episode reward: 16.978, mean reward: 0.424 [0.069, 1.000], mean action: 20.800 [1.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.227234, mean_absolute_error: 5.462699, mean_q: 6.151458
333 (array([12]),) False
  69640/500000: episode: 1741, duration: 31.330s, episode steps: 40, steps per second: 1, episode reward: 31.385, mean reward: 0.785 [0.000, 1.000], mean action: 19.525 [9.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.217246, mean_absolute_error: 5.478399, mean_q: 6.173950
799 (array([36]),) False
  69680/500000: episode: 1742, duration: 31.436s, episode steps: 40, steps per second: 1, episode reward: 20.215, mean reward: 0.505 [0.197, 0.995], mean action: 14.200 [0.000, 41.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.210041, mean_absolute_error: 5.431773, mean_q: 6.121975
729 (array([22]),) False
  69720/500000: episode: 1743, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 31.857, mean reward: 0.796 [0.022, 1.000], mean action: 20.800 [4.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.211507, mean_absolute_error: 5.480027, mean_q: 6.178603
351 (array([22]),) False
  69760/500000: episode: 1744, duration: 31.452s, episode steps: 40, steps per second: 1, episode reward: 36.256, mean reward: 0.906 [0.094, 1.000], mean action: 21.875 [11.000, 29.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.239237, mean_absolute_error: 5.476879, mean_q: 6.171008
103 (array([22]),) False
  69800/500000: episode: 1745, duration: 30.880s, episode steps: 40, steps per second: 1, episode reward: 29.294, mean reward: 0.732 [0.000, 1.000], mean action: 22.100 [1.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.222507, mean_absolute_error: 5.470705, mean_q: 6.166998
748 (array([22]),) False
  69840/500000: episode: 1746, duration: 31.408s, episode steps: 40, steps per second: 1, episode reward: 35.221, mean reward: 0.881 [0.048, 1.000], mean action: 22.900 [2.000, 47.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.213581, mean_absolute_error: 5.443503, mean_q: 6.138907
331 (array([22]),) False
  69880/500000: episode: 1747, duration: 31.496s, episode steps: 40, steps per second: 1, episode reward: 30.021, mean reward: 0.751 [0.018, 1.000], mean action: 21.675 [4.000, 55.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.231951, mean_absolute_error: 5.514530, mean_q: 6.208417
628 (array([22]),) False
  69920/500000: episode: 1748, duration: 31.329s, episode steps: 40, steps per second: 1, episode reward: 34.726, mean reward: 0.868 [0.000, 1.000], mean action: 23.225 [1.000, 55.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.222100, mean_absolute_error: 5.460892, mean_q: 6.147949
703 (array([3]),) False
  69960/500000: episode: 1749, duration: 31.360s, episode steps: 40, steps per second: 1, episode reward: 25.353, mean reward: 0.634 [0.173, 1.000], mean action: 23.325 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.214798, mean_absolute_error: 5.482326, mean_q: 6.176199
259 (array([12]),) False
  70000/500000: episode: 1750, duration: 31.409s, episode steps: 40, steps per second: 1, episode reward: 28.944, mean reward: 0.724 [0.126, 1.000], mean action: 22.975 [5.000, 53.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.207385, mean_absolute_error: 5.458309, mean_q: 6.160020
228 (array([44]),) False
  70040/500000: episode: 1751, duration: 31.425s, episode steps: 40, steps per second: 1, episode reward: 34.190, mean reward: 0.855 [0.180, 0.978], mean action: 18.875 [12.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.224260, mean_absolute_error: 5.461766, mean_q: 6.152782
238 (array([22]),) False
  70080/500000: episode: 1752, duration: 31.428s, episode steps: 40, steps per second: 1, episode reward: 33.043, mean reward: 0.826 [0.031, 1.000], mean action: 26.825 [0.000, 49.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.218687, mean_absolute_error: 5.510512, mean_q: 6.207860
443 (array([22]),) False
  70120/500000: episode: 1753, duration: 31.339s, episode steps: 40, steps per second: 1, episode reward: 32.555, mean reward: 0.814 [0.066, 1.000], mean action: 21.725 [0.000, 52.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.285233, mean_absolute_error: 5.495881, mean_q: 6.196159
470 (array([22]),) False
  70160/500000: episode: 1754, duration: 31.386s, episode steps: 40, steps per second: 1, episode reward: 32.544, mean reward: 0.814 [0.169, 1.000], mean action: 26.375 [9.000, 52.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.217857, mean_absolute_error: 5.468482, mean_q: 6.167168
830 (array([22]),) False
  70200/500000: episode: 1755, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 31.359, mean reward: 0.784 [0.155, 1.000], mean action: 26.400 [10.000, 49.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.255541, mean_absolute_error: 5.489527, mean_q: 6.194127
120 (array([44]),) False
  70240/500000: episode: 1756, duration: 31.378s, episode steps: 40, steps per second: 1, episode reward: 28.236, mean reward: 0.706 [0.000, 1.000], mean action: 17.950 [3.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.231185, mean_absolute_error: 5.464220, mean_q: 6.167377
507 (array([44]),) False
  70280/500000: episode: 1757, duration: 31.149s, episode steps: 40, steps per second: 1, episode reward: 29.295, mean reward: 0.732 [0.112, 0.988], mean action: 22.150 [2.000, 59.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.215133, mean_absolute_error: 5.431311, mean_q: 6.132318
91 (array([48]),) False
  70320/500000: episode: 1758, duration: 33.251s, episode steps: 40, steps per second: 1, episode reward: 33.108, mean reward: 0.828 [0.091, 0.950], mean action: 24.300 [1.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.217314, mean_absolute_error: 5.431393, mean_q: 6.137580
564 (array([22]),) False
  70360/500000: episode: 1759, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 32.556, mean reward: 0.814 [0.255, 1.000], mean action: 20.725 [1.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.214251, mean_absolute_error: 5.446259, mean_q: 6.143627
41 (array([12]),) False
  70400/500000: episode: 1760, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 30.832, mean reward: 0.771 [0.148, 1.000], mean action: 26.025 [9.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.209788, mean_absolute_error: 5.454715, mean_q: 6.156428
567 (array([22]),) False
  70440/500000: episode: 1761, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 22.041, mean reward: 0.551 [0.000, 1.000], mean action: 16.025 [0.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.234497, mean_absolute_error: 5.396484, mean_q: 6.100873
631 (array([22]),) False
  70480/500000: episode: 1762, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 33.711, mean reward: 0.843 [0.000, 1.000], mean action: 24.075 [1.000, 52.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.207699, mean_absolute_error: 5.470283, mean_q: 6.170628
338 (array([12]),) False
  70520/500000: episode: 1763, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 32.257, mean reward: 0.806 [0.031, 1.000], mean action: 18.275 [7.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.235848, mean_absolute_error: 5.431983, mean_q: 6.130717
770 (array([22]),) False
  70560/500000: episode: 1764, duration: 33.250s, episode steps: 40, steps per second: 1, episode reward: 32.110, mean reward: 0.803 [0.000, 1.000], mean action: 21.750 [1.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.228197, mean_absolute_error: 5.487642, mean_q: 6.192538
833 (array([22]),) False
  70600/500000: episode: 1765, duration: 33.250s, episode steps: 40, steps per second: 1, episode reward: 32.387, mean reward: 0.810 [0.231, 1.000], mean action: 20.200 [2.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.206543, mean_absolute_error: 5.428830, mean_q: 6.129974
204 (array([22]),) False
  70640/500000: episode: 1766, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 26.193, mean reward: 0.655 [0.175, 1.000], mean action: 14.450 [6.000, 55.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.233826, mean_absolute_error: 5.482791, mean_q: 6.183643
790 (array([48]),) False
  70680/500000: episode: 1767, duration: 32.296s, episode steps: 40, steps per second: 1, episode reward: 24.594, mean reward: 0.615 [0.101, 1.000], mean action: 19.225 [0.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.225560, mean_absolute_error: 5.464117, mean_q: 6.165183
398 (array([22]),) False
  70720/500000: episode: 1768, duration: 33.252s, episode steps: 40, steps per second: 1, episode reward: 33.199, mean reward: 0.830 [0.145, 1.000], mean action: 23.175 [3.000, 57.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.230103, mean_absolute_error: 5.451146, mean_q: 6.152709
216 (array([22]),) False
  70760/500000: episode: 1769, duration: 32.327s, episode steps: 40, steps per second: 1, episode reward: 24.816, mean reward: 0.620 [0.112, 1.000], mean action: 17.200 [7.000, 42.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.224890, mean_absolute_error: 5.432419, mean_q: 6.127144
125 (array([58]),) False
  70800/500000: episode: 1770, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 9.508, mean reward: 0.238 [0.000, 0.797], mean action: 22.725 [5.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.212654, mean_absolute_error: 5.453973, mean_q: 6.149049
488 (array([22]),) False
  70840/500000: episode: 1771, duration: 32.326s, episode steps: 40, steps per second: 1, episode reward: 34.889, mean reward: 0.872 [0.274, 1.000], mean action: 13.725 [0.000, 46.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.220265, mean_absolute_error: 5.467156, mean_q: 6.155454
728 (array([12]),) False
  70880/500000: episode: 1772, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 30.812, mean reward: 0.770 [0.330, 1.000], mean action: 14.300 [10.000, 41.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.240934, mean_absolute_error: 5.473489, mean_q: 6.158469
157 (array([48]),) False
  70920/500000: episode: 1773, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 33.782, mean reward: 0.845 [0.114, 0.934], mean action: 14.650 [4.000, 45.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.223284, mean_absolute_error: 5.469134, mean_q: 6.154333
442 (array([22]),) False
  70960/500000: episode: 1774, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 35.244, mean reward: 0.881 [0.100, 1.000], mean action: 24.325 [13.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.196586, mean_absolute_error: 5.414163, mean_q: 6.107778
285 (array([58]),) False
  71000/500000: episode: 1775, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 21.605, mean reward: 0.540 [0.006, 0.952], mean action: 31.350 [7.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.213727, mean_absolute_error: 5.450601, mean_q: 6.147899
830 (array([22]),) False
  71040/500000: episode: 1776, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 33.416, mean reward: 0.835 [0.195, 1.000], mean action: 22.075 [2.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.196497, mean_absolute_error: 5.454999, mean_q: 6.152915
519 (array([58]),) False
  71080/500000: episode: 1777, duration: 33.255s, episode steps: 40, steps per second: 1, episode reward: 22.501, mean reward: 0.563 [0.093, 0.733], mean action: 29.650 [10.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.223188, mean_absolute_error: 5.396636, mean_q: 6.086832
765 (array([48]),) False
  71120/500000: episode: 1778, duration: 32.539s, episode steps: 40, steps per second: 1, episode reward: 25.702, mean reward: 0.643 [0.044, 1.000], mean action: 23.750 [3.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.240584, mean_absolute_error: 5.403019, mean_q: 6.098304
586 (array([12]),) False
  71160/500000: episode: 1779, duration: 31.202s, episode steps: 40, steps per second: 1, episode reward: 33.859, mean reward: 0.846 [0.000, 1.000], mean action: 14.150 [1.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.211672, mean_absolute_error: 5.427233, mean_q: 6.125144
786 (array([22]),) False
  71200/500000: episode: 1780, duration: 31.519s, episode steps: 40, steps per second: 1, episode reward: 27.456, mean reward: 0.686 [0.123, 1.000], mean action: 19.925 [2.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.214401, mean_absolute_error: 5.434371, mean_q: 6.136480
302 (array([22]),) False
  71240/500000: episode: 1781, duration: 30.904s, episode steps: 40, steps per second: 1, episode reward: 34.828, mean reward: 0.871 [0.174, 1.000], mean action: 24.950 [12.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.239936, mean_absolute_error: 5.377679, mean_q: 6.080877
370 (array([58]),) False
  71280/500000: episode: 1782, duration: 31.335s, episode steps: 40, steps per second: 1, episode reward: 18.099, mean reward: 0.452 [0.000, 1.000], mean action: 24.200 [9.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.218294, mean_absolute_error: 5.383684, mean_q: 6.082261
807 (array([22]),) False
  71320/500000: episode: 1783, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 32.876, mean reward: 0.822 [0.339, 0.980], mean action: 22.150 [1.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.202224, mean_absolute_error: 5.405466, mean_q: 6.100256
321 (array([22]),) False
  71360/500000: episode: 1784, duration: 31.393s, episode steps: 40, steps per second: 1, episode reward: 33.254, mean reward: 0.831 [0.129, 1.000], mean action: 20.075 [3.000, 55.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.220172, mean_absolute_error: 5.437735, mean_q: 6.131087
466 (array([22]),) False
  71400/500000: episode: 1785, duration: 31.334s, episode steps: 40, steps per second: 1, episode reward: 35.705, mean reward: 0.893 [0.143, 1.000], mean action: 23.650 [4.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.206951, mean_absolute_error: 5.432737, mean_q: 6.131930
39 (array([22]),) False
  71440/500000: episode: 1786, duration: 31.318s, episode steps: 40, steps per second: 1, episode reward: 33.172, mean reward: 0.829 [0.100, 1.000], mean action: 20.200 [7.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.209686, mean_absolute_error: 5.441507, mean_q: 6.140193
544 (array([22]),) False
  71480/500000: episode: 1787, duration: 31.328s, episode steps: 40, steps per second: 1, episode reward: 34.834, mean reward: 0.871 [0.353, 1.000], mean action: 24.700 [12.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.209348, mean_absolute_error: 5.407349, mean_q: 6.108159
172 (array([12]),) False
  71520/500000: episode: 1788, duration: 31.384s, episode steps: 40, steps per second: 1, episode reward: 30.941, mean reward: 0.774 [0.082, 1.000], mean action: 16.775 [1.000, 60.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.230878, mean_absolute_error: 5.437502, mean_q: 6.152450
210 (array([58]),) False
  71560/500000: episode: 1789, duration: 31.404s, episode steps: 40, steps per second: 1, episode reward: 10.274, mean reward: 0.257 [0.021, 0.816], mean action: 16.075 [0.000, 45.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.227723, mean_absolute_error: 5.451395, mean_q: 6.156731
432 (array([22]),) False
  71600/500000: episode: 1790, duration: 31.393s, episode steps: 40, steps per second: 1, episode reward: 36.353, mean reward: 0.909 [0.244, 1.000], mean action: 24.925 [13.000, 57.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.199384, mean_absolute_error: 5.403308, mean_q: 6.107337
128 (array([22]),) False
  71640/500000: episode: 1791, duration: 32.191s, episode steps: 40, steps per second: 1, episode reward: 29.466, mean reward: 0.737 [0.250, 1.000], mean action: 18.250 [0.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.216853, mean_absolute_error: 5.406182, mean_q: 6.108740
833 (array([22]),) False
  71680/500000: episode: 1792, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 35.157, mean reward: 0.879 [0.375, 1.000], mean action: 13.725 [1.000, 45.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.232708, mean_absolute_error: 5.389606, mean_q: 6.083745
354 (array([12]),) False
  71720/500000: episode: 1793, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 24.321, mean reward: 0.608 [0.129, 1.000], mean action: 23.475 [1.000, 56.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.192844, mean_absolute_error: 5.401917, mean_q: 6.090041
52 (array([22]),) False
  71760/500000: episode: 1794, duration: 33.210s, episode steps: 40, steps per second: 1, episode reward: 36.370, mean reward: 0.909 [0.040, 1.000], mean action: 24.100 [14.000, 56.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.237698, mean_absolute_error: 5.410506, mean_q: 6.097423
358 (array([22]),) False
  71800/500000: episode: 1795, duration: 32.230s, episode steps: 40, steps per second: 1, episode reward: 32.893, mean reward: 0.822 [0.057, 1.000], mean action: 25.775 [12.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.255852, mean_absolute_error: 5.416765, mean_q: 6.113855
188 (array([22]),) False
  71840/500000: episode: 1796, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 33.328, mean reward: 0.833 [0.163, 0.949], mean action: 12.725 [0.000, 45.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.237703, mean_absolute_error: 5.419791, mean_q: 6.112639
759 (array([48]),) False
  71880/500000: episode: 1797, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 30.367, mean reward: 0.759 [0.000, 1.000], mean action: 26.975 [5.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.220949, mean_absolute_error: 5.419732, mean_q: 6.113146
321 (array([22]),) False
  71920/500000: episode: 1798, duration: 33.277s, episode steps: 40, steps per second: 1, episode reward: 35.954, mean reward: 0.899 [0.091, 1.000], mean action: 17.600 [6.000, 48.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.214329, mean_absolute_error: 5.396770, mean_q: 6.096129
505 (array([22]),) False
  71960/500000: episode: 1799, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 34.024, mean reward: 0.851 [0.415, 1.000], mean action: 23.375 [7.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.221845, mean_absolute_error: 5.395590, mean_q: 6.096262
48 (array([12]),) False
  72000/500000: episode: 1800, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 33.671, mean reward: 0.842 [0.168, 0.952], mean action: 24.075 [5.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.217655, mean_absolute_error: 5.409548, mean_q: 6.114525
853 (array([22]),) False
  72040/500000: episode: 1801, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 26.287, mean reward: 0.657 [0.107, 1.000], mean action: 20.425 [0.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.206697, mean_absolute_error: 5.398674, mean_q: 6.095758
223 (array([48]),) False
  72080/500000: episode: 1802, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 31.258, mean reward: 0.781 [0.130, 0.854], mean action: 22.875 [0.000, 51.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.209392, mean_absolute_error: 5.454527, mean_q: 6.150139
584 (array([36]),) False
  72120/500000: episode: 1803, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 15.989, mean reward: 0.400 [0.128, 0.912], mean action: 18.500 [1.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.200396, mean_absolute_error: 5.393249, mean_q: 6.088386
767 (array([48]),) False
  72160/500000: episode: 1804, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 26.731, mean reward: 0.668 [0.004, 1.000], mean action: 19.525 [0.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.233456, mean_absolute_error: 5.384239, mean_q: 6.076836
773 (array([22]),) False
  72200/500000: episode: 1805, duration: 32.152s, episode steps: 40, steps per second: 1, episode reward: 31.678, mean reward: 0.792 [0.155, 1.000], mean action: 23.375 [9.000, 51.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.199124, mean_absolute_error: 5.441480, mean_q: 6.141457
612 (array([22]),) False
  72240/500000: episode: 1806, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 32.964, mean reward: 0.824 [0.157, 1.000], mean action: 16.000 [3.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.197900, mean_absolute_error: 5.425339, mean_q: 6.121729
812 (array([22]),) False
  72280/500000: episode: 1807, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 29.978, mean reward: 0.749 [0.060, 1.000], mean action: 19.250 [4.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.239359, mean_absolute_error: 5.387340, mean_q: 6.084398
195 (array([22]),) False
  72320/500000: episode: 1808, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 32.651, mean reward: 0.816 [0.021, 1.000], mean action: 20.000 [12.000, 50.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.226776, mean_absolute_error: 5.424042, mean_q: 6.128300
43 (array([12]),) False
  72360/500000: episode: 1809, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 35.196, mean reward: 0.880 [0.271, 0.998], mean action: 25.600 [20.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.220881, mean_absolute_error: 5.390310, mean_q: 6.086046
698 (array([22]),) False
  72400/500000: episode: 1810, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 37.199, mean reward: 0.930 [0.171, 1.000], mean action: 21.650 [12.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.220395, mean_absolute_error: 5.434302, mean_q: 6.137757
782 (array([22]),) False
  72440/500000: episode: 1811, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 28.896, mean reward: 0.722 [0.241, 1.000], mean action: 18.400 [0.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.207542, mean_absolute_error: 5.392089, mean_q: 6.084144
816 (array([4]),) False
  72480/500000: episode: 1812, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 9.803, mean reward: 0.245 [0.000, 0.943], mean action: 24.150 [4.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.235028, mean_absolute_error: 5.362750, mean_q: 6.046884
390 (array([22]),) False
  72520/500000: episode: 1813, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 30.017, mean reward: 0.750 [0.021, 1.000], mean action: 24.000 [1.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.232269, mean_absolute_error: 5.419618, mean_q: 6.105143
289 (array([21]),) False
  72560/500000: episode: 1814, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 27.814, mean reward: 0.695 [0.296, 1.000], mean action: 22.450 [2.000, 50.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.228773, mean_absolute_error: 5.385808, mean_q: 6.072732
252 (array([22]),) False
  72600/500000: episode: 1815, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 34.958, mean reward: 0.874 [0.143, 1.000], mean action: 24.675 [4.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.248156, mean_absolute_error: 5.351262, mean_q: 6.033636
418 (array([22]),) False
  72640/500000: episode: 1816, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 29.570, mean reward: 0.739 [0.000, 1.000], mean action: 26.725 [0.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.223701, mean_absolute_error: 5.344452, mean_q: 6.027203
610 (array([48]),) False
  72680/500000: episode: 1817, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 32.928, mean reward: 0.823 [0.066, 1.000], mean action: 25.550 [11.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.206964, mean_absolute_error: 5.342941, mean_q: 6.021221
164 (array([22]),) False
  72720/500000: episode: 1818, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 31.967, mean reward: 0.799 [0.119, 1.000], mean action: 22.625 [6.000, 58.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.211112, mean_absolute_error: 5.383984, mean_q: 6.065358
217 (array([12]),) False
  72760/500000: episode: 1819, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 30.930, mean reward: 0.773 [0.281, 1.000], mean action: 19.000 [0.000, 53.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.219164, mean_absolute_error: 5.383701, mean_q: 6.068896
206 (array([22]),) False
  72800/500000: episode: 1820, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 27.888, mean reward: 0.697 [0.083, 1.000], mean action: 14.875 [3.000, 58.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.221654, mean_absolute_error: 5.348234, mean_q: 6.032392
327 (array([22]),) False
  72840/500000: episode: 1821, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 30.592, mean reward: 0.765 [0.118, 1.000], mean action: 18.925 [10.000, 54.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.223254, mean_absolute_error: 5.365922, mean_q: 6.041746
793 (array([12]),) False
  72880/500000: episode: 1822, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 33.475, mean reward: 0.837 [0.098, 1.000], mean action: 17.775 [10.000, 58.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.203887, mean_absolute_error: 5.389347, mean_q: 6.075261
253 (array([44]),) False
  72920/500000: episode: 1823, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 25.378, mean reward: 0.634 [0.043, 0.917], mean action: 32.250 [0.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.250618, mean_absolute_error: 5.364922, mean_q: 6.052880
457 (array([38]),) False
  72960/500000: episode: 1824, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 32.341, mean reward: 0.809 [0.675, 0.945], mean action: 25.025 [12.000, 51.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.234608, mean_absolute_error: 5.306329, mean_q: 5.992428
844 (array([48]),) False
  73000/500000: episode: 1825, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 36.460, mean reward: 0.911 [0.000, 1.000], mean action: 30.550 [7.000, 54.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.241564, mean_absolute_error: 5.379992, mean_q: 6.066930
860 (array([12]),) False
  73040/500000: episode: 1826, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 28.560, mean reward: 0.714 [0.049, 1.000], mean action: 19.850 [0.000, 53.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.227644, mean_absolute_error: 5.334325, mean_q: 6.013883
322 (array([12]),) False
  73080/500000: episode: 1827, duration: 32.285s, episode steps: 40, steps per second: 1, episode reward: 33.280, mean reward: 0.832 [0.007, 1.000], mean action: 15.600 [1.000, 54.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.221250, mean_absolute_error: 5.370034, mean_q: 6.061817
32 (array([48]),) False
  73120/500000: episode: 1828, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 33.466, mean reward: 0.837 [0.055, 1.000], mean action: 26.425 [5.000, 60.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.200588, mean_absolute_error: 5.340361, mean_q: 6.028214
178 (array([38]),) False
  73160/500000: episode: 1829, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 26.794, mean reward: 0.670 [0.000, 0.992], mean action: 17.225 [1.000, 53.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.203259, mean_absolute_error: 5.392258, mean_q: 6.079684
539 (array([22]),) False
  73200/500000: episode: 1830, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 33.867, mean reward: 0.847 [0.019, 1.000], mean action: 26.650 [9.000, 54.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.217562, mean_absolute_error: 5.349164, mean_q: 6.026398
5 (array([37]),) False
  73240/500000: episode: 1831, duration: 32.234s, episode steps: 40, steps per second: 1, episode reward: 30.642, mean reward: 0.766 [0.035, 1.000], mean action: 18.475 [0.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.222597, mean_absolute_error: 5.338711, mean_q: 6.006892
699 (array([22]),) False
  73280/500000: episode: 1832, duration: 33.248s, episode steps: 40, steps per second: 1, episode reward: 33.780, mean reward: 0.845 [0.198, 1.000], mean action: 21.700 [4.000, 52.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.225830, mean_absolute_error: 5.304642, mean_q: 5.983692
479 (array([22]),) False
  73320/500000: episode: 1833, duration: 32.978s, episode steps: 40, steps per second: 1, episode reward: 31.630, mean reward: 0.791 [0.087, 1.000], mean action: 25.900 [3.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.212378, mean_absolute_error: 5.334346, mean_q: 6.021072
333 (array([12]),) False
  73360/500000: episode: 1834, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 33.365, mean reward: 0.834 [0.152, 1.000], mean action: 19.175 [4.000, 56.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.254330, mean_absolute_error: 5.319218, mean_q: 6.002512
271 (array([18]),) False
  73400/500000: episode: 1835, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 31.195, mean reward: 0.780 [0.000, 1.000], mean action: 26.800 [5.000, 55.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.217161, mean_absolute_error: 5.345185, mean_q: 6.032393
252 (array([22]),) False
  73440/500000: episode: 1836, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 34.816, mean reward: 0.870 [0.000, 1.000], mean action: 25.025 [3.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.237452, mean_absolute_error: 5.372995, mean_q: 6.055981
667 (array([48]),) False
  73480/500000: episode: 1837, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 33.528, mean reward: 0.838 [0.000, 1.000], mean action: 39.625 [3.000, 54.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.207935, mean_absolute_error: 5.377918, mean_q: 6.056300
307 (array([22]),) False
  73520/500000: episode: 1838, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 34.337, mean reward: 0.858 [0.159, 1.000], mean action: 24.975 [1.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.223633, mean_absolute_error: 5.428759, mean_q: 6.117367
9 (array([14]),) False
  73560/500000: episode: 1839, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 30.983, mean reward: 0.775 [0.000, 0.905], mean action: 26.400 [2.000, 56.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.212346, mean_absolute_error: 5.381520, mean_q: 6.067218
354 (array([12]),) False
  73600/500000: episode: 1840, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 23.682, mean reward: 0.592 [0.000, 1.000], mean action: 22.800 [4.000, 53.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.231820, mean_absolute_error: 5.363862, mean_q: 6.052180
303 (array([22]),) False
  73640/500000: episode: 1841, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 31.374, mean reward: 0.784 [0.091, 1.000], mean action: 27.625 [7.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.225221, mean_absolute_error: 5.350836, mean_q: 6.040567
443 (array([22]),) False
  73680/500000: episode: 1842, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 36.739, mean reward: 0.918 [0.178, 1.000], mean action: 22.725 [0.000, 44.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.224333, mean_absolute_error: 5.345317, mean_q: 6.033587
163 (array([44]),) False
  73720/500000: episode: 1843, duration: 32.267s, episode steps: 40, steps per second: 1, episode reward: 36.763, mean reward: 0.919 [0.481, 0.999], mean action: 21.100 [10.000, 59.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.232459, mean_absolute_error: 5.367832, mean_q: 6.058937
440 (array([22]),) False
  73760/500000: episode: 1844, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 32.621, mean reward: 0.816 [0.036, 1.000], mean action: 24.750 [0.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.187525, mean_absolute_error: 5.394613, mean_q: 6.083905
60 (array([22]),) False
  73800/500000: episode: 1845, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 32.061, mean reward: 0.802 [0.017, 1.000], mean action: 29.600 [18.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.219135, mean_absolute_error: 5.339316, mean_q: 6.026977
48 (array([12]),) False
  73840/500000: episode: 1846, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 34.393, mean reward: 0.860 [0.292, 0.952], mean action: 24.975 [5.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.213500, mean_absolute_error: 5.393191, mean_q: 6.095607
368 (array([22]),) False
  73880/500000: episode: 1847, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 35.483, mean reward: 0.887 [0.142, 1.000], mean action: 24.575 [14.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.196373, mean_absolute_error: 5.364135, mean_q: 6.060897
471 (array([12]),) False
  73920/500000: episode: 1848, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 29.176, mean reward: 0.729 [0.256, 1.000], mean action: 24.975 [2.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.245101, mean_absolute_error: 5.348949, mean_q: 6.046862
15 (array([22]),) False
  73960/500000: episode: 1849, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 31.888, mean reward: 0.797 [0.145, 1.000], mean action: 23.900 [8.000, 59.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.209952, mean_absolute_error: 5.356103, mean_q: 6.061336
447 (array([44]),) False
  74000/500000: episode: 1850, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 29.761, mean reward: 0.744 [0.024, 1.000], mean action: 25.500 [1.000, 54.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.230429, mean_absolute_error: 5.331546, mean_q: 6.039374
181 (array([22]),) False
  74040/500000: episode: 1851, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 24.662, mean reward: 0.617 [0.152, 1.000], mean action: 19.625 [12.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.222038, mean_absolute_error: 5.385171, mean_q: 6.089263
9 (array([14]),) False
  74080/500000: episode: 1852, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 32.466, mean reward: 0.812 [0.351, 0.989], mean action: 21.000 [5.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.232009, mean_absolute_error: 5.374701, mean_q: 6.062813
548 (array([22]),) False
  74120/500000: episode: 1853, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 29.428, mean reward: 0.736 [0.029, 1.000], mean action: 20.450 [0.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.214947, mean_absolute_error: 5.396139, mean_q: 6.096656
319 (array([33]),) False
  74160/500000: episode: 1854, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 24.221, mean reward: 0.606 [0.059, 1.000], mean action: 24.475 [0.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.196060, mean_absolute_error: 5.321133, mean_q: 6.016641
190 (array([3]),) False
  74200/500000: episode: 1855, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 25.200, mean reward: 0.630 [0.047, 1.000], mean action: 14.200 [2.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.237972, mean_absolute_error: 5.358253, mean_q: 6.046329
544 (array([22]),) False
  74240/500000: episode: 1856, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 30.078, mean reward: 0.752 [0.063, 1.000], mean action: 23.350 [10.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.209100, mean_absolute_error: 5.302354, mean_q: 5.988786
739 (array([22]),) False
  74280/500000: episode: 1857, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 32.822, mean reward: 0.821 [0.079, 1.000], mean action: 14.150 [2.000, 42.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.189258, mean_absolute_error: 5.354881, mean_q: 6.041842
679 (array([44]),) False
  74320/500000: episode: 1858, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 22.362, mean reward: 0.559 [0.000, 0.988], mean action: 14.500 [0.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.220414, mean_absolute_error: 5.319617, mean_q: 6.003449
430 (array([22]),) False
  74360/500000: episode: 1859, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 30.164, mean reward: 0.754 [0.033, 1.000], mean action: 24.150 [1.000, 58.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.215676, mean_absolute_error: 5.317253, mean_q: 6.004000
404 (array([12]),) False
  74400/500000: episode: 1860, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 30.549, mean reward: 0.764 [0.283, 1.000], mean action: 26.975 [12.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.247136, mean_absolute_error: 5.267385, mean_q: 5.947294
830 (array([22]),) False
  74440/500000: episode: 1861, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 31.371, mean reward: 0.784 [0.134, 1.000], mean action: 16.925 [2.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.216497, mean_absolute_error: 5.308855, mean_q: 5.982633
494 (array([48]),) False
  74480/500000: episode: 1862, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 29.029, mean reward: 0.726 [0.014, 0.808], mean action: 14.500 [11.000, 54.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.183762, mean_absolute_error: 5.248998, mean_q: 5.918208
627 (array([48]),) False
  74520/500000: episode: 1863, duration: 32.187s, episode steps: 40, steps per second: 1, episode reward: 32.999, mean reward: 0.825 [0.012, 0.960], mean action: 22.125 [4.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.215247, mean_absolute_error: 5.285357, mean_q: 5.956207
99 (array([22]),) False
  74560/500000: episode: 1864, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 35.845, mean reward: 0.896 [0.122, 1.000], mean action: 23.375 [2.000, 60.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.216780, mean_absolute_error: 5.285642, mean_q: 5.960142
780 (array([22]),) False
  74600/500000: episode: 1865, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 30.798, mean reward: 0.770 [0.017, 1.000], mean action: 17.575 [6.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.224878, mean_absolute_error: 5.290622, mean_q: 5.962856
444 (array([22]),) False
  74640/500000: episode: 1866, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 31.185, mean reward: 0.780 [0.035, 1.000], mean action: 24.000 [2.000, 54.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.206478, mean_absolute_error: 5.262366, mean_q: 5.928041
595 (array([22]),) False
  74680/500000: episode: 1867, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 33.506, mean reward: 0.838 [0.306, 1.000], mean action: 26.150 [2.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.218803, mean_absolute_error: 5.305132, mean_q: 5.973694
142 (array([12]),) False
  74720/500000: episode: 1868, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 36.528, mean reward: 0.913 [0.132, 1.000], mean action: 17.625 [11.000, 55.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.193347, mean_absolute_error: 5.255076, mean_q: 5.939406
784 (array([22]),) False
  74760/500000: episode: 1869, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 33.561, mean reward: 0.839 [0.003, 1.000], mean action: 17.875 [6.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.222583, mean_absolute_error: 5.261036, mean_q: 5.940543
125 (array([58]),) False
  74800/500000: episode: 1870, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 15.346, mean reward: 0.384 [0.000, 1.000], mean action: 29.500 [5.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.220445, mean_absolute_error: 5.245805, mean_q: 5.930530
381 (array([22]),) False
  74840/500000: episode: 1871, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 35.361, mean reward: 0.884 [0.000, 1.000], mean action: 23.850 [3.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.226760, mean_absolute_error: 5.240976, mean_q: 5.927483
784 (array([22]),) False
  74880/500000: episode: 1872, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 33.432, mean reward: 0.836 [0.219, 1.000], mean action: 20.350 [12.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.199462, mean_absolute_error: 5.273072, mean_q: 5.966125
413 (array([22]),) False
  74920/500000: episode: 1873, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 30.089, mean reward: 0.752 [0.093, 1.000], mean action: 28.575 [7.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.208757, mean_absolute_error: 5.208707, mean_q: 5.900887
692 (array([22]),) False
  74960/500000: episode: 1874, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 34.148, mean reward: 0.854 [0.151, 1.000], mean action: 14.050 [3.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.210816, mean_absolute_error: 5.225022, mean_q: 5.909674
677 (array([48]),) False
  75000/500000: episode: 1875, duration: 32.162s, episode steps: 40, steps per second: 1, episode reward: 35.039, mean reward: 0.876 [0.117, 1.000], mean action: 16.150 [3.000, 48.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.205155, mean_absolute_error: 5.218806, mean_q: 5.896228
201 (array([22]),) False
  75040/500000: episode: 1876, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 33.530, mean reward: 0.838 [0.064, 1.000], mean action: 21.075 [5.000, 54.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.202755, mean_absolute_error: 5.262450, mean_q: 5.944474
559 (array([59]),) False
  75080/500000: episode: 1877, duration: 32.306s, episode steps: 40, steps per second: 1, episode reward: 22.661, mean reward: 0.567 [0.068, 1.000], mean action: 20.600 [8.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.194148, mean_absolute_error: 5.240176, mean_q: 5.925108
700 (array([44]),) False
  75120/500000: episode: 1878, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 28.948, mean reward: 0.724 [0.295, 0.886], mean action: 20.925 [3.000, 52.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.188337, mean_absolute_error: 5.254894, mean_q: 5.936978
115 (array([22]),) False
  75160/500000: episode: 1879, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 31.573, mean reward: 0.789 [0.190, 1.000], mean action: 16.750 [5.000, 55.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.193727, mean_absolute_error: 5.253314, mean_q: 5.931670
317 (array([12]),) False
  75200/500000: episode: 1880, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 30.162, mean reward: 0.754 [0.040, 1.000], mean action: 18.225 [2.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.206577, mean_absolute_error: 5.210508, mean_q: 5.882003
764 (array([48]),) False
  75240/500000: episode: 1881, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 31.870, mean reward: 0.797 [0.258, 1.000], mean action: 25.200 [0.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.211153, mean_absolute_error: 5.219747, mean_q: 5.897666
424 (array([22]),) False
  75280/500000: episode: 1882, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 33.449, mean reward: 0.836 [0.026, 1.000], mean action: 25.950 [3.000, 58.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.206430, mean_absolute_error: 5.210294, mean_q: 5.882216
632 (array([22]),) False
  75320/500000: episode: 1883, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 34.067, mean reward: 0.852 [0.000, 1.000], mean action: 28.025 [4.000, 59.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.206288, mean_absolute_error: 5.239306, mean_q: 5.914787
174 (array([33]),) False
  75360/500000: episode: 1884, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 20.068, mean reward: 0.502 [0.236, 0.986], mean action: 20.650 [4.000, 55.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.198829, mean_absolute_error: 5.229203, mean_q: 5.905197
525 (array([22]),) False
  75400/500000: episode: 1885, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 33.879, mean reward: 0.847 [0.090, 1.000], mean action: 14.950 [9.000, 38.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.205849, mean_absolute_error: 5.216111, mean_q: 5.896482
853 (array([22]),) False
  75440/500000: episode: 1886, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 26.926, mean reward: 0.673 [0.080, 0.856], mean action: 20.175 [6.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.226389, mean_absolute_error: 5.172044, mean_q: 5.850684
357 (array([22]),) False
  75480/500000: episode: 1887, duration: 32.251s, episode steps: 40, steps per second: 1, episode reward: 29.438, mean reward: 0.736 [0.000, 1.000], mean action: 26.625 [12.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.201216, mean_absolute_error: 5.269210, mean_q: 5.946185
130 (array([22]),) False
  75520/500000: episode: 1888, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 33.131, mean reward: 0.828 [0.012, 1.000], mean action: 18.475 [5.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.199505, mean_absolute_error: 5.228971, mean_q: 5.909011
262 (array([22]),) False
  75560/500000: episode: 1889, duration: 32.150s, episode steps: 40, steps per second: 1, episode reward: 24.403, mean reward: 0.610 [0.228, 1.000], mean action: 23.350 [12.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.208028, mean_absolute_error: 5.275599, mean_q: 5.956420
408 (array([12]),) False
  75600/500000: episode: 1890, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 32.385, mean reward: 0.810 [0.049, 1.000], mean action: 24.175 [0.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.200043, mean_absolute_error: 5.250996, mean_q: 5.926759
162 (array([22]),) False
  75640/500000: episode: 1891, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 31.781, mean reward: 0.795 [0.069, 1.000], mean action: 22.900 [12.000, 60.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.215351, mean_absolute_error: 5.216661, mean_q: 5.898223
456 (array([22]),) False
  75680/500000: episode: 1892, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 37.228, mean reward: 0.931 [0.139, 1.000], mean action: 23.350 [3.000, 49.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.195529, mean_absolute_error: 5.249913, mean_q: 5.932628
462 (array([12]),) False
  75720/500000: episode: 1893, duration: 33.247s, episode steps: 40, steps per second: 1, episode reward: 29.435, mean reward: 0.736 [0.000, 1.000], mean action: 21.900 [1.000, 54.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.237467, mean_absolute_error: 5.264513, mean_q: 5.937627
376 (array([22]),) False
  75760/500000: episode: 1894, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 35.618, mean reward: 0.890 [0.000, 1.000], mean action: 24.775 [3.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.189639, mean_absolute_error: 5.222798, mean_q: 5.897076
35 (array([48]),) False
  75800/500000: episode: 1895, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 33.728, mean reward: 0.843 [0.183, 0.959], mean action: 32.675 [5.000, 51.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.188093, mean_absolute_error: 5.247726, mean_q: 5.919263
15 (array([22]),) False
  75840/500000: episode: 1896, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 32.380, mean reward: 0.809 [0.000, 1.000], mean action: 21.950 [2.000, 42.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.202674, mean_absolute_error: 5.272049, mean_q: 5.939208
667 (array([48]),) False
  75880/500000: episode: 1897, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 33.296, mean reward: 0.832 [0.089, 1.000], mean action: 29.250 [10.000, 56.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.204149, mean_absolute_error: 5.326344, mean_q: 5.999339
719 (array([22]),) False
  75920/500000: episode: 1898, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 34.863, mean reward: 0.872 [0.174, 1.000], mean action: 15.000 [2.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.214930, mean_absolute_error: 5.313749, mean_q: 5.992787
285 (array([58]),) False
  75960/500000: episode: 1899, duration: 32.137s, episode steps: 40, steps per second: 1, episode reward: 24.035, mean reward: 0.601 [0.006, 0.949], mean action: 34.700 [8.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.195319, mean_absolute_error: 5.287035, mean_q: 5.963911
98 (array([12]),) False
  76000/500000: episode: 1900, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 34.964, mean reward: 0.874 [0.069, 0.987], mean action: 24.975 [5.000, 55.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.218161, mean_absolute_error: 5.346445, mean_q: 6.022063
207 (array([36]),) False
  76040/500000: episode: 1901, duration: 32.227s, episode steps: 40, steps per second: 1, episode reward: 25.724, mean reward: 0.643 [0.084, 0.865], mean action: 15.900 [10.000, 48.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.224855, mean_absolute_error: 5.275333, mean_q: 5.945666
658 (array([48]),) False
  76080/500000: episode: 1902, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 32.632, mean reward: 0.816 [0.000, 1.000], mean action: 29.525 [1.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.223098, mean_absolute_error: 5.285798, mean_q: 5.968721
821 (array([22]),) False
  76120/500000: episode: 1903, duration: 32.239s, episode steps: 40, steps per second: 1, episode reward: 29.427, mean reward: 0.736 [0.042, 1.000], mean action: 23.350 [8.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.227068, mean_absolute_error: 5.263148, mean_q: 5.946591
129 (array([22]),) False
  76160/500000: episode: 1904, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 34.021, mean reward: 0.851 [0.147, 1.000], mean action: 17.075 [8.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.220369, mean_absolute_error: 5.270303, mean_q: 5.956918
691 (array([22]),) False
  76200/500000: episode: 1905, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 25.062, mean reward: 0.627 [0.000, 1.000], mean action: 22.700 [5.000, 46.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.187037, mean_absolute_error: 5.346689, mean_q: 6.029242
858 (array([12]),) False
  76240/500000: episode: 1906, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 32.321, mean reward: 0.808 [0.040, 1.000], mean action: 18.550 [7.000, 40.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.215591, mean_absolute_error: 5.315327, mean_q: 5.996084
394 (array([22]),) False
  76280/500000: episode: 1907, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 33.922, mean reward: 0.848 [0.069, 1.000], mean action: 23.325 [0.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.204960, mean_absolute_error: 5.331188, mean_q: 6.017428
433 (array([22]),) False
  76320/500000: episode: 1908, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 36.105, mean reward: 0.903 [0.283, 1.000], mean action: 22.350 [1.000, 45.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.222227, mean_absolute_error: 5.319847, mean_q: 6.007418
456 (array([22]),) False
  76360/500000: episode: 1909, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 35.094, mean reward: 0.877 [0.000, 1.000], mean action: 26.775 [4.000, 56.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.198753, mean_absolute_error: 5.330424, mean_q: 6.017077
571 (array([48]),) False
  76400/500000: episode: 1910, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 25.721, mean reward: 0.643 [0.131, 1.000], mean action: 18.125 [4.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.206325, mean_absolute_error: 5.315800, mean_q: 5.996409
433 (array([22]),) False
  76440/500000: episode: 1911, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 37.968, mean reward: 0.949 [0.305, 1.000], mean action: 23.600 [5.000, 54.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.217687, mean_absolute_error: 5.329241, mean_q: 6.017558
311 (array([22]),) False
  76480/500000: episode: 1912, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 33.852, mean reward: 0.846 [0.095, 1.000], mean action: 25.125 [1.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.213309, mean_absolute_error: 5.278658, mean_q: 5.963175
780 (array([22]),) False
  76520/500000: episode: 1913, duration: 32.176s, episode steps: 40, steps per second: 1, episode reward: 32.838, mean reward: 0.821 [0.073, 1.000], mean action: 21.800 [12.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.211349, mean_absolute_error: 5.288671, mean_q: 5.972684
349 (array([48]),) False
  76560/500000: episode: 1914, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 34.446, mean reward: 0.861 [0.000, 1.000], mean action: 24.900 [1.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.210562, mean_absolute_error: 5.282732, mean_q: 5.971564
700 (array([44]),) False
  76600/500000: episode: 1915, duration: 32.199s, episode steps: 40, steps per second: 1, episode reward: 29.291, mean reward: 0.732 [0.330, 1.000], mean action: 23.675 [12.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.252199, mean_absolute_error: 5.283727, mean_q: 5.969058
601 (array([14]),) False
  76640/500000: episode: 1916, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 30.310, mean reward: 0.758 [0.183, 1.000], mean action: 18.825 [1.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.242443, mean_absolute_error: 5.300404, mean_q: 5.973311
243 (array([12]),) False
  76680/500000: episode: 1917, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 33.546, mean reward: 0.839 [0.212, 1.000], mean action: 26.125 [12.000, 58.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.207722, mean_absolute_error: 5.305217, mean_q: 5.983158
761 (array([3]),) False
  76720/500000: episode: 1918, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 19.538, mean reward: 0.488 [0.222, 0.882], mean action: 21.675 [2.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.223065, mean_absolute_error: 5.300265, mean_q: 5.976588
404 (array([12]),) False
  76760/500000: episode: 1919, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 27.827, mean reward: 0.696 [0.125, 1.000], mean action: 27.475 [5.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.219536, mean_absolute_error: 5.262561, mean_q: 5.951290
676 (array([40]),) False
  76800/500000: episode: 1920, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 21.907, mean reward: 0.548 [0.000, 0.953], mean action: 26.725 [0.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.185358, mean_absolute_error: 5.317186, mean_q: 6.009155
861 (array([22]),) False
  76840/500000: episode: 1921, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 33.371, mean reward: 0.834 [0.025, 1.000], mean action: 23.200 [3.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.200014, mean_absolute_error: 5.307176, mean_q: 5.992211
488 (array([22]),) False
  76880/500000: episode: 1922, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 32.687, mean reward: 0.817 [0.147, 1.000], mean action: 16.975 [9.000, 55.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.204624, mean_absolute_error: 5.313024, mean_q: 5.991402
215 (array([22]),) False
  76920/500000: episode: 1923, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 30.614, mean reward: 0.765 [0.154, 1.000], mean action: 25.325 [11.000, 58.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.197954, mean_absolute_error: 5.340345, mean_q: 6.017203
382 (array([22]),) False
  76960/500000: episode: 1924, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 35.753, mean reward: 0.894 [0.020, 1.000], mean action: 22.300 [0.000, 51.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.226193, mean_absolute_error: 5.317089, mean_q: 5.985415
695 (array([22]),) False
  77000/500000: episode: 1925, duration: 32.236s, episode steps: 40, steps per second: 1, episode reward: 33.109, mean reward: 0.828 [0.000, 1.000], mean action: 21.500 [1.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.200561, mean_absolute_error: 5.407006, mean_q: 6.084743
276 (array([56]),) False
  77040/500000: episode: 1926, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 23.330, mean reward: 0.583 [0.000, 0.915], mean action: 22.325 [1.000, 53.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.209538, mean_absolute_error: 5.314007, mean_q: 5.989934
21 (array([3]),) False
  77080/500000: episode: 1927, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 23.222, mean reward: 0.581 [0.016, 1.000], mean action: 23.925 [1.000, 51.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.210727, mean_absolute_error: 5.365448, mean_q: 6.041226
496 (array([48]),) False
  77120/500000: episode: 1928, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 24.233, mean reward: 0.606 [0.037, 1.000], mean action: 21.450 [12.000, 57.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.226041, mean_absolute_error: 5.340761, mean_q: 6.018840
392 (array([40]),) False
  77160/500000: episode: 1929, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 29.661, mean reward: 0.742 [0.406, 1.000], mean action: 26.750 [17.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.182750, mean_absolute_error: 5.343459, mean_q: 6.021665
303 (array([22]),) False
  77200/500000: episode: 1930, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 35.403, mean reward: 0.885 [0.237, 1.000], mean action: 24.375 [3.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.220375, mean_absolute_error: 5.341255, mean_q: 6.014795
229 (array([48]),) False
  77240/500000: episode: 1931, duration: 32.936s, episode steps: 40, steps per second: 1, episode reward: 28.703, mean reward: 0.718 [0.000, 1.000], mean action: 22.450 [0.000, 57.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.218745, mean_absolute_error: 5.312020, mean_q: 5.993522
104 (array([22]),) False
  77280/500000: episode: 1932, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 31.019, mean reward: 0.775 [0.000, 1.000], mean action: 21.950 [2.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.203034, mean_absolute_error: 5.361944, mean_q: 6.056243
185 (array([22]),) False
  77320/500000: episode: 1933, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 29.268, mean reward: 0.732 [0.158, 0.872], mean action: 16.100 [12.000, 56.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.214084, mean_absolute_error: 5.304788, mean_q: 5.996967
458 (array([22]),) False
  77360/500000: episode: 1934, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 35.962, mean reward: 0.899 [0.140, 1.000], mean action: 22.575 [4.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.193429, mean_absolute_error: 5.377134, mean_q: 6.063764
206 (array([22]),) False
  77400/500000: episode: 1935, duration: 32.085s, episode steps: 40, steps per second: 1, episode reward: 28.943, mean reward: 0.724 [0.210, 1.000], mean action: 16.850 [12.000, 56.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.198728, mean_absolute_error: 5.363881, mean_q: 6.049294
648 (array([22]),) False
  77440/500000: episode: 1936, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 31.238, mean reward: 0.781 [0.194, 1.000], mean action: 20.575 [10.000, 52.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.209710, mean_absolute_error: 5.352228, mean_q: 6.036918
136 (array([12]),) False
  77480/500000: episode: 1937, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 36.323, mean reward: 0.908 [0.404, 1.000], mean action: 17.475 [5.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.225540, mean_absolute_error: 5.349829, mean_q: 6.030913
851 (array([48]),) False
  77520/500000: episode: 1938, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 31.775, mean reward: 0.794 [0.130, 0.973], mean action: 35.775 [13.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.254808, mean_absolute_error: 5.349784, mean_q: 6.031088
174 (array([33]),) False
  77560/500000: episode: 1939, duration: 32.165s, episode steps: 40, steps per second: 1, episode reward: 19.945, mean reward: 0.499 [0.013, 0.745], mean action: 22.225 [1.000, 47.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.203358, mean_absolute_error: 5.363402, mean_q: 6.048543
323 (array([55]),) False
  77600/500000: episode: 1940, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 24.148, mean reward: 0.604 [0.000, 0.823], mean action: 21.425 [3.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.217828, mean_absolute_error: 5.343404, mean_q: 6.032262
436 (array([22]),) False
  77640/500000: episode: 1941, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 34.877, mean reward: 0.872 [0.006, 1.000], mean action: 25.850 [18.000, 53.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.203804, mean_absolute_error: 5.306282, mean_q: 5.995155
519 (array([58]),) False
  77680/500000: episode: 1942, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 21.599, mean reward: 0.540 [0.000, 0.777], mean action: 25.325 [1.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.184043, mean_absolute_error: 5.347352, mean_q: 6.035777
587 (array([14]),) False
  77720/500000: episode: 1943, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 27.146, mean reward: 0.679 [0.119, 0.867], mean action: 40.250 [2.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.211950, mean_absolute_error: 5.383533, mean_q: 6.066249
632 (array([22]),) False
  77760/500000: episode: 1944, duration: 32.994s, episode steps: 40, steps per second: 1, episode reward: 35.768, mean reward: 0.894 [0.056, 1.000], mean action: 24.175 [8.000, 59.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.238766, mean_absolute_error: 5.366796, mean_q: 6.046018
469 (array([22]),) False
  77800/500000: episode: 1945, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 31.138, mean reward: 0.778 [0.195, 1.000], mean action: 27.850 [1.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.211280, mean_absolute_error: 5.369533, mean_q: 6.063948
279 (array([22]),) False
  77840/500000: episode: 1946, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 30.042, mean reward: 0.751 [0.163, 1.000], mean action: 24.000 [1.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.194861, mean_absolute_error: 5.375289, mean_q: 6.068994
599 (array([48]),) False
  77880/500000: episode: 1947, duration: 32.147s, episode steps: 40, steps per second: 1, episode reward: 25.898, mean reward: 0.647 [0.118, 1.000], mean action: 24.000 [12.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.209019, mean_absolute_error: 5.364610, mean_q: 6.052618
795 (array([3]),) False
  77920/500000: episode: 1948, duration: 32.983s, episode steps: 40, steps per second: 1, episode reward: 22.565, mean reward: 0.564 [0.218, 0.908], mean action: 20.825 [10.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.236616, mean_absolute_error: 5.353080, mean_q: 6.037706
313 (array([22]),) False
  77960/500000: episode: 1949, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 32.472, mean reward: 0.812 [0.188, 1.000], mean action: 24.475 [0.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.248923, mean_absolute_error: 5.336932, mean_q: 6.027158
717 (array([22]),) False
  78000/500000: episode: 1950, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 35.061, mean reward: 0.877 [0.194, 1.000], mean action: 14.775 [7.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.228649, mean_absolute_error: 5.332646, mean_q: 6.023177
617 (array([22]),) False
  78040/500000: episode: 1951, duration: 32.224s, episode steps: 40, steps per second: 1, episode reward: 31.959, mean reward: 0.799 [0.118, 1.000], mean action: 14.575 [1.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.230760, mean_absolute_error: 5.326155, mean_q: 6.013226
55 (array([22]),) False
  78080/500000: episode: 1952, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 32.667, mean reward: 0.817 [0.129, 1.000], mean action: 24.275 [19.000, 41.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.211338, mean_absolute_error: 5.343652, mean_q: 6.026213
210 (array([58]),) False
  78120/500000: episode: 1953, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 15.195, mean reward: 0.380 [0.000, 1.000], mean action: 27.275 [0.000, 59.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.202254, mean_absolute_error: 5.285104, mean_q: 5.966517
511 (array([22]),) False
  78160/500000: episode: 1954, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 35.959, mean reward: 0.899 [0.153, 1.000], mean action: 20.550 [3.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.221297, mean_absolute_error: 5.291594, mean_q: 5.969263
355 (array([22]),) False
  78200/500000: episode: 1955, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 32.854, mean reward: 0.821 [0.056, 1.000], mean action: 24.600 [5.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.209037, mean_absolute_error: 5.328579, mean_q: 6.003937
831 (array([3]),) False
  78240/500000: episode: 1956, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 5.392, mean reward: 0.135 [0.000, 1.000], mean action: 25.675 [5.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.218794, mean_absolute_error: 5.328817, mean_q: 6.006347
589 (array([22]),) False
  78280/500000: episode: 1957, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 28.934, mean reward: 0.723 [0.230, 1.000], mean action: 19.050 [12.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.201943, mean_absolute_error: 5.318407, mean_q: 5.990708
799 (array([36]),) False
  78320/500000: episode: 1958, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 21.833, mean reward: 0.546 [0.000, 0.995], mean action: 22.775 [1.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.201232, mean_absolute_error: 5.323121, mean_q: 5.996306
443 (array([22]),) False
  78360/500000: episode: 1959, duration: 32.228s, episode steps: 40, steps per second: 1, episode reward: 33.794, mean reward: 0.845 [0.054, 1.000], mean action: 23.875 [0.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.200676, mean_absolute_error: 5.333058, mean_q: 5.996926
158 (array([22]),) False
  78400/500000: episode: 1960, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 31.259, mean reward: 0.781 [0.120, 1.000], mean action: 19.975 [12.000, 57.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.229004, mean_absolute_error: 5.300502, mean_q: 5.976555
519 (array([58]),) False
  78440/500000: episode: 1961, duration: 32.251s, episode steps: 40, steps per second: 1, episode reward: 22.146, mean reward: 0.554 [0.000, 0.778], mean action: 27.250 [4.000, 60.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.203663, mean_absolute_error: 5.290972, mean_q: 5.969137
717 (array([22]),) False
  78480/500000: episode: 1962, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 31.567, mean reward: 0.789 [0.000, 1.000], mean action: 18.225 [0.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.220237, mean_absolute_error: 5.324057, mean_q: 6.003232
676 (array([40]),) False
  78520/500000: episode: 1963, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 23.955, mean reward: 0.599 [0.073, 0.939], mean action: 27.100 [6.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.217406, mean_absolute_error: 5.338786, mean_q: 6.006911
481 (array([22]),) False
  78560/500000: episode: 1964, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 34.812, mean reward: 0.870 [0.122, 1.000], mean action: 17.700 [6.000, 55.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.205323, mean_absolute_error: 5.285163, mean_q: 5.941496
638 (array([22]),) False
  78600/500000: episode: 1965, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 31.351, mean reward: 0.784 [0.017, 0.887], mean action: 13.625 [3.000, 48.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.241571, mean_absolute_error: 5.342412, mean_q: 6.003940
456 (array([22]),) False
  78640/500000: episode: 1966, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 34.671, mean reward: 0.867 [0.040, 1.000], mean action: 23.150 [4.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.195187, mean_absolute_error: 5.304864, mean_q: 5.972512
759 (array([48]),) False
  78680/500000: episode: 1967, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 34.333, mean reward: 0.858 [0.313, 1.000], mean action: 23.800 [15.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.216307, mean_absolute_error: 5.271201, mean_q: 5.931183
391 (array([22]),) False
  78720/500000: episode: 1968, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 35.350, mean reward: 0.884 [0.228, 1.000], mean action: 25.500 [4.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.202285, mean_absolute_error: 5.288240, mean_q: 5.952052
42 (array([22]),) False
  78760/500000: episode: 1969, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 33.699, mean reward: 0.842 [0.000, 1.000], mean action: 23.500 [3.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.233090, mean_absolute_error: 5.308963, mean_q: 5.971454
85 (array([48]),) False
  78800/500000: episode: 1970, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 32.011, mean reward: 0.800 [0.026, 0.914], mean action: 23.125 [1.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.201714, mean_absolute_error: 5.297395, mean_q: 5.961852
385 (array([30]),) False
  78840/500000: episode: 1971, duration: 32.188s, episode steps: 40, steps per second: 1, episode reward: 32.722, mean reward: 0.818 [0.304, 1.000], mean action: 28.100 [5.000, 56.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.216202, mean_absolute_error: 5.333116, mean_q: 6.004229
722 (array([22]),) False
  78880/500000: episode: 1972, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 31.637, mean reward: 0.791 [0.018, 0.980], mean action: 18.775 [9.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.212854, mean_absolute_error: 5.343858, mean_q: 6.013397
779 (array([12]),) False
  78920/500000: episode: 1973, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 35.260, mean reward: 0.881 [0.000, 1.000], mean action: 17.175 [1.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.212885, mean_absolute_error: 5.273236, mean_q: 5.942151
589 (array([22]),) False
  78960/500000: episode: 1974, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 29.009, mean reward: 0.725 [0.216, 1.000], mean action: 13.600 [1.000, 50.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.243746, mean_absolute_error: 5.310616, mean_q: 5.977202
114 (array([22]),) False
  79000/500000: episode: 1975, duration: 32.182s, episode steps: 40, steps per second: 1, episode reward: 33.264, mean reward: 0.832 [0.046, 1.000], mean action: 17.350 [8.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.201328, mean_absolute_error: 5.299485, mean_q: 5.971749
569 (array([22]),) False
  79040/500000: episode: 1976, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 30.257, mean reward: 0.756 [0.047, 1.000], mean action: 19.800 [3.000, 38.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.208149, mean_absolute_error: 5.316745, mean_q: 5.985135
400 (array([22]),) False
  79080/500000: episode: 1977, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 35.813, mean reward: 0.895 [0.000, 1.000], mean action: 22.550 [2.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.210031, mean_absolute_error: 5.271523, mean_q: 5.942136
788 (array([3]),) False
  79120/500000: episode: 1978, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 19.871, mean reward: 0.497 [0.000, 0.961], mean action: 41.575 [4.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.201882, mean_absolute_error: 5.316761, mean_q: 5.995238
368 (array([22]),) False
  79160/500000: episode: 1979, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 36.500, mean reward: 0.913 [0.198, 1.000], mean action: 23.325 [3.000, 57.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.223258, mean_absolute_error: 5.278393, mean_q: 5.957730
802 (array([22]),) False
  79200/500000: episode: 1980, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 22.491, mean reward: 0.562 [0.033, 1.000], mean action: 24.900 [0.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.181119, mean_absolute_error: 5.346368, mean_q: 6.020955
216 (array([22]),) False
  79240/500000: episode: 1981, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 23.590, mean reward: 0.590 [0.139, 1.000], mean action: 17.475 [0.000, 46.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.221416, mean_absolute_error: 5.321332, mean_q: 5.995406
365 (array([22]),) False
  79280/500000: episode: 1982, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 37.195, mean reward: 0.930 [0.271, 1.000], mean action: 23.650 [17.000, 52.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.197739, mean_absolute_error: 5.360465, mean_q: 6.045245
537 (array([22]),) False
  79320/500000: episode: 1983, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 33.095, mean reward: 0.827 [0.243, 1.000], mean action: 24.275 [3.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.196382, mean_absolute_error: 5.309659, mean_q: 5.987994
693 (array([22]),) False
  79360/500000: episode: 1984, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 35.535, mean reward: 0.888 [0.383, 1.000], mean action: 20.150 [0.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.222168, mean_absolute_error: 5.326096, mean_q: 6.004385
321 (array([22]),) False
  79400/500000: episode: 1985, duration: 32.202s, episode steps: 40, steps per second: 1, episode reward: 32.190, mean reward: 0.805 [0.000, 1.000], mean action: 21.325 [0.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.231154, mean_absolute_error: 5.343985, mean_q: 6.019254
391 (array([22]),) False
  79440/500000: episode: 1986, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 35.968, mean reward: 0.899 [0.000, 1.000], mean action: 24.125 [4.000, 54.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.220507, mean_absolute_error: 5.325999, mean_q: 6.008839
480 (array([22]),) False
  79480/500000: episode: 1987, duration: 32.148s, episode steps: 40, steps per second: 1, episode reward: 21.368, mean reward: 0.534 [0.164, 1.000], mean action: 20.225 [12.000, 56.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.226968, mean_absolute_error: 5.264719, mean_q: 5.957447
344 (array([22]),) False
  79520/500000: episode: 1988, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 34.926, mean reward: 0.873 [0.339, 1.000], mean action: 22.250 [0.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.223393, mean_absolute_error: 5.296639, mean_q: 5.980918
243 (array([12]),) False
  79560/500000: episode: 1989, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 32.091, mean reward: 0.802 [0.038, 1.000], mean action: 23.700 [1.000, 54.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.255463, mean_absolute_error: 5.325059, mean_q: 6.004530
210 (array([58]),) False
  79600/500000: episode: 1990, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 9.832, mean reward: 0.246 [0.004, 0.780], mean action: 18.300 [10.000, 59.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.211179, mean_absolute_error: 5.349587, mean_q: 6.024230
328 (array([12]),) False
  79640/500000: episode: 1991, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 31.519, mean reward: 0.788 [0.258, 1.000], mean action: 21.275 [12.000, 56.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.196438, mean_absolute_error: 5.291263, mean_q: 5.967921
97 (array([22]),) False
  79680/500000: episode: 1992, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 32.247, mean reward: 0.806 [0.016, 1.000], mean action: 25.275 [3.000, 56.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.207747, mean_absolute_error: 5.365319, mean_q: 6.043982
701 (array([48]),) False
  79720/500000: episode: 1993, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 31.969, mean reward: 0.799 [0.007, 1.000], mean action: 24.575 [1.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.193511, mean_absolute_error: 5.360466, mean_q: 6.042728
738 (array([12]),) False
  79760/500000: episode: 1994, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 36.632, mean reward: 0.916 [0.000, 1.000], mean action: 15.000 [12.000, 40.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.232915, mean_absolute_error: 5.435273, mean_q: 6.118190
557 (array([22]),) False
  79800/500000: episode: 1995, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 31.952, mean reward: 0.799 [0.091, 1.000], mean action: 20.800 [3.000, 40.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.214738, mean_absolute_error: 5.383690, mean_q: 6.060544
52 (array([22]),) False
  79840/500000: episode: 1996, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 33.168, mean reward: 0.829 [0.000, 1.000], mean action: 25.700 [11.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.212564, mean_absolute_error: 5.381449, mean_q: 6.070966
750 (array([22]),) False
  79880/500000: episode: 1997, duration: 32.199s, episode steps: 40, steps per second: 1, episode reward: 32.448, mean reward: 0.811 [0.104, 1.000], mean action: 20.775 [0.000, 60.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.237791, mean_absolute_error: 5.423596, mean_q: 6.103992
639 (array([22]),) False
  79920/500000: episode: 1998, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 30.345, mean reward: 0.759 [0.131, 1.000], mean action: 17.350 [0.000, 40.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.211262, mean_absolute_error: 5.391897, mean_q: 6.079533
59 (array([12]),) False
  79960/500000: episode: 1999, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 29.636, mean reward: 0.741 [0.062, 1.000], mean action: 24.550 [5.000, 49.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.205772, mean_absolute_error: 5.396742, mean_q: 6.084860
423 (array([22]),) False
  80000/500000: episode: 2000, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 32.639, mean reward: 0.816 [0.104, 1.000], mean action: 21.550 [2.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.193482, mean_absolute_error: 5.400190, mean_q: 6.090296
472 (array([22]),) False
  80040/500000: episode: 2001, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 34.597, mean reward: 0.865 [0.000, 1.000], mean action: 22.850 [4.000, 42.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.200991, mean_absolute_error: 5.403211, mean_q: 6.096291
763 (array([48]),) False
  80080/500000: episode: 2002, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 33.721, mean reward: 0.843 [0.060, 1.000], mean action: 23.050 [6.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.211466, mean_absolute_error: 5.363173, mean_q: 6.051378
105 (array([22]),) False
  80120/500000: episode: 2003, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 35.552, mean reward: 0.889 [0.164, 1.000], mean action: 19.500 [5.000, 49.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.214170, mean_absolute_error: 5.412752, mean_q: 6.103720
660 (array([2]),) False
  80160/500000: episode: 2004, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 17.643, mean reward: 0.441 [0.068, 1.000], mean action: 31.050 [7.000, 54.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.209246, mean_absolute_error: 5.345119, mean_q: 6.032668
394 (array([22]),) False
  80200/500000: episode: 2005, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 35.755, mean reward: 0.894 [0.339, 1.000], mean action: 24.550 [13.000, 50.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.214516, mean_absolute_error: 5.426339, mean_q: 6.123444
809 (array([48]),) False
  80240/500000: episode: 2006, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 24.898, mean reward: 0.622 [0.123, 1.000], mean action: 23.050 [1.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.206725, mean_absolute_error: 5.405918, mean_q: 6.093457
464 (array([22]),) False
  80280/500000: episode: 2007, duration: 32.165s, episode steps: 40, steps per second: 1, episode reward: 33.987, mean reward: 0.850 [0.104, 1.000], mean action: 22.950 [1.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.227123, mean_absolute_error: 5.357661, mean_q: 6.046087
189 (array([12]),) False
  80320/500000: episode: 2008, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 36.590, mean reward: 0.915 [0.129, 1.000], mean action: 14.975 [5.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.204991, mean_absolute_error: 5.402349, mean_q: 6.085240
312 (array([12]),) False
  80360/500000: episode: 2009, duration: 32.200s, episode steps: 40, steps per second: 1, episode reward: 30.037, mean reward: 0.751 [0.211, 0.846], mean action: 35.875 [7.000, 55.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.249555, mean_absolute_error: 5.409051, mean_q: 6.091985
669 (array([15]),) False
  80400/500000: episode: 2010, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 26.433, mean reward: 0.661 [0.082, 0.916], mean action: 26.700 [8.000, 60.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.224270, mean_absolute_error: 5.373064, mean_q: 6.054221
683 (array([22]),) False
  80440/500000: episode: 2011, duration: 32.216s, episode steps: 40, steps per second: 1, episode reward: 30.876, mean reward: 0.772 [0.076, 1.000], mean action: 22.975 [2.000, 50.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.241487, mean_absolute_error: 5.343760, mean_q: 6.024386
627 (array([48]),) False
  80480/500000: episode: 2012, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 31.605, mean reward: 0.790 [0.016, 0.960], mean action: 24.075 [4.000, 54.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.219630, mean_absolute_error: 5.343606, mean_q: 6.023320
454 (array([12]),) False
  80520/500000: episode: 2013, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 27.241, mean reward: 0.681 [0.005, 1.000], mean action: 28.300 [4.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.214500, mean_absolute_error: 5.330766, mean_q: 6.003553
797 (array([22]),) False
  80560/500000: episode: 2014, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 34.169, mean reward: 0.854 [0.064, 1.000], mean action: 14.025 [3.000, 47.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.210099, mean_absolute_error: 5.349715, mean_q: 6.031297
824 (array([22]),) False
  80600/500000: episode: 2015, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 34.150, mean reward: 0.854 [0.146, 1.000], mean action: 17.650 [10.000, 46.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.236860, mean_absolute_error: 5.312712, mean_q: 5.999940
806 (array([22]),) False
  80640/500000: episode: 2016, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 30.337, mean reward: 0.758 [0.081, 1.000], mean action: 20.025 [1.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.213266, mean_absolute_error: 5.352321, mean_q: 6.036320
526 (array([22]),) False
  80680/500000: episode: 2017, duration: 32.981s, episode steps: 40, steps per second: 1, episode reward: 36.312, mean reward: 0.908 [0.136, 1.000], mean action: 18.950 [11.000, 51.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.196033, mean_absolute_error: 5.319107, mean_q: 6.003137
252 (array([22]),) False
  80720/500000: episode: 2018, duration: 32.957s, episode steps: 40, steps per second: 1, episode reward: 33.192, mean reward: 0.830 [0.041, 1.000], mean action: 23.400 [7.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.243991, mean_absolute_error: 5.328146, mean_q: 6.016860
220 (array([22]),) False
  80760/500000: episode: 2019, duration: 31.981s, episode steps: 40, steps per second: 1, episode reward: 35.054, mean reward: 0.876 [0.025, 1.000], mean action: 17.900 [5.000, 38.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.221431, mean_absolute_error: 5.338892, mean_q: 6.023895
696 (array([36]),) False
  80800/500000: episode: 2020, duration: 32.112s, episode steps: 40, steps per second: 1, episode reward: 6.528, mean reward: 0.163 [0.000, 0.887], mean action: 22.350 [0.000, 41.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.225000, mean_absolute_error: 5.350289, mean_q: 6.028385
490 (array([12]),) False
  80840/500000: episode: 2021, duration: 31.595s, episode steps: 40, steps per second: 1, episode reward: 29.598, mean reward: 0.740 [0.013, 1.000], mean action: 25.550 [0.000, 60.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.216336, mean_absolute_error: 5.378896, mean_q: 6.065006
261 (array([44]),) False
  80880/500000: episode: 2022, duration: 32.101s, episode steps: 40, steps per second: 1, episode reward: 32.374, mean reward: 0.809 [0.566, 0.880], mean action: 20.025 [7.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.218186, mean_absolute_error: 5.387900, mean_q: 6.077596
490 (array([12]),) False
  80920/500000: episode: 2023, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 35.865, mean reward: 0.897 [0.345, 1.000], mean action: 18.225 [12.000, 54.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.210766, mean_absolute_error: 5.302516, mean_q: 5.985070
17 (array([22]),) False
  80960/500000: episode: 2024, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 38.008, mean reward: 0.950 [0.161, 1.000], mean action: 24.800 [7.000, 49.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.226392, mean_absolute_error: 5.341100, mean_q: 6.027053
537 (array([22]),) False
  81000/500000: episode: 2025, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 32.352, mean reward: 0.809 [0.251, 1.000], mean action: 25.325 [4.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.244001, mean_absolute_error: 5.304648, mean_q: 5.990207
186 (array([22]),) False
  81040/500000: episode: 2026, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 30.544, mean reward: 0.764 [0.112, 0.883], mean action: 17.350 [12.000, 55.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.244555, mean_absolute_error: 5.331191, mean_q: 6.002996
359 (array([22]),) False
  81080/500000: episode: 2027, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 34.264, mean reward: 0.857 [0.156, 1.000], mean action: 24.175 [5.000, 53.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.209729, mean_absolute_error: 5.321593, mean_q: 5.998134
509 (array([22]),) False
  81120/500000: episode: 2028, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 35.208, mean reward: 0.880 [0.081, 1.000], mean action: 17.750 [5.000, 56.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.200583, mean_absolute_error: 5.353604, mean_q: 6.040986
541 (array([57]),) False
  81160/500000: episode: 2029, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 24.444, mean reward: 0.611 [0.200, 1.000], mean action: 35.150 [9.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.206484, mean_absolute_error: 5.318553, mean_q: 5.993974
855 (array([12]),) False
  81200/500000: episode: 2030, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 32.371, mean reward: 0.809 [0.073, 1.000], mean action: 16.125 [7.000, 40.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.226580, mean_absolute_error: 5.290504, mean_q: 5.969376
815 (array([22]),) False
  81240/500000: episode: 2031, duration: 32.182s, episode steps: 40, steps per second: 1, episode reward: 27.624, mean reward: 0.691 [0.000, 1.000], mean action: 20.100 [0.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.242071, mean_absolute_error: 5.326574, mean_q: 6.003325
376 (array([22]),) False
  81280/500000: episode: 2032, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 32.906, mean reward: 0.823 [0.000, 1.000], mean action: 27.175 [12.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.210493, mean_absolute_error: 5.306595, mean_q: 5.984691
254 (array([22]),) False
  81320/500000: episode: 2033, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 34.599, mean reward: 0.865 [0.127, 1.000], mean action: 22.525 [12.000, 56.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.227005, mean_absolute_error: 5.352643, mean_q: 6.031357
426 (array([22]),) False
  81360/500000: episode: 2034, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 29.623, mean reward: 0.741 [0.119, 1.000], mean action: 27.200 [11.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.208533, mean_absolute_error: 5.385198, mean_q: 6.063487
856 (array([48]),) False
  81400/500000: episode: 2035, duration: 32.254s, episode steps: 40, steps per second: 1, episode reward: 33.724, mean reward: 0.843 [0.033, 0.976], mean action: 20.575 [5.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.209304, mean_absolute_error: 5.358811, mean_q: 6.027860
703 (array([3]),) False
  81440/500000: episode: 2036, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 31.108, mean reward: 0.778 [0.113, 1.000], mean action: 15.025 [3.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.197904, mean_absolute_error: 5.341748, mean_q: 6.009257
11 (array([22]),) False
  81480/500000: episode: 2037, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 35.989, mean reward: 0.900 [0.091, 1.000], mean action: 22.250 [2.000, 54.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.221055, mean_absolute_error: 5.381995, mean_q: 6.052156
37 (array([48]),) False
  81520/500000: episode: 2038, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 35.217, mean reward: 0.880 [0.181, 1.000], mean action: 29.250 [5.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.225856, mean_absolute_error: 5.358226, mean_q: 6.023687
350 (array([12]),) False
  81560/500000: episode: 2039, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 26.428, mean reward: 0.661 [0.245, 0.903], mean action: 25.050 [8.000, 52.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.224662, mean_absolute_error: 5.385558, mean_q: 6.065379
249 (array([22]),) False
  81600/500000: episode: 2040, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 33.154, mean reward: 0.829 [0.221, 1.000], mean action: 26.025 [1.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.232884, mean_absolute_error: 5.360117, mean_q: 6.031869
320 (array([22]),) False
  81640/500000: episode: 2041, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 30.526, mean reward: 0.763 [0.007, 1.000], mean action: 19.600 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.220986, mean_absolute_error: 5.330032, mean_q: 6.003819
771 (array([12]),) False
  81680/500000: episode: 2042, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 33.703, mean reward: 0.843 [0.000, 1.000], mean action: 17.175 [0.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.244253, mean_absolute_error: 5.330564, mean_q: 5.993777
80 (array([42]),) False
  81720/500000: episode: 2043, duration: 32.087s, episode steps: 40, steps per second: 1, episode reward: 31.612, mean reward: 0.790 [0.111, 1.000], mean action: 23.050 [1.000, 57.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.204995, mean_absolute_error: 5.368627, mean_q: 6.038729
63 (array([18]),) False
  81760/500000: episode: 2044, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 36.321, mean reward: 0.908 [0.014, 0.990], mean action: 16.450 [3.000, 55.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.217936, mean_absolute_error: 5.418240, mean_q: 6.093314
172 (array([12]),) False
  81800/500000: episode: 2045, duration: 32.211s, episode steps: 40, steps per second: 1, episode reward: 33.667, mean reward: 0.842 [0.034, 1.000], mean action: 19.750 [10.000, 57.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.223387, mean_absolute_error: 5.406219, mean_q: 6.081757
288 (array([33]),) False
  81840/500000: episode: 2046, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 20.584, mean reward: 0.515 [0.246, 0.906], mean action: 25.850 [1.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.227877, mean_absolute_error: 5.375746, mean_q: 6.054191
495 (array([48]),) False
  81880/500000: episode: 2047, duration: 32.106s, episode steps: 40, steps per second: 1, episode reward: 35.447, mean reward: 0.886 [0.063, 0.966], mean action: 22.075 [2.000, 53.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.224240, mean_absolute_error: 5.392107, mean_q: 6.073270
801 (array([58]),) False
  81920/500000: episode: 2048, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 19.912, mean reward: 0.498 [0.017, 1.000], mean action: 34.550 [4.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.228976, mean_absolute_error: 5.320039, mean_q: 6.000192
4 (array([22]),) False
  81960/500000: episode: 2049, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 28.081, mean reward: 0.702 [0.227, 1.000], mean action: 22.825 [5.000, 60.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.248214, mean_absolute_error: 5.304461, mean_q: 5.977609
642 (array([22]),) False
  82000/500000: episode: 2050, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 30.454, mean reward: 0.761 [0.035, 1.000], mean action: 26.025 [10.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.227474, mean_absolute_error: 5.376315, mean_q: 6.054643
162 (array([22]),) False
  82040/500000: episode: 2051, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 31.871, mean reward: 0.797 [0.165, 1.000], mean action: 19.025 [3.000, 53.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.226594, mean_absolute_error: 5.373225, mean_q: 6.055450
255 (array([12]),) False
  82080/500000: episode: 2052, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 29.235, mean reward: 0.731 [0.015, 1.000], mean action: 22.250 [12.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.252282, mean_absolute_error: 5.340464, mean_q: 6.025149
523 (array([22]),) False
  82120/500000: episode: 2053, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 31.984, mean reward: 0.800 [0.132, 1.000], mean action: 21.125 [8.000, 46.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.204678, mean_absolute_error: 5.340062, mean_q: 6.026307
540 (array([22]),) False
  82160/500000: episode: 2054, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 33.439, mean reward: 0.836 [0.273, 1.000], mean action: 31.225 [12.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.212489, mean_absolute_error: 5.366240, mean_q: 6.050757
819 (array([48]),) False
  82200/500000: episode: 2055, duration: 32.162s, episode steps: 40, steps per second: 1, episode reward: 22.967, mean reward: 0.574 [0.110, 1.000], mean action: 17.325 [1.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.226805, mean_absolute_error: 5.364107, mean_q: 6.046315
806 (array([22]),) False
  82240/500000: episode: 2056, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 32.463, mean reward: 0.812 [0.000, 0.995], mean action: 30.750 [4.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.205460, mean_absolute_error: 5.336891, mean_q: 6.024825
255 (array([12]),) False
  82280/500000: episode: 2057, duration: 32.248s, episode steps: 40, steps per second: 1, episode reward: 24.568, mean reward: 0.614 [0.026, 1.000], mean action: 24.125 [4.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.217903, mean_absolute_error: 5.370787, mean_q: 6.064899
20 (array([22]),) False
  82320/500000: episode: 2058, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 33.331, mean reward: 0.833 [0.064, 1.000], mean action: 25.500 [15.000, 54.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.216175, mean_absolute_error: 5.384859, mean_q: 6.068687
524 (array([22]),) False
  82360/500000: episode: 2059, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 35.061, mean reward: 0.877 [0.378, 1.000], mean action: 20.225 [12.000, 50.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.219570, mean_absolute_error: 5.333417, mean_q: 6.007442
290 (array([22]),) False
  82400/500000: episode: 2060, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 32.275, mean reward: 0.807 [0.100, 1.000], mean action: 22.525 [2.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.222889, mean_absolute_error: 5.424850, mean_q: 6.103693
388 (array([22]),) False
  82440/500000: episode: 2061, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 35.157, mean reward: 0.879 [0.038, 1.000], mean action: 24.575 [4.000, 51.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.176465, mean_absolute_error: 5.353875, mean_q: 6.025822
389 (array([48]),) False
  82480/500000: episode: 2062, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 34.057, mean reward: 0.851 [0.000, 0.978], mean action: 25.375 [3.000, 57.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.213051, mean_absolute_error: 5.410442, mean_q: 6.095589
533 (array([22]),) False
  82520/500000: episode: 2063, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 30.655, mean reward: 0.766 [0.000, 1.000], mean action: 22.100 [0.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.256615, mean_absolute_error: 5.341195, mean_q: 6.023308
93 (array([22]),) False
  82560/500000: episode: 2064, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 36.366, mean reward: 0.909 [0.109, 1.000], mean action: 21.550 [9.000, 51.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.252054, mean_absolute_error: 5.346882, mean_q: 6.035762
220 (array([22]),) False
  82600/500000: episode: 2065, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 34.302, mean reward: 0.858 [0.025, 1.000], mean action: 21.025 [9.000, 53.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.250590, mean_absolute_error: 5.343521, mean_q: 6.029634
161 (array([22]),) False
  82640/500000: episode: 2066, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 29.979, mean reward: 0.749 [0.000, 0.906], mean action: 17.800 [8.000, 45.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.236254, mean_absolute_error: 5.333398, mean_q: 6.024572
718 (array([12]),) False
  82680/500000: episode: 2067, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 34.744, mean reward: 0.869 [0.075, 1.000], mean action: 17.400 [3.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.239819, mean_absolute_error: 5.348552, mean_q: 6.042751
650 (array([22]),) False
  82720/500000: episode: 2068, duration: 32.994s, episode steps: 40, steps per second: 1, episode reward: 33.129, mean reward: 0.828 [0.088, 1.000], mean action: 22.625 [4.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.198973, mean_absolute_error: 5.376737, mean_q: 6.062603
71 (array([58]),) False
  82760/500000: episode: 2069, duration: 32.262s, episode steps: 40, steps per second: 1, episode reward: 10.973, mean reward: 0.274 [0.000, 0.762], mean action: 21.050 [8.000, 40.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.218442, mean_absolute_error: 5.360067, mean_q: 6.047917
564 (array([22]),) False
  82800/500000: episode: 2070, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 33.097, mean reward: 0.827 [0.000, 1.000], mean action: 14.700 [1.000, 56.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.207605, mean_absolute_error: 5.353529, mean_q: 6.038924
641 (array([22]),) False
  82840/500000: episode: 2071, duration: 32.223s, episode steps: 40, steps per second: 1, episode reward: 34.386, mean reward: 0.860 [0.189, 1.000], mean action: 23.925 [1.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.243238, mean_absolute_error: 5.447098, mean_q: 6.134656
287 (array([48]),) False
  82880/500000: episode: 2072, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 30.326, mean reward: 0.758 [0.043, 1.000], mean action: 26.900 [14.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.215399, mean_absolute_error: 5.390269, mean_q: 6.066905
324 (array([12]),) False
  82920/500000: episode: 2073, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 35.104, mean reward: 0.878 [0.131, 1.000], mean action: 19.600 [10.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.216973, mean_absolute_error: 5.391541, mean_q: 6.068876
538 (array([12]),) False
  82960/500000: episode: 2074, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 34.748, mean reward: 0.869 [0.061, 1.000], mean action: 18.225 [11.000, 51.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.248064, mean_absolute_error: 5.341699, mean_q: 6.015543
25 (array([48]),) False
  83000/500000: episode: 2075, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 37.185, mean reward: 0.930 [0.026, 1.000], mean action: 21.325 [2.000, 31.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.236426, mean_absolute_error: 5.375413, mean_q: 6.052228
151 (array([22]),) False
  83040/500000: episode: 2076, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 29.608, mean reward: 0.740 [0.058, 0.960], mean action: 14.200 [0.000, 39.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.255851, mean_absolute_error: 5.387305, mean_q: 6.073491
236 (array([22]),) False
  83080/500000: episode: 2077, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 34.717, mean reward: 0.868 [0.213, 1.000], mean action: 27.175 [7.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.203852, mean_absolute_error: 5.402058, mean_q: 6.093755
199 (array([22]),) False
  83120/500000: episode: 2078, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 32.059, mean reward: 0.801 [0.005, 1.000], mean action: 19.975 [11.000, 54.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.209651, mean_absolute_error: 5.382586, mean_q: 6.068778
861 (array([22]),) False
  83160/500000: episode: 2079, duration: 32.177s, episode steps: 40, steps per second: 1, episode reward: 33.554, mean reward: 0.839 [0.045, 1.000], mean action: 23.700 [0.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.193670, mean_absolute_error: 5.372138, mean_q: 6.062391
231 (array([22]),) False
  83200/500000: episode: 2080, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 35.220, mean reward: 0.880 [0.237, 1.000], mean action: 21.175 [12.000, 56.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.258897, mean_absolute_error: 5.389754, mean_q: 6.075245
73 (array([22]),) False
  83240/500000: episode: 2081, duration: 32.215s, episode steps: 40, steps per second: 1, episode reward: 33.334, mean reward: 0.833 [0.222, 1.000], mean action: 21.025 [3.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.224554, mean_absolute_error: 5.327774, mean_q: 6.007247
530 (array([22]),) False
  83280/500000: episode: 2082, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 35.592, mean reward: 0.890 [0.123, 1.000], mean action: 21.025 [5.000, 55.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.194998, mean_absolute_error: 5.375764, mean_q: 6.058540
303 (array([22]),) False
  83320/500000: episode: 2083, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 32.060, mean reward: 0.801 [0.000, 1.000], mean action: 25.750 [2.000, 51.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.225451, mean_absolute_error: 5.400896, mean_q: 6.076952
738 (array([12]),) False
  83360/500000: episode: 2084, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 35.486, mean reward: 0.887 [0.185, 1.000], mean action: 14.450 [5.000, 51.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.203820, mean_absolute_error: 5.359318, mean_q: 6.026554
349 (array([48]),) False
  83400/500000: episode: 2085, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 31.541, mean reward: 0.789 [0.087, 1.000], mean action: 25.875 [0.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.236000, mean_absolute_error: 5.384644, mean_q: 6.064173
447 (array([44]),) False
  83440/500000: episode: 2086, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 30.031, mean reward: 0.751 [0.000, 1.000], mean action: 21.775 [4.000, 38.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.244814, mean_absolute_error: 5.352794, mean_q: 6.025014
1 (array([22]),) False
  83480/500000: episode: 2087, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 29.198, mean reward: 0.730 [0.021, 1.000], mean action: 23.900 [2.000, 58.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.219625, mean_absolute_error: 5.404456, mean_q: 6.090062
531 (array([22]),) False
  83520/500000: episode: 2088, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 37.011, mean reward: 0.925 [0.176, 1.000], mean action: 20.625 [8.000, 49.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.235531, mean_absolute_error: 5.361091, mean_q: 6.043190
784 (array([22]),) False
  83560/500000: episode: 2089, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 33.235, mean reward: 0.831 [0.000, 1.000], mean action: 19.725 [6.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.215556, mean_absolute_error: 5.407755, mean_q: 6.082891
478 (array([22]),) False
  83600/500000: episode: 2090, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 34.406, mean reward: 0.860 [0.063, 1.000], mean action: 26.750 [2.000, 54.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.240500, mean_absolute_error: 5.485609, mean_q: 6.179410
217 (array([12]),) False
  83640/500000: episode: 2091, duration: 32.109s, episode steps: 40, steps per second: 1, episode reward: 34.186, mean reward: 0.855 [0.149, 1.000], mean action: 16.700 [5.000, 58.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.237989, mean_absolute_error: 5.452501, mean_q: 6.141282
442 (array([22]),) False
  83680/500000: episode: 2092, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 34.839, mean reward: 0.871 [0.031, 1.000], mean action: 24.075 [11.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.252876, mean_absolute_error: 5.448334, mean_q: 6.135298
668 (array([22]),) False
  83720/500000: episode: 2093, duration: 32.204s, episode steps: 40, steps per second: 1, episode reward: 25.704, mean reward: 0.643 [0.154, 1.000], mean action: 31.525 [1.000, 51.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.213129, mean_absolute_error: 5.442050, mean_q: 6.125515
123 (array([22]),) False
  83760/500000: episode: 2094, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 34.626, mean reward: 0.866 [0.100, 1.000], mean action: 21.075 [12.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.222649, mean_absolute_error: 5.393389, mean_q: 6.080904
633 (array([22]),) False
  83800/500000: episode: 2095, duration: 32.197s, episode steps: 40, steps per second: 1, episode reward: 31.683, mean reward: 0.792 [0.022, 1.000], mean action: 20.225 [9.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.227989, mean_absolute_error: 5.496754, mean_q: 6.179008
745 (array([22]),) False
  83840/500000: episode: 2096, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 32.100, mean reward: 0.803 [0.109, 0.956], mean action: 19.425 [0.000, 55.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.221951, mean_absolute_error: 5.417731, mean_q: 6.088918
769 (array([12]),) False
  83880/500000: episode: 2097, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 31.416, mean reward: 0.785 [0.001, 1.000], mean action: 21.500 [7.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.238919, mean_absolute_error: 5.384735, mean_q: 6.065942
295 (array([22]),) False
  83920/500000: episode: 2098, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 34.564, mean reward: 0.864 [0.225, 1.000], mean action: 22.475 [5.000, 40.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.230501, mean_absolute_error: 5.422990, mean_q: 6.096202
659 (array([40]),) False
  83960/500000: episode: 2099, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 32.243, mean reward: 0.806 [0.069, 1.000], mean action: 26.125 [6.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.234857, mean_absolute_error: 5.465959, mean_q: 6.135736
380 (array([22]),) False
  84000/500000: episode: 2100, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 37.710, mean reward: 0.943 [0.287, 1.000], mean action: 23.075 [15.000, 60.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.233489, mean_absolute_error: 5.483437, mean_q: 6.155516
188 (array([22]),) False
  84040/500000: episode: 2101, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 33.836, mean reward: 0.846 [0.193, 1.000], mean action: 15.550 [9.000, 43.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.241171, mean_absolute_error: 5.477220, mean_q: 6.138689
105 (array([22]),) False
  84080/500000: episode: 2102, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 34.671, mean reward: 0.867 [0.197, 1.000], mean action: 22.675 [12.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.231311, mean_absolute_error: 5.517268, mean_q: 6.193938
520 (array([22]),) False
  84120/500000: episode: 2103, duration: 32.205s, episode steps: 40, steps per second: 1, episode reward: 33.799, mean reward: 0.845 [0.186, 1.000], mean action: 17.500 [0.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.211674, mean_absolute_error: 5.437027, mean_q: 6.115599
673 (array([3]),) False
  84160/500000: episode: 2104, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 21.011, mean reward: 0.525 [0.114, 0.850], mean action: 36.650 [4.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.219259, mean_absolute_error: 5.433519, mean_q: 6.113398
404 (array([12]),) False
  84200/500000: episode: 2105, duration: 32.084s, episode steps: 40, steps per second: 1, episode reward: 25.486, mean reward: 0.637 [0.071, 0.855], mean action: 29.225 [1.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.227394, mean_absolute_error: 5.473132, mean_q: 6.153419
154 (array([44]),) False
  84240/500000: episode: 2106, duration: 32.920s, episode steps: 40, steps per second: 1, episode reward: 31.491, mean reward: 0.787 [0.347, 0.880], mean action: 17.325 [4.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.226557, mean_absolute_error: 5.459417, mean_q: 6.140173
655 (array([22]),) False
  84280/500000: episode: 2107, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 30.913, mean reward: 0.773 [0.000, 1.000], mean action: 27.300 [9.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.248759, mean_absolute_error: 5.458119, mean_q: 6.144444
121 (array([22]),) False
  84320/500000: episode: 2108, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 35.073, mean reward: 0.877 [0.000, 1.000], mean action: 16.350 [9.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.225386, mean_absolute_error: 5.408750, mean_q: 6.083037
233 (array([54]),) False
  84360/500000: episode: 2109, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 25.652, mean reward: 0.641 [0.252, 1.000], mean action: 23.175 [7.000, 57.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.211531, mean_absolute_error: 5.428322, mean_q: 6.106287
418 (array([22]),) False
  84400/500000: episode: 2110, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 28.323, mean reward: 0.708 [0.000, 1.000], mean action: 27.275 [1.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.226692, mean_absolute_error: 5.430017, mean_q: 6.115218
862 (array([14]),) False
  84440/500000: episode: 2111, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 30.899, mean reward: 0.772 [0.000, 1.000], mean action: 21.550 [6.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.250507, mean_absolute_error: 5.423585, mean_q: 6.114529
343 (array([22]),) False
  84480/500000: episode: 2112, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 36.418, mean reward: 0.910 [0.056, 1.000], mean action: 23.100 [9.000, 41.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.199541, mean_absolute_error: 5.435822, mean_q: 6.130766
500 (array([22]),) False
  84520/500000: episode: 2113, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 33.225, mean reward: 0.831 [0.188, 1.000], mean action: 22.050 [3.000, 57.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.245544, mean_absolute_error: 5.402138, mean_q: 6.093673
398 (array([22]),) False
  84560/500000: episode: 2114, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 29.001, mean reward: 0.725 [0.014, 1.000], mean action: 25.025 [0.000, 57.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.249992, mean_absolute_error: 5.429799, mean_q: 6.120601
807 (array([22]),) False
  84600/500000: episode: 2115, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 32.790, mean reward: 0.820 [0.032, 1.000], mean action: 24.875 [1.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.203913, mean_absolute_error: 5.422391, mean_q: 6.118865
840 (array([12]),) False
  84640/500000: episode: 2116, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 23.341, mean reward: 0.584 [0.000, 1.000], mean action: 29.925 [1.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.242694, mean_absolute_error: 5.393558, mean_q: 6.093704
219 (array([36]),) False
  84680/500000: episode: 2117, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 10.967, mean reward: 0.274 [0.036, 0.714], mean action: 22.325 [0.000, 60.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.224067, mean_absolute_error: 5.419279, mean_q: 6.111006
514 (array([54]),) False
  84720/500000: episode: 2118, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 17.012, mean reward: 0.425 [0.084, 0.794], mean action: 24.225 [0.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.201934, mean_absolute_error: 5.395462, mean_q: 6.086047
102 (array([22]),) False
  84760/500000: episode: 2119, duration: 32.267s, episode steps: 40, steps per second: 1, episode reward: 33.729, mean reward: 0.843 [0.000, 1.000], mean action: 21.175 [2.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.248665, mean_absolute_error: 5.450604, mean_q: 6.131134
372 (array([22]),) False
  84800/500000: episode: 2120, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 33.268, mean reward: 0.832 [0.265, 1.000], mean action: 25.475 [12.000, 57.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.240857, mean_absolute_error: 5.393971, mean_q: 6.071863
24 (array([22]),) False
  84840/500000: episode: 2121, duration: 32.927s, episode steps: 40, steps per second: 1, episode reward: 33.105, mean reward: 0.828 [0.125, 1.000], mean action: 27.225 [0.000, 60.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.199900, mean_absolute_error: 5.400871, mean_q: 6.083459
44 (array([22]),) False
  84880/500000: episode: 2122, duration: 32.730s, episode steps: 40, steps per second: 1, episode reward: 34.334, mean reward: 0.858 [0.122, 1.000], mean action: 23.325 [1.000, 56.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.205500, mean_absolute_error: 5.399152, mean_q: 6.086154
175 (array([22]),) False
  84920/500000: episode: 2123, duration: 32.060s, episode steps: 40, steps per second: 1, episode reward: 34.827, mean reward: 0.871 [0.223, 0.985], mean action: 15.025 [2.000, 52.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.234745, mean_absolute_error: 5.457683, mean_q: 6.149013
113 (array([22]),) False
  84960/500000: episode: 2124, duration: 32.107s, episode steps: 40, steps per second: 1, episode reward: 36.313, mean reward: 0.908 [0.186, 1.000], mean action: 22.800 [3.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.224331, mean_absolute_error: 5.471498, mean_q: 6.152094
184 (array([12]),) False
  85000/500000: episode: 2125, duration: 32.034s, episode steps: 40, steps per second: 1, episode reward: 33.294, mean reward: 0.832 [0.000, 1.000], mean action: 17.125 [12.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.225982, mean_absolute_error: 5.398922, mean_q: 6.063274
849 (array([3]),) False
  85040/500000: episode: 2126, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 19.041, mean reward: 0.476 [0.000, 1.000], mean action: 26.950 [3.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.242300, mean_absolute_error: 5.394857, mean_q: 6.064680
772 (array([46]),) False
  85080/500000: episode: 2127, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 30.053, mean reward: 0.751 [0.000, 1.000], mean action: 29.675 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.226323, mean_absolute_error: 5.366925, mean_q: 6.041364
188 (array([22]),) False
  85120/500000: episode: 2128, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 33.838, mean reward: 0.846 [0.171, 1.000], mean action: 17.525 [1.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.253413, mean_absolute_error: 5.367017, mean_q: 6.036397
810 (array([12]),) False
  85160/500000: episode: 2129, duration: 32.258s, episode steps: 40, steps per second: 1, episode reward: 35.626, mean reward: 0.891 [0.369, 1.000], mean action: 24.600 [12.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.221752, mean_absolute_error: 5.390351, mean_q: 6.068139
344 (array([22]),) False
  85200/500000: episode: 2130, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 35.046, mean reward: 0.876 [0.075, 1.000], mean action: 26.850 [12.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.221521, mean_absolute_error: 5.341216, mean_q: 6.021123
496 (array([48]),) False
  85240/500000: episode: 2131, duration: 32.187s, episode steps: 40, steps per second: 1, episode reward: 28.763, mean reward: 0.719 [0.037, 0.993], mean action: 26.400 [0.000, 58.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.245378, mean_absolute_error: 5.363187, mean_q: 6.041103
466 (array([22]),) False
  85280/500000: episode: 2132, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 34.009, mean reward: 0.850 [0.121, 1.000], mean action: 24.500 [2.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.219429, mean_absolute_error: 5.374373, mean_q: 6.050244
782 (array([22]),) False
  85320/500000: episode: 2133, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 29.802, mean reward: 0.745 [0.202, 1.000], mean action: 24.400 [2.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.196717, mean_absolute_error: 5.394232, mean_q: 6.082714
165 (array([34]),) False
  85360/500000: episode: 2134, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 28.432, mean reward: 0.711 [0.000, 1.000], mean action: 18.075 [5.000, 55.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.235003, mean_absolute_error: 5.355283, mean_q: 6.046534
652 (array([22]),) False
  85400/500000: episode: 2135, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 32.801, mean reward: 0.820 [0.024, 1.000], mean action: 23.450 [8.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.218779, mean_absolute_error: 5.349275, mean_q: 6.033321
735 (array([22]),) False
  85440/500000: episode: 2136, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 33.194, mean reward: 0.830 [0.180, 1.000], mean action: 22.575 [0.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.263583, mean_absolute_error: 5.412829, mean_q: 6.101291
563 (array([22]),) False
  85480/500000: episode: 2137, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 33.880, mean reward: 0.847 [0.039, 0.976], mean action: 18.800 [12.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.235238, mean_absolute_error: 5.374631, mean_q: 6.055923
82 (array([22]),) False
  85520/500000: episode: 2138, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 32.010, mean reward: 0.800 [0.031, 1.000], mean action: 23.900 [0.000, 58.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.212258, mean_absolute_error: 5.364866, mean_q: 6.046609
248 (array([12]),) False
  85560/500000: episode: 2139, duration: 32.072s, episode steps: 40, steps per second: 1, episode reward: 32.595, mean reward: 0.815 [0.096, 1.000], mean action: 21.950 [9.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.215714, mean_absolute_error: 5.351712, mean_q: 6.030000
642 (array([22]),) False
  85600/500000: episode: 2140, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 36.724, mean reward: 0.918 [0.102, 1.000], mean action: 23.450 [14.000, 54.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.230329, mean_absolute_error: 5.348358, mean_q: 6.033111
209 (array([8]),) False
  85640/500000: episode: 2141, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 28.347, mean reward: 0.709 [0.195, 1.000], mean action: 26.525 [2.000, 60.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.228853, mean_absolute_error: 5.286440, mean_q: 5.966358
757 (array([48]),) False
  85680/500000: episode: 2142, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 35.104, mean reward: 0.878 [0.000, 0.989], mean action: 24.950 [12.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.211261, mean_absolute_error: 5.308787, mean_q: 5.989586
288 (array([33]),) False
  85720/500000: episode: 2143, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 21.874, mean reward: 0.547 [0.104, 1.000], mean action: 23.875 [2.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.236506, mean_absolute_error: 5.264717, mean_q: 5.948953
52 (array([22]),) False
  85760/500000: episode: 2144, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 33.127, mean reward: 0.828 [0.067, 1.000], mean action: 23.150 [3.000, 52.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.233121, mean_absolute_error: 5.297775, mean_q: 5.979082
198 (array([22]),) False
  85800/500000: episode: 2145, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 35.398, mean reward: 0.885 [0.112, 1.000], mean action: 15.275 [0.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.236432, mean_absolute_error: 5.263035, mean_q: 5.938272
620 (array([44]),) False
  85840/500000: episode: 2146, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 30.441, mean reward: 0.761 [0.211, 1.000], mean action: 27.000 [12.000, 54.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.207369, mean_absolute_error: 5.256495, mean_q: 5.932438
409 (array([22]),) False
  85880/500000: episode: 2147, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 36.484, mean reward: 0.912 [0.371, 1.000], mean action: 25.375 [21.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.201859, mean_absolute_error: 5.269967, mean_q: 5.949709
493 (array([22]),) False
  85920/500000: episode: 2148, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 31.076, mean reward: 0.777 [0.198, 1.000], mean action: 19.300 [7.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.213459, mean_absolute_error: 5.261880, mean_q: 5.940261
404 (array([12]),) False
  85960/500000: episode: 2149, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 29.482, mean reward: 0.737 [0.284, 1.000], mean action: 26.625 [10.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.211711, mean_absolute_error: 5.321535, mean_q: 6.002059
112 (array([12]),) False
  86000/500000: episode: 2150, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 36.874, mean reward: 0.922 [0.334, 1.000], mean action: 15.575 [12.000, 46.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.208000, mean_absolute_error: 5.311539, mean_q: 5.991675
166 (array([22]),) False
  86040/500000: episode: 2151, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 28.265, mean reward: 0.707 [0.110, 1.000], mean action: 18.175 [12.000, 52.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.215317, mean_absolute_error: 5.305416, mean_q: 5.987617
129 (array([22]),) False
  86080/500000: episode: 2152, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 31.670, mean reward: 0.792 [0.088, 1.000], mean action: 19.475 [5.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.203169, mean_absolute_error: 5.339003, mean_q: 6.026635
426 (array([22]),) False
  86120/500000: episode: 2153, duration: 32.223s, episode steps: 40, steps per second: 1, episode reward: 21.160, mean reward: 0.529 [0.031, 1.000], mean action: 36.900 [4.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.223512, mean_absolute_error: 5.315544, mean_q: 5.997488
764 (array([48]),) False
  86160/500000: episode: 2154, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 31.181, mean reward: 0.780 [0.048, 1.000], mean action: 26.350 [4.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.216149, mean_absolute_error: 5.327821, mean_q: 6.009759
662 (array([12]),) False
  86200/500000: episode: 2155, duration: 32.093s, episode steps: 40, steps per second: 1, episode reward: 35.681, mean reward: 0.892 [0.140, 1.000], mean action: 15.725 [6.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.219344, mean_absolute_error: 5.330925, mean_q: 6.009778
85 (array([48]),) False
  86240/500000: episode: 2156, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 34.215, mean reward: 0.855 [0.068, 1.000], mean action: 24.850 [12.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.220513, mean_absolute_error: 5.370439, mean_q: 6.051020
260 (array([22]),) False
  86280/500000: episode: 2157, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 35.055, mean reward: 0.876 [0.260, 1.000], mean action: 23.300 [6.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.248734, mean_absolute_error: 5.393856, mean_q: 6.074467
377 (array([22]),) False
  86320/500000: episode: 2158, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 37.163, mean reward: 0.929 [0.000, 1.000], mean action: 23.875 [22.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.214469, mean_absolute_error: 5.375563, mean_q: 6.053790
145 (array([19]),) False
  86360/500000: episode: 2159, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 23.203, mean reward: 0.580 [0.000, 0.941], mean action: 23.550 [11.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.225544, mean_absolute_error: 5.395783, mean_q: 6.085129
726 (array([12]),) False
  86400/500000: episode: 2160, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 33.605, mean reward: 0.840 [0.001, 1.000], mean action: 20.525 [5.000, 45.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.234395, mean_absolute_error: 5.329416, mean_q: 6.011223
695 (array([22]),) False
  86440/500000: episode: 2161, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 34.760, mean reward: 0.869 [0.222, 1.000], mean action: 19.850 [0.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.229521, mean_absolute_error: 5.357585, mean_q: 6.040576
501 (array([12]),) False
  86480/500000: episode: 2162, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 34.835, mean reward: 0.871 [0.000, 1.000], mean action: 19.100 [0.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.234969, mean_absolute_error: 5.352273, mean_q: 6.032737
121 (array([22]),) False
  86520/500000: episode: 2163, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 34.926, mean reward: 0.873 [0.258, 1.000], mean action: 14.675 [1.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.235601, mean_absolute_error: 5.366445, mean_q: 6.040122
432 (array([22]),) False
  86560/500000: episode: 2164, duration: 32.911s, episode steps: 40, steps per second: 1, episode reward: 36.670, mean reward: 0.917 [0.185, 1.000], mean action: 23.075 [9.000, 52.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.237072, mean_absolute_error: 5.327434, mean_q: 6.002966
140 (array([12]),) False
  86600/500000: episode: 2165, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 36.933, mean reward: 0.923 [0.364, 1.000], mean action: 15.650 [5.000, 47.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.245869, mean_absolute_error: 5.300326, mean_q: 5.975079
279 (array([22]),) False
  86640/500000: episode: 2166, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 33.786, mean reward: 0.845 [0.375, 1.000], mean action: 25.825 [2.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.247557, mean_absolute_error: 5.323923, mean_q: 6.000976
803 (array([58]),) False
  86680/500000: episode: 2167, duration: 32.184s, episode steps: 40, steps per second: 1, episode reward: 18.428, mean reward: 0.461 [0.120, 1.000], mean action: 21.950 [12.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.218910, mean_absolute_error: 5.318540, mean_q: 5.990685
449 (array([22]),) False
  86720/500000: episode: 2168, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 31.786, mean reward: 0.795 [0.061, 1.000], mean action: 24.950 [4.000, 57.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.223165, mean_absolute_error: 5.341957, mean_q: 6.014614
681 (array([12]),) False
  86760/500000: episode: 2169, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 34.736, mean reward: 0.868 [0.088, 1.000], mean action: 21.125 [0.000, 54.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.203220, mean_absolute_error: 5.336208, mean_q: 6.008389
562 (array([22]),) False
  86800/500000: episode: 2170, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 28.075, mean reward: 0.702 [0.017, 1.000], mean action: 24.275 [2.000, 53.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.217446, mean_absolute_error: 5.331394, mean_q: 6.010840
340 (array([12]),) False
  86840/500000: episode: 2171, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 31.529, mean reward: 0.788 [0.074, 1.000], mean action: 25.950 [4.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.261958, mean_absolute_error: 5.345177, mean_q: 6.015357
597 (array([22]),) False
  86880/500000: episode: 2172, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 33.011, mean reward: 0.825 [0.229, 1.000], mean action: 23.825 [8.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.228384, mean_absolute_error: 5.386552, mean_q: 6.058074
257 (array([22]),) False
  86920/500000: episode: 2173, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 37.383, mean reward: 0.935 [0.389, 1.000], mean action: 23.750 [11.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.248151, mean_absolute_error: 5.375188, mean_q: 6.056535
619 (array([3]),) False
  86960/500000: episode: 2174, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 14.312, mean reward: 0.358 [0.000, 1.000], mean action: 21.600 [3.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.236016, mean_absolute_error: 5.373957, mean_q: 6.045694
756 (array([48]),) False
  87000/500000: episode: 2175, duration: 32.226s, episode steps: 40, steps per second: 1, episode reward: 35.025, mean reward: 0.876 [0.161, 1.000], mean action: 25.900 [8.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.206104, mean_absolute_error: 5.342115, mean_q: 6.020196
636 (array([12]),) False
  87040/500000: episode: 2176, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 32.502, mean reward: 0.813 [0.032, 1.000], mean action: 24.275 [10.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.245044, mean_absolute_error: 5.405921, mean_q: 6.086424
530 (array([22]),) False
  87080/500000: episode: 2177, duration: 32.256s, episode steps: 40, steps per second: 1, episode reward: 34.058, mean reward: 0.851 [0.000, 1.000], mean action: 21.300 [6.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.217444, mean_absolute_error: 5.367978, mean_q: 6.037378
555 (array([22]),) False
  87120/500000: episode: 2178, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 32.100, mean reward: 0.802 [0.091, 1.000], mean action: 18.100 [1.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.206292, mean_absolute_error: 5.349706, mean_q: 6.017133
726 (array([12]),) False
  87160/500000: episode: 2179, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 34.721, mean reward: 0.868 [0.155, 1.000], mean action: 20.850 [8.000, 49.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.213351, mean_absolute_error: 5.367412, mean_q: 6.038921
623 (array([37]),) False
  87200/500000: episode: 2180, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 33.092, mean reward: 0.827 [0.167, 1.000], mean action: 32.625 [12.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.191833, mean_absolute_error: 5.384170, mean_q: 6.073597
693 (array([22]),) False
  87240/500000: episode: 2181, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 37.391, mean reward: 0.935 [0.068, 1.000], mean action: 21.650 [2.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.223883, mean_absolute_error: 5.409022, mean_q: 6.101701
2 (array([12]),) False
  87280/500000: episode: 2182, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 27.629, mean reward: 0.691 [0.261, 0.832], mean action: 23.800 [7.000, 60.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.197144, mean_absolute_error: 5.385863, mean_q: 6.080878
713 (array([37]),) False
  87320/500000: episode: 2183, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 33.345, mean reward: 0.834 [0.079, 0.998], mean action: 19.750 [9.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.259697, mean_absolute_error: 5.427794, mean_q: 6.126118
433 (array([22]),) False
  87360/500000: episode: 2184, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 34.998, mean reward: 0.875 [0.109, 1.000], mean action: 24.100 [1.000, 59.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.246580, mean_absolute_error: 5.369775, mean_q: 6.042726
607 (array([12]),) False
  87400/500000: episode: 2185, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 35.561, mean reward: 0.889 [0.222, 1.000], mean action: 16.000 [10.000, 45.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.230869, mean_absolute_error: 5.455317, mean_q: 6.130235
5 (array([37]),) False
  87440/500000: episode: 2186, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 35.087, mean reward: 0.877 [0.000, 1.000], mean action: 32.625 [2.000, 48.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.234265, mean_absolute_error: 5.414350, mean_q: 6.082923
802 (array([22]),) False
  87480/500000: episode: 2187, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 27.182, mean reward: 0.680 [0.195, 1.000], mean action: 25.750 [6.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.238469, mean_absolute_error: 5.437457, mean_q: 6.108259
141 (array([44]),) False
  87520/500000: episode: 2188, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 22.280, mean reward: 0.557 [0.140, 1.000], mean action: 18.500 [9.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.265415, mean_absolute_error: 5.424656, mean_q: 6.096657
343 (array([22]),) False
  87560/500000: episode: 2189, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 36.588, mean reward: 0.915 [0.122, 1.000], mean action: 23.275 [4.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.227440, mean_absolute_error: 5.355062, mean_q: 6.035223
85 (array([48]),) False
  87600/500000: episode: 2190, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 33.462, mean reward: 0.837 [0.177, 0.914], mean action: 23.625 [0.000, 54.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.224844, mean_absolute_error: 5.405325, mean_q: 6.094298
47 (array([44]),) False
  87640/500000: episode: 2191, duration: 32.106s, episode steps: 40, steps per second: 1, episode reward: 33.476, mean reward: 0.837 [0.240, 1.000], mean action: 23.875 [2.000, 54.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.221195, mean_absolute_error: 5.408537, mean_q: 6.096943
13 (array([48]),) False
  87680/500000: episode: 2192, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 33.263, mean reward: 0.832 [0.035, 0.973], mean action: 21.700 [0.000, 49.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.204081, mean_absolute_error: 5.432725, mean_q: 6.119549
420 (array([22]),) False
  87720/500000: episode: 2193, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 32.027, mean reward: 0.801 [0.000, 1.000], mean action: 23.350 [0.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.245595, mean_absolute_error: 5.395482, mean_q: 6.077708
618 (array([12]),) False
  87760/500000: episode: 2194, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 34.605, mean reward: 0.865 [0.000, 1.000], mean action: 20.825 [5.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.244239, mean_absolute_error: 5.424371, mean_q: 6.113080
257 (array([22]),) False
  87800/500000: episode: 2195, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 31.064, mean reward: 0.777 [0.166, 1.000], mean action: 26.250 [2.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.225773, mean_absolute_error: 5.429907, mean_q: 6.120947
546 (array([22]),) False
  87840/500000: episode: 2196, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 34.601, mean reward: 0.865 [0.032, 1.000], mean action: 16.775 [3.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.218935, mean_absolute_error: 5.397817, mean_q: 6.086129
54 (array([8]),) False
  87880/500000: episode: 2197, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 23.351, mean reward: 0.584 [0.379, 0.977], mean action: 35.675 [11.000, 60.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.238873, mean_absolute_error: 5.424943, mean_q: 6.104241
240 (array([22]),) False
  87920/500000: episode: 2198, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 33.757, mean reward: 0.844 [0.095, 1.000], mean action: 20.100 [0.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.235704, mean_absolute_error: 5.488416, mean_q: 6.173995
330 (array([38]),) False
  87960/500000: episode: 2199, duration: 32.194s, episode steps: 40, steps per second: 1, episode reward: 33.093, mean reward: 0.827 [0.252, 1.000], mean action: 21.150 [5.000, 43.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.229918, mean_absolute_error: 5.491139, mean_q: 6.171666
131 (array([22]),) False
  88000/500000: episode: 2200, duration: 32.964s, episode steps: 40, steps per second: 1, episode reward: 37.107, mean reward: 0.928 [0.103, 1.000], mean action: 20.975 [6.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.240967, mean_absolute_error: 5.373832, mean_q: 6.048789
752 (array([3]),) False
  88040/500000: episode: 2201, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 17.630, mean reward: 0.441 [0.108, 1.000], mean action: 21.750 [3.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.246321, mean_absolute_error: 5.472216, mean_q: 6.151565
202 (array([22]),) False
  88080/500000: episode: 2202, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 33.855, mean reward: 0.846 [0.211, 1.000], mean action: 17.650 [5.000, 51.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.242463, mean_absolute_error: 5.438345, mean_q: 6.118167
370 (array([58]),) False
  88120/500000: episode: 2203, duration: 32.227s, episode steps: 40, steps per second: 1, episode reward: 21.634, mean reward: 0.541 [0.000, 1.000], mean action: 28.050 [9.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.216722, mean_absolute_error: 5.442275, mean_q: 6.131824
24 (array([22]),) False
  88160/500000: episode: 2204, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 36.170, mean reward: 0.904 [0.086, 1.000], mean action: 21.700 [2.000, 49.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.248674, mean_absolute_error: 5.408650, mean_q: 6.083871
216 (array([22]),) False
  88200/500000: episode: 2205, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 22.421, mean reward: 0.561 [0.063, 1.000], mean action: 14.275 [1.000, 40.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.247284, mean_absolute_error: 5.428134, mean_q: 6.111121
74 (array([22]),) False
  88240/500000: episode: 2206, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 35.762, mean reward: 0.894 [0.120, 1.000], mean action: 19.525 [1.000, 50.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.245373, mean_absolute_error: 5.390594, mean_q: 6.074196
32 (array([48]),) False
  88280/500000: episode: 2207, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 34.557, mean reward: 0.864 [0.062, 1.000], mean action: 26.550 [22.000, 54.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.220501, mean_absolute_error: 5.460783, mean_q: 6.151262
615 (array([36]),) False
  88320/500000: episode: 2208, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 23.670, mean reward: 0.592 [0.264, 0.930], mean action: 23.325 [10.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.230865, mean_absolute_error: 5.431761, mean_q: 6.114963
260 (array([22]),) False
  88360/500000: episode: 2209, duration: 32.914s, episode steps: 40, steps per second: 1, episode reward: 32.041, mean reward: 0.801 [0.082, 1.000], mean action: 25.300 [5.000, 55.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.246635, mean_absolute_error: 5.459835, mean_q: 6.152449
597 (array([22]),) False
  88400/500000: episode: 2210, duration: 32.995s, episode steps: 40, steps per second: 1, episode reward: 30.136, mean reward: 0.753 [0.061, 1.000], mean action: 17.625 [1.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.228140, mean_absolute_error: 5.421457, mean_q: 6.116143
390 (array([22]),) False
  88440/500000: episode: 2211, duration: 32.089s, episode steps: 40, steps per second: 1, episode reward: 32.118, mean reward: 0.803 [0.120, 1.000], mean action: 26.200 [13.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.227112, mean_absolute_error: 5.367198, mean_q: 6.054978
178 (array([38]),) False
  88480/500000: episode: 2212, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 29.453, mean reward: 0.736 [0.510, 0.992], mean action: 13.325 [7.000, 46.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.226800, mean_absolute_error: 5.419212, mean_q: 6.105708
133 (array([22]),) False
  88520/500000: episode: 2213, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 33.986, mean reward: 0.850 [0.184, 1.000], mean action: 23.425 [4.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.204966, mean_absolute_error: 5.361556, mean_q: 6.047514
91 (array([48]),) False
  88560/500000: episode: 2214, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 36.575, mean reward: 0.914 [0.154, 1.000], mean action: 29.400 [9.000, 37.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.200911, mean_absolute_error: 5.373400, mean_q: 6.061523
806 (array([22]),) False
  88600/500000: episode: 2215, duration: 32.204s, episode steps: 40, steps per second: 1, episode reward: 33.401, mean reward: 0.835 [0.069, 0.995], mean action: 40.725 [3.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.223036, mean_absolute_error: 5.393410, mean_q: 6.080961
544 (array([22]),) False
  88640/500000: episode: 2216, duration: 33.152s, episode steps: 40, steps per second: 1, episode reward: 30.506, mean reward: 0.763 [0.082, 1.000], mean action: 21.050 [3.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.256132, mean_absolute_error: 5.395869, mean_q: 6.083321
472 (array([22]),) False
  88680/500000: episode: 2217, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 32.684, mean reward: 0.817 [0.062, 1.000], mean action: 21.575 [0.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.236373, mean_absolute_error: 5.412772, mean_q: 6.097232
65 (array([48]),) False
  88720/500000: episode: 2218, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 31.442, mean reward: 0.786 [0.114, 1.000], mean action: 18.350 [1.000, 56.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.239153, mean_absolute_error: 5.397984, mean_q: 6.083877
602 (array([36]),) False
  88760/500000: episode: 2219, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 17.183, mean reward: 0.430 [0.052, 0.911], mean action: 30.275 [2.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.210284, mean_absolute_error: 5.479631, mean_q: 6.174393
339 (array([22]),) False
  88800/500000: episode: 2220, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 34.755, mean reward: 0.869 [0.000, 1.000], mean action: 33.475 [1.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.224667, mean_absolute_error: 5.376195, mean_q: 6.061577
636 (array([12]),) False
  88840/500000: episode: 2221, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 35.072, mean reward: 0.877 [0.236, 1.000], mean action: 19.775 [5.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.231537, mean_absolute_error: 5.440001, mean_q: 6.120220
433 (array([22]),) False
  88880/500000: episode: 2222, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 32.862, mean reward: 0.822 [0.099, 1.000], mean action: 25.075 [5.000, 57.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.235512, mean_absolute_error: 5.441802, mean_q: 6.121977
767 (array([48]),) False
  88920/500000: episode: 2223, duration: 32.151s, episode steps: 40, steps per second: 1, episode reward: 29.857, mean reward: 0.746 [0.214, 0.893], mean action: 23.500 [0.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.214059, mean_absolute_error: 5.395653, mean_q: 6.079905
193 (array([36]),) False
  88960/500000: episode: 2224, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 20.562, mean reward: 0.514 [0.219, 0.775], mean action: 15.575 [3.000, 59.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.244431, mean_absolute_error: 5.437766, mean_q: 6.119854
2 (array([12]),) False
  89000/500000: episode: 2225, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 25.328, mean reward: 0.633 [0.023, 0.832], mean action: 25.400 [4.000, 52.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.227179, mean_absolute_error: 5.418790, mean_q: 6.092047
173 (array([3]),) False
  89040/500000: episode: 2226, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 23.358, mean reward: 0.584 [0.168, 1.000], mean action: 20.750 [3.000, 54.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.215710, mean_absolute_error: 5.426294, mean_q: 6.104516
510 (array([22]),) False
  89080/500000: episode: 2227, duration: 32.145s, episode steps: 40, steps per second: 1, episode reward: 33.265, mean reward: 0.832 [0.273, 1.000], mean action: 15.750 [12.000, 50.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.233186, mean_absolute_error: 5.420226, mean_q: 6.097940
821 (array([22]),) False
  89120/500000: episode: 2228, duration: 32.954s, episode steps: 40, steps per second: 1, episode reward: 35.109, mean reward: 0.878 [0.428, 1.000], mean action: 18.475 [7.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.229451, mean_absolute_error: 5.381842, mean_q: 6.064840
838 (array([21]),) False
  89160/500000: episode: 2229, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 29.219, mean reward: 0.730 [0.195, 1.000], mean action: 22.850 [2.000, 57.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.232552, mean_absolute_error: 5.394151, mean_q: 6.082066
731 (array([21]),) False
  89200/500000: episode: 2230, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 32.868, mean reward: 0.822 [0.117, 1.000], mean action: 18.025 [2.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.240284, mean_absolute_error: 5.434729, mean_q: 6.124583
144 (array([22]),) False
  89240/500000: episode: 2231, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 28.781, mean reward: 0.720 [0.092, 1.000], mean action: 13.600 [2.000, 33.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.244501, mean_absolute_error: 5.365739, mean_q: 6.047154
596 (array([22]),) False
  89280/500000: episode: 2232, duration: 32.957s, episode steps: 40, steps per second: 1, episode reward: 33.394, mean reward: 0.835 [0.081, 1.000], mean action: 21.850 [0.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.244242, mean_absolute_error: 5.395045, mean_q: 6.075620
24 (array([22]),) False
  89320/500000: episode: 2233, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 36.531, mean reward: 0.913 [0.100, 1.000], mean action: 23.725 [5.000, 42.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.244264, mean_absolute_error: 5.375617, mean_q: 6.054793
603 (array([58]),) False
  89360/500000: episode: 2234, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 20.371, mean reward: 0.509 [0.188, 0.835], mean action: 20.700 [1.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.218931, mean_absolute_error: 5.399997, mean_q: 6.083229
5 (array([37]),) False
  89400/500000: episode: 2235, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 35.963, mean reward: 0.899 [0.035, 1.000], mean action: 37.825 [23.000, 53.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.239765, mean_absolute_error: 5.393731, mean_q: 6.075588
719 (array([22]),) False
  89440/500000: episode: 2236, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 35.842, mean reward: 0.896 [0.159, 1.000], mean action: 13.100 [1.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.265901, mean_absolute_error: 5.428124, mean_q: 6.121180
623 (array([37]),) False
  89480/500000: episode: 2237, duration: 32.215s, episode steps: 40, steps per second: 1, episode reward: 25.678, mean reward: 0.642 [0.000, 1.000], mean action: 19.450 [5.000, 55.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.246959, mean_absolute_error: 5.349534, mean_q: 6.033952
311 (array([22]),) False
  89520/500000: episode: 2238, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 34.819, mean reward: 0.870 [0.230, 1.000], mean action: 33.675 [13.000, 54.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.233366, mean_absolute_error: 5.398977, mean_q: 6.078536
213 (array([22]),) False
  89560/500000: episode: 2239, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 34.081, mean reward: 0.852 [0.115, 1.000], mean action: 22.150 [7.000, 56.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.212344, mean_absolute_error: 5.379110, mean_q: 6.059814
68 (array([22]),) False
  89600/500000: episode: 2240, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 30.039, mean reward: 0.751 [0.130, 1.000], mean action: 21.975 [7.000, 53.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.234905, mean_absolute_error: 5.461546, mean_q: 6.146337
262 (array([22]),) False
  89640/500000: episode: 2241, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 25.888, mean reward: 0.647 [0.188, 1.000], mean action: 23.100 [7.000, 52.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.227648, mean_absolute_error: 5.430215, mean_q: 6.113916
816 (array([4]),) False
  89680/500000: episode: 2242, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 7.417, mean reward: 0.185 [0.000, 0.709], mean action: 22.125 [1.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.249622, mean_absolute_error: 5.361907, mean_q: 6.042542
852 (array([44]),) False
  89720/500000: episode: 2243, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 31.348, mean reward: 0.784 [0.164, 1.000], mean action: 22.325 [0.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.229003, mean_absolute_error: 5.419185, mean_q: 6.111525
534 (array([22]),) False
  89760/500000: episode: 2244, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 33.944, mean reward: 0.849 [0.212, 1.000], mean action: 18.825 [6.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.221710, mean_absolute_error: 5.418567, mean_q: 6.106259
16 (array([22]),) False
  89800/500000: episode: 2245, duration: 32.238s, episode steps: 40, steps per second: 1, episode reward: 33.962, mean reward: 0.849 [0.039, 1.000], mean action: 24.975 [11.000, 49.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.225018, mean_absolute_error: 5.376217, mean_q: 6.054362
147 (array([44]),) False
  89840/500000: episode: 2246, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 25.535, mean reward: 0.638 [0.280, 0.831], mean action: 14.750 [3.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.264537, mean_absolute_error: 5.453339, mean_q: 6.131330
745 (array([22]),) False
  89880/500000: episode: 2247, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 30.364, mean reward: 0.759 [0.089, 1.000], mean action: 13.825 [0.000, 38.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.266606, mean_absolute_error: 5.430335, mean_q: 6.108943
362 (array([22]),) False
  89920/500000: episode: 2248, duration: 33.004s, episode steps: 40, steps per second: 1, episode reward: 34.473, mean reward: 0.862 [0.004, 1.000], mean action: 22.450 [2.000, 51.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.232998, mean_absolute_error: 5.395247, mean_q: 6.069408
114 (array([22]),) False
  89960/500000: episode: 2249, duration: 32.275s, episode steps: 40, steps per second: 1, episode reward: 29.284, mean reward: 0.732 [0.000, 1.000], mean action: 24.025 [0.000, 57.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.226735, mean_absolute_error: 5.432313, mean_q: 6.105122
512 (array([48]),) False
  90000/500000: episode: 2250, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 34.808, mean reward: 0.870 [0.132, 1.000], mean action: 15.500 [11.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.217971, mean_absolute_error: 5.446659, mean_q: 6.130574
258 (array([22]),) False
  90040/500000: episode: 2251, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 36.264, mean reward: 0.907 [0.163, 1.000], mean action: 20.725 [0.000, 55.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.228889, mean_absolute_error: 5.415744, mean_q: 6.084189
573 (array([22]),) False
  90080/500000: episode: 2252, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 32.127, mean reward: 0.803 [0.132, 1.000], mean action: 18.750 [1.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.212930, mean_absolute_error: 5.412498, mean_q: 6.089625
109 (array([48]),) False
  90120/500000: episode: 2253, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 31.725, mean reward: 0.793 [0.065, 1.000], mean action: 16.850 [12.000, 54.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.242060, mean_absolute_error: 5.460496, mean_q: 6.137182
313 (array([22]),) False
  90160/500000: episode: 2254, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 31.171, mean reward: 0.779 [0.109, 1.000], mean action: 24.150 [0.000, 52.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.247005, mean_absolute_error: 5.422823, mean_q: 6.102428
29 (array([22]),) False
  90200/500000: episode: 2255, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 32.014, mean reward: 0.800 [0.041, 1.000], mean action: 20.375 [1.000, 41.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.222213, mean_absolute_error: 5.410781, mean_q: 6.102965
512 (array([48]),) False
  90240/500000: episode: 2256, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 34.594, mean reward: 0.865 [0.024, 1.000], mean action: 15.575 [0.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.245436, mean_absolute_error: 5.459321, mean_q: 6.145968
726 (array([12]),) False
  90280/500000: episode: 2257, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 34.407, mean reward: 0.860 [0.114, 1.000], mean action: 20.450 [8.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.244814, mean_absolute_error: 5.439192, mean_q: 6.128922
670 (array([22]),) False
  90320/500000: episode: 2258, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 33.027, mean reward: 0.826 [0.410, 1.000], mean action: 20.550 [12.000, 47.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.210881, mean_absolute_error: 5.421582, mean_q: 6.114563
140 (array([12]),) False
  90360/500000: episode: 2259, duration: 33.146s, episode steps: 40, steps per second: 1, episode reward: 34.559, mean reward: 0.864 [0.000, 1.000], mean action: 42.850 [2.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.217345, mean_absolute_error: 5.433689, mean_q: 6.124975
5 (array([37]),) False
  90400/500000: episode: 2260, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 32.916, mean reward: 0.823 [0.240, 1.000], mean action: 33.725 [3.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.220899, mean_absolute_error: 5.462499, mean_q: 6.153999
659 (array([40]),) False
  90440/500000: episode: 2261, duration: 32.260s, episode steps: 40, steps per second: 1, episode reward: 30.046, mean reward: 0.751 [0.129, 1.000], mean action: 31.850 [2.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.217740, mean_absolute_error: 5.475360, mean_q: 6.169349
718 (array([12]),) False
  90480/500000: episode: 2262, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 35.737, mean reward: 0.893 [0.000, 1.000], mean action: 14.750 [0.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.236321, mean_absolute_error: 5.475696, mean_q: 6.164562
449 (array([22]),) False
  90520/500000: episode: 2263, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 34.219, mean reward: 0.855 [0.239, 1.000], mean action: 24.750 [1.000, 55.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.239464, mean_absolute_error: 5.449070, mean_q: 6.127889
159 (array([48]),) False
  90560/500000: episode: 2264, duration: 32.952s, episode steps: 40, steps per second: 1, episode reward: 35.031, mean reward: 0.876 [0.206, 1.000], mean action: 20.300 [4.000, 60.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.243670, mean_absolute_error: 5.413969, mean_q: 6.091619
737 (array([15]),) False
  90600/500000: episode: 2265, duration: 32.254s, episode steps: 40, steps per second: 1, episode reward: 24.600, mean reward: 0.615 [0.209, 0.955], mean action: 16.500 [5.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.240422, mean_absolute_error: 5.412084, mean_q: 6.096402
621 (array([22]),) False
  90640/500000: episode: 2266, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 32.831, mean reward: 0.821 [0.021, 1.000], mean action: 29.000 [0.000, 49.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.226827, mean_absolute_error: 5.448403, mean_q: 6.136971
391 (array([22]),) False
  90680/500000: episode: 2267, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 34.760, mean reward: 0.869 [0.129, 1.000], mean action: 23.650 [9.000, 57.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.247492, mean_absolute_error: 5.402362, mean_q: 6.091271
576 (array([58]),) False
  90720/500000: episode: 2268, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 18.018, mean reward: 0.450 [0.243, 0.808], mean action: 24.300 [12.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.212945, mean_absolute_error: 5.448504, mean_q: 6.140283
654 (array([22]),) False
  90760/500000: episode: 2269, duration: 32.139s, episode steps: 40, steps per second: 1, episode reward: 32.954, mean reward: 0.824 [0.214, 1.000], mean action: 36.175 [12.000, 48.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.228630, mean_absolute_error: 5.452218, mean_q: 6.144163
346 (array([12]),) False
  90800/500000: episode: 2270, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 31.800, mean reward: 0.795 [0.072, 1.000], mean action: 25.600 [7.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.261473, mean_absolute_error: 5.466899, mean_q: 6.155086
846 (array([48]),) False
  90840/500000: episode: 2271, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 34.238, mean reward: 0.856 [0.062, 0.974], mean action: 26.225 [12.000, 46.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.226172, mean_absolute_error: 5.456696, mean_q: 6.149944
642 (array([22]),) False
  90880/500000: episode: 2272, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 35.248, mean reward: 0.881 [0.000, 1.000], mean action: 22.950 [7.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.242787, mean_absolute_error: 5.365246, mean_q: 6.051397
176 (array([3]),) False
  90920/500000: episode: 2273, duration: 31.574s, episode steps: 40, steps per second: 1, episode reward: 15.455, mean reward: 0.386 [0.023, 0.765], mean action: 25.850 [9.000, 49.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.239570, mean_absolute_error: 5.469237, mean_q: 6.158384
433 (array([22]),) False
  90960/500000: episode: 2274, duration: 31.545s, episode steps: 40, steps per second: 1, episode reward: 36.557, mean reward: 0.914 [0.121, 1.000], mean action: 22.550 [3.000, 49.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.234422, mean_absolute_error: 5.450840, mean_q: 6.135921
560 (array([22]),) False
  91000/500000: episode: 2275, duration: 31.302s, episode steps: 40, steps per second: 1, episode reward: 28.595, mean reward: 0.715 [0.160, 0.872], mean action: 15.625 [2.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.228137, mean_absolute_error: 5.488421, mean_q: 6.170443
661 (array([48]),) False
  91040/500000: episode: 2276, duration: 31.454s, episode steps: 40, steps per second: 1, episode reward: 32.113, mean reward: 0.803 [0.202, 1.000], mean action: 37.175 [2.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.259231, mean_absolute_error: 5.458410, mean_q: 6.136971
256 (array([22]),) False
  91080/500000: episode: 2277, duration: 31.078s, episode steps: 40, steps per second: 1, episode reward: 35.084, mean reward: 0.877 [0.119, 1.000], mean action: 25.575 [16.000, 60.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.234990, mean_absolute_error: 5.465558, mean_q: 6.137491
27 (array([22]),) False
  91120/500000: episode: 2278, duration: 31.615s, episode steps: 40, steps per second: 1, episode reward: 35.401, mean reward: 0.885 [0.197, 1.000], mean action: 23.675 [16.000, 51.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.261042, mean_absolute_error: 5.464650, mean_q: 6.138653
288 (array([33]),) False
  91160/500000: episode: 2279, duration: 31.425s, episode steps: 40, steps per second: 1, episode reward: 22.536, mean reward: 0.563 [0.151, 1.000], mean action: 33.850 [2.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.231709, mean_absolute_error: 5.545962, mean_q: 6.223720
841 (array([21]),) False
  91200/500000: episode: 2280, duration: 31.605s, episode steps: 40, steps per second: 1, episode reward: 29.407, mean reward: 0.735 [0.145, 0.966], mean action: 17.550 [3.000, 51.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.269319, mean_absolute_error: 5.560164, mean_q: 6.251147
795 (array([3]),) False
  91240/500000: episode: 2281, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 22.445, mean reward: 0.561 [0.356, 0.967], mean action: 15.425 [6.000, 49.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.222893, mean_absolute_error: 5.471383, mean_q: 6.150897
6 (array([58]),) False
  91280/500000: episode: 2282, duration: 31.148s, episode steps: 40, steps per second: 1, episode reward: 31.233, mean reward: 0.781 [0.087, 1.000], mean action: 23.475 [1.000, 41.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.256710, mean_absolute_error: 5.497057, mean_q: 6.176604
32 (array([48]),) False
  91320/500000: episode: 2283, duration: 31.574s, episode steps: 40, steps per second: 1, episode reward: 34.203, mean reward: 0.855 [0.042, 1.000], mean action: 22.875 [1.000, 59.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.257472, mean_absolute_error: 5.475757, mean_q: 6.163077
349 (array([48]),) False
  91360/500000: episode: 2284, duration: 31.544s, episode steps: 40, steps per second: 1, episode reward: 35.784, mean reward: 0.895 [0.229, 1.000], mean action: 25.475 [1.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.216062, mean_absolute_error: 5.454453, mean_q: 6.138094
86 (array([22]),) False
  91400/500000: episode: 2285, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 33.332, mean reward: 0.833 [0.184, 1.000], mean action: 22.175 [4.000, 46.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.234626, mean_absolute_error: 5.489315, mean_q: 6.175485
487 (array([48]),) False
  91440/500000: episode: 2286, duration: 31.409s, episode steps: 40, steps per second: 1, episode reward: 35.262, mean reward: 0.882 [0.085, 1.000], mean action: 18.050 [8.000, 47.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.262569, mean_absolute_error: 5.505418, mean_q: 6.179337
57 (array([37]),) False
  91480/500000: episode: 2287, duration: 31.443s, episode steps: 40, steps per second: 1, episode reward: 30.678, mean reward: 0.767 [0.062, 0.963], mean action: 35.600 [14.000, 58.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.235251, mean_absolute_error: 5.547484, mean_q: 6.226150
506 (array([8]),) False
  91520/500000: episode: 2288, duration: 31.479s, episode steps: 40, steps per second: 1, episode reward: 12.340, mean reward: 0.309 [0.061, 0.758], mean action: 15.200 [2.000, 55.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.235171, mean_absolute_error: 5.472055, mean_q: 6.148321
597 (array([22]),) False
  91560/500000: episode: 2289, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 35.138, mean reward: 0.878 [0.540, 1.000], mean action: 21.775 [5.000, 48.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.227899, mean_absolute_error: 5.486397, mean_q: 6.169484
157 (array([48]),) False
  91600/500000: episode: 2290, duration: 31.374s, episode steps: 40, steps per second: 1, episode reward: 32.245, mean reward: 0.806 [0.114, 0.999], mean action: 19.100 [8.000, 59.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.267581, mean_absolute_error: 5.481615, mean_q: 6.166698
189 (array([12]),) False
  91640/500000: episode: 2291, duration: 31.449s, episode steps: 40, steps per second: 1, episode reward: 32.374, mean reward: 0.809 [0.071, 1.000], mean action: 20.750 [3.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.225707, mean_absolute_error: 5.482823, mean_q: 6.161338
654 (array([22]),) False
  91680/500000: episode: 2292, duration: 31.382s, episode steps: 40, steps per second: 1, episode reward: 29.682, mean reward: 0.742 [0.018, 1.000], mean action: 36.000 [3.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.235970, mean_absolute_error: 5.476315, mean_q: 6.160178
860 (array([12]),) False
  91720/500000: episode: 2293, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 31.075, mean reward: 0.777 [0.268, 1.000], mean action: 21.825 [9.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.218501, mean_absolute_error: 5.391215, mean_q: 6.080329
418 (array([22]),) False
  91760/500000: episode: 2294, duration: 31.516s, episode steps: 40, steps per second: 1, episode reward: 30.894, mean reward: 0.772 [0.273, 1.000], mean action: 21.625 [4.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.276854, mean_absolute_error: 5.510001, mean_q: 6.213743
610 (array([48]),) False
  91800/500000: episode: 2295, duration: 31.425s, episode steps: 40, steps per second: 1, episode reward: 32.207, mean reward: 0.805 [0.014, 0.999], mean action: 20.000 [11.000, 50.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.228917, mean_absolute_error: 5.410888, mean_q: 6.094869
250 (array([22]),) False
  91840/500000: episode: 2296, duration: 31.440s, episode steps: 40, steps per second: 1, episode reward: 34.244, mean reward: 0.856 [0.063, 1.000], mean action: 23.625 [8.000, 57.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.260151, mean_absolute_error: 5.451019, mean_q: 6.136712
264 (array([12]),) False
  91880/500000: episode: 2297, duration: 31.015s, episode steps: 40, steps per second: 1, episode reward: 31.535, mean reward: 0.788 [0.034, 1.000], mean action: 22.350 [0.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.242339, mean_absolute_error: 5.423892, mean_q: 6.112599
326 (array([48]),) False
  91920/500000: episode: 2298, duration: 31.423s, episode steps: 40, steps per second: 1, episode reward: 33.825, mean reward: 0.846 [0.045, 1.000], mean action: 19.275 [1.000, 57.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.248000, mean_absolute_error: 5.439793, mean_q: 6.127244
68 (array([22]),) False
  91960/500000: episode: 2299, duration: 31.405s, episode steps: 40, steps per second: 1, episode reward: 25.045, mean reward: 0.626 [0.054, 1.000], mean action: 23.725 [2.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.246732, mean_absolute_error: 5.479247, mean_q: 6.157971
67 (array([8]),) False
  92000/500000: episode: 2300, duration: 31.403s, episode steps: 40, steps per second: 1, episode reward: 24.543, mean reward: 0.614 [0.351, 0.956], mean action: 22.825 [5.000, 53.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.226787, mean_absolute_error: 5.459630, mean_q: 6.138973
507 (array([44]),) False
  92040/500000: episode: 2301, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 29.749, mean reward: 0.744 [0.255, 0.988], mean action: 19.600 [0.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.233997, mean_absolute_error: 5.397766, mean_q: 6.079828
856 (array([48]),) False
  92080/500000: episode: 2302, duration: 31.437s, episode steps: 40, steps per second: 1, episode reward: 34.882, mean reward: 0.872 [0.292, 0.973], mean action: 16.250 [1.000, 59.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.223136, mean_absolute_error: 5.403901, mean_q: 6.086860
743 (array([48]),) False
  92120/500000: episode: 2303, duration: 31.428s, episode steps: 40, steps per second: 1, episode reward: 24.740, mean reward: 0.619 [0.080, 0.994], mean action: 16.525 [6.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.240731, mean_absolute_error: 5.430509, mean_q: 6.110337
737 (array([15]),) False
  92160/500000: episode: 2304, duration: 31.480s, episode steps: 40, steps per second: 1, episode reward: 24.450, mean reward: 0.611 [0.231, 0.785], mean action: 17.275 [1.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.246585, mean_absolute_error: 5.412699, mean_q: 6.084876
720 (array([22]),) False
  92200/500000: episode: 2305, duration: 30.955s, episode steps: 40, steps per second: 1, episode reward: 31.177, mean reward: 0.779 [0.000, 1.000], mean action: 30.925 [9.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.238463, mean_absolute_error: 5.373748, mean_q: 6.052438
69 (array([12]),) False
  92240/500000: episode: 2306, duration: 31.435s, episode steps: 40, steps per second: 1, episode reward: 25.190, mean reward: 0.630 [0.190, 1.000], mean action: 23.150 [7.000, 60.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.243955, mean_absolute_error: 5.424890, mean_q: 6.109238
440 (array([22]),) False
  92280/500000: episode: 2307, duration: 31.461s, episode steps: 40, steps per second: 1, episode reward: 32.983, mean reward: 0.825 [0.000, 1.000], mean action: 23.450 [2.000, 58.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.231775, mean_absolute_error: 5.357262, mean_q: 6.033713
702 (array([22]),) False
  92320/500000: episode: 2308, duration: 31.405s, episode steps: 40, steps per second: 1, episode reward: 32.183, mean reward: 0.805 [0.107, 1.000], mean action: 20.675 [4.000, 51.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.230964, mean_absolute_error: 5.417764, mean_q: 6.098643
234 (array([22]),) False
  92360/500000: episode: 2309, duration: 31.118s, episode steps: 40, steps per second: 1, episode reward: 33.440, mean reward: 0.836 [0.104, 1.000], mean action: 21.900 [10.000, 60.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.235591, mean_absolute_error: 5.415398, mean_q: 6.093545
326 (array([48]),) False
  92400/500000: episode: 2310, duration: 31.541s, episode steps: 40, steps per second: 1, episode reward: 32.062, mean reward: 0.802 [0.222, 1.000], mean action: 20.700 [4.000, 41.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.223256, mean_absolute_error: 5.431962, mean_q: 6.119142
759 (array([48]),) False
  92440/500000: episode: 2311, duration: 31.400s, episode steps: 40, steps per second: 1, episode reward: 34.967, mean reward: 0.874 [0.132, 1.000], mean action: 29.325 [5.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.253829, mean_absolute_error: 5.418195, mean_q: 6.108733
548 (array([22]),) False
  92480/500000: episode: 2312, duration: 31.268s, episode steps: 40, steps per second: 1, episode reward: 32.566, mean reward: 0.814 [0.000, 1.000], mean action: 20.300 [2.000, 55.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.237247, mean_absolute_error: 5.431994, mean_q: 6.126853
672 (array([44]),) False
  92520/500000: episode: 2313, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 27.394, mean reward: 0.685 [0.518, 0.987], mean action: 23.850 [12.000, 53.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.208098, mean_absolute_error: 5.509429, mean_q: 6.201440
407 (array([22]),) False
  92560/500000: episode: 2314, duration: 31.214s, episode steps: 40, steps per second: 1, episode reward: 37.175, mean reward: 0.929 [0.193, 1.000], mean action: 22.450 [3.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.236196, mean_absolute_error: 5.429469, mean_q: 6.114755
832 (array([22]),) False
  92600/500000: episode: 2315, duration: 30.380s, episode steps: 40, steps per second: 1, episode reward: 32.522, mean reward: 0.813 [0.084, 1.000], mean action: 20.100 [1.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.213354, mean_absolute_error: 5.372621, mean_q: 6.055989
398 (array([22]),) False
  92640/500000: episode: 2316, duration: 30.299s, episode steps: 40, steps per second: 1, episode reward: 30.377, mean reward: 0.759 [0.068, 1.000], mean action: 27.025 [12.000, 48.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.203946, mean_absolute_error: 5.487618, mean_q: 6.180186
827 (array([14]),) False
  92680/500000: episode: 2317, duration: 29.702s, episode steps: 40, steps per second: 1, episode reward: 29.331, mean reward: 0.733 [0.040, 1.000], mean action: 23.625 [0.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.255823, mean_absolute_error: 5.497363, mean_q: 6.191597
644 (array([12]),) False
  92720/500000: episode: 2318, duration: 34.625s, episode steps: 40, steps per second: 1, episode reward: 32.764, mean reward: 0.819 [0.378, 1.000], mean action: 21.025 [12.000, 52.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.232245, mean_absolute_error: 5.460494, mean_q: 6.144876
778 (array([12]),) False
  92760/500000: episode: 2319, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 30.153, mean reward: 0.754 [0.041, 1.000], mean action: 27.000 [0.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.250477, mean_absolute_error: 5.401137, mean_q: 6.083202
136 (array([12]),) False
  92800/500000: episode: 2320, duration: 30.719s, episode steps: 40, steps per second: 1, episode reward: 32.610, mean reward: 0.815 [0.000, 1.000], mean action: 19.250 [1.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.246702, mean_absolute_error: 5.440881, mean_q: 6.122104
520 (array([22]),) False
  92840/500000: episode: 2321, duration: 29.835s, episode steps: 40, steps per second: 1, episode reward: 35.565, mean reward: 0.889 [0.000, 1.000], mean action: 17.800 [9.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.216948, mean_absolute_error: 5.444876, mean_q: 6.126222
69 (array([12]),) False
  92880/500000: episode: 2322, duration: 30.298s, episode steps: 40, steps per second: 1, episode reward: 25.677, mean reward: 0.642 [0.076, 0.923], mean action: 22.725 [1.000, 54.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.263029, mean_absolute_error: 5.474244, mean_q: 6.155059
581 (array([22]),) False
  92920/500000: episode: 2323, duration: 31.043s, episode steps: 40, steps per second: 1, episode reward: 33.185, mean reward: 0.830 [0.052, 1.000], mean action: 24.225 [10.000, 59.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.246353, mean_absolute_error: 5.385885, mean_q: 6.068328
698 (array([22]),) False
  92960/500000: episode: 2324, duration: 31.062s, episode steps: 40, steps per second: 1, episode reward: 35.433, mean reward: 0.886 [0.330, 1.000], mean action: 23.350 [9.000, 50.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.226174, mean_absolute_error: 5.407987, mean_q: 6.093411
464 (array([22]),) False
  93000/500000: episode: 2325, duration: 30.567s, episode steps: 40, steps per second: 1, episode reward: 37.087, mean reward: 0.927 [0.058, 1.000], mean action: 22.300 [10.000, 41.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.251608, mean_absolute_error: 5.438155, mean_q: 6.130544
60 (array([22]),) False
  93040/500000: episode: 2326, duration: 31.287s, episode steps: 40, steps per second: 1, episode reward: 30.189, mean reward: 0.755 [0.000, 1.000], mean action: 30.350 [3.000, 49.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.250341, mean_absolute_error: 5.451059, mean_q: 6.144919
106 (array([22]),) False
  93080/500000: episode: 2327, duration: 31.142s, episode steps: 40, steps per second: 1, episode reward: 28.354, mean reward: 0.709 [0.000, 1.000], mean action: 24.350 [9.000, 51.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.232230, mean_absolute_error: 5.389020, mean_q: 6.074579
133 (array([22]),) False
  93120/500000: episode: 2328, duration: 31.123s, episode steps: 40, steps per second: 1, episode reward: 32.793, mean reward: 0.820 [0.142, 1.000], mean action: 20.050 [2.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.234835, mean_absolute_error: 5.438767, mean_q: 6.121211
700 (array([44]),) False
  93160/500000: episode: 2329, duration: 30.047s, episode steps: 40, steps per second: 1, episode reward: 29.365, mean reward: 0.734 [0.594, 0.816], mean action: 22.875 [12.000, 47.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.252462, mean_absolute_error: 5.441100, mean_q: 6.117599
511 (array([22]),) False
  93200/500000: episode: 2330, duration: 31.004s, episode steps: 40, steps per second: 1, episode reward: 34.234, mean reward: 0.856 [0.342, 1.000], mean action: 15.700 [7.000, 42.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.237972, mean_absolute_error: 5.448319, mean_q: 6.125915
548 (array([22]),) False
  93240/500000: episode: 2331, duration: 31.138s, episode steps: 40, steps per second: 1, episode reward: 28.947, mean reward: 0.724 [0.000, 1.000], mean action: 18.400 [2.000, 49.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.216253, mean_absolute_error: 5.419441, mean_q: 6.096134
294 (array([22]),) False
  93280/500000: episode: 2332, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 37.311, mean reward: 0.933 [0.200, 1.000], mean action: 24.050 [0.000, 44.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.234213, mean_absolute_error: 5.395833, mean_q: 6.073173
77 (array([22]),) False
  93320/500000: episode: 2333, duration: 30.255s, episode steps: 40, steps per second: 1, episode reward: 31.041, mean reward: 0.776 [0.000, 1.000], mean action: 25.825 [0.000, 58.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.248614, mean_absolute_error: 5.417955, mean_q: 6.096140
234 (array([22]),) False
  93360/500000: episode: 2334, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 35.678, mean reward: 0.892 [0.373, 1.000], mean action: 20.150 [12.000, 53.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.213367, mean_absolute_error: 5.411846, mean_q: 6.096177
543 (array([12]),) False
  93400/500000: episode: 2335, duration: 31.141s, episode steps: 40, steps per second: 1, episode reward: 31.259, mean reward: 0.781 [0.053, 1.000], mean action: 17.650 [1.000, 46.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.235320, mean_absolute_error: 5.374005, mean_q: 6.059951
536 (array([22]),) False
  93440/500000: episode: 2336, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 32.986, mean reward: 0.825 [0.121, 1.000], mean action: 23.875 [9.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.233235, mean_absolute_error: 5.382461, mean_q: 6.069723
289 (array([21]),) False
  93480/500000: episode: 2337, duration: 30.035s, episode steps: 40, steps per second: 1, episode reward: 26.797, mean reward: 0.670 [0.217, 1.000], mean action: 24.500 [0.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.237845, mean_absolute_error: 5.418999, mean_q: 6.104621
832 (array([22]),) False
  93520/500000: episode: 2338, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 33.903, mean reward: 0.848 [0.117, 1.000], mean action: 18.900 [0.000, 54.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.228014, mean_absolute_error: 5.421400, mean_q: 6.105908
197 (array([22]),) False
  93560/500000: episode: 2339, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 34.619, mean reward: 0.865 [0.028, 1.000], mean action: 16.700 [3.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.247181, mean_absolute_error: 5.453990, mean_q: 6.133712
414 (array([48]),) False
  93600/500000: episode: 2340, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 31.428, mean reward: 0.786 [0.013, 0.993], mean action: 25.875 [5.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.248899, mean_absolute_error: 5.462142, mean_q: 6.143817
338 (array([12]),) False
  93640/500000: episode: 2341, duration: 30.144s, episode steps: 40, steps per second: 1, episode reward: 35.968, mean reward: 0.899 [0.491, 1.000], mean action: 19.300 [0.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.228822, mean_absolute_error: 5.420011, mean_q: 6.100116
792 (array([58]),) False
  93680/500000: episode: 2342, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 15.761, mean reward: 0.394 [0.000, 0.932], mean action: 22.225 [4.000, 56.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.237313, mean_absolute_error: 5.420440, mean_q: 6.102764
474 (array([22]),) False
  93720/500000: episode: 2343, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 38.596, mean reward: 0.965 [0.373, 1.000], mean action: 22.825 [12.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.232793, mean_absolute_error: 5.447004, mean_q: 6.135780
710 (array([12]),) False
  93760/500000: episode: 2344, duration: 30.829s, episode steps: 40, steps per second: 1, episode reward: 33.469, mean reward: 0.837 [0.440, 1.000], mean action: 15.550 [1.000, 54.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.210484, mean_absolute_error: 5.461768, mean_q: 6.143874
731 (array([21]),) False
  93800/500000: episode: 2345, duration: 30.193s, episode steps: 40, steps per second: 1, episode reward: 32.036, mean reward: 0.801 [0.238, 1.000], mean action: 18.725 [9.000, 46.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.229832, mean_absolute_error: 5.485364, mean_q: 6.171793
631 (array([22]),) False
  93840/500000: episode: 2346, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 35.343, mean reward: 0.884 [0.172, 1.000], mean action: 25.475 [12.000, 48.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.215854, mean_absolute_error: 5.466946, mean_q: 6.158534
383 (array([22]),) False
  93880/500000: episode: 2347, duration: 30.840s, episode steps: 40, steps per second: 1, episode reward: 35.822, mean reward: 0.896 [0.023, 1.000], mean action: 22.875 [4.000, 52.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.219025, mean_absolute_error: 5.438047, mean_q: 6.133683
835 (array([50]),) False
  93920/500000: episode: 2348, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 32.336, mean reward: 0.808 [0.351, 1.000], mean action: 29.300 [2.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.214916, mean_absolute_error: 5.501894, mean_q: 6.203202
685 (array([22]),) False
  93960/500000: episode: 2349, duration: 30.065s, episode steps: 40, steps per second: 1, episode reward: 35.921, mean reward: 0.898 [0.109, 1.000], mean action: 14.600 [0.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.235550, mean_absolute_error: 5.489330, mean_q: 6.179299
855 (array([12]),) False
  94000/500000: episode: 2350, duration: 30.799s, episode steps: 40, steps per second: 1, episode reward: 34.092, mean reward: 0.852 [0.190, 1.000], mean action: 16.975 [12.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.245915, mean_absolute_error: 5.491468, mean_q: 6.187833
558 (array([40]),) False
  94040/500000: episode: 2351, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 26.233, mean reward: 0.656 [0.000, 1.000], mean action: 15.800 [9.000, 53.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.256754, mean_absolute_error: 5.465269, mean_q: 6.148939
787 (array([3]),) False
  94080/500000: episode: 2352, duration: 30.918s, episode steps: 40, steps per second: 1, episode reward: 23.488, mean reward: 0.587 [0.150, 1.000], mean action: 24.250 [2.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.223386, mean_absolute_error: 5.518745, mean_q: 6.210152
315 (array([12]),) False
  94120/500000: episode: 2353, duration: 30.128s, episode steps: 40, steps per second: 1, episode reward: 32.046, mean reward: 0.801 [0.202, 1.000], mean action: 27.650 [8.000, 55.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.219423, mean_absolute_error: 5.482512, mean_q: 6.171374
630 (array([22]),) False
  94160/500000: episode: 2354, duration: 30.915s, episode steps: 40, steps per second: 1, episode reward: 35.154, mean reward: 0.879 [0.088, 1.000], mean action: 21.375 [8.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.217014, mean_absolute_error: 5.467748, mean_q: 6.160433
780 (array([22]),) False
  94200/500000: episode: 2355, duration: 30.954s, episode steps: 40, steps per second: 1, episode reward: 33.975, mean reward: 0.849 [0.000, 1.000], mean action: 22.975 [6.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.212188, mean_absolute_error: 5.484704, mean_q: 6.180014
806 (array([22]),) False
  94240/500000: episode: 2356, duration: 30.905s, episode steps: 40, steps per second: 1, episode reward: 32.092, mean reward: 0.802 [0.045, 0.921], mean action: 20.350 [12.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.236307, mean_absolute_error: 5.491693, mean_q: 6.199152
144 (array([22]),) False
  94280/500000: episode: 2357, duration: 30.115s, episode steps: 40, steps per second: 1, episode reward: 30.169, mean reward: 0.754 [0.000, 1.000], mean action: 17.150 [8.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.220032, mean_absolute_error: 5.554100, mean_q: 6.259692
219 (array([36]),) False
  94320/500000: episode: 2358, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 20.900, mean reward: 0.522 [0.095, 0.922], mean action: 27.100 [3.000, 50.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.277708, mean_absolute_error: 5.556506, mean_q: 6.241105
658 (array([48]),) False
  94360/500000: episode: 2359, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 28.407, mean reward: 0.710 [0.000, 1.000], mean action: 37.100 [3.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.236685, mean_absolute_error: 5.510208, mean_q: 6.195611
546 (array([22]),) False
  94400/500000: episode: 2360, duration: 30.906s, episode steps: 40, steps per second: 1, episode reward: 29.871, mean reward: 0.747 [0.262, 0.962], mean action: 33.625 [0.000, 43.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.271450, mean_absolute_error: 5.483438, mean_q: 6.169110
535 (array([22]),) False
  94440/500000: episode: 2361, duration: 30.050s, episode steps: 40, steps per second: 1, episode reward: 33.174, mean reward: 0.829 [0.000, 1.000], mean action: 15.925 [4.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.254013, mean_absolute_error: 5.495113, mean_q: 6.177534
608 (array([36]),) False
  94480/500000: episode: 2362, duration: 31.039s, episode steps: 40, steps per second: 1, episode reward: 23.693, mean reward: 0.592 [0.016, 1.000], mean action: 22.675 [3.000, 43.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.283800, mean_absolute_error: 5.472997, mean_q: 6.159371
512 (array([48]),) False
  94520/500000: episode: 2363, duration: 31.023s, episode steps: 40, steps per second: 1, episode reward: 35.460, mean reward: 0.886 [0.013, 1.000], mean action: 16.550 [5.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.241609, mean_absolute_error: 5.449641, mean_q: 6.134527
627 (array([48]),) False
  94560/500000: episode: 2364, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 34.549, mean reward: 0.864 [0.019, 1.000], mean action: 17.075 [12.000, 53.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.250320, mean_absolute_error: 5.463873, mean_q: 6.148657
605 (array([22]),) False
  94600/500000: episode: 2365, duration: 30.116s, episode steps: 40, steps per second: 1, episode reward: 32.224, mean reward: 0.806 [0.033, 1.000], mean action: 21.600 [5.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.256163, mean_absolute_error: 5.482148, mean_q: 6.164792
384 (array([22]),) False
  94640/500000: episode: 2366, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 34.868, mean reward: 0.872 [0.000, 1.000], mean action: 23.375 [4.000, 47.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.229313, mean_absolute_error: 5.448440, mean_q: 6.128757
135 (array([22]),) False
  94680/500000: episode: 2367, duration: 30.899s, episode steps: 40, steps per second: 1, episode reward: 34.034, mean reward: 0.851 [0.130, 1.000], mean action: 20.700 [0.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.229313, mean_absolute_error: 5.403131, mean_q: 6.077395
721 (array([22]),) False
  94720/500000: episode: 2368, duration: 31.042s, episode steps: 40, steps per second: 1, episode reward: 29.159, mean reward: 0.729 [0.056, 0.954], mean action: 16.400 [0.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.243157, mean_absolute_error: 5.404927, mean_q: 6.083234
528 (array([12]),) False
  94760/500000: episode: 2369, duration: 30.158s, episode steps: 40, steps per second: 1, episode reward: 33.440, mean reward: 0.836 [0.155, 1.000], mean action: 19.075 [12.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.237203, mean_absolute_error: 5.395416, mean_q: 6.078513
755 (array([22]),) False
  94800/500000: episode: 2370, duration: 31.034s, episode steps: 40, steps per second: 1, episode reward: 33.933, mean reward: 0.848 [0.086, 1.000], mean action: 23.400 [5.000, 44.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.246119, mean_absolute_error: 5.418124, mean_q: 6.096559
108 (array([48]),) False
  94840/500000: episode: 2371, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 28.471, mean reward: 0.712 [0.044, 0.934], mean action: 22.825 [2.000, 47.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.236469, mean_absolute_error: 5.431342, mean_q: 6.108102
91 (array([48]),) False
  94880/500000: episode: 2372, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 33.545, mean reward: 0.839 [0.000, 1.000], mean action: 29.550 [1.000, 55.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.247047, mean_absolute_error: 5.409925, mean_q: 6.083887
661 (array([48]),) False
  94920/500000: episode: 2373, duration: 30.107s, episode steps: 40, steps per second: 1, episode reward: 32.471, mean reward: 0.812 [0.188, 1.000], mean action: 40.500 [6.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.234989, mean_absolute_error: 5.428436, mean_q: 6.101008
666 (array([22]),) False
  94960/500000: episode: 2374, duration: 31.015s, episode steps: 40, steps per second: 1, episode reward: 33.513, mean reward: 0.838 [0.001, 1.000], mean action: 26.350 [4.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.236337, mean_absolute_error: 5.444914, mean_q: 6.118815
451 (array([38]),) False
  95000/500000: episode: 2375, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 31.741, mean reward: 0.794 [0.252, 1.000], mean action: 22.275 [1.000, 42.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.238072, mean_absolute_error: 5.488257, mean_q: 6.159526
647 (array([22]),) False
  95040/500000: episode: 2376, duration: 31.006s, episode steps: 40, steps per second: 1, episode reward: 35.659, mean reward: 0.891 [0.143, 1.000], mean action: 21.150 [1.000, 53.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.237443, mean_absolute_error: 5.443513, mean_q: 6.113588
172 (array([12]),) False
  95080/500000: episode: 2377, duration: 30.167s, episode steps: 40, steps per second: 1, episode reward: 32.507, mean reward: 0.813 [0.124, 1.000], mean action: 15.000 [2.000, 31.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.232161, mean_absolute_error: 5.478377, mean_q: 6.163736
721 (array([22]),) False
  95120/500000: episode: 2378, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 29.777, mean reward: 0.744 [0.003, 0.964], mean action: 20.200 [1.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.223407, mean_absolute_error: 5.425672, mean_q: 6.113976
544 (array([22]),) False
  95160/500000: episode: 2379, duration: 30.996s, episode steps: 40, steps per second: 1, episode reward: 32.842, mean reward: 0.821 [0.135, 1.000], mean action: 21.875 [1.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.220341, mean_absolute_error: 5.491098, mean_q: 6.181142
821 (array([22]),) False
  95200/500000: episode: 2380, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 34.777, mean reward: 0.869 [0.113, 1.000], mean action: 19.075 [5.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.229166, mean_absolute_error: 5.436650, mean_q: 6.122564
287 (array([48]),) False
  95240/500000: episode: 2381, duration: 30.134s, episode steps: 40, steps per second: 1, episode reward: 33.633, mean reward: 0.841 [0.310, 1.000], mean action: 24.375 [22.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.228105, mean_absolute_error: 5.420067, mean_q: 6.111093
760 (array([22]),) False
  95280/500000: episode: 2382, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 30.819, mean reward: 0.770 [0.061, 1.000], mean action: 25.425 [5.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.231830, mean_absolute_error: 5.405536, mean_q: 6.092175
712 (array([22]),) False
  95320/500000: episode: 2383, duration: 30.994s, episode steps: 40, steps per second: 1, episode reward: 32.603, mean reward: 0.815 [0.098, 1.000], mean action: 15.425 [8.000, 37.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.245569, mean_absolute_error: 5.331351, mean_q: 6.010430
703 (array([3]),) False
  95360/500000: episode: 2384, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 24.477, mean reward: 0.612 [0.040, 1.000], mean action: 9.750 [3.000, 53.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.221036, mean_absolute_error: 5.451215, mean_q: 6.132532
239 (array([22]),) False
  95400/500000: episode: 2385, duration: 30.149s, episode steps: 40, steps per second: 1, episode reward: 33.964, mean reward: 0.849 [0.233, 1.000], mean action: 25.525 [16.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.215288, mean_absolute_error: 5.406312, mean_q: 6.091020
680 (array([22]),) False
  95440/500000: episode: 2386, duration: 31.102s, episode steps: 40, steps per second: 1, episode reward: 31.261, mean reward: 0.782 [0.000, 0.913], mean action: 15.925 [0.000, 53.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.263578, mean_absolute_error: 5.380311, mean_q: 6.060652
71 (array([58]),) False
  95480/500000: episode: 2387, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 12.310, mean reward: 0.308 [0.037, 1.000], mean action: 25.950 [7.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.246750, mean_absolute_error: 5.353111, mean_q: 6.028361
479 (array([22]),) False
  95520/500000: episode: 2388, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 30.551, mean reward: 0.764 [0.000, 1.000], mean action: 24.300 [6.000, 52.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.234929, mean_absolute_error: 5.408982, mean_q: 6.088937
805 (array([22]),) False
  95560/500000: episode: 2389, duration: 30.118s, episode steps: 40, steps per second: 1, episode reward: 37.074, mean reward: 0.927 [0.266, 1.000], mean action: 18.450 [12.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.236404, mean_absolute_error: 5.416200, mean_q: 6.096117
389 (array([48]),) False
  95600/500000: episode: 2390, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 34.932, mean reward: 0.873 [0.030, 0.978], mean action: 21.575 [3.000, 55.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.243073, mean_absolute_error: 5.399667, mean_q: 6.083545
591 (array([22]),) False
  95640/500000: episode: 2391, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 28.550, mean reward: 0.714 [0.000, 1.000], mean action: 14.625 [5.000, 47.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.230364, mean_absolute_error: 5.365431, mean_q: 6.045249
337 (array([22]),) False
  95680/500000: episode: 2392, duration: 31.050s, episode steps: 40, steps per second: 1, episode reward: 35.935, mean reward: 0.898 [0.371, 1.000], mean action: 20.125 [0.000, 55.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.249200, mean_absolute_error: 5.408853, mean_q: 6.088232
186 (array([22]),) False
  95720/500000: episode: 2393, duration: 30.175s, episode steps: 40, steps per second: 1, episode reward: 30.710, mean reward: 0.768 [0.218, 1.000], mean action: 15.500 [4.000, 58.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.237031, mean_absolute_error: 5.438272, mean_q: 6.116168
109 (array([48]),) False
  95760/500000: episode: 2394, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 30.390, mean reward: 0.760 [0.063, 1.000], mean action: 22.275 [12.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.227183, mean_absolute_error: 5.381223, mean_q: 6.051561
304 (array([22]),) False
  95800/500000: episode: 2395, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 32.068, mean reward: 0.802 [0.095, 1.000], mean action: 22.875 [1.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.235872, mean_absolute_error: 5.377203, mean_q: 6.055755
818 (array([48]),) False
  95840/500000: episode: 2396, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 27.326, mean reward: 0.683 [0.000, 0.818], mean action: 17.575 [1.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.219661, mean_absolute_error: 5.407042, mean_q: 6.092307
654 (array([22]),) False
  95880/500000: episode: 2397, duration: 30.125s, episode steps: 40, steps per second: 1, episode reward: 31.389, mean reward: 0.785 [0.044, 1.000], mean action: 37.150 [6.000, 57.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.248069, mean_absolute_error: 5.386810, mean_q: 6.069470
413 (array([22]),) False
  95920/500000: episode: 2398, duration: 31.044s, episode steps: 40, steps per second: 1, episode reward: 36.236, mean reward: 0.906 [0.326, 1.000], mean action: 22.875 [1.000, 45.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.272286, mean_absolute_error: 5.421378, mean_q: 6.100458
138 (array([3]),) False
  95960/500000: episode: 2399, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 14.029, mean reward: 0.351 [0.164, 0.880], mean action: 21.475 [5.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.259200, mean_absolute_error: 5.356977, mean_q: 6.035765
320 (array([22]),) False
  96000/500000: episode: 2400, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 33.331, mean reward: 0.833 [0.207, 1.000], mean action: 26.625 [1.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.235240, mean_absolute_error: 5.350031, mean_q: 6.023221
562 (array([22]),) False
  96040/500000: episode: 2401, duration: 30.100s, episode steps: 40, steps per second: 1, episode reward: 32.413, mean reward: 0.810 [0.117, 1.000], mean action: 22.450 [11.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.235745, mean_absolute_error: 5.387211, mean_q: 6.062076
798 (array([18]),) False
  96080/500000: episode: 2402, duration: 30.936s, episode steps: 40, steps per second: 1, episode reward: 30.929, mean reward: 0.773 [0.249, 0.992], mean action: 20.700 [8.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.220568, mean_absolute_error: 5.375168, mean_q: 6.049542
643 (array([44]),) False
  96120/500000: episode: 2403, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 32.993, mean reward: 0.825 [0.244, 1.000], mean action: 25.300 [5.000, 55.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.228373, mean_absolute_error: 5.359293, mean_q: 6.039724
523 (array([22]),) False
  96160/500000: episode: 2404, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 34.842, mean reward: 0.871 [0.243, 1.000], mean action: 18.775 [7.000, 46.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.255702, mean_absolute_error: 5.336711, mean_q: 6.025618
176 (array([3]),) False
  96200/500000: episode: 2405, duration: 30.145s, episode steps: 40, steps per second: 1, episode reward: 13.869, mean reward: 0.347 [0.023, 0.802], mean action: 29.025 [10.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.239578, mean_absolute_error: 5.396305, mean_q: 6.083911
178 (array([38]),) False
  96240/500000: episode: 2406, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 28.763, mean reward: 0.719 [0.251, 1.000], mean action: 15.800 [0.000, 46.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.240135, mean_absolute_error: 5.375020, mean_q: 6.055190
491 (array([22]),) False
  96280/500000: episode: 2407, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 35.846, mean reward: 0.896 [0.161, 1.000], mean action: 23.225 [12.000, 59.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.247869, mean_absolute_error: 5.414695, mean_q: 6.094683
32 (array([48]),) False
  96320/500000: episode: 2408, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 34.597, mean reward: 0.865 [0.056, 1.000], mean action: 27.250 [2.000, 47.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.267729, mean_absolute_error: 5.379414, mean_q: 6.061119
757 (array([48]),) False
  96360/500000: episode: 2409, duration: 30.162s, episode steps: 40, steps per second: 1, episode reward: 34.317, mean reward: 0.858 [0.000, 0.989], mean action: 24.550 [5.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.240511, mean_absolute_error: 5.383392, mean_q: 6.064963
45 (array([22]),) False
  96400/500000: episode: 2410, duration: 31.035s, episode steps: 40, steps per second: 1, episode reward: 32.872, mean reward: 0.822 [0.052, 1.000], mean action: 25.800 [14.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.244028, mean_absolute_error: 5.406082, mean_q: 6.092554
205 (array([22]),) False
  96440/500000: episode: 2411, duration: 31.035s, episode steps: 40, steps per second: 1, episode reward: 30.797, mean reward: 0.770 [0.314, 1.000], mean action: 14.825 [12.000, 56.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.236293, mean_absolute_error: 5.412704, mean_q: 6.101893
48 (array([12]),) False
  96480/500000: episode: 2412, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 36.037, mean reward: 0.901 [0.159, 0.952], mean action: 23.450 [8.000, 48.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.247984, mean_absolute_error: 5.388258, mean_q: 6.076999
716 (array([48]),) False
  96520/500000: episode: 2413, duration: 30.188s, episode steps: 40, steps per second: 1, episode reward: 30.776, mean reward: 0.769 [0.000, 0.993], mean action: 17.025 [1.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.256910, mean_absolute_error: 5.434577, mean_q: 6.125156
149 (array([8]),) False
  96560/500000: episode: 2414, duration: 31.030s, episode steps: 40, steps per second: 1, episode reward: 25.055, mean reward: 0.626 [0.000, 0.993], mean action: 42.400 [11.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.248303, mean_absolute_error: 5.402996, mean_q: 6.098861
418 (array([22]),) False
  96600/500000: episode: 2415, duration: 30.909s, episode steps: 40, steps per second: 1, episode reward: 28.197, mean reward: 0.705 [0.084, 1.000], mean action: 21.375 [5.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.234134, mean_absolute_error: 5.463908, mean_q: 6.164230
300 (array([22]),) False
  96640/500000: episode: 2416, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 32.023, mean reward: 0.801 [0.011, 1.000], mean action: 27.625 [4.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.233233, mean_absolute_error: 5.420391, mean_q: 6.111786
595 (array([22]),) False
  96680/500000: episode: 2417, duration: 30.130s, episode steps: 40, steps per second: 1, episode reward: 35.253, mean reward: 0.881 [0.248, 1.000], mean action: 24.500 [2.000, 57.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.232245, mean_absolute_error: 5.446664, mean_q: 6.136212
276 (array([56]),) False
  96720/500000: episode: 2418, duration: 31.068s, episode steps: 40, steps per second: 1, episode reward: 26.757, mean reward: 0.669 [0.206, 0.915], mean action: 27.750 [12.000, 57.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.251169, mean_absolute_error: 5.377232, mean_q: 6.063674
5 (array([37]),) False
  96760/500000: episode: 2419, duration: 30.959s, episode steps: 40, steps per second: 1, episode reward: 34.280, mean reward: 0.857 [0.035, 1.000], mean action: 34.400 [6.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.225323, mean_absolute_error: 5.437985, mean_q: 6.124203
495 (array([48]),) False
  96800/500000: episode: 2420, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 36.528, mean reward: 0.913 [0.226, 0.966], mean action: 22.575 [4.000, 56.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.239021, mean_absolute_error: 5.457196, mean_q: 6.143877
372 (array([22]),) False
  96840/500000: episode: 2421, duration: 30.149s, episode steps: 40, steps per second: 1, episode reward: 32.384, mean reward: 0.810 [0.127, 1.000], mean action: 25.375 [12.000, 54.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.240872, mean_absolute_error: 5.392875, mean_q: 6.078292
599 (array([48]),) False
  96880/500000: episode: 2422, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 26.315, mean reward: 0.658 [0.035, 1.000], mean action: 24.475 [0.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.239140, mean_absolute_error: 5.455832, mean_q: 6.143853
359 (array([22]),) False
  96920/500000: episode: 2423, duration: 31.011s, episode steps: 40, steps per second: 1, episode reward: 34.937, mean reward: 0.873 [0.189, 1.000], mean action: 23.425 [0.000, 56.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.247604, mean_absolute_error: 5.458899, mean_q: 6.149054
29 (array([22]),) False
  96960/500000: episode: 2424, duration: 30.970s, episode steps: 40, steps per second: 1, episode reward: 34.083, mean reward: 0.852 [0.115, 1.000], mean action: 24.900 [6.000, 60.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.221321, mean_absolute_error: 5.410071, mean_q: 6.097825
784 (array([22]),) False
  97000/500000: episode: 2425, duration: 30.122s, episode steps: 40, steps per second: 1, episode reward: 35.363, mean reward: 0.884 [0.166, 1.000], mean action: 22.700 [5.000, 49.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.261920, mean_absolute_error: 5.450477, mean_q: 6.133935
441 (array([22]),) False
  97040/500000: episode: 2426, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 33.649, mean reward: 0.841 [0.050, 1.000], mean action: 27.725 [18.000, 57.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.238324, mean_absolute_error: 5.463042, mean_q: 6.151341
316 (array([12]),) False
  97080/500000: episode: 2427, duration: 30.925s, episode steps: 40, steps per second: 1, episode reward: 33.100, mean reward: 0.827 [0.080, 1.000], mean action: 22.650 [1.000, 53.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.254485, mean_absolute_error: 5.512133, mean_q: 6.200213
301 (array([22]),) False
  97120/500000: episode: 2428, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 33.923, mean reward: 0.848 [0.055, 1.000], mean action: 28.075 [4.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.270991, mean_absolute_error: 5.414560, mean_q: 6.097397
326 (array([48]),) False
  97160/500000: episode: 2429, duration: 30.087s, episode steps: 40, steps per second: 1, episode reward: 32.276, mean reward: 0.807 [0.029, 1.000], mean action: 20.225 [3.000, 57.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.250857, mean_absolute_error: 5.400711, mean_q: 6.087941
1 (array([22]),) False
  97200/500000: episode: 2430, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 29.216, mean reward: 0.730 [0.030, 1.000], mean action: 27.300 [1.000, 60.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.232293, mean_absolute_error: 5.388070, mean_q: 6.072606
106 (array([22]),) False
  97240/500000: episode: 2431, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 27.218, mean reward: 0.680 [0.006, 1.000], mean action: 24.550 [3.000, 55.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.242575, mean_absolute_error: 5.484729, mean_q: 6.169805
580 (array([22]),) False
  97280/500000: episode: 2432, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 29.901, mean reward: 0.748 [0.077, 1.000], mean action: 21.350 [3.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.260812, mean_absolute_error: 5.432773, mean_q: 6.123798
219 (array([36]),) False
  97320/500000: episode: 2433, duration: 30.109s, episode steps: 40, steps per second: 1, episode reward: 15.687, mean reward: 0.392 [0.097, 0.980], mean action: 17.200 [3.000, 58.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.222590, mean_absolute_error: 5.439816, mean_q: 6.128402
299 (array([12]),) False
  97360/500000: episode: 2434, duration: 31.017s, episode steps: 40, steps per second: 1, episode reward: 29.690, mean reward: 0.742 [0.024, 1.000], mean action: 25.650 [2.000, 47.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.233362, mean_absolute_error: 5.387849, mean_q: 6.074674
253 (array([44]),) False
  97400/500000: episode: 2435, duration: 30.989s, episode steps: 40, steps per second: 1, episode reward: 17.955, mean reward: 0.449 [0.000, 0.974], mean action: 31.100 [6.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.239164, mean_absolute_error: 5.427454, mean_q: 6.112991
504 (array([48]),) False
  97440/500000: episode: 2436, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 21.648, mean reward: 0.541 [0.051, 0.656], mean action: 19.875 [0.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.259942, mean_absolute_error: 5.428199, mean_q: 6.113469
87 (array([3]),) False
  97480/500000: episode: 2437, duration: 30.154s, episode steps: 40, steps per second: 1, episode reward: 11.095, mean reward: 0.277 [0.185, 0.875], mean action: 23.625 [2.000, 54.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.239029, mean_absolute_error: 5.436368, mean_q: 6.123311
398 (array([22]),) False
  97520/500000: episode: 2438, duration: 31.048s, episode steps: 40, steps per second: 1, episode reward: 35.678, mean reward: 0.892 [0.349, 1.000], mean action: 22.375 [1.000, 44.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.228450, mean_absolute_error: 5.423448, mean_q: 6.106216
678 (array([22]),) False
  97560/500000: episode: 2439, duration: 31.083s, episode steps: 40, steps per second: 1, episode reward: 34.621, mean reward: 0.866 [0.144, 1.000], mean action: 23.075 [0.000, 58.000], mean observation: -0.107 [-1.000, 1.000], loss: 0.251973, mean_absolute_error: 5.503375, mean_q: 6.186893
66 (array([22]),) False
  97600/500000: episode: 2440, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 36.310, mean reward: 0.908 [0.053, 1.000], mean action: 23.800 [15.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.242383, mean_absolute_error: 5.417220, mean_q: 6.100655
413 (array([22]),) False
  97640/500000: episode: 2441, duration: 30.115s, episode steps: 40, steps per second: 1, episode reward: 35.193, mean reward: 0.880 [0.000, 1.000], mean action: 22.850 [5.000, 51.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.224242, mean_absolute_error: 5.458512, mean_q: 6.145618
582 (array([44]),) False
  97680/500000: episode: 2442, duration: 31.043s, episode steps: 40, steps per second: 1, episode reward: 33.091, mean reward: 0.827 [0.192, 1.000], mean action: 17.300 [8.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.255438, mean_absolute_error: 5.507697, mean_q: 6.192954
504 (array([48]),) False
  97720/500000: episode: 2443, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 21.666, mean reward: 0.542 [0.022, 0.656], mean action: 19.050 [6.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.262443, mean_absolute_error: 5.523940, mean_q: 6.201350
771 (array([12]),) False
  97760/500000: episode: 2444, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 36.134, mean reward: 0.903 [0.040, 1.000], mean action: 13.100 [0.000, 40.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.215417, mean_absolute_error: 5.476169, mean_q: 6.149624
818 (array([48]),) False
  97800/500000: episode: 2445, duration: 30.146s, episode steps: 40, steps per second: 1, episode reward: 29.527, mean reward: 0.738 [0.394, 1.000], mean action: 17.400 [12.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.240976, mean_absolute_error: 5.511604, mean_q: 6.191878
803 (array([58]),) False
  97840/500000: episode: 2446, duration: 31.079s, episode steps: 40, steps per second: 1, episode reward: 20.832, mean reward: 0.521 [0.074, 1.000], mean action: 24.375 [0.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.244898, mean_absolute_error: 5.500051, mean_q: 6.180975
782 (array([22]),) False
  97880/500000: episode: 2447, duration: 30.970s, episode steps: 40, steps per second: 1, episode reward: 36.238, mean reward: 0.906 [0.233, 1.000], mean action: 21.875 [3.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.259291, mean_absolute_error: 5.542736, mean_q: 6.229711
329 (array([12]),) False
  97920/500000: episode: 2448, duration: 30.825s, episode steps: 40, steps per second: 1, episode reward: 31.547, mean reward: 0.789 [0.224, 1.000], mean action: 19.350 [10.000, 52.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.238238, mean_absolute_error: 5.515911, mean_q: 6.201385
353 (array([22]),) False
  97960/500000: episode: 2449, duration: 30.168s, episode steps: 40, steps per second: 1, episode reward: 33.285, mean reward: 0.832 [0.146, 1.000], mean action: 25.025 [3.000, 53.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.240012, mean_absolute_error: 5.550829, mean_q: 6.234376
807 (array([22]),) False
  98000/500000: episode: 2450, duration: 31.024s, episode steps: 40, steps per second: 1, episode reward: 34.196, mean reward: 0.855 [0.104, 1.000], mean action: 33.475 [10.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.268095, mean_absolute_error: 5.588585, mean_q: 6.279103
764 (array([48]),) False
  98040/500000: episode: 2451, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 32.803, mean reward: 0.820 [0.048, 1.000], mean action: 29.450 [12.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.235153, mean_absolute_error: 5.472150, mean_q: 6.156162
353 (array([22]),) False
  98080/500000: episode: 2452, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 31.418, mean reward: 0.785 [0.000, 1.000], mean action: 24.000 [1.000, 56.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.257957, mean_absolute_error: 5.567956, mean_q: 6.262248
95 (array([22]),) False
  98120/500000: episode: 2453, duration: 30.070s, episode steps: 40, steps per second: 1, episode reward: 29.376, mean reward: 0.734 [0.416, 1.000], mean action: 27.950 [12.000, 52.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.238719, mean_absolute_error: 5.498797, mean_q: 6.185528
718 (array([12]),) False
  98160/500000: episode: 2454, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 35.969, mean reward: 0.899 [0.000, 1.000], mean action: 17.800 [11.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.279950, mean_absolute_error: 5.521919, mean_q: 6.208827
666 (array([22]),) False
  98200/500000: episode: 2455, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 28.967, mean reward: 0.724 [0.000, 1.000], mean action: 39.925 [8.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.284824, mean_absolute_error: 5.490283, mean_q: 6.175900
280 (array([48]),) False
  98240/500000: episode: 2456, duration: 30.979s, episode steps: 40, steps per second: 1, episode reward: 34.459, mean reward: 0.861 [0.119, 0.987], mean action: 22.775 [4.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.234796, mean_absolute_error: 5.510694, mean_q: 6.197785
494 (array([48]),) False
  98280/500000: episode: 2457, duration: 30.130s, episode steps: 40, steps per second: 1, episode reward: 29.594, mean reward: 0.740 [0.253, 0.785], mean action: 21.525 [4.000, 34.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.236511, mean_absolute_error: 5.489591, mean_q: 6.172255
856 (array([48]),) False
  98320/500000: episode: 2458, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 34.650, mean reward: 0.866 [0.067, 0.973], mean action: 15.325 [5.000, 42.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.244959, mean_absolute_error: 5.477132, mean_q: 6.161063
646 (array([44]),) False
  98360/500000: episode: 2459, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 8.034, mean reward: 0.201 [0.000, 0.716], mean action: 25.925 [2.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.253027, mean_absolute_error: 5.514158, mean_q: 6.213922
356 (array([22]),) False
  98400/500000: episode: 2460, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 33.437, mean reward: 0.836 [0.092, 1.000], mean action: 19.800 [7.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.238660, mean_absolute_error: 5.538947, mean_q: 6.233647
416 (array([22]),) False
  98440/500000: episode: 2461, duration: 30.132s, episode steps: 40, steps per second: 1, episode reward: 35.752, mean reward: 0.894 [0.319, 1.000], mean action: 37.675 [1.000, 50.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.267847, mean_absolute_error: 5.519669, mean_q: 6.212552
220 (array([22]),) False
  98480/500000: episode: 2462, duration: 31.040s, episode steps: 40, steps per second: 1, episode reward: 34.218, mean reward: 0.855 [0.000, 1.000], mean action: 20.075 [1.000, 57.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.243933, mean_absolute_error: 5.428129, mean_q: 6.112311
382 (array([22]),) False
  98520/500000: episode: 2463, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 39.051, mean reward: 0.976 [0.404, 1.000], mean action: 22.350 [19.000, 39.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.213045, mean_absolute_error: 5.445251, mean_q: 6.139768
326 (array([48]),) False
  98560/500000: episode: 2464, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 33.513, mean reward: 0.838 [0.310, 1.000], mean action: 19.050 [2.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.229949, mean_absolute_error: 5.515298, mean_q: 6.211414
796 (array([38]),) False
  98600/500000: episode: 2465, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 35.139, mean reward: 0.878 [0.278, 0.995], mean action: 19.525 [12.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.249687, mean_absolute_error: 5.496514, mean_q: 6.195537
403 (array([12]),) False
  98640/500000: episode: 2466, duration: 31.060s, episode steps: 40, steps per second: 1, episode reward: 33.990, mean reward: 0.850 [0.330, 1.000], mean action: 25.575 [7.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.248020, mean_absolute_error: 5.445261, mean_q: 6.139396
732 (array([12]),) False
  98680/500000: episode: 2467, duration: 31.041s, episode steps: 40, steps per second: 1, episode reward: 35.201, mean reward: 0.880 [0.321, 1.000], mean action: 18.225 [12.000, 49.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.247770, mean_absolute_error: 5.469463, mean_q: 6.164160
319 (array([33]),) False
  98720/500000: episode: 2468, duration: 30.857s, episode steps: 40, steps per second: 1, episode reward: 25.704, mean reward: 0.643 [0.111, 1.000], mean action: 23.225 [1.000, 47.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.269690, mean_absolute_error: 5.460509, mean_q: 6.149669
481 (array([22]),) False
  98760/500000: episode: 2469, duration: 30.159s, episode steps: 40, steps per second: 1, episode reward: 33.933, mean reward: 0.848 [0.000, 1.000], mean action: 22.675 [2.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.222802, mean_absolute_error: 5.464452, mean_q: 6.149413
410 (array([22]),) False
  98800/500000: episode: 2470, duration: 31.366s, episode steps: 40, steps per second: 1, episode reward: 34.225, mean reward: 0.856 [0.001, 1.000], mean action: 22.200 [8.000, 41.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.217244, mean_absolute_error: 5.497621, mean_q: 6.180715
263 (array([8]),) False
  98840/500000: episode: 2471, duration: 31.491s, episode steps: 40, steps per second: 1, episode reward: 20.720, mean reward: 0.518 [0.215, 0.878], mean action: 35.200 [9.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.238426, mean_absolute_error: 5.539958, mean_q: 6.233641
636 (array([12]),) False
  98880/500000: episode: 2472, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 34.978, mean reward: 0.874 [0.000, 1.000], mean action: 20.425 [12.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.235359, mean_absolute_error: 5.525889, mean_q: 6.208949
472 (array([22]),) False
  98920/500000: episode: 2473, duration: 30.603s, episode steps: 40, steps per second: 1, episode reward: 29.268, mean reward: 0.732 [0.086, 1.000], mean action: 26.800 [6.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.256462, mean_absolute_error: 5.428916, mean_q: 6.110448
272 (array([12]),) False
  98960/500000: episode: 2474, duration: 31.324s, episode steps: 40, steps per second: 1, episode reward: 34.560, mean reward: 0.864 [0.221, 1.000], mean action: 21.900 [4.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.236502, mean_absolute_error: 5.458859, mean_q: 6.143800
181 (array([22]),) False
  99000/500000: episode: 2475, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 23.989, mean reward: 0.600 [0.130, 1.000], mean action: 20.875 [12.000, 52.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.227305, mean_absolute_error: 5.525170, mean_q: 6.211832
191 (array([38]),) False
  99040/500000: episode: 2476, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 25.257, mean reward: 0.631 [0.202, 0.901], mean action: 14.100 [12.000, 51.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.253562, mean_absolute_error: 5.435408, mean_q: 6.118274
284 (array([12]),) False
  99080/500000: episode: 2477, duration: 30.122s, episode steps: 40, steps per second: 1, episode reward: 28.437, mean reward: 0.711 [0.104, 1.000], mean action: 23.650 [8.000, 59.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.236497, mean_absolute_error: 5.457787, mean_q: 6.142379
232 (array([22]),) False
  99120/500000: episode: 2478, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 35.087, mean reward: 0.877 [0.218, 1.000], mean action: 20.375 [12.000, 54.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.202093, mean_absolute_error: 5.484263, mean_q: 6.175184
275 (array([12]),) False
  99160/500000: episode: 2479, duration: 30.897s, episode steps: 40, steps per second: 1, episode reward: 23.325, mean reward: 0.583 [0.105, 1.000], mean action: 31.750 [7.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.247885, mean_absolute_error: 5.489081, mean_q: 6.188327
122 (array([12]),) False
  99200/500000: episode: 2480, duration: 30.815s, episode steps: 40, steps per second: 1, episode reward: 32.112, mean reward: 0.803 [0.087, 1.000], mean action: 21.250 [2.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.269276, mean_absolute_error: 5.457766, mean_q: 6.155961
147 (array([44]),) False
  99240/500000: episode: 2481, duration: 30.036s, episode steps: 40, steps per second: 1, episode reward: 25.406, mean reward: 0.635 [0.429, 0.747], mean action: 14.900 [12.000, 52.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.249827, mean_absolute_error: 5.454134, mean_q: 6.148814
490 (array([12]),) False
  99280/500000: episode: 2482, duration: 30.887s, episode steps: 40, steps per second: 1, episode reward: 34.655, mean reward: 0.866 [0.124, 1.000], mean action: 17.650 [4.000, 56.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.223211, mean_absolute_error: 5.528795, mean_q: 6.222497
443 (array([22]),) False
  99320/500000: episode: 2483, duration: 30.872s, episode steps: 40, steps per second: 1, episode reward: 33.249, mean reward: 0.831 [0.068, 1.000], mean action: 23.550 [5.000, 46.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.263438, mean_absolute_error: 5.448002, mean_q: 6.134879
521 (array([22]),) False
  99360/500000: episode: 2484, duration: 30.820s, episode steps: 40, steps per second: 1, episode reward: 33.133, mean reward: 0.828 [0.190, 1.000], mean action: 18.725 [2.000, 50.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.240232, mean_absolute_error: 5.514483, mean_q: 6.206868
22 (array([37]),) False
  99400/500000: episode: 2485, duration: 30.144s, episode steps: 40, steps per second: 1, episode reward: 29.208, mean reward: 0.730 [0.096, 0.823], mean action: 22.750 [3.000, 54.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.251897, mean_absolute_error: 5.525324, mean_q: 6.216359
569 (array([22]),) False
  99440/500000: episode: 2486, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 30.554, mean reward: 0.764 [0.149, 1.000], mean action: 18.950 [4.000, 39.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.276741, mean_absolute_error: 5.443513, mean_q: 6.130200
6 (array([58]),) False
  99480/500000: episode: 2487, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 26.752, mean reward: 0.669 [0.087, 1.000], mean action: 21.375 [2.000, 58.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.231678, mean_absolute_error: 5.451037, mean_q: 6.126529
731 (array([21]),) False
  99520/500000: episode: 2488, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 30.755, mean reward: 0.769 [0.069, 1.000], mean action: 19.125 [0.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.254278, mean_absolute_error: 5.465499, mean_q: 6.148767
466 (array([22]),) False
  99560/500000: episode: 2489, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 35.688, mean reward: 0.892 [0.000, 1.000], mean action: 23.800 [8.000, 44.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.250385, mean_absolute_error: 5.452865, mean_q: 6.138449
686 (array([48]),) False
  99600/500000: episode: 2490, duration: 31.000s, episode steps: 40, steps per second: 1, episode reward: 30.677, mean reward: 0.767 [0.006, 0.922], mean action: 23.250 [3.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.257098, mean_absolute_error: 5.488085, mean_q: 6.171298
533 (array([22]),) False
  99640/500000: episode: 2491, duration: 30.953s, episode steps: 40, steps per second: 1, episode reward: 32.214, mean reward: 0.805 [0.384, 1.000], mean action: 21.275 [0.000, 50.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.289222, mean_absolute_error: 5.440111, mean_q: 6.117479
284 (array([12]),) False
  99680/500000: episode: 2492, duration: 31.017s, episode steps: 40, steps per second: 1, episode reward: 30.242, mean reward: 0.756 [0.270, 1.000], mean action: 25.450 [7.000, 60.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.243311, mean_absolute_error: 5.443460, mean_q: 6.125669
580 (array([22]),) False
  99720/500000: episode: 2493, duration: 30.182s, episode steps: 40, steps per second: 1, episode reward: 30.991, mean reward: 0.775 [0.115, 1.000], mean action: 25.050 [4.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.237615, mean_absolute_error: 5.456665, mean_q: 6.144620
105 (array([22]),) False
  99760/500000: episode: 2494, duration: 31.009s, episode steps: 40, steps per second: 1, episode reward: 35.995, mean reward: 0.900 [0.388, 1.000], mean action: 21.675 [12.000, 52.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.251067, mean_absolute_error: 5.469443, mean_q: 6.156737
300 (array([22]),) False
  99800/500000: episode: 2495, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 33.643, mean reward: 0.841 [0.187, 1.000], mean action: 25.175 [1.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.240165, mean_absolute_error: 5.434120, mean_q: 6.113326
612 (array([22]),) False
  99840/500000: episode: 2496, duration: 30.996s, episode steps: 40, steps per second: 1, episode reward: 34.364, mean reward: 0.859 [0.314, 1.000], mean action: 16.350 [12.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.226328, mean_absolute_error: 5.425986, mean_q: 6.111128
198 (array([22]),) False
  99880/500000: episode: 2497, duration: 30.114s, episode steps: 40, steps per second: 1, episode reward: 35.523, mean reward: 0.888 [0.228, 1.000], mean action: 16.625 [6.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.257041, mean_absolute_error: 5.437665, mean_q: 6.124086
151 (array([22]),) False
  99920/500000: episode: 2498, duration: 31.037s, episode steps: 40, steps per second: 1, episode reward: 34.442, mean reward: 0.861 [0.170, 0.961], mean action: 14.350 [12.000, 47.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.260149, mean_absolute_error: 5.397800, mean_q: 6.085698
452 (array([22]),) False
  99960/500000: episode: 2499, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 35.261, mean reward: 0.882 [0.432, 1.000], mean action: 23.375 [1.000, 55.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.226650, mean_absolute_error: 5.424871, mean_q: 6.116251
342 (array([12]),) False
 100000/500000: episode: 2500, duration: 31.075s, episode steps: 40, steps per second: 1, episode reward: 35.804, mean reward: 0.895 [0.189, 1.000], mean action: 23.350 [7.000, 45.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.225458, mean_absolute_error: 5.378761, mean_q: 6.066921
570 (array([47]),) False
 100040/500000: episode: 2501, duration: 30.073s, episode steps: 40, steps per second: 1, episode reward: 31.359, mean reward: 0.784 [0.208, 1.000], mean action: 23.950 [12.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.261201, mean_absolute_error: 5.450204, mean_q: 6.142852
658 (array([48]),) False
 100080/500000: episode: 2502, duration: 30.991s, episode steps: 40, steps per second: 1, episode reward: 33.505, mean reward: 0.838 [0.000, 1.000], mean action: 43.150 [15.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.248784, mean_absolute_error: 5.436164, mean_q: 6.129400
632 (array([22]),) False
 100120/500000: episode: 2503, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 35.494, mean reward: 0.887 [0.111, 1.000], mean action: 23.275 [1.000, 52.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.252345, mean_absolute_error: 5.434365, mean_q: 6.124433
759 (array([48]),) False
 100160/500000: episode: 2504, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 33.040, mean reward: 0.826 [0.146, 1.000], mean action: 24.225 [9.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.236586, mean_absolute_error: 5.462052, mean_q: 6.151799
546 (array([22]),) False
 100200/500000: episode: 2505, duration: 30.119s, episode steps: 40, steps per second: 1, episode reward: 35.873, mean reward: 0.897 [0.261, 0.962], mean action: 21.500 [9.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.251377, mean_absolute_error: 5.453653, mean_q: 6.139297
669 (array([15]),) False
 100240/500000: episode: 2506, duration: 30.933s, episode steps: 40, steps per second: 1, episode reward: 32.371, mean reward: 0.809 [0.068, 1.000], mean action: 12.675 [3.000, 44.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.252949, mean_absolute_error: 5.428085, mean_q: 6.112183
860 (array([12]),) False
 100280/500000: episode: 2507, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 32.771, mean reward: 0.819 [0.089, 1.000], mean action: 18.050 [9.000, 50.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.235865, mean_absolute_error: 5.474164, mean_q: 6.161346
586 (array([12]),) False
 100320/500000: episode: 2508, duration: 30.927s, episode steps: 40, steps per second: 1, episode reward: 37.816, mean reward: 0.945 [0.016, 1.000], mean action: 13.350 [12.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.241470, mean_absolute_error: 5.439662, mean_q: 6.118909
211 (array([22]),) False
 100360/500000: episode: 2509, duration: 30.174s, episode steps: 40, steps per second: 1, episode reward: 30.819, mean reward: 0.770 [0.046, 0.826], mean action: 13.500 [3.000, 58.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.227183, mean_absolute_error: 5.427476, mean_q: 6.112734
224 (array([12]),) False
 100400/500000: episode: 2510, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 34.083, mean reward: 0.852 [0.052, 1.000], mean action: 19.675 [7.000, 57.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.237720, mean_absolute_error: 5.442296, mean_q: 6.124267
652 (array([22]),) False
 100440/500000: episode: 2511, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 34.392, mean reward: 0.860 [0.327, 1.000], mean action: 25.575 [0.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.247082, mean_absolute_error: 5.454617, mean_q: 6.142944
636 (array([12]),) False
 100480/500000: episode: 2512, duration: 31.046s, episode steps: 40, steps per second: 1, episode reward: 35.077, mean reward: 0.877 [0.294, 1.000], mean action: 22.175 [12.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.253731, mean_absolute_error: 5.424275, mean_q: 6.110039
456 (array([22]),) False
 100520/500000: episode: 2513, duration: 30.120s, episode steps: 40, steps per second: 1, episode reward: 35.370, mean reward: 0.884 [0.129, 1.000], mean action: 22.675 [1.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.253707, mean_absolute_error: 5.478533, mean_q: 6.164910
569 (array([22]),) False
 100560/500000: episode: 2514, duration: 31.024s, episode steps: 40, steps per second: 1, episode reward: 31.347, mean reward: 0.784 [0.073, 1.000], mean action: 16.725 [5.000, 49.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.248619, mean_absolute_error: 5.437973, mean_q: 6.125164
855 (array([12]),) False
 100600/500000: episode: 2515, duration: 31.005s, episode steps: 40, steps per second: 1, episode reward: 35.227, mean reward: 0.881 [0.000, 1.000], mean action: 14.925 [7.000, 47.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.223342, mean_absolute_error: 5.522564, mean_q: 6.211445
645 (array([48]),) False
 100640/500000: episode: 2516, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 36.436, mean reward: 0.911 [0.112, 1.000], mean action: 13.950 [1.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.255604, mean_absolute_error: 5.424799, mean_q: 6.106898
87 (array([3]),) False
 100680/500000: episode: 2517, duration: 30.124s, episode steps: 40, steps per second: 1, episode reward: 10.899, mean reward: 0.272 [0.185, 0.669], mean action: 24.075 [11.000, 50.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.247803, mean_absolute_error: 5.396230, mean_q: 6.080483
819 (array([48]),) False
 100720/500000: episode: 2518, duration: 31.036s, episode steps: 40, steps per second: 1, episode reward: 24.696, mean reward: 0.617 [0.146, 0.750], mean action: 14.175 [7.000, 38.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.235414, mean_absolute_error: 5.362722, mean_q: 6.041796
795 (array([3]),) False
 100760/500000: episode: 2519, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 21.245, mean reward: 0.531 [0.364, 0.903], mean action: 15.625 [12.000, 53.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.239131, mean_absolute_error: 5.450184, mean_q: 6.133527
479 (array([22]),) False
 100800/500000: episode: 2520, duration: 31.147s, episode steps: 40, steps per second: 1, episode reward: 32.496, mean reward: 0.812 [0.087, 1.000], mean action: 26.550 [3.000, 49.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.242536, mean_absolute_error: 5.503864, mean_q: 6.183434
235 (array([14]),) False
 100840/500000: episode: 2521, duration: 30.520s, episode steps: 40, steps per second: 1, episode reward: 35.117, mean reward: 0.878 [0.332, 1.000], mean action: 22.425 [4.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.228581, mean_absolute_error: 5.507965, mean_q: 6.190473
441 (array([22]),) False
 100880/500000: episode: 2522, duration: 31.113s, episode steps: 40, steps per second: 1, episode reward: 33.472, mean reward: 0.837 [0.132, 1.000], mean action: 24.500 [3.000, 56.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.247273, mean_absolute_error: 5.444643, mean_q: 6.113206
581 (array([22]),) False
 100920/500000: episode: 2523, duration: 31.041s, episode steps: 40, steps per second: 1, episode reward: 34.561, mean reward: 0.864 [0.000, 1.000], mean action: 23.200 [1.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.266369, mean_absolute_error: 5.386388, mean_q: 6.060538
631 (array([22]),) False
 100960/500000: episode: 2524, duration: 31.026s, episode steps: 40, steps per second: 1, episode reward: 35.805, mean reward: 0.895 [0.332, 1.000], mean action: 28.900 [12.000, 53.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.244397, mean_absolute_error: 5.397260, mean_q: 6.071212
283 (array([34]),) False
 101000/500000: episode: 2525, duration: 30.237s, episode steps: 40, steps per second: 1, episode reward: 22.332, mean reward: 0.558 [0.080, 1.000], mean action: 32.300 [12.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.221789, mean_absolute_error: 5.448143, mean_q: 6.131866
422 (array([48]),) False
 101040/500000: episode: 2526, duration: 30.823s, episode steps: 40, steps per second: 1, episode reward: 29.929, mean reward: 0.748 [0.059, 1.000], mean action: 27.000 [12.000, 49.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.276476, mean_absolute_error: 5.396655, mean_q: 6.078516
816 (array([4]),) False
 101080/500000: episode: 2527, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 9.869, mean reward: 0.247 [0.000, 0.955], mean action: 23.375 [1.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.254507, mean_absolute_error: 5.363687, mean_q: 6.040354
731 (array([21]),) False
 101120/500000: episode: 2528, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 30.280, mean reward: 0.757 [0.089, 1.000], mean action: 17.250 [3.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.239382, mean_absolute_error: 5.461668, mean_q: 6.142032
354 (array([12]),) False
 101160/500000: episode: 2529, duration: 30.358s, episode steps: 40, steps per second: 1, episode reward: 25.730, mean reward: 0.643 [0.222, 1.000], mean action: 22.725 [12.000, 45.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.232660, mean_absolute_error: 5.495165, mean_q: 6.176631
253 (array([44]),) False
 101200/500000: episode: 2530, duration: 31.111s, episode steps: 40, steps per second: 1, episode reward: 17.766, mean reward: 0.444 [0.000, 1.000], mean action: 29.700 [4.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.237929, mean_absolute_error: 5.445578, mean_q: 6.120137
540 (array([22]),) False
 101240/500000: episode: 2531, duration: 31.091s, episode steps: 40, steps per second: 1, episode reward: 30.528, mean reward: 0.763 [0.118, 1.000], mean action: 27.450 [1.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.243453, mean_absolute_error: 5.435391, mean_q: 6.114818
751 (array([22]),) False
 101280/500000: episode: 2532, duration: 31.162s, episode steps: 40, steps per second: 1, episode reward: 27.192, mean reward: 0.680 [0.018, 1.000], mean action: 21.850 [2.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.228117, mean_absolute_error: 5.400653, mean_q: 6.089520
473 (array([22]),) False
 101320/500000: episode: 2533, duration: 30.545s, episode steps: 40, steps per second: 1, episode reward: 32.402, mean reward: 0.810 [0.103, 1.000], mean action: 24.375 [5.000, 60.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.239628, mean_absolute_error: 5.477126, mean_q: 6.171806
307 (array([22]),) False
 101360/500000: episode: 2534, duration: 31.128s, episode steps: 40, steps per second: 1, episode reward: 35.103, mean reward: 0.878 [0.159, 1.000], mean action: 25.100 [4.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.232604, mean_absolute_error: 5.420048, mean_q: 6.101070
237 (array([22]),) False
 101400/500000: episode: 2535, duration: 31.137s, episode steps: 40, steps per second: 1, episode reward: 36.344, mean reward: 0.909 [0.162, 1.000], mean action: 22.775 [3.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.255256, mean_absolute_error: 5.378751, mean_q: 6.058128
389 (array([48]),) False
 101440/500000: episode: 2536, duration: 31.121s, episode steps: 40, steps per second: 1, episode reward: 34.528, mean reward: 0.863 [0.032, 0.978], mean action: 22.525 [0.000, 59.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.238613, mean_absolute_error: 5.439481, mean_q: 6.123200
101 (array([22]),) False
 101480/500000: episode: 2537, duration: 30.842s, episode steps: 40, steps per second: 1, episode reward: 35.526, mean reward: 0.888 [0.344, 1.000], mean action: 23.700 [0.000, 54.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.244181, mean_absolute_error: 5.467398, mean_q: 6.157400
99 (array([22]),) False
 101520/500000: episode: 2538, duration: 31.305s, episode steps: 40, steps per second: 1, episode reward: 35.532, mean reward: 0.888 [0.159, 1.000], mean action: 22.250 [6.000, 59.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.240043, mean_absolute_error: 5.389721, mean_q: 6.070307
548 (array([22]),) False
 101560/500000: episode: 2539, duration: 31.317s, episode steps: 40, steps per second: 1, episode reward: 30.143, mean reward: 0.754 [0.266, 1.000], mean action: 22.775 [0.000, 55.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.263273, mean_absolute_error: 5.461968, mean_q: 6.145531
153 (array([44]),) False
 101600/500000: episode: 2540, duration: 31.376s, episode steps: 40, steps per second: 1, episode reward: 23.209, mean reward: 0.580 [0.361, 0.929], mean action: 11.900 [0.000, 27.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.259262, mean_absolute_error: 5.440246, mean_q: 6.128153
272 (array([12]),) False
 101640/500000: episode: 2541, duration: 30.895s, episode steps: 40, steps per second: 1, episode reward: 35.356, mean reward: 0.884 [0.002, 1.000], mean action: 22.200 [8.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.249094, mean_absolute_error: 5.449231, mean_q: 6.129996
445 (array([22]),) False
 101680/500000: episode: 2542, duration: 31.578s, episode steps: 40, steps per second: 1, episode reward: 36.422, mean reward: 0.911 [0.126, 1.000], mean action: 23.250 [4.000, 54.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.250719, mean_absolute_error: 5.443389, mean_q: 6.116221
768 (array([22]),) False
 101720/500000: episode: 2543, duration: 31.316s, episode steps: 40, steps per second: 1, episode reward: 31.084, mean reward: 0.777 [0.000, 1.000], mean action: 20.825 [2.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.259201, mean_absolute_error: 5.446052, mean_q: 6.122603
699 (array([22]),) False
 101760/500000: episode: 2544, duration: 31.565s, episode steps: 40, steps per second: 1, episode reward: 32.905, mean reward: 0.823 [0.057, 1.000], mean action: 22.300 [7.000, 49.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.247835, mean_absolute_error: 5.451615, mean_q: 6.132785
366 (array([22]),) False
 101800/500000: episode: 2545, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 37.658, mean reward: 0.941 [0.228, 1.000], mean action: 24.275 [14.000, 53.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.241908, mean_absolute_error: 5.400878, mean_q: 6.082751
558 (array([40]),) False
 101840/500000: episode: 2546, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 28.616, mean reward: 0.715 [0.307, 1.000], mean action: 18.050 [12.000, 52.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.260671, mean_absolute_error: 5.427278, mean_q: 6.110917
234 (array([22]),) False
 101880/500000: episode: 2547, duration: 31.191s, episode steps: 40, steps per second: 1, episode reward: 33.006, mean reward: 0.825 [0.194, 1.000], mean action: 18.375 [12.000, 53.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.259800, mean_absolute_error: 5.487012, mean_q: 6.166154
114 (array([22]),) False
 101920/500000: episode: 2548, duration: 30.942s, episode steps: 40, steps per second: 1, episode reward: 35.938, mean reward: 0.898 [0.257, 1.000], mean action: 21.150 [12.000, 59.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.254862, mean_absolute_error: 5.430188, mean_q: 6.108758
69 (array([12]),) False
 101960/500000: episode: 2549, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 35.966, mean reward: 0.899 [0.076, 1.000], mean action: 15.550 [6.000, 60.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.240419, mean_absolute_error: 5.467111, mean_q: 6.148277
34 (array([22]),) False
 102000/500000: episode: 2550, duration: 31.081s, episode steps: 40, steps per second: 1, episode reward: 35.674, mean reward: 0.892 [0.051, 1.000], mean action: 25.150 [2.000, 58.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.254840, mean_absolute_error: 5.417196, mean_q: 6.105200
414 (array([48]),) False
 102040/500000: episode: 2551, duration: 31.493s, episode steps: 40, steps per second: 1, episode reward: 31.329, mean reward: 0.783 [0.224, 1.000], mean action: 28.525 [0.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.268995, mean_absolute_error: 5.397426, mean_q: 6.079695
829 (array([21]),) False
 102080/500000: episode: 2552, duration: 31.368s, episode steps: 40, steps per second: 1, episode reward: 33.709, mean reward: 0.843 [0.424, 0.884], mean action: 13.850 [6.000, 47.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.250110, mean_absolute_error: 5.414396, mean_q: 6.094621
371 (array([14]),) False
 102120/500000: episode: 2553, duration: 31.321s, episode steps: 40, steps per second: 1, episode reward: 32.614, mean reward: 0.815 [0.127, 1.000], mean action: 24.325 [4.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.258120, mean_absolute_error: 5.362531, mean_q: 6.034398
728 (array([12]),) False
 102160/500000: episode: 2554, duration: 31.439s, episode steps: 40, steps per second: 1, episode reward: 31.550, mean reward: 0.789 [0.000, 1.000], mean action: 18.725 [1.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.256877, mean_absolute_error: 5.404852, mean_q: 6.085851
616 (array([22]),) False
 102200/500000: episode: 2555, duration: 31.436s, episode steps: 40, steps per second: 1, episode reward: 29.870, mean reward: 0.747 [0.170, 0.858], mean action: 18.850 [12.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.235497, mean_absolute_error: 5.408136, mean_q: 6.084081
122 (array([12]),) False
 102240/500000: episode: 2556, duration: 31.372s, episode steps: 40, steps per second: 1, episode reward: 29.491, mean reward: 0.737 [0.252, 0.957], mean action: 26.450 [5.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.228093, mean_absolute_error: 5.397632, mean_q: 6.085004
505 (array([22]),) False
 102280/500000: episode: 2557, duration: 30.872s, episode steps: 40, steps per second: 1, episode reward: 33.524, mean reward: 0.838 [0.000, 1.000], mean action: 24.025 [6.000, 59.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.257988, mean_absolute_error: 5.384094, mean_q: 6.074102
553 (array([22]),) False
 102320/500000: episode: 2558, duration: 32.347s, episode steps: 40, steps per second: 1, episode reward: 33.075, mean reward: 0.827 [0.218, 1.000], mean action: 16.125 [1.000, 52.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.223507, mean_absolute_error: 5.425096, mean_q: 6.118802
283 (array([34]),) False
 102360/500000: episode: 2559, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 23.732, mean reward: 0.593 [0.106, 1.000], mean action: 29.825 [8.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.247130, mean_absolute_error: 5.413505, mean_q: 6.100403
435 (array([22]),) False
 102400/500000: episode: 2560, duration: 33.004s, episode steps: 40, steps per second: 1, episode reward: 35.478, mean reward: 0.887 [0.025, 1.000], mean action: 26.175 [2.000, 49.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.250032, mean_absolute_error: 5.408339, mean_q: 6.086655
713 (array([37]),) False
 102440/500000: episode: 2561, duration: 32.198s, episode steps: 40, steps per second: 1, episode reward: 35.367, mean reward: 0.884 [0.213, 0.967], mean action: 20.375 [10.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.271865, mean_absolute_error: 5.410022, mean_q: 6.092608
414 (array([48]),) False
 102480/500000: episode: 2562, duration: 31.586s, episode steps: 40, steps per second: 1, episode reward: 31.902, mean reward: 0.798 [0.224, 1.000], mean action: 23.925 [5.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.230880, mean_absolute_error: 5.406393, mean_q: 6.098200
222 (array([22]),) False
 102520/500000: episode: 2563, duration: 31.412s, episode steps: 40, steps per second: 1, episode reward: 35.386, mean reward: 0.885 [0.047, 1.000], mean action: 17.675 [12.000, 58.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.245133, mean_absolute_error: 5.456345, mean_q: 6.146750
110 (array([22]),) False
 102560/500000: episode: 2564, duration: 31.403s, episode steps: 40, steps per second: 1, episode reward: 34.533, mean reward: 0.863 [0.322, 1.000], mean action: 22.750 [12.000, 52.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.257000, mean_absolute_error: 5.385776, mean_q: 6.069325
136 (array([12]),) False
 102600/500000: episode: 2565, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 30.783, mean reward: 0.770 [0.059, 1.000], mean action: 24.575 [12.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.262412, mean_absolute_error: 5.383264, mean_q: 6.059964
405 (array([22]),) False
 102640/500000: episode: 2566, duration: 31.400s, episode steps: 40, steps per second: 1, episode reward: 36.263, mean reward: 0.907 [0.163, 1.000], mean action: 25.050 [22.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.249693, mean_absolute_error: 5.401189, mean_q: 6.076751
282 (array([22]),) False
 102680/500000: episode: 2567, duration: 31.372s, episode steps: 40, steps per second: 1, episode reward: 35.081, mean reward: 0.877 [0.085, 1.000], mean action: 25.000 [2.000, 54.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.238118, mean_absolute_error: 5.439754, mean_q: 6.117415
385 (array([30]),) False
 102720/500000: episode: 2568, duration: 31.445s, episode steps: 40, steps per second: 1, episode reward: 34.412, mean reward: 0.860 [0.043, 1.000], mean action: 23.925 [6.000, 51.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.228463, mean_absolute_error: 5.384961, mean_q: 6.058937
356 (array([22]),) False
 102760/500000: episode: 2569, duration: 30.884s, episode steps: 40, steps per second: 1, episode reward: 37.464, mean reward: 0.937 [0.307, 1.000], mean action: 22.225 [0.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.236736, mean_absolute_error: 5.357653, mean_q: 6.035383
612 (array([22]),) False
 102800/500000: episode: 2570, duration: 31.429s, episode steps: 40, steps per second: 1, episode reward: 33.387, mean reward: 0.835 [0.066, 1.000], mean action: 17.225 [12.000, 36.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.233395, mean_absolute_error: 5.415350, mean_q: 6.098308
28 (array([58]),) False
 102840/500000: episode: 2571, duration: 31.392s, episode steps: 40, steps per second: 1, episode reward: 21.167, mean reward: 0.529 [0.000, 1.000], mean action: 24.550 [1.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.244561, mean_absolute_error: 5.314915, mean_q: 5.995481
466 (array([22]),) False
 102880/500000: episode: 2572, duration: 31.324s, episode steps: 40, steps per second: 1, episode reward: 33.523, mean reward: 0.838 [0.147, 1.000], mean action: 23.325 [2.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.245814, mean_absolute_error: 5.398975, mean_q: 6.081040
209 (array([8]),) False
 102920/500000: episode: 2573, duration: 31.682s, episode steps: 40, steps per second: 1, episode reward: 31.636, mean reward: 0.791 [0.166, 1.000], mean action: 29.325 [4.000, 53.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.237400, mean_absolute_error: 5.390993, mean_q: 6.067623
391 (array([22]),) False
 102960/500000: episode: 2574, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 36.262, mean reward: 0.907 [0.062, 1.000], mean action: 24.350 [11.000, 49.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.247014, mean_absolute_error: 5.372690, mean_q: 6.044446
586 (array([12]),) False
 103000/500000: episode: 2575, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 34.871, mean reward: 0.872 [0.166, 1.000], mean action: 17.025 [4.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.236413, mean_absolute_error: 5.451343, mean_q: 6.129420
710 (array([12]),) False
 103040/500000: episode: 2576, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 30.349, mean reward: 0.759 [0.000, 1.000], mean action: 16.275 [2.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.293613, mean_absolute_error: 5.410690, mean_q: 6.086971
746 (array([37]),) False
 103080/500000: episode: 2577, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 32.896, mean reward: 0.822 [0.000, 0.968], mean action: 27.700 [12.000, 50.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.224834, mean_absolute_error: 5.496416, mean_q: 6.176034
117 (array([44]),) False
 103120/500000: episode: 2578, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 30.874, mean reward: 0.772 [0.493, 0.902], mean action: 23.275 [5.000, 52.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.236683, mean_absolute_error: 5.347181, mean_q: 6.021600
89 (array([58]),) False
 103160/500000: episode: 2579, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 13.542, mean reward: 0.339 [0.041, 1.000], mean action: 32.800 [1.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.255203, mean_absolute_error: 5.442251, mean_q: 6.127026
65 (array([48]),) False
 103200/500000: episode: 2580, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 35.285, mean reward: 0.882 [0.191, 1.000], mean action: 26.500 [1.000, 57.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.235376, mean_absolute_error: 5.410190, mean_q: 6.094946
190 (array([3]),) False
 103240/500000: episode: 2581, duration: 32.316s, episode steps: 40, steps per second: 1, episode reward: 18.683, mean reward: 0.467 [0.048, 0.817], mean action: 25.800 [4.000, 51.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.239265, mean_absolute_error: 5.462155, mean_q: 6.150156
679 (array([44]),) False
 103280/500000: episode: 2582, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 27.164, mean reward: 0.679 [0.000, 1.000], mean action: 17.150 [12.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.229367, mean_absolute_error: 5.395573, mean_q: 6.091474
285 (array([58]),) False
 103320/500000: episode: 2583, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 29.951, mean reward: 0.749 [0.014, 0.956], mean action: 46.875 [1.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.229669, mean_absolute_error: 5.388551, mean_q: 6.075306
703 (array([3]),) False
 103360/500000: episode: 2584, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 26.064, mean reward: 0.652 [0.036, 1.000], mean action: 9.600 [3.000, 44.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.273672, mean_absolute_error: 5.408586, mean_q: 6.096322
536 (array([22]),) False
 103400/500000: episode: 2585, duration: 32.291s, episode steps: 40, steps per second: 1, episode reward: 31.601, mean reward: 0.790 [0.081, 1.000], mean action: 20.550 [0.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.238272, mean_absolute_error: 5.398753, mean_q: 6.087064
826 (array([22]),) False
 103440/500000: episode: 2586, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 36.261, mean reward: 0.907 [0.298, 1.000], mean action: 22.350 [12.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.240916, mean_absolute_error: 5.448302, mean_q: 6.144849
669 (array([15]),) False
 103480/500000: episode: 2587, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 33.910, mean reward: 0.848 [0.000, 0.916], mean action: 14.100 [0.000, 41.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.236375, mean_absolute_error: 5.384620, mean_q: 6.079089
113 (array([22]),) False
 103520/500000: episode: 2588, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 34.029, mean reward: 0.851 [0.000, 1.000], mean action: 23.425 [6.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.242783, mean_absolute_error: 5.420853, mean_q: 6.112425
52 (array([22]),) False
 103560/500000: episode: 2589, duration: 32.171s, episode steps: 40, steps per second: 1, episode reward: 35.628, mean reward: 0.891 [0.040, 1.000], mean action: 25.325 [9.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.277791, mean_absolute_error: 5.452004, mean_q: 6.145948
229 (array([48]),) False
 103600/500000: episode: 2590, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 31.993, mean reward: 0.800 [0.000, 1.000], mean action: 22.175 [10.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.236545, mean_absolute_error: 5.367355, mean_q: 6.050908
227 (array([22]),) False
 103640/500000: episode: 2591, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 27.884, mean reward: 0.697 [0.045, 1.000], mean action: 17.025 [3.000, 48.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.253709, mean_absolute_error: 5.375410, mean_q: 6.063741
117 (array([44]),) False
 103680/500000: episode: 2592, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 31.206, mean reward: 0.780 [0.453, 1.000], mean action: 20.675 [0.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.226006, mean_absolute_error: 5.379981, mean_q: 6.065609
695 (array([22]),) False
 103720/500000: episode: 2593, duration: 32.204s, episode steps: 40, steps per second: 1, episode reward: 37.101, mean reward: 0.928 [0.371, 1.000], mean action: 24.775 [12.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.231670, mean_absolute_error: 5.421439, mean_q: 6.110797
484 (array([22]),) False
 103760/500000: episode: 2594, duration: 33.204s, episode steps: 40, steps per second: 1, episode reward: 33.349, mean reward: 0.834 [0.146, 1.000], mean action: 31.750 [0.000, 55.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.266034, mean_absolute_error: 5.389025, mean_q: 6.075793
198 (array([22]),) False
 103800/500000: episode: 2595, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 35.910, mean reward: 0.898 [0.110, 1.000], mean action: 15.425 [3.000, 55.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.257619, mean_absolute_error: 5.386669, mean_q: 6.073149
42 (array([22]),) False
 103840/500000: episode: 2596, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 34.717, mean reward: 0.868 [0.223, 1.000], mean action: 23.675 [14.000, 53.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.277219, mean_absolute_error: 5.376139, mean_q: 6.066645
801 (array([58]),) False
 103880/500000: episode: 2597, duration: 32.309s, episode steps: 40, steps per second: 1, episode reward: 19.959, mean reward: 0.499 [0.000, 1.000], mean action: 28.075 [1.000, 59.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.252496, mean_absolute_error: 5.302378, mean_q: 5.984875
712 (array([22]),) False
 103920/500000: episode: 2598, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 32.856, mean reward: 0.821 [0.048, 1.000], mean action: 19.075 [2.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.259353, mean_absolute_error: 5.359990, mean_q: 6.049834
244 (array([14]),) False
 103960/500000: episode: 2599, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 32.464, mean reward: 0.812 [0.277, 1.000], mean action: 31.125 [14.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.250857, mean_absolute_error: 5.394761, mean_q: 6.087234
572 (array([58]),) False
 104000/500000: episode: 2600, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 20.010, mean reward: 0.500 [0.110, 0.958], mean action: 22.850 [5.000, 51.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.243434, mean_absolute_error: 5.334406, mean_q: 6.023431
837 (array([48]),) False
 104040/500000: episode: 2601, duration: 32.247s, episode steps: 40, steps per second: 1, episode reward: 34.239, mean reward: 0.856 [0.102, 0.975], mean action: 20.425 [4.000, 45.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.235587, mean_absolute_error: 5.341184, mean_q: 6.025527
277 (array([56]),) False
 104080/500000: episode: 2602, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 30.752, mean reward: 0.769 [0.382, 1.000], mean action: 21.925 [3.000, 42.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.267264, mean_absolute_error: 5.414893, mean_q: 6.108736
361 (array([22]),) False
 104120/500000: episode: 2603, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 32.762, mean reward: 0.819 [0.007, 1.000], mean action: 25.650 [1.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.257704, mean_absolute_error: 5.383640, mean_q: 6.072613
109 (array([48]),) False
 104160/500000: episode: 2604, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 32.956, mean reward: 0.824 [0.020, 1.000], mean action: 24.650 [12.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.237955, mean_absolute_error: 5.347183, mean_q: 6.040329
672 (array([44]),) False
 104200/500000: episode: 2605, duration: 32.270s, episode steps: 40, steps per second: 1, episode reward: 26.441, mean reward: 0.661 [0.245, 0.980], mean action: 34.200 [0.000, 53.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.233724, mean_absolute_error: 5.324958, mean_q: 6.013954
623 (array([37]),) False
 104240/500000: episode: 2606, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 32.664, mean reward: 0.817 [0.096, 1.000], mean action: 32.500 [9.000, 48.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.232231, mean_absolute_error: 5.316163, mean_q: 6.002515
812 (array([22]),) False
 104280/500000: episode: 2607, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 29.102, mean reward: 0.728 [0.000, 1.000], mean action: 21.200 [12.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.252268, mean_absolute_error: 5.362698, mean_q: 6.055216
820 (array([48]),) False
 104320/500000: episode: 2608, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 27.940, mean reward: 0.698 [0.000, 0.855], mean action: 22.175 [12.000, 54.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.245304, mean_absolute_error: 5.321182, mean_q: 6.002362
413 (array([22]),) False
 104360/500000: episode: 2609, duration: 32.240s, episode steps: 40, steps per second: 1, episode reward: 35.362, mean reward: 0.884 [0.238, 1.000], mean action: 24.525 [8.000, 55.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.259945, mean_absolute_error: 5.343432, mean_q: 6.030515
740 (array([58]),) False
 104400/500000: episode: 2610, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 11.234, mean reward: 0.281 [0.000, 0.727], mean action: 25.000 [6.000, 49.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.251980, mean_absolute_error: 5.349131, mean_q: 6.035077
520 (array([22]),) False
 104440/500000: episode: 2611, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 31.449, mean reward: 0.786 [0.181, 1.000], mean action: 25.375 [0.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.242933, mean_absolute_error: 5.394992, mean_q: 6.072452
513 (array([12]),) False
 104480/500000: episode: 2612, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 36.162, mean reward: 0.904 [0.164, 1.000], mean action: 14.150 [4.000, 33.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.243471, mean_absolute_error: 5.248820, mean_q: 5.928367
189 (array([12]),) False
 104520/500000: episode: 2613, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 35.794, mean reward: 0.895 [0.069, 1.000], mean action: 17.725 [4.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.222561, mean_absolute_error: 5.321468, mean_q: 6.004709
581 (array([22]),) False
 104560/500000: episode: 2614, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 36.251, mean reward: 0.906 [0.070, 1.000], mean action: 23.125 [6.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.239475, mean_absolute_error: 5.341797, mean_q: 6.016715
546 (array([22]),) False
 104600/500000: episode: 2615, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 34.259, mean reward: 0.856 [0.082, 0.957], mean action: 44.350 [9.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.234026, mean_absolute_error: 5.365440, mean_q: 6.038163
255 (array([12]),) False
 104640/500000: episode: 2616, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 28.496, mean reward: 0.712 [0.102, 1.000], mean action: 29.025 [6.000, 53.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.218237, mean_absolute_error: 5.330668, mean_q: 5.999588
828 (array([48]),) False
 104680/500000: episode: 2617, duration: 32.235s, episode steps: 40, steps per second: 1, episode reward: 34.456, mean reward: 0.861 [0.036, 0.974], mean action: 14.925 [1.000, 39.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.267810, mean_absolute_error: 5.332565, mean_q: 6.005493
51 (array([22]),) False
 104720/500000: episode: 2618, duration: 33.282s, episode steps: 40, steps per second: 1, episode reward: 32.969, mean reward: 0.824 [0.151, 1.000], mean action: 21.600 [4.000, 40.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.238931, mean_absolute_error: 5.359218, mean_q: 6.033422
672 (array([44]),) False
 104760/500000: episode: 2619, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 28.719, mean reward: 0.718 [0.394, 0.987], mean action: 25.725 [4.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.236892, mean_absolute_error: 5.297338, mean_q: 5.974783
739 (array([22]),) False
 104800/500000: episode: 2620, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 34.035, mean reward: 0.851 [0.000, 1.000], mean action: 15.750 [1.000, 49.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.243130, mean_absolute_error: 5.310513, mean_q: 5.981826
348 (array([22]),) False
 104840/500000: episode: 2621, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 36.806, mean reward: 0.920 [0.088, 1.000], mean action: 23.925 [13.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.229194, mean_absolute_error: 5.362113, mean_q: 6.035594
9 (array([14]),) False
 104880/500000: episode: 2622, duration: 33.164s, episode steps: 40, steps per second: 1, episode reward: 30.852, mean reward: 0.771 [0.088, 0.906], mean action: 25.025 [2.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.235671, mean_absolute_error: 5.347647, mean_q: 6.022835
576 (array([58]),) False
 104920/500000: episode: 2623, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 20.927, mean reward: 0.523 [0.293, 1.000], mean action: 40.225 [5.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.243419, mean_absolute_error: 5.389334, mean_q: 6.073404
764 (array([48]),) False
 104960/500000: episode: 2624, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 32.171, mean reward: 0.804 [0.198, 1.000], mean action: 31.950 [1.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.241442, mean_absolute_error: 5.380734, mean_q: 6.064947
589 (array([22]),) False
 105000/500000: episode: 2625, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 30.586, mean reward: 0.765 [0.286, 1.000], mean action: 13.850 [12.000, 40.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.250876, mean_absolute_error: 5.342896, mean_q: 6.021657
429 (array([22]),) False
 105040/500000: episode: 2626, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 35.454, mean reward: 0.886 [0.111, 1.000], mean action: 26.325 [8.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.236520, mean_absolute_error: 5.360244, mean_q: 6.044422
318 (array([48]),) False
 105080/500000: episode: 2627, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 36.976, mean reward: 0.924 [0.114, 1.000], mean action: 26.350 [14.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.239998, mean_absolute_error: 5.325341, mean_q: 6.007879
238 (array([22]),) False
 105120/500000: episode: 2628, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 36.262, mean reward: 0.907 [0.080, 1.000], mean action: 22.850 [7.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.247343, mean_absolute_error: 5.438208, mean_q: 6.120229
627 (array([48]),) False
 105160/500000: episode: 2629, duration: 32.318s, episode steps: 40, steps per second: 1, episode reward: 35.507, mean reward: 0.888 [0.219, 0.936], mean action: 17.000 [12.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.283227, mean_absolute_error: 5.316735, mean_q: 5.995624
15 (array([22]),) False
 105200/500000: episode: 2630, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 35.111, mean reward: 0.878 [0.072, 1.000], mean action: 24.075 [13.000, 58.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.226303, mean_absolute_error: 5.347722, mean_q: 6.028565
771 (array([12]),) False
 105240/500000: episode: 2631, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 35.398, mean reward: 0.885 [0.067, 1.000], mean action: 15.300 [1.000, 53.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.235902, mean_absolute_error: 5.311137, mean_q: 5.993767
461 (array([22]),) False
 105280/500000: episode: 2632, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 34.636, mean reward: 0.866 [0.071, 1.000], mean action: 23.100 [4.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.248936, mean_absolute_error: 5.373155, mean_q: 6.056295
204 (array([22]),) False
 105320/500000: episode: 2633, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 25.436, mean reward: 0.636 [0.012, 0.819], mean action: 18.650 [8.000, 54.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.271933, mean_absolute_error: 5.375966, mean_q: 6.064588
557 (array([22]),) False
 105360/500000: episode: 2634, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 32.315, mean reward: 0.808 [0.331, 1.000], mean action: 19.000 [12.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.235603, mean_absolute_error: 5.355064, mean_q: 6.043621
658 (array([48]),) False
 105400/500000: episode: 2635, duration: 33.189s, episode steps: 40, steps per second: 1, episode reward: 33.728, mean reward: 0.843 [0.099, 1.000], mean action: 41.950 [3.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.242479, mean_absolute_error: 5.346709, mean_q: 6.030910
730 (array([54]),) False
 105440/500000: episode: 2636, duration: 32.987s, episode steps: 40, steps per second: 1, episode reward: 9.196, mean reward: 0.230 [0.066, 0.926], mean action: 22.675 [6.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.231501, mean_absolute_error: 5.405398, mean_q: 6.096244
5 (array([37]),) False
 105480/500000: episode: 2637, duration: 32.229s, episode steps: 40, steps per second: 1, episode reward: 38.645, mean reward: 0.966 [0.487, 1.000], mean action: 38.125 [37.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.227421, mean_absolute_error: 5.313371, mean_q: 5.991877
390 (array([22]),) False
 105520/500000: episode: 2638, duration: 33.159s, episode steps: 40, steps per second: 1, episode reward: 32.564, mean reward: 0.814 [0.017, 1.000], mean action: 22.925 [1.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.273510, mean_absolute_error: 5.387555, mean_q: 6.072043
247 (array([14]),) False
 105560/500000: episode: 2639, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 36.137, mean reward: 0.903 [0.398, 1.000], mean action: 21.900 [14.000, 39.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.270033, mean_absolute_error: 5.355296, mean_q: 6.042945
513 (array([12]),) False
 105600/500000: episode: 2640, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 33.124, mean reward: 0.828 [0.000, 1.000], mean action: 16.525 [2.000, 55.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.237528, mean_absolute_error: 5.344300, mean_q: 6.034842
575 (array([44]),) False
 105640/500000: episode: 2641, duration: 32.250s, episode steps: 40, steps per second: 1, episode reward: 31.886, mean reward: 0.797 [0.000, 1.000], mean action: 22.925 [2.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.238312, mean_absolute_error: 5.367284, mean_q: 6.050692
293 (array([22]),) False
 105680/500000: episode: 2642, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 35.849, mean reward: 0.896 [0.117, 1.000], mean action: 25.225 [21.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.261878, mean_absolute_error: 5.343758, mean_q: 6.023191
152 (array([58]),) False
 105720/500000: episode: 2643, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 16.691, mean reward: 0.417 [0.009, 0.797], mean action: 21.900 [1.000, 52.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.234491, mean_absolute_error: 5.378764, mean_q: 6.060748
50 (array([22]),) False
 105760/500000: episode: 2644, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 31.516, mean reward: 0.788 [0.000, 1.000], mean action: 25.875 [3.000, 59.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.291846, mean_absolute_error: 5.383687, mean_q: 6.061865
794 (array([22]),) False
 105800/500000: episode: 2645, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 34.778, mean reward: 0.869 [0.074, 1.000], mean action: 21.075 [3.000, 49.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.257087, mean_absolute_error: 5.515948, mean_q: 6.191536
570 (array([47]),) False
 105840/500000: episode: 2646, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 32.020, mean reward: 0.800 [0.000, 1.000], mean action: 25.675 [9.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.245835, mean_absolute_error: 5.391863, mean_q: 6.065874
757 (array([48]),) False
 105880/500000: episode: 2647, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 33.296, mean reward: 0.832 [0.109, 1.000], mean action: 23.125 [1.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.257233, mean_absolute_error: 5.396386, mean_q: 6.071236
262 (array([22]),) False
 105920/500000: episode: 2648, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 25.695, mean reward: 0.642 [0.101, 1.000], mean action: 24.900 [4.000, 37.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.240992, mean_absolute_error: 5.414557, mean_q: 6.098786
384 (array([22]),) False
 105960/500000: episode: 2649, duration: 32.220s, episode steps: 40, steps per second: 1, episode reward: 34.504, mean reward: 0.863 [0.010, 1.000], mean action: 23.725 [6.000, 57.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.233940, mean_absolute_error: 5.442598, mean_q: 6.142556
41 (array([12]),) False
 106000/500000: episode: 2650, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 31.869, mean reward: 0.797 [0.000, 1.000], mean action: 22.675 [14.000, 55.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.285784, mean_absolute_error: 5.436291, mean_q: 6.120771
44 (array([22]),) False
 106040/500000: episode: 2651, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 33.569, mean reward: 0.839 [0.141, 1.000], mean action: 24.225 [2.000, 57.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.256185, mean_absolute_error: 5.422839, mean_q: 6.104287
677 (array([48]),) False
 106080/500000: episode: 2652, duration: 32.332s, episode steps: 40, steps per second: 1, episode reward: 33.757, mean reward: 0.844 [0.180, 1.000], mean action: 24.825 [8.000, 60.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.246135, mean_absolute_error: 5.447953, mean_q: 6.135982
531 (array([22]),) False
 106120/500000: episode: 2653, duration: 32.203s, episode steps: 40, steps per second: 1, episode reward: 37.025, mean reward: 0.926 [0.307, 1.000], mean action: 21.050 [10.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.250620, mean_absolute_error: 5.348923, mean_q: 6.030641
487 (array([48]),) False
 106160/500000: episode: 2654, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 34.875, mean reward: 0.872 [0.111, 1.000], mean action: 21.950 [3.000, 55.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.237058, mean_absolute_error: 5.400995, mean_q: 6.087874
219 (array([36]),) False
 106200/500000: episode: 2655, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 20.089, mean reward: 0.502 [0.095, 1.000], mean action: 35.475 [3.000, 57.000], mean observation: -0.196 [-1.000, 1.000], loss: 0.244246, mean_absolute_error: 5.449744, mean_q: 6.140885
807 (array([22]),) False
 106240/500000: episode: 2656, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 35.453, mean reward: 0.886 [0.000, 1.000], mean action: 30.850 [9.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.253862, mean_absolute_error: 5.360055, mean_q: 6.046144
660 (array([2]),) False
 106280/500000: episode: 2657, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 17.101, mean reward: 0.428 [0.096, 0.838], mean action: 39.625 [6.000, 58.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.265535, mean_absolute_error: 5.388173, mean_q: 6.071502
735 (array([22]),) False
 106320/500000: episode: 2658, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 36.205, mean reward: 0.905 [0.253, 1.000], mean action: 23.475 [12.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.237738, mean_absolute_error: 5.311164, mean_q: 5.990681
164 (array([22]),) False
 106360/500000: episode: 2659, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 31.032, mean reward: 0.776 [0.000, 1.000], mean action: 24.525 [3.000, 54.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.245798, mean_absolute_error: 5.402379, mean_q: 6.089778
225 (array([48]),) False
 106400/500000: episode: 2660, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 34.420, mean reward: 0.860 [0.160, 1.000], mean action: 20.250 [8.000, 54.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.244969, mean_absolute_error: 5.371695, mean_q: 6.055615
343 (array([22]),) False
 106440/500000: episode: 2661, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 30.758, mean reward: 0.769 [0.071, 1.000], mean action: 26.125 [0.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.261374, mean_absolute_error: 5.379851, mean_q: 6.062411
644 (array([12]),) False
 106480/500000: episode: 2662, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 31.475, mean reward: 0.787 [0.000, 1.000], mean action: 20.400 [6.000, 53.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.216170, mean_absolute_error: 5.375597, mean_q: 6.055825
214 (array([22]),) False
 106520/500000: episode: 2663, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 36.367, mean reward: 0.909 [0.337, 1.000], mean action: 18.375 [1.000, 52.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.251938, mean_absolute_error: 5.371633, mean_q: 6.057773
128 (array([22]),) False
 106560/500000: episode: 2664, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 38.263, mean reward: 0.957 [0.137, 1.000], mean action: 22.550 [19.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.242778, mean_absolute_error: 5.420190, mean_q: 6.106058
162 (array([22]),) False
 106600/500000: episode: 2665, duration: 32.246s, episode steps: 40, steps per second: 1, episode reward: 31.429, mean reward: 0.786 [0.000, 1.000], mean action: 21.050 [11.000, 59.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.266362, mean_absolute_error: 5.385190, mean_q: 6.069247
289 (array([21]),) False
 106640/500000: episode: 2666, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 28.352, mean reward: 0.709 [0.084, 1.000], mean action: 27.600 [9.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.259948, mean_absolute_error: 5.401360, mean_q: 6.093347
777 (array([48]),) False
 106680/500000: episode: 2667, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 33.236, mean reward: 0.831 [0.016, 0.981], mean action: 24.600 [3.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.241391, mean_absolute_error: 5.346425, mean_q: 6.034743
273 (array([22]),) False
 106720/500000: episode: 2668, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 31.750, mean reward: 0.794 [0.135, 1.000], mean action: 31.425 [9.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.261325, mean_absolute_error: 5.378953, mean_q: 6.067716
272 (array([12]),) False
 106760/500000: episode: 2669, duration: 32.214s, episode steps: 40, steps per second: 1, episode reward: 32.030, mean reward: 0.801 [0.092, 1.000], mean action: 26.200 [0.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.229779, mean_absolute_error: 5.300008, mean_q: 5.987564
643 (array([44]),) False
 106800/500000: episode: 2670, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 34.982, mean reward: 0.875 [0.303, 1.000], mean action: 25.800 [2.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.235993, mean_absolute_error: 5.381309, mean_q: 6.076253
771 (array([12]),) False
 106840/500000: episode: 2671, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 27.795, mean reward: 0.695 [0.199, 1.000], mean action: 35.975 [12.000, 40.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.279281, mean_absolute_error: 5.347800, mean_q: 6.039210
216 (array([22]),) False
 106880/500000: episode: 2672, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 23.743, mean reward: 0.594 [0.000, 1.000], mean action: 15.100 [6.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.227051, mean_absolute_error: 5.399472, mean_q: 6.080074
292 (array([22]),) False
 106920/500000: episode: 2673, duration: 32.200s, episode steps: 40, steps per second: 1, episode reward: 33.183, mean reward: 0.830 [0.324, 1.000], mean action: 24.025 [2.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.265231, mean_absolute_error: 5.395685, mean_q: 6.074315
59 (array([12]),) False
 106960/500000: episode: 2674, duration: 33.258s, episode steps: 40, steps per second: 1, episode reward: 29.656, mean reward: 0.741 [0.070, 1.000], mean action: 25.475 [1.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.233321, mean_absolute_error: 5.419131, mean_q: 6.099499
247 (array([14]),) False
 107000/500000: episode: 2675, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 33.232, mean reward: 0.831 [0.205, 1.000], mean action: 24.475 [5.000, 56.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.277039, mean_absolute_error: 5.413226, mean_q: 6.091596
147 (array([44]),) False
 107040/500000: episode: 2676, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 26.119, mean reward: 0.653 [0.589, 0.891], mean action: 15.075 [12.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.232911, mean_absolute_error: 5.435666, mean_q: 6.117608
206 (array([22]),) False
 107080/500000: episode: 2677, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 28.266, mean reward: 0.707 [0.248, 1.000], mean action: 15.800 [3.000, 50.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.268440, mean_absolute_error: 5.438550, mean_q: 6.123254
617 (array([22]),) False
 107120/500000: episode: 2678, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 36.694, mean reward: 0.917 [0.375, 1.000], mean action: 17.850 [12.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.250868, mean_absolute_error: 5.393960, mean_q: 6.072425
370 (array([58]),) False
 107160/500000: episode: 2679, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 24.197, mean reward: 0.605 [0.086, 1.000], mean action: 31.725 [1.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.238279, mean_absolute_error: 5.474713, mean_q: 6.169015
56 (array([12]),) False
 107200/500000: episode: 2680, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 34.798, mean reward: 0.870 [0.308, 0.970], mean action: 22.075 [9.000, 54.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.281623, mean_absolute_error: 5.429842, mean_q: 6.111375
285 (array([58]),) False
 107240/500000: episode: 2681, duration: 32.206s, episode steps: 40, steps per second: 1, episode reward: 30.106, mean reward: 0.753 [0.016, 0.952], mean action: 46.375 [14.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.223747, mean_absolute_error: 5.435837, mean_q: 6.126579
773 (array([22]),) False
 107280/500000: episode: 2682, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 34.988, mean reward: 0.875 [0.255, 1.000], mean action: 25.725 [4.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.248009, mean_absolute_error: 5.497634, mean_q: 6.192223
850 (array([12]),) False
 107320/500000: episode: 2683, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 31.011, mean reward: 0.775 [0.329, 1.000], mean action: 17.325 [0.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.256521, mean_absolute_error: 5.496192, mean_q: 6.193659
584 (array([36]),) False
 107360/500000: episode: 2684, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 14.616, mean reward: 0.365 [0.128, 0.908], mean action: 20.000 [1.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.235752, mean_absolute_error: 5.545787, mean_q: 6.241817
557 (array([22]),) False
 107400/500000: episode: 2685, duration: 32.230s, episode steps: 40, steps per second: 1, episode reward: 31.510, mean reward: 0.788 [0.173, 1.000], mean action: 17.025 [12.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.283091, mean_absolute_error: 5.451591, mean_q: 6.147770
237 (array([22]),) False
 107440/500000: episode: 2686, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 36.574, mean reward: 0.914 [0.262, 1.000], mean action: 22.450 [5.000, 55.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.251708, mean_absolute_error: 5.468485, mean_q: 6.162493
137 (array([22]),) False
 107480/500000: episode: 2687, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 32.585, mean reward: 0.815 [0.124, 1.000], mean action: 20.150 [12.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.257735, mean_absolute_error: 5.504472, mean_q: 6.198021
245 (array([22]),) False
 107520/500000: episode: 2688, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 32.976, mean reward: 0.824 [0.027, 1.000], mean action: 21.950 [0.000, 56.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.257318, mean_absolute_error: 5.442010, mean_q: 6.136647
558 (array([40]),) False
 107560/500000: episode: 2689, duration: 32.210s, episode steps: 40, steps per second: 1, episode reward: 28.182, mean reward: 0.705 [0.221, 1.000], mean action: 19.175 [4.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.255828, mean_absolute_error: 5.395888, mean_q: 6.087549
862 (array([14]),) False
 107600/500000: episode: 2690, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 31.532, mean reward: 0.788 [0.041, 1.000], mean action: 20.900 [4.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.256252, mean_absolute_error: 5.470355, mean_q: 6.161513
444 (array([22]),) False
 107640/500000: episode: 2691, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 35.138, mean reward: 0.878 [0.058, 1.000], mean action: 25.275 [8.000, 60.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.230851, mean_absolute_error: 5.430018, mean_q: 6.123807
133 (array([22]),) False
 107680/500000: episode: 2692, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 33.692, mean reward: 0.842 [0.096, 1.000], mean action: 26.900 [0.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.256472, mean_absolute_error: 5.451906, mean_q: 6.144114
353 (array([22]),) False
 107720/500000: episode: 2693, duration: 32.260s, episode steps: 40, steps per second: 1, episode reward: 35.647, mean reward: 0.891 [0.081, 1.000], mean action: 24.725 [2.000, 54.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.267152, mean_absolute_error: 5.463738, mean_q: 6.161260
859 (array([22]),) False
 107760/500000: episode: 2694, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 24.797, mean reward: 0.620 [0.059, 1.000], mean action: 18.475 [5.000, 50.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.258516, mean_absolute_error: 5.403718, mean_q: 6.097395
96 (array([22]),) False
 107800/500000: episode: 2695, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 35.797, mean reward: 0.895 [0.112, 1.000], mean action: 21.200 [0.000, 34.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.252623, mean_absolute_error: 5.390180, mean_q: 6.072815
578 (array([22]),) False
 107840/500000: episode: 2696, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 35.396, mean reward: 0.885 [0.083, 1.000], mean action: 27.800 [8.000, 55.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.225708, mean_absolute_error: 5.448911, mean_q: 6.140028
412 (array([16]),) False
 107880/500000: episode: 2697, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 33.982, mean reward: 0.850 [0.584, 0.925], mean action: 27.725 [8.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.282006, mean_absolute_error: 5.351598, mean_q: 6.030018
555 (array([22]),) False
 107920/500000: episode: 2698, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 34.313, mean reward: 0.858 [0.117, 1.000], mean action: 17.000 [12.000, 50.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.262236, mean_absolute_error: 5.418246, mean_q: 6.100847
699 (array([22]),) False
 107960/500000: episode: 2699, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 30.045, mean reward: 0.751 [0.228, 1.000], mean action: 19.400 [0.000, 52.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.263270, mean_absolute_error: 5.437031, mean_q: 6.123755
454 (array([12]),) False
 108000/500000: episode: 2700, duration: 32.999s, episode steps: 40, steps per second: 1, episode reward: 31.208, mean reward: 0.780 [0.067, 0.889], mean action: 24.450 [11.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.239579, mean_absolute_error: 5.363718, mean_q: 6.047333
661 (array([48]),) False
 108040/500000: episode: 2701, duration: 32.171s, episode steps: 40, steps per second: 1, episode reward: 31.485, mean reward: 0.787 [0.200, 1.000], mean action: 40.650 [2.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.254722, mean_absolute_error: 5.431219, mean_q: 6.111159
695 (array([22]),) False
 108080/500000: episode: 2702, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 32.816, mean reward: 0.820 [0.076, 1.000], mean action: 25.700 [3.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.283356, mean_absolute_error: 5.406670, mean_q: 6.083853
733 (array([22]),) False
 108120/500000: episode: 2703, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 36.531, mean reward: 0.913 [0.107, 1.000], mean action: 15.100 [8.000, 51.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.266797, mean_absolute_error: 5.412307, mean_q: 6.098292
395 (array([22]),) False
 108160/500000: episode: 2704, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 36.626, mean reward: 0.916 [0.243, 1.000], mean action: 23.375 [9.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.233205, mean_absolute_error: 5.413672, mean_q: 6.111834
401 (array([12]),) False
 108200/500000: episode: 2705, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 26.469, mean reward: 0.662 [0.015, 0.903], mean action: 27.950 [0.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.251875, mean_absolute_error: 5.383013, mean_q: 6.087451
180 (array([48]),) False
 108240/500000: episode: 2706, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 33.724, mean reward: 0.843 [0.077, 1.000], mean action: 18.950 [2.000, 59.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.268318, mean_absolute_error: 5.474964, mean_q: 6.167452
763 (array([48]),) False
 108280/500000: episode: 2707, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 35.261, mean reward: 0.882 [0.036, 1.000], mean action: 24.700 [19.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.275312, mean_absolute_error: 5.377587, mean_q: 6.066829
565 (array([12]),) False
 108320/500000: episode: 2708, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 36.644, mean reward: 0.916 [0.178, 1.000], mean action: 17.075 [8.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.293872, mean_absolute_error: 5.319438, mean_q: 6.006698
594 (array([48]),) False
 108360/500000: episode: 2709, duration: 32.244s, episode steps: 40, steps per second: 1, episode reward: 30.600, mean reward: 0.765 [0.000, 0.962], mean action: 17.125 [0.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.248550, mean_absolute_error: 5.304203, mean_q: 5.980369
2 (array([12]),) False
 108400/500000: episode: 2710, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 29.851, mean reward: 0.746 [0.508, 0.832], mean action: 24.200 [22.000, 59.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.233519, mean_absolute_error: 5.364219, mean_q: 6.049205
589 (array([22]),) False
 108440/500000: episode: 2711, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 27.828, mean reward: 0.696 [0.144, 1.000], mean action: 15.025 [2.000, 51.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.239932, mean_absolute_error: 5.337665, mean_q: 6.023798
432 (array([22]),) False
 108480/500000: episode: 2712, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 34.549, mean reward: 0.864 [0.044, 1.000], mean action: 20.800 [0.000, 53.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.259578, mean_absolute_error: 5.386392, mean_q: 6.085597
537 (array([22]),) False
 108520/500000: episode: 2713, duration: 32.195s, episode steps: 40, steps per second: 1, episode reward: 31.561, mean reward: 0.789 [0.124, 1.000], mean action: 20.200 [9.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.232559, mean_absolute_error: 5.371280, mean_q: 6.064814
844 (array([48]),) False
 108560/500000: episode: 2714, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 34.751, mean reward: 0.869 [0.130, 1.000], mean action: 19.200 [0.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.243334, mean_absolute_error: 5.447201, mean_q: 6.141714
105 (array([22]),) False
 108600/500000: episode: 2715, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 35.496, mean reward: 0.887 [0.292, 1.000], mean action: 26.375 [12.000, 57.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.251958, mean_absolute_error: 5.412708, mean_q: 6.105973
237 (array([22]),) False
 108640/500000: episode: 2716, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 35.314, mean reward: 0.883 [0.275, 1.000], mean action: 24.375 [12.000, 55.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.251604, mean_absolute_error: 5.310073, mean_q: 5.999955
704 (array([22]),) False
 108680/500000: episode: 2717, duration: 32.247s, episode steps: 40, steps per second: 1, episode reward: 25.400, mean reward: 0.635 [0.000, 1.000], mean action: 15.250 [3.000, 53.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.255145, mean_absolute_error: 5.393840, mean_q: 6.081145
158 (array([22]),) False
 108720/500000: episode: 2718, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 33.423, mean reward: 0.836 [0.185, 0.923], mean action: 16.300 [4.000, 58.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.252717, mean_absolute_error: 5.350992, mean_q: 6.035515
547 (array([21]),) False
 108760/500000: episode: 2719, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 29.459, mean reward: 0.736 [0.140, 1.000], mean action: 24.400 [2.000, 51.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.240979, mean_absolute_error: 5.341417, mean_q: 6.023116
470 (array([22]),) False
 108800/500000: episode: 2720, duration: 32.958s, episode steps: 40, steps per second: 1, episode reward: 34.709, mean reward: 0.868 [0.194, 1.000], mean action: 28.625 [4.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.258375, mean_absolute_error: 5.360635, mean_q: 6.034691
858 (array([12]),) False
 108840/500000: episode: 2721, duration: 32.259s, episode steps: 40, steps per second: 1, episode reward: 32.905, mean reward: 0.823 [0.144, 1.000], mean action: 15.700 [1.000, 42.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.238636, mean_absolute_error: 5.344350, mean_q: 6.026993
57 (array([37]),) False
 108880/500000: episode: 2722, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 30.267, mean reward: 0.757 [0.086, 1.000], mean action: 25.150 [3.000, 55.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.286159, mean_absolute_error: 5.357132, mean_q: 6.040641
82 (array([22]),) False
 108920/500000: episode: 2723, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 36.211, mean reward: 0.905 [0.031, 1.000], mean action: 22.250 [4.000, 54.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.255912, mean_absolute_error: 5.354738, mean_q: 6.046114
684 (array([22]),) False
 108960/500000: episode: 2724, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 36.733, mean reward: 0.918 [0.054, 1.000], mean action: 23.650 [17.000, 54.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.226621, mean_absolute_error: 5.383780, mean_q: 6.081290
575 (array([44]),) False
 109000/500000: episode: 2725, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 33.057, mean reward: 0.826 [0.105, 1.000], mean action: 20.250 [2.000, 33.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.262802, mean_absolute_error: 5.377823, mean_q: 6.074132
214 (array([22]),) False
 109040/500000: episode: 2726, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 34.320, mean reward: 0.858 [0.263, 1.000], mean action: 21.850 [0.000, 60.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.236928, mean_absolute_error: 5.391772, mean_q: 6.078506
167 (array([22]),) False
 109080/500000: episode: 2727, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 36.107, mean reward: 0.903 [0.440, 1.000], mean action: 15.550 [12.000, 47.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.277359, mean_absolute_error: 5.301904, mean_q: 5.986459
7 (array([22]),) False
 109120/500000: episode: 2728, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 35.644, mean reward: 0.891 [0.153, 1.000], mean action: 24.450 [2.000, 49.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.265110, mean_absolute_error: 5.363901, mean_q: 6.047753
191 (array([38]),) False
 109160/500000: episode: 2729, duration: 32.209s, episode steps: 40, steps per second: 1, episode reward: 26.310, mean reward: 0.658 [0.202, 1.000], mean action: 15.350 [5.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.235911, mean_absolute_error: 5.392243, mean_q: 6.078995
452 (array([22]),) False
 109200/500000: episode: 2730, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 35.528, mean reward: 0.888 [0.270, 1.000], mean action: 25.325 [10.000, 49.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.223423, mean_absolute_error: 5.417194, mean_q: 6.104642
55 (array([22]),) False
 109240/500000: episode: 2731, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 27.749, mean reward: 0.694 [0.100, 1.000], mean action: 31.425 [1.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.248223, mean_absolute_error: 5.352386, mean_q: 6.038650
701 (array([48]),) False
 109280/500000: episode: 2732, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 35.055, mean reward: 0.876 [0.302, 1.000], mean action: 22.150 [8.000, 50.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.285101, mean_absolute_error: 5.326404, mean_q: 6.001233
353 (array([22]),) False
 109320/500000: episode: 2733, duration: 32.209s, episode steps: 40, steps per second: 1, episode reward: 35.301, mean reward: 0.883 [0.006, 1.000], mean action: 23.725 [19.000, 42.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.262607, mean_absolute_error: 5.438283, mean_q: 6.114483
575 (array([44]),) False
 109360/500000: episode: 2734, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 34.231, mean reward: 0.856 [0.343, 1.000], mean action: 23.325 [12.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.257154, mean_absolute_error: 5.416016, mean_q: 6.104062
496 (array([48]),) False
 109400/500000: episode: 2735, duration: 33.016s, episode steps: 40, steps per second: 1, episode reward: 27.092, mean reward: 0.677 [0.015, 1.000], mean action: 19.800 [3.000, 43.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.259242, mean_absolute_error: 5.418339, mean_q: 6.107642
566 (array([12]),) False
 109440/500000: episode: 2736, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 33.982, mean reward: 0.850 [0.264, 1.000], mean action: 13.400 [1.000, 43.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.245512, mean_absolute_error: 5.391686, mean_q: 6.073736
237 (array([22]),) False
 109480/500000: episode: 2737, duration: 32.255s, episode steps: 40, steps per second: 1, episode reward: 35.434, mean reward: 0.886 [0.006, 1.000], mean action: 24.100 [12.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.260575, mean_absolute_error: 5.381104, mean_q: 6.060004
797 (array([22]),) False
 109520/500000: episode: 2738, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 31.203, mean reward: 0.780 [0.116, 1.000], mean action: 18.725 [10.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.268237, mean_absolute_error: 5.427469, mean_q: 6.109281
452 (array([22]),) False
 109560/500000: episode: 2739, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 33.232, mean reward: 0.831 [0.169, 1.000], mean action: 24.375 [2.000, 53.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.266188, mean_absolute_error: 5.394697, mean_q: 6.074095
408 (array([12]),) False
 109600/500000: episode: 2740, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 33.007, mean reward: 0.825 [0.152, 0.989], mean action: 22.350 [0.000, 50.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.222017, mean_absolute_error: 5.440347, mean_q: 6.126184
572 (array([58]),) False
 109640/500000: episode: 2741, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 22.628, mean reward: 0.566 [0.102, 0.967], mean action: 24.625 [7.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.260383, mean_absolute_error: 5.432656, mean_q: 6.114590
83 (array([22]),) False
 109680/500000: episode: 2742, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 35.101, mean reward: 0.878 [0.038, 1.000], mean action: 23.525 [12.000, 57.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.244867, mean_absolute_error: 5.451941, mean_q: 6.142462
57 (array([37]),) False
 109720/500000: episode: 2743, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 28.548, mean reward: 0.714 [0.000, 1.000], mean action: 25.700 [0.000, 59.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.260340, mean_absolute_error: 5.395365, mean_q: 6.078012
534 (array([22]),) False
 109760/500000: episode: 2744, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 31.072, mean reward: 0.777 [0.127, 0.924], mean action: 24.825 [0.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.246805, mean_absolute_error: 5.477993, mean_q: 6.164301
105 (array([22]),) False
 109800/500000: episode: 2745, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 36.366, mean reward: 0.909 [0.120, 1.000], mean action: 22.350 [12.000, 49.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.236005, mean_absolute_error: 5.418360, mean_q: 6.097457
59 (array([12]),) False
 109840/500000: episode: 2746, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 34.723, mean reward: 0.868 [0.164, 1.000], mean action: 22.125 [7.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.260349, mean_absolute_error: 5.424513, mean_q: 6.109748
818 (array([48]),) False
 109880/500000: episode: 2747, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 30.478, mean reward: 0.762 [0.132, 1.000], mean action: 29.475 [1.000, 54.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.237967, mean_absolute_error: 5.441738, mean_q: 6.135493
849 (array([3]),) False
 109920/500000: episode: 2748, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 16.442, mean reward: 0.411 [0.000, 0.789], mean action: 34.250 [0.000, 57.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.266721, mean_absolute_error: 5.439405, mean_q: 6.126780
215 (array([22]),) False
 109960/500000: episode: 2749, duration: 32.217s, episode steps: 40, steps per second: 1, episode reward: 33.835, mean reward: 0.846 [0.428, 1.000], mean action: 19.450 [12.000, 54.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.246835, mean_absolute_error: 5.419445, mean_q: 6.096002
717 (array([22]),) False
 110000/500000: episode: 2750, duration: 33.219s, episode steps: 40, steps per second: 1, episode reward: 36.635, mean reward: 0.916 [0.468, 1.000], mean action: 20.575 [5.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.235186, mean_absolute_error: 5.460649, mean_q: 6.138477
509 (array([22]),) False
 110040/500000: episode: 2751, duration: 32.197s, episode steps: 40, steps per second: 1, episode reward: 37.553, mean reward: 0.939 [0.165, 1.000], mean action: 22.000 [10.000, 39.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.240888, mean_absolute_error: 5.422240, mean_q: 6.099188
624 (array([48]),) False
 110080/500000: episode: 2752, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 35.539, mean reward: 0.888 [0.146, 1.000], mean action: 40.925 [10.000, 50.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.279396, mean_absolute_error: 5.419463, mean_q: 6.101285
193 (array([36]),) False
 110120/500000: episode: 2753, duration: 32.159s, episode steps: 40, steps per second: 1, episode reward: 28.984, mean reward: 0.725 [0.314, 1.000], mean action: 26.250 [7.000, 60.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.248823, mean_absolute_error: 5.458758, mean_q: 6.146333
705 (array([22]),) False
 110160/500000: episode: 2754, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 32.824, mean reward: 0.821 [0.083, 1.000], mean action: 14.725 [5.000, 53.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.259806, mean_absolute_error: 5.377173, mean_q: 6.059619
638 (array([22]),) False
 110200/500000: episode: 2755, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 28.258, mean reward: 0.706 [0.000, 1.000], mean action: 34.675 [2.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.257653, mean_absolute_error: 5.495660, mean_q: 6.177058
328 (array([12]),) False
 110240/500000: episode: 2756, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 33.714, mean reward: 0.843 [0.023, 1.000], mean action: 17.725 [6.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.248187, mean_absolute_error: 5.409416, mean_q: 6.083674
407 (array([22]),) False
 110280/500000: episode: 2757, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 36.402, mean reward: 0.910 [0.233, 1.000], mean action: 23.925 [5.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.230663, mean_absolute_error: 5.375516, mean_q: 6.057227
213 (array([22]),) False
 110320/500000: episode: 2758, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 36.677, mean reward: 0.917 [0.140, 1.000], mean action: 23.250 [8.000, 47.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.256128, mean_absolute_error: 5.398091, mean_q: 6.080247
290 (array([22]),) False
 110360/500000: episode: 2759, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 37.538, mean reward: 0.938 [0.067, 1.000], mean action: 23.700 [22.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.225517, mean_absolute_error: 5.401927, mean_q: 6.079694
94 (array([44]),) False
 110400/500000: episode: 2760, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 31.332, mean reward: 0.783 [0.000, 0.932], mean action: 21.800 [0.000, 56.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.282784, mean_absolute_error: 5.347292, mean_q: 6.019653
126 (array([22]),) False
 110440/500000: episode: 2761, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 31.751, mean reward: 0.794 [0.198, 1.000], mean action: 21.825 [12.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.248150, mean_absolute_error: 5.368320, mean_q: 6.040745
544 (array([22]),) False
 110480/500000: episode: 2762, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 33.051, mean reward: 0.826 [0.104, 1.000], mean action: 27.925 [11.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.270419, mean_absolute_error: 5.388219, mean_q: 6.058245
242 (array([22]),) False
 110520/500000: episode: 2763, duration: 32.184s, episode steps: 40, steps per second: 1, episode reward: 36.177, mean reward: 0.904 [0.218, 1.000], mean action: 22.275 [8.000, 41.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.223594, mean_absolute_error: 5.365161, mean_q: 6.031924
696 (array([36]),) False
 110560/500000: episode: 2764, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 20.343, mean reward: 0.509 [0.048, 0.815], mean action: 16.925 [3.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.250800, mean_absolute_error: 5.408201, mean_q: 6.075177
613 (array([22]),) False
 110600/500000: episode: 2765, duration: 32.139s, episode steps: 40, steps per second: 1, episode reward: 34.056, mean reward: 0.851 [0.159, 1.000], mean action: 24.100 [2.000, 52.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.260490, mean_absolute_error: 5.407606, mean_q: 6.082352
32 (array([48]),) False
 110640/500000: episode: 2766, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 32.014, mean reward: 0.800 [0.001, 1.000], mean action: 24.650 [3.000, 54.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.275640, mean_absolute_error: 5.441958, mean_q: 6.116292
14 (array([48]),) False
 110680/500000: episode: 2767, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 34.895, mean reward: 0.872 [0.000, 1.000], mean action: 23.975 [3.000, 49.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.246102, mean_absolute_error: 5.390125, mean_q: 6.064947
423 (array([22]),) False
 110720/500000: episode: 2768, duration: 32.325s, episode steps: 40, steps per second: 1, episode reward: 36.786, mean reward: 0.920 [0.119, 1.000], mean action: 24.075 [9.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.238259, mean_absolute_error: 5.362235, mean_q: 6.042393
740 (array([58]),) False
 110760/500000: episode: 2769, duration: 31.395s, episode steps: 40, steps per second: 1, episode reward: 11.666, mean reward: 0.292 [0.000, 0.787], mean action: 26.625 [3.000, 56.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.260887, mean_absolute_error: 5.359404, mean_q: 6.037084
529 (array([3]),) False
 110800/500000: episode: 2770, duration: 31.721s, episode steps: 40, steps per second: 1, episode reward: 12.631, mean reward: 0.316 [0.129, 0.570], mean action: 25.250 [8.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.250240, mean_absolute_error: 5.356696, mean_q: 6.034102
835 (array([50]),) False
 110840/500000: episode: 2771, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 34.754, mean reward: 0.869 [0.466, 1.000], mean action: 23.775 [12.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.244374, mean_absolute_error: 5.276093, mean_q: 5.960431
464 (array([22]),) False
 110880/500000: episode: 2772, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 32.478, mean reward: 0.812 [0.000, 1.000], mean action: 24.400 [1.000, 50.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.244730, mean_absolute_error: 5.334700, mean_q: 6.019984
208 (array([22]),) False
 110920/500000: episode: 2773, duration: 32.133s, episode steps: 40, steps per second: 1, episode reward: 35.630, mean reward: 0.891 [0.094, 1.000], mean action: 19.225 [12.000, 60.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.240003, mean_absolute_error: 5.326697, mean_q: 6.016857
681 (array([12]),) False
 110960/500000: episode: 2774, duration: 32.829s, episode steps: 40, steps per second: 1, episode reward: 38.753, mean reward: 0.969 [0.222, 0.997], mean action: 22.625 [22.000, 37.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.236839, mean_absolute_error: 5.330789, mean_q: 6.018027
268 (array([22]),) False
 111000/500000: episode: 2775, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 37.740, mean reward: 0.943 [0.177, 1.000], mean action: 21.225 [1.000, 39.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.254286, mean_absolute_error: 5.270581, mean_q: 5.950660
542 (array([44]),) False
 111040/500000: episode: 2776, duration: 32.964s, episode steps: 40, steps per second: 1, episode reward: 28.705, mean reward: 0.718 [0.107, 0.936], mean action: 39.250 [6.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.255787, mean_absolute_error: 5.278865, mean_q: 5.962678
584 (array([36]),) False
 111080/500000: episode: 2777, duration: 32.103s, episode steps: 40, steps per second: 1, episode reward: 15.478, mean reward: 0.387 [0.208, 0.911], mean action: 18.500 [5.000, 41.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.243135, mean_absolute_error: 5.309205, mean_q: 5.990561
422 (array([48]),) False
 111120/500000: episode: 2778, duration: 32.937s, episode steps: 40, steps per second: 1, episode reward: 32.118, mean reward: 0.803 [0.269, 1.000], mean action: 21.975 [0.000, 55.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.271423, mean_absolute_error: 5.284376, mean_q: 5.968460
827 (array([14]),) False
 111160/500000: episode: 2779, duration: 32.824s, episode steps: 40, steps per second: 1, episode reward: 32.805, mean reward: 0.820 [0.030, 1.000], mean action: 19.450 [2.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.227335, mean_absolute_error: 5.326312, mean_q: 6.021546
775 (array([58]),) False
 111200/500000: episode: 2780, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 34.274, mean reward: 0.857 [0.022, 0.914], mean action: 56.700 [22.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.251359, mean_absolute_error: 5.339290, mean_q: 6.033496
475 (array([22]),) False
 111240/500000: episode: 2781, duration: 32.701s, episode steps: 40, steps per second: 1, episode reward: 33.516, mean reward: 0.838 [0.166, 1.000], mean action: 20.400 [5.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.285289, mean_absolute_error: 5.312743, mean_q: 6.001232
391 (array([22]),) False
 111280/500000: episode: 2782, duration: 32.135s, episode steps: 40, steps per second: 1, episode reward: 32.542, mean reward: 0.814 [0.125, 1.000], mean action: 27.225 [1.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.231527, mean_absolute_error: 5.344748, mean_q: 6.037757
506 (array([8]),) False
 111320/500000: episode: 2783, duration: 32.028s, episode steps: 40, steps per second: 1, episode reward: 14.149, mean reward: 0.354 [0.020, 1.000], mean action: 29.075 [12.000, 57.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.254765, mean_absolute_error: 5.307434, mean_q: 6.003948
288 (array([33]),) False
 111360/500000: episode: 2784, duration: 32.131s, episode steps: 40, steps per second: 1, episode reward: 22.005, mean reward: 0.550 [0.081, 1.000], mean action: 24.650 [4.000, 58.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.235648, mean_absolute_error: 5.342624, mean_q: 6.042200
317 (array([12]),) False
 111400/500000: episode: 2785, duration: 31.975s, episode steps: 40, steps per second: 1, episode reward: 29.755, mean reward: 0.744 [0.395, 1.000], mean action: 23.225 [14.000, 53.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.264543, mean_absolute_error: 5.286709, mean_q: 5.976435
664 (array([22]),) False
 111440/500000: episode: 2786, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 28.486, mean reward: 0.712 [0.079, 1.000], mean action: 31.300 [3.000, 55.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.246609, mean_absolute_error: 5.279178, mean_q: 5.959453
737 (array([15]),) False
 111480/500000: episode: 2787, duration: 32.066s, episode steps: 40, steps per second: 1, episode reward: 24.004, mean reward: 0.600 [0.000, 0.842], mean action: 18.175 [0.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.251369, mean_absolute_error: 5.273830, mean_q: 5.952603
561 (array([22]),) False
 111520/500000: episode: 2788, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 30.505, mean reward: 0.763 [0.342, 1.000], mean action: 24.025 [12.000, 51.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.266389, mean_absolute_error: 5.247983, mean_q: 5.933192
484 (array([22]),) False
 111560/500000: episode: 2789, duration: 32.205s, episode steps: 40, steps per second: 1, episode reward: 35.875, mean reward: 0.897 [0.245, 1.000], mean action: 24.250 [0.000, 57.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.239022, mean_absolute_error: 5.289721, mean_q: 5.981616
77 (array([22]),) False
 111600/500000: episode: 2790, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 37.335, mean reward: 0.933 [0.255, 1.000], mean action: 22.675 [5.000, 55.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.263489, mean_absolute_error: 5.323963, mean_q: 6.028569
212 (array([36]),) False
 111640/500000: episode: 2791, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 20.873, mean reward: 0.522 [0.162, 0.753], mean action: 22.825 [0.000, 51.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.220945, mean_absolute_error: 5.250602, mean_q: 5.946305
556 (array([48]),) False
 111680/500000: episode: 2792, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 22.041, mean reward: 0.551 [0.047, 0.657], mean action: 16.225 [10.000, 40.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.254872, mean_absolute_error: 5.261748, mean_q: 5.952264
646 (array([44]),) False
 111720/500000: episode: 2793, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 11.401, mean reward: 0.285 [0.004, 0.827], mean action: 18.575 [1.000, 57.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.228029, mean_absolute_error: 5.363350, mean_q: 6.051944
830 (array([22]),) False
 111760/500000: episode: 2794, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 38.176, mean reward: 0.954 [0.524, 1.000], mean action: 20.150 [11.000, 49.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.257016, mean_absolute_error: 5.374558, mean_q: 6.067361
389 (array([48]),) False
 111800/500000: episode: 2795, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 35.125, mean reward: 0.878 [0.161, 0.977], mean action: 24.050 [11.000, 51.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.249355, mean_absolute_error: 5.356153, mean_q: 6.043703
101 (array([22]),) False
 111840/500000: episode: 2796, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 36.586, mean reward: 0.915 [0.251, 1.000], mean action: 21.900 [0.000, 43.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.228917, mean_absolute_error: 5.353512, mean_q: 6.043096
158 (array([22]),) False
 111880/500000: episode: 2797, duration: 32.230s, episode steps: 40, steps per second: 1, episode reward: 30.218, mean reward: 0.755 [0.055, 1.000], mean action: 19.900 [12.000, 55.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.262509, mean_absolute_error: 5.324963, mean_q: 6.020617
729 (array([22]),) False
 111920/500000: episode: 2798, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 33.016, mean reward: 0.825 [0.273, 1.000], mean action: 19.350 [0.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.246116, mean_absolute_error: 5.322608, mean_q: 6.021184
390 (array([22]),) False
 111960/500000: episode: 2799, duration: 32.202s, episode steps: 40, steps per second: 1, episode reward: 32.232, mean reward: 0.806 [0.053, 1.000], mean action: 25.175 [17.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.218928, mean_absolute_error: 5.305401, mean_q: 5.997878
641 (array([22]),) False
 112000/500000: episode: 2800, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 32.719, mean reward: 0.818 [0.296, 1.000], mean action: 23.650 [11.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.247147, mean_absolute_error: 5.348689, mean_q: 6.035903
837 (array([48]),) False
 112040/500000: episode: 2801, duration: 32.196s, episode steps: 40, steps per second: 1, episode reward: 38.011, mean reward: 0.950 [0.492, 0.975], mean action: 22.450 [12.000, 52.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.264558, mean_absolute_error: 5.306363, mean_q: 5.990181
631 (array([22]),) False
 112080/500000: episode: 2802, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 36.077, mean reward: 0.902 [0.143, 1.000], mean action: 26.800 [12.000, 58.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.246539, mean_absolute_error: 5.325436, mean_q: 6.009923
792 (array([58]),) False
 112120/500000: episode: 2803, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 11.754, mean reward: 0.294 [0.000, 0.773], mean action: 31.600 [9.000, 51.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.236030, mean_absolute_error: 5.414116, mean_q: 6.103339
43 (array([12]),) False
 112160/500000: episode: 2804, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 35.961, mean reward: 0.899 [0.000, 0.994], mean action: 22.525 [8.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.241727, mean_absolute_error: 5.394330, mean_q: 6.088351
408 (array([12]),) False
 112200/500000: episode: 2805, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 32.049, mean reward: 0.801 [0.034, 0.989], mean action: 24.475 [3.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.235342, mean_absolute_error: 5.405713, mean_q: 6.095515
571 (array([48]),) False
 112240/500000: episode: 2806, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 28.474, mean reward: 0.712 [0.167, 1.000], mean action: 19.025 [3.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.243270, mean_absolute_error: 5.378039, mean_q: 6.068382
816 (array([4]),) False
 112280/500000: episode: 2807, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 8.976, mean reward: 0.224 [0.000, 0.966], mean action: 28.750 [1.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.258535, mean_absolute_error: 5.365911, mean_q: 6.056705
179 (array([18]),) False
 112320/500000: episode: 2808, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 28.253, mean reward: 0.706 [0.111, 1.000], mean action: 16.175 [0.000, 48.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.252887, mean_absolute_error: 5.398624, mean_q: 6.093279
195 (array([22]),) False
 112360/500000: episode: 2809, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 34.294, mean reward: 0.857 [0.145, 1.000], mean action: 23.550 [12.000, 57.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.230569, mean_absolute_error: 5.319575, mean_q: 6.002746
5 (array([37]),) False
 112400/500000: episode: 2810, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 36.323, mean reward: 0.908 [0.318, 1.000], mean action: 37.925 [16.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.230498, mean_absolute_error: 5.385812, mean_q: 6.071042
423 (array([22]),) False
 112440/500000: episode: 2811, duration: 32.117s, episode steps: 40, steps per second: 1, episode reward: 37.210, mean reward: 0.930 [0.398, 1.000], mean action: 23.800 [12.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.252615, mean_absolute_error: 5.363670, mean_q: 6.044197
610 (array([48]),) False
 112480/500000: episode: 2812, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 34.093, mean reward: 0.852 [0.044, 1.000], mean action: 21.675 [1.000, 56.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.274812, mean_absolute_error: 5.405452, mean_q: 6.098846
459 (array([22]),) False
 112520/500000: episode: 2813, duration: 32.142s, episode steps: 40, steps per second: 1, episode reward: 35.624, mean reward: 0.891 [0.190, 1.000], mean action: 22.150 [7.000, 49.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.275628, mean_absolute_error: 5.459649, mean_q: 6.149381
816 (array([4]),) False
 112560/500000: episode: 2814, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 5.312, mean reward: 0.133 [0.000, 0.900], mean action: 30.900 [1.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.267846, mean_absolute_error: 5.399797, mean_q: 6.091258
246 (array([22]),) False
 112600/500000: episode: 2815, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 34.432, mean reward: 0.861 [0.033, 1.000], mean action: 21.200 [1.000, 60.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.231749, mean_absolute_error: 5.388144, mean_q: 6.082059
411 (array([22]),) False
 112640/500000: episode: 2816, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 37.999, mean reward: 0.950 [0.472, 1.000], mean action: 23.100 [7.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.248795, mean_absolute_error: 5.383386, mean_q: 6.074537
466 (array([22]),) False
 112680/500000: episode: 2817, duration: 32.994s, episode steps: 40, steps per second: 1, episode reward: 38.131, mean reward: 0.953 [0.259, 1.000], mean action: 23.225 [12.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.254383, mean_absolute_error: 5.386790, mean_q: 6.075938
526 (array([22]),) False
 112720/500000: episode: 2818, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 35.778, mean reward: 0.894 [0.282, 1.000], mean action: 43.150 [5.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.244427, mean_absolute_error: 5.429501, mean_q: 6.115327
793 (array([12]),) False
 112760/500000: episode: 2819, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 35.794, mean reward: 0.895 [0.066, 1.000], mean action: 15.200 [10.000, 51.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.239442, mean_absolute_error: 5.444623, mean_q: 6.130212
742 (array([33]),) False
 112800/500000: episode: 2820, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 25.166, mean reward: 0.629 [0.263, 1.000], mean action: 19.150 [10.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.264480, mean_absolute_error: 5.403192, mean_q: 6.086917
723 (array([48]),) False
 112840/500000: episode: 2821, duration: 32.198s, episode steps: 40, steps per second: 1, episode reward: 29.756, mean reward: 0.744 [0.132, 1.000], mean action: 20.900 [12.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.298750, mean_absolute_error: 5.403634, mean_q: 6.083411
270 (array([3]),) False
 112880/500000: episode: 2822, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 11.026, mean reward: 0.276 [0.000, 1.000], mean action: 28.425 [3.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.237908, mean_absolute_error: 5.363259, mean_q: 6.042401
646 (array([44]),) False
 112920/500000: episode: 2823, duration: 32.145s, episode steps: 40, steps per second: 1, episode reward: 9.886, mean reward: 0.247 [0.000, 0.640], mean action: 18.075 [5.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.274460, mean_absolute_error: 5.413102, mean_q: 6.089973
371 (array([14]),) False
 112960/500000: episode: 2824, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 33.634, mean reward: 0.841 [0.349, 1.000], mean action: 21.475 [5.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.276435, mean_absolute_error: 5.374694, mean_q: 6.060999
562 (array([22]),) False
 113000/500000: episode: 2825, duration: 32.215s, episode steps: 40, steps per second: 1, episode reward: 32.518, mean reward: 0.813 [0.000, 1.000], mean action: 21.500 [12.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.261489, mean_absolute_error: 5.313441, mean_q: 6.007008
153 (array([44]),) False
 113040/500000: episode: 2826, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 25.111, mean reward: 0.628 [0.472, 0.932], mean action: 19.175 [12.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.266492, mean_absolute_error: 5.354022, mean_q: 6.046100
643 (array([44]),) False
 113080/500000: episode: 2827, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 33.859, mean reward: 0.846 [0.251, 1.000], mean action: 25.300 [18.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.291138, mean_absolute_error: 5.305171, mean_q: 5.995968
595 (array([22]),) False
 113120/500000: episode: 2828, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 36.449, mean reward: 0.911 [0.309, 1.000], mean action: 23.600 [2.000, 49.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.279816, mean_absolute_error: 5.284524, mean_q: 5.974264
788 (array([3]),) False
 113160/500000: episode: 2829, duration: 32.962s, episode steps: 40, steps per second: 1, episode reward: 20.449, mean reward: 0.511 [0.000, 1.000], mean action: 30.225 [3.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.237711, mean_absolute_error: 5.381262, mean_q: 6.077928
807 (array([22]),) False
 113200/500000: episode: 2830, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 35.216, mean reward: 0.880 [0.050, 1.000], mean action: 39.600 [8.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.256198, mean_absolute_error: 5.332859, mean_q: 6.017847
319 (array([33]),) False
 113240/500000: episode: 2831, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 24.030, mean reward: 0.601 [0.000, 1.000], mean action: 23.675 [12.000, 53.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.285150, mean_absolute_error: 5.369687, mean_q: 6.051594
393 (array([22]),) False
 113280/500000: episode: 2832, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 36.580, mean reward: 0.915 [0.315, 1.000], mean action: 25.175 [20.000, 51.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.264001, mean_absolute_error: 5.377381, mean_q: 6.059721
288 (array([33]),) False
 113320/500000: episode: 2833, duration: 32.206s, episode steps: 40, steps per second: 1, episode reward: 26.200, mean reward: 0.655 [0.153, 1.000], mean action: 28.375 [1.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.269847, mean_absolute_error: 5.378002, mean_q: 6.061554
565 (array([12]),) False
 113360/500000: episode: 2834, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 33.970, mean reward: 0.849 [0.226, 1.000], mean action: 20.800 [0.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.271064, mean_absolute_error: 5.399560, mean_q: 6.092074
730 (array([54]),) False
 113400/500000: episode: 2835, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 20.962, mean reward: 0.524 [0.082, 0.946], mean action: 28.350 [2.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.234446, mean_absolute_error: 5.347743, mean_q: 6.027252
114 (array([22]),) False
 113440/500000: episode: 2836, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 34.494, mean reward: 0.862 [0.423, 1.000], mean action: 21.725 [5.000, 48.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.273784, mean_absolute_error: 5.263995, mean_q: 5.947286
774 (array([57]),) False
 113480/500000: episode: 2837, duration: 32.104s, episode steps: 40, steps per second: 1, episode reward: 31.268, mean reward: 0.782 [0.390, 1.000], mean action: 24.175 [3.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.254790, mean_absolute_error: 5.261303, mean_q: 5.962322
334 (array([48]),) False
 113520/500000: episode: 2838, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 34.706, mean reward: 0.868 [0.129, 0.987], mean action: 22.775 [1.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.247873, mean_absolute_error: 5.339634, mean_q: 6.043672
417 (array([12]),) False
 113560/500000: episode: 2839, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 25.578, mean reward: 0.639 [0.000, 0.915], mean action: 26.100 [2.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.259861, mean_absolute_error: 5.290494, mean_q: 5.975237
477 (array([22]),) False
 113600/500000: episode: 2840, duration: 33.149s, episode steps: 40, steps per second: 1, episode reward: 32.169, mean reward: 0.804 [0.034, 1.000], mean action: 15.525 [5.000, 50.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.237012, mean_absolute_error: 5.287263, mean_q: 5.967827
2 (array([12]),) False
 113640/500000: episode: 2841, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 28.502, mean reward: 0.713 [0.088, 0.832], mean action: 20.125 [3.000, 59.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.262397, mean_absolute_error: 5.342646, mean_q: 6.018968
61 (array([48]),) False
 113680/500000: episode: 2842, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 33.580, mean reward: 0.840 [0.123, 1.000], mean action: 20.300 [5.000, 56.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.253178, mean_absolute_error: 5.302327, mean_q: 5.980414
204 (array([22]),) False
 113720/500000: episode: 2843, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 27.353, mean reward: 0.684 [0.120, 1.000], mean action: 16.625 [4.000, 60.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.237917, mean_absolute_error: 5.348433, mean_q: 6.029300
668 (array([22]),) False
 113760/500000: episode: 2844, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 29.707, mean reward: 0.743 [0.279, 1.000], mean action: 30.925 [22.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.264511, mean_absolute_error: 5.309244, mean_q: 5.985005
247 (array([14]),) False
 113800/500000: episode: 2845, duration: 32.147s, episode steps: 40, steps per second: 1, episode reward: 34.960, mean reward: 0.874 [0.282, 1.000], mean action: 22.075 [5.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.291772, mean_absolute_error: 5.223345, mean_q: 5.896355
258 (array([22]),) False
 113840/500000: episode: 2846, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 37.275, mean reward: 0.932 [0.261, 1.000], mean action: 25.000 [14.000, 48.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.244826, mean_absolute_error: 5.261686, mean_q: 5.952801
790 (array([48]),) False
 113880/500000: episode: 2847, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 27.783, mean reward: 0.695 [0.098, 1.000], mean action: 25.000 [12.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.261627, mean_absolute_error: 5.302579, mean_q: 5.991594
563 (array([22]),) False
 113920/500000: episode: 2848, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 32.818, mean reward: 0.820 [0.121, 1.000], mean action: 18.125 [7.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.274112, mean_absolute_error: 5.331349, mean_q: 6.023467
35 (array([48]),) False
 113960/500000: episode: 2849, duration: 32.169s, episode steps: 40, steps per second: 1, episode reward: 35.049, mean reward: 0.876 [0.004, 0.959], mean action: 23.675 [11.000, 53.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.242632, mean_absolute_error: 5.317677, mean_q: 5.993243
546 (array([22]),) False
 114000/500000: episode: 2850, duration: 33.146s, episode steps: 40, steps per second: 1, episode reward: 35.307, mean reward: 0.883 [0.104, 0.957], mean action: 45.675 [7.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.245067, mean_absolute_error: 5.324727, mean_q: 6.005064
168 (array([22]),) False
 114040/500000: episode: 2851, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 34.582, mean reward: 0.865 [0.024, 1.000], mean action: 17.850 [12.000, 56.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.232279, mean_absolute_error: 5.291337, mean_q: 5.970387
705 (array([22]),) False
 114080/500000: episode: 2852, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 29.078, mean reward: 0.727 [0.207, 0.915], mean action: 13.250 [3.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.239825, mean_absolute_error: 5.279772, mean_q: 5.958914
208 (array([22]),) False
 114120/500000: episode: 2853, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 35.805, mean reward: 0.895 [0.208, 1.000], mean action: 16.725 [6.000, 53.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.253726, mean_absolute_error: 5.350760, mean_q: 6.039527
507 (array([44]),) False
 114160/500000: episode: 2854, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 30.819, mean reward: 0.770 [0.070, 0.994], mean action: 19.950 [2.000, 48.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.248462, mean_absolute_error: 5.271352, mean_q: 5.949902
361 (array([22]),) False
 114200/500000: episode: 2855, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 35.300, mean reward: 0.882 [0.027, 1.000], mean action: 20.900 [0.000, 51.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.243353, mean_absolute_error: 5.254518, mean_q: 5.929765
663 (array([22]),) False
 114240/500000: episode: 2856, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 22.873, mean reward: 0.572 [0.114, 1.000], mean action: 17.750 [8.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.243923, mean_absolute_error: 5.256406, mean_q: 5.937803
255 (array([12]),) False
 114280/500000: episode: 2857, duration: 32.142s, episode steps: 40, steps per second: 1, episode reward: 31.983, mean reward: 0.800 [0.000, 1.000], mean action: 25.875 [4.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.268777, mean_absolute_error: 5.164350, mean_q: 5.837216
724 (array([58]),) False
 114320/500000: episode: 2858, duration: 33.108s, episode steps: 40, steps per second: 1, episode reward: 12.103, mean reward: 0.303 [0.000, 0.794], mean action: 10.750 [2.000, 50.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.247209, mean_absolute_error: 5.274899, mean_q: 5.960258
558 (array([40]),) False
 114360/500000: episode: 2859, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 25.757, mean reward: 0.644 [0.045, 1.000], mean action: 16.050 [1.000, 47.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.257750, mean_absolute_error: 5.257785, mean_q: 5.942208
599 (array([48]),) False
 114400/500000: episode: 2860, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 25.489, mean reward: 0.637 [0.084, 0.932], mean action: 17.700 [1.000, 53.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.242336, mean_absolute_error: 5.240521, mean_q: 5.923940
11 (array([22]),) False
 114440/500000: episode: 2861, duration: 32.140s, episode steps: 40, steps per second: 1, episode reward: 34.926, mean reward: 0.873 [0.095, 1.000], mean action: 29.350 [8.000, 51.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.249766, mean_absolute_error: 5.191961, mean_q: 5.877333
123 (array([22]),) False
 114480/500000: episode: 2862, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 34.005, mean reward: 0.850 [0.021, 1.000], mean action: 22.150 [5.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.276477, mean_absolute_error: 5.244380, mean_q: 5.926070
153 (array([44]),) False
 114520/500000: episode: 2863, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 24.415, mean reward: 0.610 [0.385, 0.929], mean action: 15.275 [12.000, 47.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.233806, mean_absolute_error: 5.269302, mean_q: 5.958076
248 (array([12]),) False
 114560/500000: episode: 2864, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 31.215, mean reward: 0.780 [0.155, 1.000], mean action: 25.425 [1.000, 59.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.239817, mean_absolute_error: 5.222423, mean_q: 5.910909
105 (array([22]),) False
 114600/500000: episode: 2865, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 35.768, mean reward: 0.894 [0.000, 1.000], mean action: 21.825 [3.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.257036, mean_absolute_error: 5.276190, mean_q: 5.971426
563 (array([22]),) False
 114640/500000: episode: 2866, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 32.140, mean reward: 0.803 [0.142, 0.976], mean action: 16.550 [1.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.250463, mean_absolute_error: 5.160807, mean_q: 5.840857
328 (array([12]),) False
 114680/500000: episode: 2867, duration: 32.966s, episode steps: 40, steps per second: 1, episode reward: 33.766, mean reward: 0.844 [0.184, 1.000], mean action: 17.500 [10.000, 57.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.244107, mean_absolute_error: 5.250661, mean_q: 5.938900
193 (array([36]),) False
 114720/500000: episode: 2868, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 33.440, mean reward: 0.836 [0.398, 1.000], mean action: 27.900 [0.000, 58.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.226043, mean_absolute_error: 5.242805, mean_q: 5.926278
61 (array([48]),) False
 114760/500000: episode: 2869, duration: 32.183s, episode steps: 40, steps per second: 1, episode reward: 32.847, mean reward: 0.821 [0.140, 1.000], mean action: 16.350 [5.000, 51.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.229063, mean_absolute_error: 5.211508, mean_q: 5.887108
463 (array([22]),) False
 114800/500000: episode: 2870, duration: 32.978s, episode steps: 40, steps per second: 1, episode reward: 35.471, mean reward: 0.887 [0.117, 1.000], mean action: 24.150 [20.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.233277, mean_absolute_error: 5.266945, mean_q: 5.953598
300 (array([22]),) False
 114840/500000: episode: 2871, duration: 32.202s, episode steps: 40, steps per second: 1, episode reward: 35.643, mean reward: 0.891 [0.271, 1.000], mean action: 26.025 [14.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.246386, mean_absolute_error: 5.202281, mean_q: 5.889647
473 (array([22]),) False
 114880/500000: episode: 2872, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 35.333, mean reward: 0.883 [0.075, 1.000], mean action: 22.450 [2.000, 48.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.238617, mean_absolute_error: 5.223672, mean_q: 5.915762
403 (array([12]),) False
 114920/500000: episode: 2873, duration: 32.210s, episode steps: 40, steps per second: 1, episode reward: 33.750, mean reward: 0.844 [0.223, 1.000], mean action: 23.550 [5.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.284758, mean_absolute_error: 5.191468, mean_q: 5.881691
827 (array([14]),) False
 114960/500000: episode: 2874, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 31.049, mean reward: 0.776 [0.167, 1.000], mean action: 29.450 [12.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.257525, mean_absolute_error: 5.232862, mean_q: 5.928543
826 (array([22]),) False
 115000/500000: episode: 2875, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 35.084, mean reward: 0.877 [0.209, 1.000], mean action: 29.475 [7.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.260122, mean_absolute_error: 5.207945, mean_q: 5.892896
696 (array([36]),) False
 115040/500000: episode: 2876, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 18.886, mean reward: 0.472 [0.000, 0.891], mean action: 19.075 [3.000, 49.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.249515, mean_absolute_error: 5.202974, mean_q: 5.890436
310 (array([12]),) False
 115080/500000: episode: 2877, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 32.347, mean reward: 0.809 [0.073, 0.880], mean action: 36.925 [11.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.253984, mean_absolute_error: 5.190307, mean_q: 5.867710
518 (array([22]),) False
 115120/500000: episode: 2878, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 33.223, mean reward: 0.831 [0.000, 1.000], mean action: 19.500 [12.000, 54.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.254093, mean_absolute_error: 5.215850, mean_q: 5.897944
831 (array([3]),) False
 115160/500000: episode: 2879, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 10.204, mean reward: 0.255 [0.000, 0.909], mean action: 14.150 [4.000, 56.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.247920, mean_absolute_error: 5.192731, mean_q: 5.869356
319 (array([33]),) False
 115200/500000: episode: 2880, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 24.515, mean reward: 0.613 [0.166, 1.000], mean action: 15.750 [12.000, 36.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.252930, mean_absolute_error: 5.212025, mean_q: 5.890386
166 (array([22]),) False
 115240/500000: episode: 2881, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 29.241, mean reward: 0.731 [0.182, 1.000], mean action: 19.125 [2.000, 54.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.256079, mean_absolute_error: 5.185784, mean_q: 5.868846
851 (array([48]),) False
 115280/500000: episode: 2882, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 36.093, mean reward: 0.902 [0.392, 1.000], mean action: 17.875 [12.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.255298, mean_absolute_error: 5.152525, mean_q: 5.840552
400 (array([22]),) False
 115320/500000: episode: 2883, duration: 32.204s, episode steps: 40, steps per second: 1, episode reward: 32.879, mean reward: 0.822 [0.222, 1.000], mean action: 24.175 [5.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.262684, mean_absolute_error: 5.213457, mean_q: 5.904695
624 (array([48]),) False
 115360/500000: episode: 2884, duration: 32.983s, episode steps: 40, steps per second: 1, episode reward: 33.733, mean reward: 0.843 [0.146, 1.000], mean action: 31.625 [12.000, 57.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.254421, mean_absolute_error: 5.191255, mean_q: 5.880742
276 (array([56]),) False
 115400/500000: episode: 2885, duration: 32.188s, episode steps: 40, steps per second: 1, episode reward: 24.668, mean reward: 0.617 [0.105, 0.933], mean action: 18.500 [6.000, 59.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.220539, mean_absolute_error: 5.186944, mean_q: 5.874797
179 (array([18]),) False
 115440/500000: episode: 2886, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 29.109, mean reward: 0.728 [0.000, 1.000], mean action: 18.150 [4.000, 49.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.242578, mean_absolute_error: 5.162177, mean_q: 5.847764
199 (array([22]),) False
 115480/500000: episode: 2887, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 32.382, mean reward: 0.810 [0.219, 1.000], mean action: 18.500 [7.000, 58.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.248374, mean_absolute_error: 5.224860, mean_q: 5.914782
276 (array([56]),) False
 115520/500000: episode: 2888, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 23.576, mean reward: 0.589 [0.000, 0.933], mean action: 18.300 [11.000, 48.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.235620, mean_absolute_error: 5.172375, mean_q: 5.856269
534 (array([22]),) False
 115560/500000: episode: 2889, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 33.636, mean reward: 0.841 [0.278, 1.000], mean action: 32.275 [12.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.217402, mean_absolute_error: 5.228630, mean_q: 5.916033
212 (array([36]),) False
 115600/500000: episode: 2890, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 21.319, mean reward: 0.533 [0.182, 0.664], mean action: 21.575 [2.000, 48.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.268580, mean_absolute_error: 5.224576, mean_q: 5.909355
436 (array([22]),) False
 115640/500000: episode: 2891, duration: 33.004s, episode steps: 40, steps per second: 1, episode reward: 36.443, mean reward: 0.911 [0.082, 1.000], mean action: 25.000 [9.000, 57.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.236343, mean_absolute_error: 5.145855, mean_q: 5.829048
553 (array([22]),) False
 115680/500000: episode: 2892, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 34.300, mean reward: 0.858 [0.000, 1.000], mean action: 15.725 [10.000, 50.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.254305, mean_absolute_error: 5.203983, mean_q: 5.892659
412 (array([16]),) False
 115720/500000: episode: 2893, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 33.466, mean reward: 0.837 [0.135, 0.925], mean action: 26.625 [15.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.237335, mean_absolute_error: 5.083832, mean_q: 5.767436
146 (array([12]),) False
 115760/500000: episode: 2894, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 36.369, mean reward: 0.909 [0.135, 1.000], mean action: 12.625 [3.000, 33.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.275168, mean_absolute_error: 5.153926, mean_q: 5.835667
453 (array([22]),) False
 115800/500000: episode: 2895, duration: 32.158s, episode steps: 40, steps per second: 1, episode reward: 31.726, mean reward: 0.793 [0.177, 1.000], mean action: 22.225 [4.000, 50.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.248681, mean_absolute_error: 5.153100, mean_q: 5.840250
790 (array([48]),) False
 115840/500000: episode: 2896, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 27.282, mean reward: 0.682 [0.402, 1.000], mean action: 17.800 [12.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.201255, mean_absolute_error: 5.192531, mean_q: 5.876235
632 (array([22]),) False
 115880/500000: episode: 2897, duration: 32.142s, episode steps: 40, steps per second: 1, episode reward: 37.445, mean reward: 0.936 [0.367, 1.000], mean action: 22.600 [3.000, 47.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.249796, mean_absolute_error: 5.157506, mean_q: 5.833854
89 (array([58]),) False
 115920/500000: episode: 2898, duration: 32.999s, episode steps: 40, steps per second: 1, episode reward: 19.527, mean reward: 0.488 [0.000, 1.000], mean action: 31.075 [3.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.242201, mean_absolute_error: 5.137187, mean_q: 5.811887
231 (array([22]),) False
 115960/500000: episode: 2899, duration: 33.016s, episode steps: 40, steps per second: 1, episode reward: 34.329, mean reward: 0.858 [0.101, 1.000], mean action: 18.375 [1.000, 47.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.258800, mean_absolute_error: 5.155435, mean_q: 5.826168
695 (array([22]),) False
 116000/500000: episode: 2900, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 35.401, mean reward: 0.885 [0.218, 1.000], mean action: 21.825 [5.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.234908, mean_absolute_error: 5.148576, mean_q: 5.823270
632 (array([22]),) False
 116040/500000: episode: 2901, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 33.905, mean reward: 0.848 [0.118, 1.000], mean action: 24.350 [2.000, 59.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.278247, mean_absolute_error: 5.200459, mean_q: 5.873372
679 (array([44]),) False
 116080/500000: episode: 2902, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 27.710, mean reward: 0.693 [0.099, 1.000], mean action: 22.025 [12.000, 55.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.265808, mean_absolute_error: 5.195647, mean_q: 5.877827
153 (array([44]),) False
 116120/500000: episode: 2903, duration: 32.999s, episode steps: 40, steps per second: 1, episode reward: 24.824, mean reward: 0.621 [0.329, 1.000], mean action: 14.975 [6.000, 56.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.232604, mean_absolute_error: 5.186112, mean_q: 5.869585
350 (array([12]),) False
 116160/500000: episode: 2904, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 26.572, mean reward: 0.664 [0.163, 0.856], mean action: 24.450 [0.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.265478, mean_absolute_error: 5.180373, mean_q: 5.860505
14 (array([48]),) False
 116200/500000: episode: 2905, duration: 32.238s, episode steps: 40, steps per second: 1, episode reward: 36.778, mean reward: 0.919 [0.229, 1.000], mean action: 25.750 [22.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.216320, mean_absolute_error: 5.247941, mean_q: 5.932359
552 (array([22]),) False
 116240/500000: episode: 2906, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 36.463, mean reward: 0.912 [0.151, 1.000], mean action: 15.775 [12.000, 49.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.244492, mean_absolute_error: 5.206553, mean_q: 5.878942
298 (array([22]),) False
 116280/500000: episode: 2907, duration: 32.123s, episode steps: 40, steps per second: 1, episode reward: 35.233, mean reward: 0.881 [0.349, 1.000], mean action: 25.200 [0.000, 49.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.232689, mean_absolute_error: 5.193441, mean_q: 5.863997
71 (array([58]),) False
 116320/500000: episode: 2908, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 18.662, mean reward: 0.467 [0.043, 1.000], mean action: 30.125 [12.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.235600, mean_absolute_error: 5.170868, mean_q: 5.845378
834 (array([44]),) False
 116360/500000: episode: 2909, duration: 32.095s, episode steps: 40, steps per second: 1, episode reward: 33.623, mean reward: 0.841 [0.088, 0.967], mean action: 17.475 [12.000, 53.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.239040, mean_absolute_error: 5.206302, mean_q: 5.878522
266 (array([12]),) False
 116400/500000: episode: 2910, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 27.460, mean reward: 0.686 [0.130, 0.857], mean action: 24.200 [12.000, 56.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.276882, mean_absolute_error: 5.182585, mean_q: 5.862918
277 (array([56]),) False
 116440/500000: episode: 2911, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 28.205, mean reward: 0.705 [0.189, 0.873], mean action: 22.150 [2.000, 54.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.263827, mean_absolute_error: 5.218942, mean_q: 5.895257
405 (array([22]),) False
 116480/500000: episode: 2912, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 35.637, mean reward: 0.891 [0.066, 1.000], mean action: 24.175 [2.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.274383, mean_absolute_error: 5.163698, mean_q: 5.839938
69 (array([12]),) False
 116520/500000: episode: 2913, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 36.932, mean reward: 0.923 [0.212, 1.000], mean action: 15.500 [10.000, 59.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.237984, mean_absolute_error: 5.197643, mean_q: 5.876096
611 (array([22]),) False
 116560/500000: episode: 2914, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 33.248, mean reward: 0.831 [0.146, 0.974], mean action: 18.625 [2.000, 56.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.262937, mean_absolute_error: 5.217664, mean_q: 5.902516
464 (array([22]),) False
 116600/500000: episode: 2915, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 37.943, mean reward: 0.949 [0.355, 1.000], mean action: 23.325 [22.000, 45.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.246210, mean_absolute_error: 5.247058, mean_q: 5.939095
758 (array([38]),) False
 116640/500000: episode: 2916, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 36.738, mean reward: 0.918 [0.337, 0.952], mean action: 20.775 [5.000, 22.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.273286, mean_absolute_error: 5.170728, mean_q: 5.855052
89 (array([58]),) False
 116680/500000: episode: 2917, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 27.915, mean reward: 0.698 [0.017, 0.998], mean action: 26.400 [3.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.246307, mean_absolute_error: 5.145825, mean_q: 5.830490
762 (array([22]),) False
 116720/500000: episode: 2918, duration: 33.204s, episode steps: 40, steps per second: 1, episode reward: 36.664, mean reward: 0.917 [0.177, 1.000], mean action: 27.625 [7.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.237013, mean_absolute_error: 5.226243, mean_q: 5.920283
668 (array([22]),) False
 116760/500000: episode: 2919, duration: 32.140s, episode steps: 40, steps per second: 1, episode reward: 28.185, mean reward: 0.705 [0.187, 1.000], mean action: 30.350 [9.000, 50.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.234840, mean_absolute_error: 5.121104, mean_q: 5.802293
669 (array([15]),) False
 116800/500000: episode: 2920, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 25.884, mean reward: 0.647 [0.000, 0.777], mean action: 35.525 [1.000, 55.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.244535, mean_absolute_error: 5.171478, mean_q: 5.854246
38 (array([22]),) False
 116840/500000: episode: 2921, duration: 32.158s, episode steps: 40, steps per second: 1, episode reward: 35.177, mean reward: 0.879 [0.051, 1.000], mean action: 25.500 [22.000, 52.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.278056, mean_absolute_error: 5.174597, mean_q: 5.855555
105 (array([22]),) False
 116880/500000: episode: 2922, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 36.514, mean reward: 0.913 [0.223, 1.000], mean action: 19.850 [5.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.270911, mean_absolute_error: 5.200264, mean_q: 5.884155
736 (array([22]),) False
 116920/500000: episode: 2923, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 34.491, mean reward: 0.862 [0.347, 1.000], mean action: 15.050 [6.000, 39.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.239550, mean_absolute_error: 5.182232, mean_q: 5.868721
423 (array([22]),) False
 116960/500000: episode: 2924, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 34.957, mean reward: 0.874 [0.000, 1.000], mean action: 22.100 [4.000, 45.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.274314, mean_absolute_error: 5.215593, mean_q: 5.899096
0 (array([48]),) False
 117000/500000: episode: 2925, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 33.133, mean reward: 0.828 [0.114, 1.000], mean action: 24.375 [7.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.247839, mean_absolute_error: 5.113629, mean_q: 5.795850
679 (array([44]),) False
 117040/500000: episode: 2926, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 28.484, mean reward: 0.712 [0.130, 1.000], mean action: 19.300 [0.000, 60.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.267536, mean_absolute_error: 5.190381, mean_q: 5.879381
805 (array([22]),) False
 117080/500000: episode: 2927, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 32.990, mean reward: 0.825 [0.152, 1.000], mean action: 28.625 [0.000, 55.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.273420, mean_absolute_error: 5.218739, mean_q: 5.903732
238 (array([22]),) False
 117120/500000: episode: 2928, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 35.144, mean reward: 0.879 [0.052, 1.000], mean action: 23.300 [1.000, 49.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.245300, mean_absolute_error: 5.130431, mean_q: 5.811004
633 (array([22]),) False
 117160/500000: episode: 2929, duration: 32.184s, episode steps: 40, steps per second: 1, episode reward: 30.544, mean reward: 0.764 [0.134, 1.000], mean action: 24.100 [0.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.244353, mean_absolute_error: 5.321692, mean_q: 6.007922
720 (array([22]),) False
 117200/500000: episode: 2930, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 32.549, mean reward: 0.814 [0.136, 1.000], mean action: 27.825 [9.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.256339, mean_absolute_error: 5.165514, mean_q: 5.850631
164 (array([22]),) False
 117240/500000: episode: 2931, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 32.297, mean reward: 0.807 [0.113, 1.000], mean action: 24.950 [2.000, 49.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.266315, mean_absolute_error: 5.215227, mean_q: 5.902362
846 (array([48]),) False
 117280/500000: episode: 2932, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 34.799, mean reward: 0.870 [0.000, 0.974], mean action: 18.950 [3.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.299458, mean_absolute_error: 5.211301, mean_q: 5.888610
815 (array([22]),) False
 117320/500000: episode: 2933, duration: 32.254s, episode steps: 40, steps per second: 1, episode reward: 30.369, mean reward: 0.759 [0.156, 1.000], mean action: 34.400 [2.000, 53.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.259877, mean_absolute_error: 5.245230, mean_q: 5.929333
794 (array([22]),) False
 117360/500000: episode: 2934, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 34.659, mean reward: 0.866 [0.412, 1.000], mean action: 19.150 [4.000, 52.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.221087, mean_absolute_error: 5.254334, mean_q: 5.942601
737 (array([15]),) False
 117400/500000: episode: 2935, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 26.847, mean reward: 0.671 [0.252, 0.952], mean action: 17.000 [1.000, 31.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.261832, mean_absolute_error: 5.236250, mean_q: 5.925388
649 (array([22]),) False
 117440/500000: episode: 2936, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 33.329, mean reward: 0.833 [0.000, 1.000], mean action: 25.150 [2.000, 52.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.255120, mean_absolute_error: 5.234038, mean_q: 5.924786
315 (array([12]),) False
 117480/500000: episode: 2937, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 32.895, mean reward: 0.822 [0.006, 1.000], mean action: 24.775 [5.000, 54.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.243909, mean_absolute_error: 5.272999, mean_q: 5.962617
817 (array([12]),) False
 117520/500000: episode: 2938, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 26.974, mean reward: 0.674 [0.161, 1.000], mean action: 43.100 [8.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.228857, mean_absolute_error: 5.157108, mean_q: 5.834141
644 (array([12]),) False
 117560/500000: episode: 2939, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 30.611, mean reward: 0.765 [0.056, 0.995], mean action: 31.975 [9.000, 58.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.250728, mean_absolute_error: 5.203158, mean_q: 5.882325
418 (array([22]),) False
 117600/500000: episode: 2940, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 33.148, mean reward: 0.829 [0.312, 1.000], mean action: 29.750 [1.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.247304, mean_absolute_error: 5.237138, mean_q: 5.918930
272 (array([12]),) False
 117640/500000: episode: 2941, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 36.905, mean reward: 0.923 [0.180, 1.000], mean action: 24.425 [9.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.273719, mean_absolute_error: 5.251887, mean_q: 5.933354
309 (array([22]),) False
 117680/500000: episode: 2942, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 35.523, mean reward: 0.888 [0.069, 1.000], mean action: 26.800 [9.000, 48.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.254485, mean_absolute_error: 5.290825, mean_q: 5.978488
549 (array([22]),) False
 117720/500000: episode: 2943, duration: 32.152s, episode steps: 40, steps per second: 1, episode reward: 36.514, mean reward: 0.913 [0.241, 1.000], mean action: 22.150 [12.000, 38.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.262736, mean_absolute_error: 5.216429, mean_q: 5.906280
293 (array([22]),) False
 117760/500000: episode: 2944, duration: 32.940s, episode steps: 40, steps per second: 1, episode reward: 39.188, mean reward: 0.980 [0.415, 1.000], mean action: 22.325 [17.000, 40.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.211172, mean_absolute_error: 5.159083, mean_q: 5.836767
580 (array([22]),) False
 117800/500000: episode: 2945, duration: 32.087s, episode steps: 40, steps per second: 1, episode reward: 36.539, mean reward: 0.913 [0.276, 1.000], mean action: 24.100 [12.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.277188, mean_absolute_error: 5.194182, mean_q: 5.881113
145 (array([19]),) False
 117840/500000: episode: 2946, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 25.733, mean reward: 0.643 [0.106, 0.822], mean action: 17.525 [6.000, 53.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.264055, mean_absolute_error: 5.244880, mean_q: 5.929730
563 (array([22]),) False
 117880/500000: episode: 2947, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 32.687, mean reward: 0.817 [0.000, 1.000], mean action: 13.150 [9.000, 29.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.252397, mean_absolute_error: 5.158144, mean_q: 5.827913
795 (array([3]),) False
 117920/500000: episode: 2948, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 21.428, mean reward: 0.536 [0.000, 0.910], mean action: 16.925 [1.000, 52.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.244409, mean_absolute_error: 5.281039, mean_q: 5.959565
509 (array([22]),) False
 117960/500000: episode: 2949, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 35.441, mean reward: 0.886 [0.000, 1.000], mean action: 22.375 [2.000, 55.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.234741, mean_absolute_error: 5.206970, mean_q: 5.884017
700 (array([44]),) False
 118000/500000: episode: 2950, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 36.246, mean reward: 0.906 [0.300, 1.000], mean action: 38.875 [20.000, 54.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.271674, mean_absolute_error: 5.159916, mean_q: 5.830867
795 (array([3]),) False
 118040/500000: episode: 2951, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 21.920, mean reward: 0.548 [0.000, 0.966], mean action: 16.775 [5.000, 46.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.263688, mean_absolute_error: 5.211631, mean_q: 5.888984
154 (array([44]),) False
 118080/500000: episode: 2952, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 35.505, mean reward: 0.888 [0.073, 0.998], mean action: 17.600 [2.000, 47.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.271394, mean_absolute_error: 5.223978, mean_q: 5.906608
108 (array([48]),) False
 118120/500000: episode: 2953, duration: 32.137s, episode steps: 40, steps per second: 1, episode reward: 28.708, mean reward: 0.718 [0.179, 1.000], mean action: 15.825 [1.000, 33.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.269604, mean_absolute_error: 5.139745, mean_q: 5.825552
675 (array([22]),) False
 118160/500000: episode: 2954, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 38.148, mean reward: 0.954 [0.318, 1.000], mean action: 24.100 [22.000, 60.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.219175, mean_absolute_error: 5.112308, mean_q: 5.795573
551 (array([22]),) False
 118200/500000: episode: 2955, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 36.581, mean reward: 0.915 [0.069, 1.000], mean action: 18.150 [12.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.218777, mean_absolute_error: 5.186133, mean_q: 5.873988
133 (array([22]),) False
 118240/500000: episode: 2956, duration: 32.989s, episode steps: 40, steps per second: 1, episode reward: 34.170, mean reward: 0.854 [0.000, 1.000], mean action: 23.300 [6.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.274683, mean_absolute_error: 5.189867, mean_q: 5.884758
514 (array([54]),) False
 118280/500000: episode: 2957, duration: 32.148s, episode steps: 40, steps per second: 1, episode reward: 17.468, mean reward: 0.437 [0.140, 0.903], mean action: 13.300 [8.000, 40.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.258972, mean_absolute_error: 5.226712, mean_q: 5.911750
737 (array([15]),) False
 118320/500000: episode: 2958, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 25.635, mean reward: 0.641 [0.060, 0.952], mean action: 20.900 [2.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.258758, mean_absolute_error: 5.228133, mean_q: 5.911362
473 (array([22]),) False
 118360/500000: episode: 2959, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 33.899, mean reward: 0.847 [0.069, 1.000], mean action: 24.725 [4.000, 57.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.269941, mean_absolute_error: 5.243466, mean_q: 5.918772
799 (array([36]),) False
 118400/500000: episode: 2960, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 25.405, mean reward: 0.635 [0.124, 1.000], mean action: 20.275 [0.000, 39.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.257759, mean_absolute_error: 5.191340, mean_q: 5.875777
751 (array([22]),) False
 118440/500000: episode: 2961, duration: 32.122s, episode steps: 40, steps per second: 1, episode reward: 33.869, mean reward: 0.847 [0.020, 1.000], mean action: 22.600 [12.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.257863, mean_absolute_error: 5.202451, mean_q: 5.885900
36 (array([22]),) False
 118480/500000: episode: 2962, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 29.380, mean reward: 0.734 [0.017, 1.000], mean action: 24.675 [1.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.263759, mean_absolute_error: 5.257663, mean_q: 5.947815
696 (array([36]),) False
 118520/500000: episode: 2963, duration: 32.171s, episode steps: 40, steps per second: 1, episode reward: 27.635, mean reward: 0.691 [0.167, 1.000], mean action: 34.575 [3.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.270198, mean_absolute_error: 5.205235, mean_q: 5.887221
80 (array([42]),) False
 118560/500000: episode: 2964, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 36.100, mean reward: 0.903 [0.416, 1.000], mean action: 23.025 [12.000, 59.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.257070, mean_absolute_error: 5.203099, mean_q: 5.892982
404 (array([12]),) False
 118600/500000: episode: 2965, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 26.901, mean reward: 0.673 [0.289, 1.000], mean action: 28.150 [6.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.234040, mean_absolute_error: 5.154395, mean_q: 5.844378
564 (array([22]),) False
 118640/500000: episode: 2966, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 33.736, mean reward: 0.843 [0.226, 1.000], mean action: 15.575 [5.000, 42.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.264504, mean_absolute_error: 5.165370, mean_q: 5.855002
605 (array([22]),) False
 118680/500000: episode: 2967, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 34.127, mean reward: 0.853 [0.000, 1.000], mean action: 24.775 [22.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.252087, mean_absolute_error: 5.153570, mean_q: 5.833602
860 (array([12]),) False
 118720/500000: episode: 2968, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 32.988, mean reward: 0.825 [0.047, 1.000], mean action: 19.975 [12.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.253520, mean_absolute_error: 5.275146, mean_q: 5.966001
287 (array([48]),) False
 118760/500000: episode: 2969, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 29.463, mean reward: 0.737 [0.290, 1.000], mean action: 35.100 [3.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.251838, mean_absolute_error: 5.262322, mean_q: 5.952256
295 (array([22]),) False
 118800/500000: episode: 2970, duration: 32.991s, episode steps: 40, steps per second: 1, episode reward: 37.311, mean reward: 0.933 [0.292, 1.000], mean action: 24.475 [12.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.261539, mean_absolute_error: 5.198785, mean_q: 5.881248
747 (array([22]),) False
 118840/500000: episode: 2971, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 37.512, mean reward: 0.938 [0.128, 1.000], mean action: 20.025 [4.000, 22.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.285102, mean_absolute_error: 5.208127, mean_q: 5.887568
510 (array([22]),) False
 118880/500000: episode: 2972, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 29.974, mean reward: 0.749 [0.053, 0.992], mean action: 17.400 [1.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.271039, mean_absolute_error: 5.245098, mean_q: 5.930581
143 (array([12]),) False
 118920/500000: episode: 2973, duration: 32.193s, episode steps: 40, steps per second: 1, episode reward: 35.048, mean reward: 0.876 [0.068, 1.000], mean action: 13.425 [4.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.253992, mean_absolute_error: 5.213902, mean_q: 5.894286
533 (array([22]),) False
 118960/500000: episode: 2974, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 29.933, mean reward: 0.748 [0.186, 1.000], mean action: 26.350 [6.000, 58.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.265702, mean_absolute_error: 5.191060, mean_q: 5.864555
272 (array([12]),) False
 119000/500000: episode: 2975, duration: 32.145s, episode steps: 40, steps per second: 1, episode reward: 37.424, mean reward: 0.936 [0.316, 1.000], mean action: 23.400 [12.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.251939, mean_absolute_error: 5.115770, mean_q: 5.787497
589 (array([22]),) False
 119040/500000: episode: 2976, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 29.560, mean reward: 0.739 [0.214, 1.000], mean action: 15.150 [3.000, 56.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.252305, mean_absolute_error: 5.137446, mean_q: 5.814413
564 (array([22]),) False
 119080/500000: episode: 2977, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 34.614, mean reward: 0.865 [0.237, 1.000], mean action: 15.975 [12.000, 50.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.272894, mean_absolute_error: 5.206952, mean_q: 5.897311
716 (array([48]),) False
 119120/500000: episode: 2978, duration: 32.964s, episode steps: 40, steps per second: 1, episode reward: 33.837, mean reward: 0.846 [0.124, 0.993], mean action: 16.175 [0.000, 47.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.243484, mean_absolute_error: 5.174800, mean_q: 5.861558
545 (array([22]),) False
 119160/500000: episode: 2979, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 34.619, mean reward: 0.865 [0.171, 1.000], mean action: 23.650 [12.000, 60.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.270962, mean_absolute_error: 5.148042, mean_q: 5.827682
549 (array([22]),) False
 119200/500000: episode: 2980, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 36.102, mean reward: 0.903 [0.422, 1.000], mean action: 22.200 [3.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.244355, mean_absolute_error: 5.138966, mean_q: 5.817958
845 (array([22]),) False
 119240/500000: episode: 2981, duration: 33.004s, episode steps: 40, steps per second: 1, episode reward: 36.966, mean reward: 0.924 [0.018, 1.000], mean action: 24.875 [18.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.233493, mean_absolute_error: 5.176515, mean_q: 5.868100
59 (array([12]),) False
 119280/500000: episode: 2982, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 32.628, mean reward: 0.816 [0.106, 1.000], mean action: 23.875 [8.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.256930, mean_absolute_error: 5.177235, mean_q: 5.867703
491 (array([22]),) False
 119320/500000: episode: 2983, duration: 32.958s, episode steps: 40, steps per second: 1, episode reward: 37.639, mean reward: 0.941 [0.302, 1.000], mean action: 20.950 [12.000, 46.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.256301, mean_absolute_error: 5.158994, mean_q: 5.845043
377 (array([22]),) False
 119360/500000: episode: 2984, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 35.860, mean reward: 0.897 [0.000, 1.000], mean action: 22.375 [4.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.245933, mean_absolute_error: 5.216229, mean_q: 5.912129
462 (array([12]),) False
 119400/500000: episode: 2985, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 30.174, mean reward: 0.754 [0.139, 0.947], mean action: 22.350 [2.000, 45.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.250352, mean_absolute_error: 5.227229, mean_q: 5.927268
801 (array([58]),) False
 119440/500000: episode: 2986, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 18.286, mean reward: 0.457 [0.000, 1.000], mean action: 26.475 [3.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.247814, mean_absolute_error: 5.197131, mean_q: 5.892870
291 (array([22]),) False
 119480/500000: episode: 2987, duration: 32.177s, episode steps: 40, steps per second: 1, episode reward: 33.722, mean reward: 0.843 [0.000, 1.000], mean action: 19.400 [6.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.288892, mean_absolute_error: 5.172494, mean_q: 5.865048
250 (array([22]),) False
 119520/500000: episode: 2988, duration: 32.973s, episode steps: 40, steps per second: 1, episode reward: 32.063, mean reward: 0.802 [0.095, 1.000], mean action: 30.550 [0.000, 57.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.250970, mean_absolute_error: 5.134802, mean_q: 5.825746
692 (array([22]),) False
 119560/500000: episode: 2989, duration: 32.162s, episode steps: 40, steps per second: 1, episode reward: 35.140, mean reward: 0.879 [0.051, 1.000], mean action: 26.450 [14.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.266692, mean_absolute_error: 5.200629, mean_q: 5.893151
703 (array([3]),) False
 119600/500000: episode: 2990, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 31.934, mean reward: 0.798 [0.004, 1.000], mean action: 9.675 [1.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.266110, mean_absolute_error: 5.250370, mean_q: 5.947879
314 (array([22]),) False
 119640/500000: episode: 2991, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 34.668, mean reward: 0.867 [0.000, 1.000], mean action: 28.050 [9.000, 57.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.284130, mean_absolute_error: 5.225591, mean_q: 5.913020
71 (array([58]),) False
 119680/500000: episode: 2992, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 19.724, mean reward: 0.493 [0.000, 0.919], mean action: 31.850 [3.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.245070, mean_absolute_error: 5.216280, mean_q: 5.910449
98 (array([12]),) False
 119720/500000: episode: 2993, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 36.775, mean reward: 0.919 [0.055, 0.987], mean action: 21.725 [3.000, 51.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.249430, mean_absolute_error: 5.208807, mean_q: 5.905303
278 (array([48]),) False
 119760/500000: episode: 2994, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 32.418, mean reward: 0.810 [0.225, 1.000], mean action: 29.150 [5.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.260895, mean_absolute_error: 5.203666, mean_q: 5.892347
847 (array([21]),) False
 119800/500000: episode: 2995, duration: 32.960s, episode steps: 40, steps per second: 1, episode reward: 32.151, mean reward: 0.804 [0.167, 1.000], mean action: 20.350 [2.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.248323, mean_absolute_error: 5.294422, mean_q: 5.986313
606 (array([22]),) False
 119840/500000: episode: 2996, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 34.163, mean reward: 0.854 [0.098, 1.000], mean action: 20.550 [3.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.296568, mean_absolute_error: 5.209234, mean_q: 5.899889
487 (array([48]),) False
 119880/500000: episode: 2997, duration: 32.147s, episode steps: 40, steps per second: 1, episode reward: 36.927, mean reward: 0.923 [0.291, 1.000], mean action: 18.400 [5.000, 42.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.226514, mean_absolute_error: 5.247210, mean_q: 5.939003
44 (array([22]),) False
 119920/500000: episode: 2998, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 34.039, mean reward: 0.851 [0.085, 1.000], mean action: 27.650 [14.000, 55.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.241028, mean_absolute_error: 5.161283, mean_q: 5.848053
850 (array([12]),) False
 119960/500000: episode: 2999, duration: 32.187s, episode steps: 40, steps per second: 1, episode reward: 30.317, mean reward: 0.758 [0.298, 1.000], mean action: 16.475 [10.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.235019, mean_absolute_error: 5.211911, mean_q: 5.900144
619 (array([3]),) False
 120000/500000: episode: 3000, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 19.573, mean reward: 0.489 [0.000, 1.000], mean action: 27.900 [3.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.247139, mean_absolute_error: 5.255657, mean_q: 5.950516
689 (array([12]),) False
 120040/500000: episode: 3001, duration: 32.114s, episode steps: 40, steps per second: 1, episode reward: 30.758, mean reward: 0.769 [0.182, 0.865], mean action: 22.825 [1.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.250743, mean_absolute_error: 5.184242, mean_q: 5.880193
525 (array([22]),) False
 120080/500000: episode: 3002, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 35.691, mean reward: 0.892 [0.019, 1.000], mean action: 21.725 [8.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.286839, mean_absolute_error: 5.294685, mean_q: 6.002380
368 (array([22]),) False
 120120/500000: episode: 3003, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 33.421, mean reward: 0.836 [0.236, 1.000], mean action: 31.575 [0.000, 52.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.262310, mean_absolute_error: 5.224818, mean_q: 5.934894
445 (array([22]),) False
 120160/500000: episode: 3004, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 35.785, mean reward: 0.895 [0.063, 1.000], mean action: 24.875 [12.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.252091, mean_absolute_error: 5.199111, mean_q: 5.902627
127 (array([22]),) False
 120200/500000: episode: 3005, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 30.223, mean reward: 0.756 [0.042, 1.000], mean action: 15.875 [4.000, 59.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.252573, mean_absolute_error: 5.213632, mean_q: 5.914754
453 (array([22]),) False
 120240/500000: episode: 3006, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 31.194, mean reward: 0.780 [0.094, 1.000], mean action: 24.200 [1.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.238247, mean_absolute_error: 5.273169, mean_q: 5.975616
293 (array([22]),) False
 120280/500000: episode: 3007, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 35.500, mean reward: 0.888 [0.072, 1.000], mean action: 24.300 [0.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.263567, mean_absolute_error: 5.240725, mean_q: 5.931824
164 (array([22]),) False
 120320/500000: episode: 3008, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 32.070, mean reward: 0.802 [0.000, 1.000], mean action: 28.025 [6.000, 54.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.254819, mean_absolute_error: 5.258539, mean_q: 5.955724
577 (array([12]),) False
 120360/500000: episode: 3009, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 35.605, mean reward: 0.890 [0.015, 1.000], mean action: 23.850 [3.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.266137, mean_absolute_error: 5.223491, mean_q: 5.918239
434 (array([22]),) False
 120400/500000: episode: 3010, duration: 32.953s, episode steps: 40, steps per second: 1, episode reward: 18.014, mean reward: 0.450 [0.233, 1.000], mean action: 48.750 [0.000, 54.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.283262, mean_absolute_error: 5.254169, mean_q: 5.944166
639 (array([22]),) False
 120440/500000: episode: 3011, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 30.935, mean reward: 0.773 [0.000, 1.000], mean action: 26.900 [3.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.251776, mean_absolute_error: 5.221858, mean_q: 5.907979
757 (array([48]),) False
 120480/500000: episode: 3012, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 35.846, mean reward: 0.896 [0.177, 1.000], mean action: 26.125 [1.000, 49.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.245059, mean_absolute_error: 5.219425, mean_q: 5.904741
741 (array([22]),) False
 120520/500000: episode: 3013, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 36.359, mean reward: 0.909 [0.180, 1.000], mean action: 15.800 [8.000, 51.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.248910, mean_absolute_error: 5.207763, mean_q: 5.897416
9 (array([14]),) False
 120560/500000: episode: 3014, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 33.122, mean reward: 0.828 [0.393, 1.000], mean action: 26.025 [13.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.253955, mean_absolute_error: 5.199071, mean_q: 5.888330
262 (array([22]),) False
 120600/500000: episode: 3015, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 29.530, mean reward: 0.738 [0.225, 1.000], mean action: 20.900 [4.000, 34.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.263296, mean_absolute_error: 5.232747, mean_q: 5.920842
82 (array([22]),) False
 120640/500000: episode: 3016, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 34.213, mean reward: 0.855 [0.018, 1.000], mean action: 24.050 [3.000, 53.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.226689, mean_absolute_error: 5.293507, mean_q: 5.984233
259 (array([12]),) False
 120680/500000: episode: 3017, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 31.251, mean reward: 0.781 [0.267, 1.000], mean action: 23.775 [0.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.279698, mean_absolute_error: 5.168256, mean_q: 5.857229
759 (array([48]),) False
 120720/500000: episode: 3018, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 33.314, mean reward: 0.833 [0.199, 1.000], mean action: 26.825 [10.000, 47.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.290812, mean_absolute_error: 5.164995, mean_q: 5.852643
174 (array([33]),) False
 120760/500000: episode: 3019, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 20.933, mean reward: 0.523 [0.155, 0.996], mean action: 22.875 [12.000, 60.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.230146, mean_absolute_error: 5.253480, mean_q: 5.936915
478 (array([22]),) False
 120800/500000: episode: 3020, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 37.024, mean reward: 0.926 [0.063, 1.000], mean action: 22.300 [2.000, 54.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.267491, mean_absolute_error: 5.193934, mean_q: 5.878863
246 (array([22]),) False
 120840/500000: episode: 3021, duration: 32.098s, episode steps: 40, steps per second: 1, episode reward: 35.306, mean reward: 0.883 [0.250, 1.000], mean action: 25.600 [14.000, 57.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.258905, mean_absolute_error: 5.256472, mean_q: 5.946342
190 (array([3]),) False
 120880/500000: episode: 3022, duration: 32.891s, episode steps: 40, steps per second: 1, episode reward: 25.262, mean reward: 0.632 [0.307, 0.811], mean action: 38.575 [6.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.269400, mean_absolute_error: 5.252688, mean_q: 5.940099
625 (array([22]),) False
 120920/500000: episode: 3023, duration: 32.122s, episode steps: 40, steps per second: 1, episode reward: 35.193, mean reward: 0.880 [0.000, 1.000], mean action: 33.500 [5.000, 53.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.258467, mean_absolute_error: 5.260818, mean_q: 5.945240
831 (array([3]),) False
 120960/500000: episode: 3024, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 16.846, mean reward: 0.421 [0.002, 0.958], mean action: 29.750 [5.000, 60.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.254930, mean_absolute_error: 5.218934, mean_q: 5.893616
693 (array([22]),) False
 121000/500000: episode: 3025, duration: 32.134s, episode steps: 40, steps per second: 1, episode reward: 38.426, mean reward: 0.961 [0.364, 1.000], mean action: 22.475 [14.000, 39.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.270007, mean_absolute_error: 5.337893, mean_q: 6.027644
374 (array([22]),) False
 121040/500000: episode: 3026, duration: 32.972s, episode steps: 40, steps per second: 1, episode reward: 37.840, mean reward: 0.946 [0.348, 1.000], mean action: 24.100 [14.000, 52.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.263381, mean_absolute_error: 5.302541, mean_q: 5.990700
598 (array([22]),) False
 121080/500000: episode: 3027, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 38.077, mean reward: 0.952 [0.120, 1.000], mean action: 21.675 [9.000, 47.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.292206, mean_absolute_error: 5.309422, mean_q: 5.995826
126 (array([22]),) False
 121120/500000: episode: 3028, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 33.411, mean reward: 0.835 [0.127, 1.000], mean action: 18.100 [2.000, 59.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.276934, mean_absolute_error: 5.260146, mean_q: 5.951732
622 (array([36]),) False
 121160/500000: episode: 3029, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 10.576, mean reward: 0.264 [0.202, 0.680], mean action: 31.800 [1.000, 48.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.271448, mean_absolute_error: 5.273905, mean_q: 5.958213
370 (array([58]),) False
 121200/500000: episode: 3030, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 22.995, mean reward: 0.575 [0.000, 1.000], mean action: 28.100 [12.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.250410, mean_absolute_error: 5.303998, mean_q: 5.998624
61 (array([48]),) False
 121240/500000: episode: 3031, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 34.170, mean reward: 0.854 [0.126, 1.000], mean action: 20.900 [1.000, 44.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.300811, mean_absolute_error: 5.260133, mean_q: 5.948838
553 (array([22]),) False
 121280/500000: episode: 3032, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 32.425, mean reward: 0.811 [0.000, 1.000], mean action: 17.700 [0.000, 60.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.234458, mean_absolute_error: 5.304713, mean_q: 5.998907
411 (array([22]),) False
 121320/500000: episode: 3033, duration: 32.070s, episode steps: 40, steps per second: 1, episode reward: 27.074, mean reward: 0.677 [0.098, 1.000], mean action: 38.125 [2.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.311254, mean_absolute_error: 5.281199, mean_q: 5.972498
704 (array([22]),) False
 121360/500000: episode: 3034, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 25.475, mean reward: 0.637 [0.240, 1.000], mean action: 14.050 [3.000, 55.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.259400, mean_absolute_error: 5.282843, mean_q: 5.976204
71 (array([58]),) False
 121400/500000: episode: 3035, duration: 32.115s, episode steps: 40, steps per second: 1, episode reward: 20.860, mean reward: 0.521 [0.040, 0.924], mean action: 30.475 [4.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.268553, mean_absolute_error: 5.379365, mean_q: 6.079527
470 (array([22]),) False
 121440/500000: episode: 3036, duration: 32.968s, episode steps: 40, steps per second: 1, episode reward: 33.754, mean reward: 0.844 [0.000, 1.000], mean action: 25.725 [3.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.238230, mean_absolute_error: 5.245459, mean_q: 5.944308
414 (array([48]),) False
 121480/500000: episode: 3037, duration: 32.174s, episode steps: 40, steps per second: 1, episode reward: 28.419, mean reward: 0.710 [0.012, 1.000], mean action: 24.025 [2.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.243682, mean_absolute_error: 5.327484, mean_q: 6.032197
187 (array([15]),) False
 121520/500000: episode: 3038, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 35.668, mean reward: 0.892 [0.108, 1.000], mean action: 14.300 [4.000, 36.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.251497, mean_absolute_error: 5.354183, mean_q: 6.062264
505 (array([22]),) False
 121560/500000: episode: 3039, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 32.109, mean reward: 0.803 [0.163, 1.000], mean action: 20.000 [0.000, 49.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.281686, mean_absolute_error: 5.280217, mean_q: 5.976168
793 (array([12]),) False
 121600/500000: episode: 3040, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 37.166, mean reward: 0.929 [0.042, 1.000], mean action: 11.675 [5.000, 14.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.304796, mean_absolute_error: 5.282164, mean_q: 5.984281
27 (array([22]),) False
 121640/500000: episode: 3041, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 37.889, mean reward: 0.947 [0.220, 1.000], mean action: 22.775 [4.000, 49.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.283664, mean_absolute_error: 5.304623, mean_q: 6.006670
735 (array([22]),) False
 121680/500000: episode: 3042, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 37.084, mean reward: 0.927 [0.306, 1.000], mean action: 22.175 [0.000, 44.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.247371, mean_absolute_error: 5.264634, mean_q: 5.965516
163 (array([44]),) False
 121720/500000: episode: 3043, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 36.070, mean reward: 0.902 [0.303, 0.999], mean action: 17.875 [8.000, 52.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.306709, mean_absolute_error: 5.342809, mean_q: 6.044250
207 (array([36]),) False
 121760/500000: episode: 3044, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 23.023, mean reward: 0.576 [0.000, 0.853], mean action: 15.200 [12.000, 59.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.239546, mean_absolute_error: 5.326322, mean_q: 6.028876
361 (array([22]),) False
 121800/500000: episode: 3045, duration: 32.206s, episode steps: 40, steps per second: 1, episode reward: 35.603, mean reward: 0.890 [0.253, 1.000], mean action: 23.475 [19.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.288192, mean_absolute_error: 5.238542, mean_q: 5.933749
45 (array([22]),) False
 121840/500000: episode: 3046, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 33.329, mean reward: 0.833 [0.076, 1.000], mean action: 23.575 [1.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.257744, mean_absolute_error: 5.231513, mean_q: 5.918643
389 (array([48]),) False
 121880/500000: episode: 3047, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 36.787, mean reward: 0.920 [0.318, 0.978], mean action: 24.175 [22.000, 44.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.292737, mean_absolute_error: 5.327680, mean_q: 6.032284
512 (array([48]),) False
 121920/500000: episode: 3048, duration: 32.986s, episode steps: 40, steps per second: 1, episode reward: 36.171, mean reward: 0.904 [0.106, 1.000], mean action: 13.825 [12.000, 38.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.291601, mean_absolute_error: 5.211010, mean_q: 5.903602
647 (array([22]),) False
 121960/500000: episode: 3049, duration: 32.103s, episode steps: 40, steps per second: 1, episode reward: 35.964, mean reward: 0.899 [0.000, 1.000], mean action: 20.100 [0.000, 22.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.256770, mean_absolute_error: 5.211767, mean_q: 5.904532
532 (array([25]),) False
 122000/500000: episode: 3050, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 22.715, mean reward: 0.568 [0.105, 0.753], mean action: 19.225 [12.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.231542, mean_absolute_error: 5.184863, mean_q: 5.876107
271 (array([18]),) False
 122040/500000: episode: 3051, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 34.213, mean reward: 0.855 [0.432, 1.000], mean action: 20.700 [12.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.220336, mean_absolute_error: 5.276640, mean_q: 5.966682
61 (array([48]),) False
 122080/500000: episode: 3052, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 32.760, mean reward: 0.819 [0.053, 1.000], mean action: 19.425 [3.000, 47.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.278184, mean_absolute_error: 5.218162, mean_q: 5.905152
193 (array([36]),) False
 122120/500000: episode: 3053, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 30.613, mean reward: 0.765 [0.187, 1.000], mean action: 28.800 [9.000, 58.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.239474, mean_absolute_error: 5.261368, mean_q: 5.957527
576 (array([58]),) False
 122160/500000: episode: 3054, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 20.089, mean reward: 0.502 [0.053, 0.850], mean action: 24.450 [8.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.241028, mean_absolute_error: 5.218628, mean_q: 5.910715
298 (array([22]),) False
 122200/500000: episode: 3055, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 33.486, mean reward: 0.837 [0.165, 1.000], mean action: 25.075 [3.000, 49.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.277756, mean_absolute_error: 5.184622, mean_q: 5.870574
815 (array([22]),) False
 122240/500000: episode: 3056, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 29.643, mean reward: 0.741 [0.118, 1.000], mean action: 16.900 [0.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.306758, mean_absolute_error: 5.324627, mean_q: 6.019296
277 (array([56]),) False
 122280/500000: episode: 3057, duration: 32.203s, episode steps: 40, steps per second: 1, episode reward: 29.503, mean reward: 0.738 [0.224, 0.873], mean action: 23.175 [6.000, 52.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.280845, mean_absolute_error: 5.238645, mean_q: 5.922969
419 (array([40]),) False
 122320/500000: episode: 3058, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 34.340, mean reward: 0.859 [0.318, 1.000], mean action: 21.975 [1.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.254409, mean_absolute_error: 5.165898, mean_q: 5.848221
456 (array([22]),) False
 122360/500000: episode: 3059, duration: 32.132s, episode steps: 40, steps per second: 1, episode reward: 36.925, mean reward: 0.923 [0.127, 1.000], mean action: 23.675 [8.000, 55.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.235215, mean_absolute_error: 5.194955, mean_q: 5.877800
862 (array([14]),) False
 122400/500000: episode: 3060, duration: 33.007s, episode steps: 40, steps per second: 1, episode reward: 35.127, mean reward: 0.878 [0.230, 1.000], mean action: 17.400 [12.000, 41.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.284560, mean_absolute_error: 5.205315, mean_q: 5.889771
425 (array([22]),) False
 122440/500000: episode: 3061, duration: 32.120s, episode steps: 40, steps per second: 1, episode reward: 33.669, mean reward: 0.842 [0.000, 1.000], mean action: 27.975 [4.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.254587, mean_absolute_error: 5.133554, mean_q: 5.825702
75 (array([22]),) False
 122480/500000: episode: 3062, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 35.269, mean reward: 0.882 [0.117, 1.000], mean action: 25.450 [1.000, 60.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.264372, mean_absolute_error: 5.218459, mean_q: 5.917922
29 (array([22]),) False
 122520/500000: episode: 3063, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 37.885, mean reward: 0.947 [0.533, 1.000], mean action: 26.800 [21.000, 49.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.282350, mean_absolute_error: 5.177224, mean_q: 5.866712
118 (array([22]),) False
 122560/500000: episode: 3064, duration: 33.091s, episode steps: 40, steps per second: 1, episode reward: 26.502, mean reward: 0.663 [0.000, 1.000], mean action: 18.500 [5.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.265487, mean_absolute_error: 5.165920, mean_q: 5.852449
729 (array([22]),) False
 122600/500000: episode: 3065, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 32.264, mean reward: 0.807 [0.298, 1.000], mean action: 20.725 [2.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.279573, mean_absolute_error: 5.167643, mean_q: 5.861681
302 (array([22]),) False
 122640/500000: episode: 3066, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 37.212, mean reward: 0.930 [0.231, 1.000], mean action: 23.975 [13.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.249901, mean_absolute_error: 5.187228, mean_q: 5.880384
633 (array([22]),) False
 122680/500000: episode: 3067, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 33.632, mean reward: 0.841 [0.101, 1.000], mean action: 23.775 [2.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.272823, mean_absolute_error: 5.184278, mean_q: 5.866801
795 (array([3]),) False
 122720/500000: episode: 3068, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 20.639, mean reward: 0.516 [0.000, 0.924], mean action: 14.000 [4.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.229783, mean_absolute_error: 5.153641, mean_q: 5.835855
415 (array([22]),) False
 122760/500000: episode: 3069, duration: 32.161s, episode steps: 40, steps per second: 1, episode reward: 34.680, mean reward: 0.867 [0.016, 1.000], mean action: 24.300 [1.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.233124, mean_absolute_error: 5.168461, mean_q: 5.852801
812 (array([22]),) False
 122800/500000: episode: 3070, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 32.893, mean reward: 0.822 [0.555, 0.913], mean action: 19.875 [12.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.241761, mean_absolute_error: 5.175603, mean_q: 5.859458
240 (array([22]),) False
 122840/500000: episode: 3071, duration: 32.121s, episode steps: 40, steps per second: 1, episode reward: 31.463, mean reward: 0.787 [0.067, 1.000], mean action: 26.425 [7.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.266940, mean_absolute_error: 5.175957, mean_q: 5.865077
845 (array([22]),) False
 122880/500000: episode: 3072, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 33.675, mean reward: 0.842 [0.022, 1.000], mean action: 23.075 [9.000, 53.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.266478, mean_absolute_error: 5.119296, mean_q: 5.810493
570 (array([47]),) False
 122920/500000: episode: 3073, duration: 32.100s, episode steps: 40, steps per second: 1, episode reward: 27.318, mean reward: 0.683 [0.095, 1.000], mean action: 22.425 [12.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.241241, mean_absolute_error: 5.118785, mean_q: 5.808617
478 (array([22]),) False
 122960/500000: episode: 3074, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 35.013, mean reward: 0.875 [0.100, 1.000], mean action: 23.075 [5.000, 60.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.268362, mean_absolute_error: 5.209712, mean_q: 5.896559
799 (array([36]),) False
 123000/500000: episode: 3075, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 22.163, mean reward: 0.554 [0.199, 0.995], mean action: 16.925 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.254430, mean_absolute_error: 5.224577, mean_q: 5.909305
799 (array([36]),) False
 123040/500000: episode: 3076, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 21.410, mean reward: 0.535 [0.086, 0.995], mean action: 14.750 [0.000, 42.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.254303, mean_absolute_error: 5.203880, mean_q: 5.883606
738 (array([12]),) False
 123080/500000: episode: 3077, duration: 32.977s, episode steps: 40, steps per second: 1, episode reward: 34.912, mean reward: 0.873 [0.279, 1.000], mean action: 15.025 [2.000, 39.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.269166, mean_absolute_error: 5.259039, mean_q: 5.940234
114 (array([22]),) False
 123120/500000: episode: 3078, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 34.671, mean reward: 0.867 [0.226, 1.000], mean action: 15.000 [12.000, 47.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.229983, mean_absolute_error: 5.224258, mean_q: 5.913680
205 (array([22]),) False
 123160/500000: episode: 3079, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 29.607, mean reward: 0.740 [0.221, 0.788], mean action: 14.400 [5.000, 48.000], mean observation: -0.181 [-1.000, 1.000], loss: 0.261063, mean_absolute_error: 5.113182, mean_q: 5.801724
14 (array([48]),) False
 123200/500000: episode: 3080, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 34.110, mean reward: 0.853 [0.000, 1.000], mean action: 28.750 [15.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.241411, mean_absolute_error: 5.198262, mean_q: 5.889018
709 (array([41]),) False
 123240/500000: episode: 3081, duration: 32.167s, episode steps: 40, steps per second: 1, episode reward: 22.184, mean reward: 0.555 [0.374, 0.937], mean action: 14.175 [3.000, 33.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.264226, mean_absolute_error: 5.168235, mean_q: 5.851367
790 (array([48]),) False
 123280/500000: episode: 3082, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 29.709, mean reward: 0.743 [0.158, 1.000], mean action: 21.350 [2.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.240896, mean_absolute_error: 5.238545, mean_q: 5.926891
136 (array([12]),) False
 123320/500000: episode: 3083, duration: 32.081s, episode steps: 40, steps per second: 1, episode reward: 29.709, mean reward: 0.743 [0.110, 0.936], mean action: 26.150 [7.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.259863, mean_absolute_error: 5.177664, mean_q: 5.862659
599 (array([48]),) False
 123360/500000: episode: 3084, duration: 32.963s, episode steps: 40, steps per second: 1, episode reward: 28.571, mean reward: 0.714 [0.155, 1.000], mean action: 21.825 [1.000, 48.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.262072, mean_absolute_error: 5.282400, mean_q: 5.974558
850 (array([12]),) False
 123400/500000: episode: 3085, duration: 32.123s, episode steps: 40, steps per second: 1, episode reward: 28.417, mean reward: 0.710 [0.164, 1.000], mean action: 18.050 [6.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.226300, mean_absolute_error: 5.103125, mean_q: 5.786721
750 (array([22]),) False
 123440/500000: episode: 3086, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 33.574, mean reward: 0.839 [0.056, 1.000], mean action: 18.950 [1.000, 35.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.250499, mean_absolute_error: 5.208975, mean_q: 5.894594
846 (array([48]),) False
 123480/500000: episode: 3087, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 35.538, mean reward: 0.888 [0.261, 0.974], mean action: 18.725 [10.000, 53.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.253076, mean_absolute_error: 5.243272, mean_q: 5.932469
570 (array([47]),) False
 123520/500000: episode: 3088, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 29.033, mean reward: 0.726 [0.000, 1.000], mean action: 18.150 [4.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.271959, mean_absolute_error: 5.184922, mean_q: 5.874623
710 (array([12]),) False
 123560/500000: episode: 3089, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 30.951, mean reward: 0.774 [0.408, 1.000], mean action: 20.400 [5.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.262173, mean_absolute_error: 5.208135, mean_q: 5.903595
837 (array([48]),) False
 123600/500000: episode: 3090, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 35.665, mean reward: 0.892 [0.246, 0.975], mean action: 23.325 [1.000, 60.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.288830, mean_absolute_error: 5.209554, mean_q: 5.906030
206 (array([22]),) False
 123640/500000: episode: 3091, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 29.263, mean reward: 0.732 [0.112, 1.000], mean action: 15.400 [9.000, 59.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.265380, mean_absolute_error: 5.173058, mean_q: 5.866697
38 (array([22]),) False
 123680/500000: episode: 3092, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 36.334, mean reward: 0.908 [0.051, 1.000], mean action: 24.100 [5.000, 56.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.288935, mean_absolute_error: 5.184261, mean_q: 5.882602
455 (array([22]),) False
 123720/500000: episode: 3093, duration: 32.147s, episode steps: 40, steps per second: 1, episode reward: 36.827, mean reward: 0.921 [0.318, 1.000], mean action: 22.625 [0.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.250488, mean_absolute_error: 5.172294, mean_q: 5.873465
790 (array([48]),) False
 123760/500000: episode: 3094, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 28.503, mean reward: 0.713 [0.000, 1.000], mean action: 19.925 [2.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.254398, mean_absolute_error: 5.182570, mean_q: 5.881270
151 (array([22]),) False
 123800/500000: episode: 3095, duration: 32.178s, episode steps: 40, steps per second: 1, episode reward: 32.390, mean reward: 0.810 [0.148, 0.961], mean action: 17.150 [12.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.271654, mean_absolute_error: 5.148239, mean_q: 5.843987
337 (array([22]),) False
 123840/500000: episode: 3096, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 34.751, mean reward: 0.869 [0.021, 1.000], mean action: 20.000 [1.000, 44.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.260296, mean_absolute_error: 5.205467, mean_q: 5.900479
44 (array([22]),) False
 123880/500000: episode: 3097, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 36.273, mean reward: 0.907 [0.157, 1.000], mean action: 23.550 [5.000, 49.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.256248, mean_absolute_error: 5.229512, mean_q: 5.917224
551 (array([22]),) False
 123920/500000: episode: 3098, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 34.392, mean reward: 0.860 [0.088, 1.000], mean action: 15.550 [2.000, 59.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.249995, mean_absolute_error: 5.272061, mean_q: 5.963954
767 (array([48]),) False
 123960/500000: episode: 3099, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 27.722, mean reward: 0.693 [0.148, 0.895], mean action: 23.925 [11.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.307250, mean_absolute_error: 5.167975, mean_q: 5.850614
96 (array([22]),) False
 124000/500000: episode: 3100, duration: 33.009s, episode steps: 40, steps per second: 1, episode reward: 38.004, mean reward: 0.950 [0.112, 1.000], mean action: 23.225 [16.000, 51.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.253575, mean_absolute_error: 5.181213, mean_q: 5.873028
624 (array([48]),) False
 124040/500000: episode: 3101, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 37.391, mean reward: 0.935 [0.348, 1.000], mean action: 39.400 [12.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.261942, mean_absolute_error: 5.227061, mean_q: 5.911368
362 (array([22]),) False
 124080/500000: episode: 3102, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 34.135, mean reward: 0.853 [0.004, 1.000], mean action: 24.700 [15.000, 56.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.273689, mean_absolute_error: 5.211505, mean_q: 5.901068
505 (array([22]),) False
 124120/500000: episode: 3103, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 34.818, mean reward: 0.870 [0.000, 1.000], mean action: 20.025 [12.000, 52.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.270478, mean_absolute_error: 5.177299, mean_q: 5.859730
512 (array([48]),) False
 124160/500000: episode: 3104, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 32.415, mean reward: 0.810 [0.051, 1.000], mean action: 13.825 [2.000, 43.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.217564, mean_absolute_error: 5.124401, mean_q: 5.809390
406 (array([48]),) False
 124200/500000: episode: 3105, duration: 32.158s, episode steps: 40, steps per second: 1, episode reward: 35.897, mean reward: 0.897 [0.117, 1.000], mean action: 23.100 [5.000, 47.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.241570, mean_absolute_error: 5.224574, mean_q: 5.910386
321 (array([22]),) False
 124240/500000: episode: 3106, duration: 32.977s, episode steps: 40, steps per second: 1, episode reward: 39.203, mean reward: 0.980 [0.654, 1.000], mean action: 19.800 [12.000, 22.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.259570, mean_absolute_error: 5.218157, mean_q: 5.908238
855 (array([12]),) False
 124280/500000: episode: 3107, duration: 32.245s, episode steps: 40, steps per second: 1, episode reward: 35.479, mean reward: 0.887 [0.188, 1.000], mean action: 12.350 [1.000, 28.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.237394, mean_absolute_error: 5.141604, mean_q: 5.839860
541 (array([57]),) False
 124320/500000: episode: 3108, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 25.629, mean reward: 0.641 [0.153, 0.846], mean action: 27.450 [4.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.247485, mean_absolute_error: 5.347259, mean_q: 6.050185
42 (array([22]),) False
 124360/500000: episode: 3109, duration: 32.123s, episode steps: 40, steps per second: 1, episode reward: 34.932, mean reward: 0.873 [0.000, 1.000], mean action: 25.325 [3.000, 50.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.260919, mean_absolute_error: 5.209103, mean_q: 5.906600
747 (array([22]),) False
 124400/500000: episode: 3110, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 36.155, mean reward: 0.904 [0.156, 1.000], mean action: 19.750 [10.000, 60.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.231477, mean_absolute_error: 5.214602, mean_q: 5.909558
2 (array([12]),) False
 124440/500000: episode: 3111, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 28.014, mean reward: 0.700 [0.042, 0.832], mean action: 22.275 [5.000, 59.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.275505, mean_absolute_error: 5.283759, mean_q: 5.982200
747 (array([22]),) False
 124480/500000: episode: 3112, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 36.790, mean reward: 0.920 [0.169, 1.000], mean action: 20.400 [7.000, 53.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.260763, mean_absolute_error: 5.196891, mean_q: 5.893878
662 (array([12]),) False
 124520/500000: episode: 3113, duration: 32.950s, episode steps: 40, steps per second: 1, episode reward: 38.321, mean reward: 0.958 [0.113, 1.000], mean action: 13.650 [11.000, 49.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.254366, mean_absolute_error: 5.199723, mean_q: 5.896342
651 (array([22]),) False
 124560/500000: episode: 3114, duration: 32.836s, episode steps: 40, steps per second: 1, episode reward: 37.690, mean reward: 0.942 [0.390, 1.000], mean action: 22.150 [8.000, 39.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.251757, mean_absolute_error: 5.265698, mean_q: 5.967156
311 (array([22]),) False
 124600/500000: episode: 3115, duration: 32.962s, episode steps: 40, steps per second: 1, episode reward: 37.251, mean reward: 0.931 [0.246, 1.000], mean action: 26.325 [12.000, 48.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.238292, mean_absolute_error: 5.271609, mean_q: 5.969954
229 (array([48]),) False
 124640/500000: episode: 3116, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 31.870, mean reward: 0.797 [0.220, 1.000], mean action: 25.075 [12.000, 51.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.265707, mean_absolute_error: 5.230814, mean_q: 5.928215
572 (array([58]),) False
 124680/500000: episode: 3117, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 20.336, mean reward: 0.508 [0.000, 0.967], mean action: 26.775 [12.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.233082, mean_absolute_error: 5.198599, mean_q: 5.903331
154 (array([44]),) False
 124720/500000: episode: 3118, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 34.184, mean reward: 0.855 [0.079, 0.998], mean action: 16.900 [2.000, 51.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.233973, mean_absolute_error: 5.240803, mean_q: 5.947799
810 (array([12]),) False
 124760/500000: episode: 3119, duration: 32.199s, episode steps: 40, steps per second: 1, episode reward: 35.746, mean reward: 0.894 [0.267, 1.000], mean action: 27.050 [12.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.220302, mean_absolute_error: 5.255910, mean_q: 5.949522
28 (array([58]),) False
 124800/500000: episode: 3120, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 21.627, mean reward: 0.541 [0.000, 1.000], mean action: 30.675 [15.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.259501, mean_absolute_error: 5.260985, mean_q: 5.952968
771 (array([12]),) False
 124840/500000: episode: 3121, duration: 32.125s, episode steps: 40, steps per second: 1, episode reward: 35.233, mean reward: 0.881 [0.099, 1.000], mean action: 16.175 [10.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.279571, mean_absolute_error: 5.273612, mean_q: 5.976100
95 (array([22]),) False
 124880/500000: episode: 3122, duration: 32.989s, episode steps: 40, steps per second: 1, episode reward: 34.717, mean reward: 0.868 [0.322, 1.000], mean action: 22.600 [5.000, 50.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.248831, mean_absolute_error: 5.204328, mean_q: 5.902488
505 (array([22]),) False
 124920/500000: episode: 3123, duration: 32.921s, episode steps: 40, steps per second: 1, episode reward: 34.894, mean reward: 0.872 [0.199, 1.000], mean action: 22.025 [1.000, 48.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.251100, mean_absolute_error: 5.244302, mean_q: 5.940660
169 (array([22]),) False
 124960/500000: episode: 3124, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 35.189, mean reward: 0.880 [0.148, 1.000], mean action: 18.300 [5.000, 58.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.281481, mean_absolute_error: 5.322995, mean_q: 6.019076
421 (array([22]),) False
 125000/500000: episode: 3125, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 25.821, mean reward: 0.646 [0.000, 1.000], mean action: 25.225 [3.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.251744, mean_absolute_error: 5.242707, mean_q: 5.932949
615 (array([36]),) False
 125040/500000: episode: 3126, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 22.974, mean reward: 0.574 [0.305, 0.964], mean action: 19.950 [3.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.284609, mean_absolute_error: 5.286759, mean_q: 5.988769
344 (array([22]),) False
 125080/500000: episode: 3127, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 28.485, mean reward: 0.712 [0.075, 1.000], mean action: 22.175 [6.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.263643, mean_absolute_error: 5.220411, mean_q: 5.913911
536 (array([22]),) False
 125120/500000: episode: 3128, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 30.299, mean reward: 0.757 [0.120, 1.000], mean action: 17.925 [1.000, 55.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.239858, mean_absolute_error: 5.259125, mean_q: 5.969541
761 (array([3]),) False
 125160/500000: episode: 3129, duration: 32.158s, episode steps: 40, steps per second: 1, episode reward: 15.530, mean reward: 0.388 [0.000, 0.720], mean action: 28.625 [12.000, 53.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.291012, mean_absolute_error: 5.267352, mean_q: 5.974898
629 (array([22]),) False
 125200/500000: episode: 3130, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 34.526, mean reward: 0.863 [0.000, 1.000], mean action: 23.350 [12.000, 57.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.264874, mean_absolute_error: 5.258573, mean_q: 5.975844
617 (array([22]),) False
 125240/500000: episode: 3131, duration: 32.070s, episode steps: 40, steps per second: 1, episode reward: 37.832, mean reward: 0.946 [0.389, 1.000], mean action: 16.100 [4.000, 25.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.296104, mean_absolute_error: 5.247816, mean_q: 5.955068
731 (array([21]),) False
 125280/500000: episode: 3132, duration: 33.009s, episode steps: 40, steps per second: 1, episode reward: 33.552, mean reward: 0.839 [0.084, 1.000], mean action: 21.675 [12.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.246917, mean_absolute_error: 5.245595, mean_q: 5.940129
790 (array([48]),) False
 125320/500000: episode: 3133, duration: 32.229s, episode steps: 40, steps per second: 1, episode reward: 30.398, mean reward: 0.760 [0.086, 1.000], mean action: 25.725 [1.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.289024, mean_absolute_error: 5.239218, mean_q: 5.934501
486 (array([22]),) False
 125360/500000: episode: 3134, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 34.852, mean reward: 0.871 [0.181, 1.000], mean action: 24.225 [4.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.271419, mean_absolute_error: 5.198665, mean_q: 5.895444
236 (array([22]),) False
 125400/500000: episode: 3135, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 36.542, mean reward: 0.914 [0.188, 1.000], mean action: 23.825 [12.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.257080, mean_absolute_error: 5.206934, mean_q: 5.898418
810 (array([12]),) False
 125440/500000: episode: 3136, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 34.320, mean reward: 0.858 [0.399, 0.959], mean action: 28.175 [5.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.237106, mean_absolute_error: 5.170194, mean_q: 5.859463
814 (array([22]),) False
 125480/500000: episode: 3137, duration: 33.008s, episode steps: 40, steps per second: 1, episode reward: 32.797, mean reward: 0.820 [0.159, 1.000], mean action: 18.850 [2.000, 49.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.245855, mean_absolute_error: 5.241625, mean_q: 5.935229
509 (array([22]),) False
 125520/500000: episode: 3138, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 37.875, mean reward: 0.947 [0.138, 1.000], mean action: 22.400 [6.000, 50.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.234036, mean_absolute_error: 5.277505, mean_q: 5.970374
457 (array([38]),) False
 125560/500000: episode: 3139, duration: 32.959s, episode steps: 40, steps per second: 1, episode reward: 31.003, mean reward: 0.775 [0.265, 1.000], mean action: 22.175 [9.000, 38.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.283511, mean_absolute_error: 5.286310, mean_q: 5.975673
709 (array([41]),) False
 125600/500000: episode: 3140, duration: 32.980s, episode steps: 40, steps per second: 1, episode reward: 21.723, mean reward: 0.543 [0.352, 0.778], mean action: 15.450 [0.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.234463, mean_absolute_error: 5.152387, mean_q: 5.842679
65 (array([48]),) False
 125640/500000: episode: 3141, duration: 32.115s, episode steps: 40, steps per second: 1, episode reward: 35.419, mean reward: 0.885 [0.195, 1.000], mean action: 30.500 [12.000, 57.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.234407, mean_absolute_error: 5.206111, mean_q: 5.890329
428 (array([22]),) False
 125680/500000: episode: 3142, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 36.449, mean reward: 0.911 [0.107, 1.000], mean action: 23.000 [1.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.256175, mean_absolute_error: 5.266123, mean_q: 5.953518
10 (array([3]),) False
 125720/500000: episode: 3143, duration: 32.137s, episode steps: 40, steps per second: 1, episode reward: 25.550, mean reward: 0.639 [0.000, 1.000], mean action: 24.575 [11.000, 53.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.281924, mean_absolute_error: 5.222859, mean_q: 5.906368
695 (array([22]),) False
 125760/500000: episode: 3144, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 30.494, mean reward: 0.762 [0.243, 1.000], mean action: 37.850 [5.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.248445, mean_absolute_error: 5.215339, mean_q: 5.895822
35 (array([48]),) False
 125800/500000: episode: 3145, duration: 32.136s, episode steps: 40, steps per second: 1, episode reward: 36.479, mean reward: 0.912 [0.054, 0.972], mean action: 35.450 [22.000, 60.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.274531, mean_absolute_error: 5.243104, mean_q: 5.926600
694 (array([22]),) False
 125840/500000: episode: 3146, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 36.660, mean reward: 0.917 [0.215, 1.000], mean action: 23.125 [12.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.268647, mean_absolute_error: 5.234496, mean_q: 5.920962
65 (array([48]),) False
 125880/500000: episode: 3147, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 36.407, mean reward: 0.910 [0.103, 1.000], mean action: 31.225 [3.000, 51.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.270917, mean_absolute_error: 5.220299, mean_q: 5.905406
791 (array([54]),) False
 125920/500000: episode: 3148, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 27.428, mean reward: 0.686 [0.241, 0.849], mean action: 16.425 [12.000, 44.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.267893, mean_absolute_error: 5.185050, mean_q: 5.870070
565 (array([12]),) False
 125960/500000: episode: 3149, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 37.303, mean reward: 0.933 [0.100, 1.000], mean action: 13.300 [6.000, 31.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.303222, mean_absolute_error: 5.171491, mean_q: 5.847815
836 (array([22]),) False
 126000/500000: episode: 3150, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 28.603, mean reward: 0.715 [0.265, 1.000], mean action: 18.325 [12.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.266457, mean_absolute_error: 5.198503, mean_q: 5.890007
777 (array([48]),) False
 126040/500000: episode: 3151, duration: 32.948s, episode steps: 40, steps per second: 1, episode reward: 33.890, mean reward: 0.847 [0.235, 0.978], mean action: 27.625 [12.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.242276, mean_absolute_error: 5.173907, mean_q: 5.861445
590 (array([22]),) False
 126080/500000: episode: 3152, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 35.996, mean reward: 0.900 [0.525, 1.000], mean action: 14.175 [12.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.273832, mean_absolute_error: 5.213106, mean_q: 5.894580
534 (array([22]),) False
 126120/500000: episode: 3153, duration: 32.095s, episode steps: 40, steps per second: 1, episode reward: 35.005, mean reward: 0.875 [0.280, 1.000], mean action: 22.650 [7.000, 55.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.257677, mean_absolute_error: 5.195802, mean_q: 5.878274
513 (array([12]),) False
 126160/500000: episode: 3154, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 39.495, mean reward: 0.987 [0.547, 1.000], mean action: 12.925 [12.000, 39.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.266425, mean_absolute_error: 5.185479, mean_q: 5.866508
622 (array([36]),) False
 126200/500000: episode: 3155, duration: 32.069s, episode steps: 40, steps per second: 1, episode reward: 18.586, mean reward: 0.465 [0.179, 0.949], mean action: 19.725 [3.000, 57.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.269786, mean_absolute_error: 5.108312, mean_q: 5.785562
191 (array([38]),) False
 126240/500000: episode: 3156, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 25.435, mean reward: 0.636 [0.215, 1.000], mean action: 16.925 [2.000, 43.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.237532, mean_absolute_error: 5.221977, mean_q: 5.909465
543 (array([12]),) False
 126280/500000: episode: 3157, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 38.275, mean reward: 0.957 [0.060, 1.000], mean action: 11.975 [3.000, 21.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.245272, mean_absolute_error: 5.216206, mean_q: 5.908484
735 (array([22]),) False
 126320/500000: episode: 3158, duration: 32.966s, episode steps: 40, steps per second: 1, episode reward: 37.691, mean reward: 0.942 [0.356, 1.000], mean action: 22.000 [12.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.279974, mean_absolute_error: 5.206494, mean_q: 5.895648
691 (array([22]),) False
 126360/500000: episode: 3159, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 36.119, mean reward: 0.903 [0.196, 1.000], mean action: 21.975 [0.000, 50.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.242238, mean_absolute_error: 5.164407, mean_q: 5.856212
279 (array([22]),) False
 126400/500000: episode: 3160, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 31.753, mean reward: 0.794 [0.289, 1.000], mean action: 22.425 [1.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.237528, mean_absolute_error: 5.179416, mean_q: 5.869752
414 (array([48]),) False
 126440/500000: episode: 3161, duration: 32.989s, episode steps: 40, steps per second: 1, episode reward: 30.861, mean reward: 0.772 [0.186, 0.845], mean action: 20.400 [12.000, 59.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.260491, mean_absolute_error: 5.210356, mean_q: 5.902078
652 (array([22]),) False
 126480/500000: episode: 3162, duration: 33.000s, episode steps: 40, steps per second: 1, episode reward: 38.067, mean reward: 0.952 [0.024, 1.000], mean action: 23.250 [22.000, 49.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.230158, mean_absolute_error: 5.193331, mean_q: 5.886786
52 (array([22]),) False
 126520/500000: episode: 3163, duration: 32.778s, episode steps: 40, steps per second: 1, episode reward: 38.106, mean reward: 0.953 [0.429, 1.000], mean action: 23.975 [0.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.244500, mean_absolute_error: 5.275493, mean_q: 5.969503
726 (array([12]),) False
 126560/500000: episode: 3164, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 37.978, mean reward: 0.949 [0.426, 1.000], mean action: 16.000 [12.000, 49.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.262777, mean_absolute_error: 5.199877, mean_q: 5.886919
267 (array([22]),) False
 126600/500000: episode: 3165, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 35.947, mean reward: 0.899 [0.000, 1.000], mean action: 26.600 [18.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.255338, mean_absolute_error: 5.328856, mean_q: 6.027493
247 (array([14]),) False
 126640/500000: episode: 3166, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 30.307, mean reward: 0.758 [0.019, 1.000], mean action: 24.175 [3.000, 49.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.252743, mean_absolute_error: 5.250308, mean_q: 5.945920
42 (array([22]),) False
 126680/500000: episode: 3167, duration: 32.084s, episode steps: 40, steps per second: 1, episode reward: 38.260, mean reward: 0.957 [0.299, 1.000], mean action: 25.025 [22.000, 50.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.234193, mean_absolute_error: 5.249918, mean_q: 5.945962
60 (array([22]),) False
 126720/500000: episode: 3168, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 36.458, mean reward: 0.911 [0.396, 1.000], mean action: 22.400 [12.000, 49.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.249177, mean_absolute_error: 5.336858, mean_q: 6.046008
717 (array([22]),) False
 126760/500000: episode: 3169, duration: 32.078s, episode steps: 40, steps per second: 1, episode reward: 36.116, mean reward: 0.903 [0.277, 1.000], mean action: 16.375 [0.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.282095, mean_absolute_error: 5.329530, mean_q: 6.025436
104 (array([22]),) False
 126800/500000: episode: 3170, duration: 32.959s, episode steps: 40, steps per second: 1, episode reward: 35.383, mean reward: 0.885 [0.044, 1.000], mean action: 21.925 [2.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.250655, mean_absolute_error: 5.341157, mean_q: 6.032214
801 (array([58]),) False
 126840/500000: episode: 3171, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 21.944, mean reward: 0.549 [0.099, 1.000], mean action: 29.425 [3.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.251984, mean_absolute_error: 5.331951, mean_q: 6.017412
826 (array([22]),) False
 126880/500000: episode: 3172, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 37.987, mean reward: 0.950 [0.296, 1.000], mean action: 22.100 [12.000, 56.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.271033, mean_absolute_error: 5.270564, mean_q: 5.959105
542 (array([44]),) False
 126920/500000: episode: 3173, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 31.955, mean reward: 0.799 [0.296, 0.921], mean action: 18.725 [0.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.245874, mean_absolute_error: 5.365000, mean_q: 6.062423
513 (array([12]),) False
 126960/500000: episode: 3174, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 35.944, mean reward: 0.899 [0.060, 1.000], mean action: 16.125 [3.000, 56.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.266578, mean_absolute_error: 5.374049, mean_q: 6.066154
345 (array([22]),) False
 127000/500000: episode: 3175, duration: 32.939s, episode steps: 40, steps per second: 1, episode reward: 33.694, mean reward: 0.842 [0.000, 1.000], mean action: 22.850 [6.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.300616, mean_absolute_error: 5.315307, mean_q: 6.012999
782 (array([22]),) False
 127040/500000: episode: 3176, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 33.023, mean reward: 0.826 [0.088, 1.000], mean action: 22.325 [5.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.249290, mean_absolute_error: 5.329120, mean_q: 6.026069
571 (array([48]),) False
 127080/500000: episode: 3177, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 26.452, mean reward: 0.661 [0.049, 1.000], mean action: 17.475 [2.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.252309, mean_absolute_error: 5.287796, mean_q: 5.985118
701 (array([48]),) False
 127120/500000: episode: 3178, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 30.795, mean reward: 0.770 [0.242, 0.986], mean action: 36.425 [1.000, 44.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.253694, mean_absolute_error: 5.449656, mean_q: 6.152433
444 (array([22]),) False
 127160/500000: episode: 3179, duration: 32.171s, episode steps: 40, steps per second: 1, episode reward: 37.744, mean reward: 0.944 [0.073, 1.000], mean action: 21.225 [2.000, 22.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.257543, mean_absolute_error: 5.260598, mean_q: 5.956866
375 (array([22]),) False
 127200/500000: episode: 3180, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 33.216, mean reward: 0.830 [0.085, 1.000], mean action: 23.250 [6.000, 44.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.260987, mean_absolute_error: 5.295507, mean_q: 5.993218
13 (array([48]),) False
 127240/500000: episode: 3181, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 34.100, mean reward: 0.853 [0.020, 0.973], mean action: 34.950 [2.000, 57.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.263030, mean_absolute_error: 5.310131, mean_q: 6.012498
643 (array([44]),) False
 127280/500000: episode: 3182, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 32.117, mean reward: 0.803 [0.225, 1.000], mean action: 24.750 [2.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.274487, mean_absolute_error: 5.314847, mean_q: 6.008773
178 (array([38]),) False
 127320/500000: episode: 3183, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 30.417, mean reward: 0.760 [0.254, 1.000], mean action: 16.000 [12.000, 48.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.254668, mean_absolute_error: 5.346818, mean_q: 6.041484
713 (array([37]),) False
 127360/500000: episode: 3184, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 31.750, mean reward: 0.794 [0.099, 0.967], mean action: 25.100 [3.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.259821, mean_absolute_error: 5.275658, mean_q: 5.967963
322 (array([12]),) False
 127400/500000: episode: 3185, duration: 32.954s, episode steps: 40, steps per second: 1, episode reward: 37.214, mean reward: 0.930 [0.230, 1.000], mean action: 15.050 [4.000, 48.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.271738, mean_absolute_error: 5.298606, mean_q: 5.988688
117 (array([44]),) False
 127440/500000: episode: 3186, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 30.413, mean reward: 0.760 [0.624, 0.900], mean action: 26.825 [12.000, 55.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.266795, mean_absolute_error: 5.249263, mean_q: 5.942306
0 (array([48]),) False
 127480/500000: episode: 3187, duration: 32.982s, episode steps: 40, steps per second: 1, episode reward: 30.304, mean reward: 0.758 [0.021, 1.000], mean action: 23.200 [3.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.269819, mean_absolute_error: 5.223791, mean_q: 5.917788
287 (array([48]),) False
 127520/500000: episode: 3188, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 30.811, mean reward: 0.770 [0.153, 1.000], mean action: 22.475 [3.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.265344, mean_absolute_error: 5.367334, mean_q: 6.064279
408 (array([12]),) False
 127560/500000: episode: 3189, duration: 32.195s, episode steps: 40, steps per second: 1, episode reward: 33.302, mean reward: 0.833 [0.109, 0.989], mean action: 28.250 [14.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.242678, mean_absolute_error: 5.227083, mean_q: 5.923667
306 (array([22]),) False
 127600/500000: episode: 3190, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 34.463, mean reward: 0.862 [0.127, 1.000], mean action: 20.600 [0.000, 42.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.262316, mean_absolute_error: 5.344026, mean_q: 6.045474
626 (array([22]),) False
 127640/500000: episode: 3191, duration: 32.108s, episode steps: 40, steps per second: 1, episode reward: 35.211, mean reward: 0.880 [0.189, 1.000], mean action: 44.175 [5.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.259475, mean_absolute_error: 5.323989, mean_q: 6.021821
709 (array([41]),) False
 127680/500000: episode: 3192, duration: 32.939s, episode steps: 40, steps per second: 1, episode reward: 19.911, mean reward: 0.498 [0.000, 0.963], mean action: 19.175 [0.000, 52.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.266224, mean_absolute_error: 5.332871, mean_q: 6.028033
265 (array([22]),) False
 127720/500000: episode: 3193, duration: 32.130s, episode steps: 40, steps per second: 1, episode reward: 34.599, mean reward: 0.865 [0.076, 1.000], mean action: 26.275 [12.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.237195, mean_absolute_error: 5.332217, mean_q: 6.024736
771 (array([12]),) False
 127760/500000: episode: 3194, duration: 32.922s, episode steps: 40, steps per second: 1, episode reward: 31.975, mean reward: 0.799 [0.000, 1.000], mean action: 31.650 [9.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.273397, mean_absolute_error: 5.304716, mean_q: 5.995227
651 (array([22]),) False
 127800/500000: episode: 3195, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 34.683, mean reward: 0.867 [0.046, 1.000], mean action: 23.800 [0.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.300618, mean_absolute_error: 5.347490, mean_q: 6.048219
604 (array([40]),) False
 127840/500000: episode: 3196, duration: 32.968s, episode steps: 40, steps per second: 1, episode reward: 33.525, mean reward: 0.838 [0.000, 0.968], mean action: 21.475 [8.000, 31.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.238277, mean_absolute_error: 5.315195, mean_q: 6.008208
493 (array([22]),) False
 127880/500000: episode: 3197, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 37.585, mean reward: 0.940 [0.216, 1.000], mean action: 21.400 [1.000, 43.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.255398, mean_absolute_error: 5.335518, mean_q: 6.026317
728 (array([12]),) False
 127920/500000: episode: 3198, duration: 33.126s, episode steps: 40, steps per second: 1, episode reward: 29.631, mean reward: 0.741 [0.327, 1.000], mean action: 16.450 [12.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.254028, mean_absolute_error: 5.404595, mean_q: 6.096692
180 (array([48]),) False
 127960/500000: episode: 3199, duration: 32.977s, episode steps: 40, steps per second: 1, episode reward: 36.342, mean reward: 0.909 [0.292, 0.981], mean action: 17.750 [12.000, 55.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.282617, mean_absolute_error: 5.296882, mean_q: 5.985197
668 (array([22]),) False
 128000/500000: episode: 3200, duration: 33.008s, episode steps: 40, steps per second: 1, episode reward: 28.665, mean reward: 0.717 [0.199, 1.000], mean action: 35.225 [7.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.308241, mean_absolute_error: 5.273553, mean_q: 5.961325
457 (array([38]),) False
 128040/500000: episode: 3201, duration: 32.154s, episode steps: 40, steps per second: 1, episode reward: 31.928, mean reward: 0.798 [0.531, 0.945], mean action: 23.400 [1.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.257148, mean_absolute_error: 5.307824, mean_q: 5.999341
245 (array([22]),) False
 128080/500000: episode: 3202, duration: 33.008s, episode steps: 40, steps per second: 1, episode reward: 22.807, mean reward: 0.570 [0.095, 1.000], mean action: 27.425 [1.000, 57.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.258184, mean_absolute_error: 5.311626, mean_q: 6.006907
68 (array([22]),) False
 128120/500000: episode: 3203, duration: 32.164s, episode steps: 40, steps per second: 1, episode reward: 24.386, mean reward: 0.610 [0.054, 1.000], mean action: 32.525 [2.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.265086, mean_absolute_error: 5.333968, mean_q: 6.027851
517 (array([22]),) False
 128160/500000: episode: 3204, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 32.122, mean reward: 0.803 [0.161, 1.000], mean action: 19.125 [9.000, 52.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.228898, mean_absolute_error: 5.343022, mean_q: 6.039238
834 (array([44]),) False
 128200/500000: episode: 3205, duration: 32.113s, episode steps: 40, steps per second: 1, episode reward: 34.485, mean reward: 0.862 [0.364, 1.000], mean action: 29.450 [0.000, 49.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.268787, mean_absolute_error: 5.331755, mean_q: 6.029431
811 (array([33]),) False
 128240/500000: episode: 3206, duration: 33.000s, episode steps: 40, steps per second: 1, episode reward: 30.901, mean reward: 0.773 [0.160, 1.000], mean action: 32.800 [7.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.233820, mean_absolute_error: 5.307442, mean_q: 5.995695
564 (array([22]),) False
 128280/500000: episode: 3207, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 33.423, mean reward: 0.836 [0.238, 0.933], mean action: 16.050 [12.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.268569, mean_absolute_error: 5.303296, mean_q: 5.986945
295 (array([22]),) False
 128320/500000: episode: 3208, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 34.604, mean reward: 0.865 [0.159, 1.000], mean action: 25.825 [6.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.285657, mean_absolute_error: 5.342182, mean_q: 6.030419
54 (array([8]),) False
 128360/500000: episode: 3209, duration: 32.995s, episode steps: 40, steps per second: 1, episode reward: 31.363, mean reward: 0.784 [0.216, 0.977], mean action: 15.125 [0.000, 48.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.244343, mean_absolute_error: 5.362066, mean_q: 6.046748
439 (array([12]),) False
 128400/500000: episode: 3210, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 36.547, mean reward: 0.914 [0.169, 0.987], mean action: 24.225 [17.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.236953, mean_absolute_error: 5.332938, mean_q: 6.021174
110 (array([22]),) False
 128440/500000: episode: 3211, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 33.551, mean reward: 0.839 [0.296, 1.000], mean action: 22.325 [12.000, 50.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.246420, mean_absolute_error: 5.301494, mean_q: 6.003863
385 (array([30]),) False
 128480/500000: episode: 3212, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 37.016, mean reward: 0.925 [0.332, 1.000], mean action: 23.625 [14.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.265090, mean_absolute_error: 5.313992, mean_q: 6.009046
351 (array([22]),) False
 128520/500000: episode: 3213, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 35.064, mean reward: 0.877 [0.321, 1.000], mean action: 22.625 [0.000, 44.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.266320, mean_absolute_error: 5.344327, mean_q: 6.042441
597 (array([22]),) False
 128560/500000: episode: 3214, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 38.416, mean reward: 0.960 [0.280, 1.000], mean action: 21.100 [7.000, 31.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.276504, mean_absolute_error: 5.344237, mean_q: 6.034555
468 (array([22]),) False
 128600/500000: episode: 3215, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 37.533, mean reward: 0.938 [0.252, 1.000], mean action: 24.100 [3.000, 60.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.294670, mean_absolute_error: 5.294922, mean_q: 5.983083
50 (array([22]),) False
 128640/500000: episode: 3216, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 39.001, mean reward: 0.975 [0.357, 1.000], mean action: 23.200 [22.000, 59.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.246718, mean_absolute_error: 5.281229, mean_q: 5.977572
52 (array([22]),) False
 128680/500000: episode: 3217, duration: 32.133s, episode steps: 40, steps per second: 1, episode reward: 37.832, mean reward: 0.946 [0.134, 1.000], mean action: 22.725 [11.000, 51.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.276718, mean_absolute_error: 5.324028, mean_q: 6.020695
637 (array([12]),) False
 128720/500000: episode: 3218, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 33.416, mean reward: 0.835 [0.081, 1.000], mean action: 23.875 [3.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.278348, mean_absolute_error: 5.242872, mean_q: 5.933233
352 (array([22]),) False
 128760/500000: episode: 3219, duration: 32.991s, episode steps: 40, steps per second: 1, episode reward: 36.132, mean reward: 0.903 [0.091, 1.000], mean action: 20.650 [2.000, 46.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.248937, mean_absolute_error: 5.376765, mean_q: 6.063515
140 (array([12]),) False
 128800/500000: episode: 3220, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 35.802, mean reward: 0.895 [0.231, 0.993], mean action: 20.325 [4.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.219717, mean_absolute_error: 5.293757, mean_q: 5.976396
17 (array([22]),) False
 128840/500000: episode: 3221, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 37.072, mean reward: 0.927 [0.005, 1.000], mean action: 22.800 [11.000, 46.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.233836, mean_absolute_error: 5.308260, mean_q: 6.002190
390 (array([22]),) False
 128880/500000: episode: 3222, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 33.264, mean reward: 0.832 [0.193, 1.000], mean action: 24.125 [14.000, 55.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.280693, mean_absolute_error: 5.309119, mean_q: 6.011851
282 (array([22]),) False
 128920/500000: episode: 3223, duration: 32.956s, episode steps: 40, steps per second: 1, episode reward: 37.340, mean reward: 0.933 [0.234, 1.000], mean action: 21.175 [6.000, 33.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.245225, mean_absolute_error: 5.346587, mean_q: 6.042022
720 (array([22]),) False
 128960/500000: episode: 3224, duration: 33.000s, episode steps: 40, steps per second: 1, episode reward: 36.873, mean reward: 0.922 [0.218, 1.000], mean action: 25.800 [3.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.253157, mean_absolute_error: 5.266284, mean_q: 5.958830
365 (array([22]),) False
 129000/500000: episode: 3225, duration: 32.196s, episode steps: 40, steps per second: 1, episode reward: 36.250, mean reward: 0.906 [0.185, 1.000], mean action: 24.925 [4.000, 56.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.260514, mean_absolute_error: 5.237488, mean_q: 5.924996
669 (array([15]),) False
 129040/500000: episode: 3226, duration: 32.955s, episode steps: 40, steps per second: 1, episode reward: 29.629, mean reward: 0.741 [0.265, 0.768], mean action: 37.025 [8.000, 57.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.257711, mean_absolute_error: 5.330760, mean_q: 6.026882
446 (array([22]),) False
 129080/500000: episode: 3227, duration: 32.150s, episode steps: 40, steps per second: 1, episode reward: 33.113, mean reward: 0.828 [0.150, 1.000], mean action: 24.175 [4.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.250211, mean_absolute_error: 5.242415, mean_q: 5.926959
527 (array([58]),) False
 129120/500000: episode: 3228, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 19.920, mean reward: 0.498 [0.094, 0.700], mean action: 19.375 [7.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.251551, mean_absolute_error: 5.302275, mean_q: 5.995430
347 (array([22]),) False
 129160/500000: episode: 3229, duration: 32.108s, episode steps: 40, steps per second: 1, episode reward: 21.011, mean reward: 0.525 [0.135, 0.663], mean action: 40.825 [1.000, 50.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.285325, mean_absolute_error: 5.315975, mean_q: 6.014603
303 (array([22]),) False
 129200/500000: episode: 3230, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 37.289, mean reward: 0.932 [0.266, 1.000], mean action: 24.875 [19.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.235853, mean_absolute_error: 5.338485, mean_q: 6.033413
410 (array([22]),) False
 129240/500000: episode: 3231, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 35.683, mean reward: 0.892 [0.009, 1.000], mean action: 24.250 [5.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.274241, mean_absolute_error: 5.337972, mean_q: 6.034011
118 (array([22]),) False
 129280/500000: episode: 3232, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 33.636, mean reward: 0.841 [0.235, 1.000], mean action: 23.750 [3.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.256543, mean_absolute_error: 5.291785, mean_q: 5.982490
207 (array([36]),) False
 129320/500000: episode: 3233, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 24.444, mean reward: 0.611 [0.012, 0.853], mean action: 15.575 [12.000, 49.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.306500, mean_absolute_error: 5.347640, mean_q: 6.033093
849 (array([3]),) False
 129360/500000: episode: 3234, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 22.813, mean reward: 0.570 [0.000, 1.000], mean action: 39.025 [3.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.262155, mean_absolute_error: 5.411754, mean_q: 6.105143
192 (array([22]),) False
 129400/500000: episode: 3235, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 36.018, mean reward: 0.900 [0.293, 1.000], mean action: 14.325 [12.000, 42.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.251817, mean_absolute_error: 5.275228, mean_q: 5.960721
61 (array([48]),) False
 129440/500000: episode: 3236, duration: 32.780s, episode steps: 40, steps per second: 1, episode reward: 36.012, mean reward: 0.900 [0.012, 1.000], mean action: 21.275 [1.000, 27.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.223938, mean_absolute_error: 5.437791, mean_q: 6.140113
322 (array([12]),) False
 129480/500000: episode: 3237, duration: 32.201s, episode steps: 40, steps per second: 1, episode reward: 36.170, mean reward: 0.904 [0.007, 1.000], mean action: 17.650 [9.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.249389, mean_absolute_error: 5.363363, mean_q: 6.062132
307 (array([22]),) False
 129520/500000: episode: 3238, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 34.116, mean reward: 0.853 [0.170, 1.000], mean action: 24.900 [16.000, 59.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.285039, mean_absolute_error: 5.344225, mean_q: 6.049076
461 (array([22]),) False
 129560/500000: episode: 3239, duration: 32.025s, episode steps: 40, steps per second: 1, episode reward: 38.633, mean reward: 0.966 [0.342, 1.000], mean action: 23.200 [12.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.261405, mean_absolute_error: 5.361152, mean_q: 6.059060
141 (array([44]),) False
 129600/500000: episode: 3240, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 23.124, mean reward: 0.578 [0.127, 1.000], mean action: 19.425 [11.000, 53.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.250630, mean_absolute_error: 5.389781, mean_q: 6.090346
128 (array([22]),) False
 129640/500000: episode: 3241, duration: 32.146s, episode steps: 40, steps per second: 1, episode reward: 36.492, mean reward: 0.912 [0.131, 1.000], mean action: 23.125 [5.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.251064, mean_absolute_error: 5.380334, mean_q: 6.080451
146 (array([12]),) False
 129680/500000: episode: 3242, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 33.270, mean reward: 0.832 [0.244, 1.000], mean action: 17.950 [0.000, 43.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.244057, mean_absolute_error: 5.368415, mean_q: 6.063058
46 (array([22]),) False
 129720/500000: episode: 3243, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 34.732, mean reward: 0.868 [0.084, 1.000], mean action: 25.200 [22.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.298693, mean_absolute_error: 5.366002, mean_q: 6.054323
498 (array([12]),) False
 129760/500000: episode: 3244, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 23.035, mean reward: 0.576 [0.136, 1.000], mean action: 20.525 [12.000, 28.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.268644, mean_absolute_error: 5.461411, mean_q: 6.155969
68 (array([22]),) False
 129800/500000: episode: 3245, duration: 32.923s, episode steps: 40, steps per second: 1, episode reward: 25.728, mean reward: 0.643 [0.065, 1.000], mean action: 40.225 [6.000, 52.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.285022, mean_absolute_error: 5.423102, mean_q: 6.117805
522 (array([22]),) False
 129840/500000: episode: 3246, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 32.388, mean reward: 0.810 [0.119, 1.000], mean action: 26.800 [12.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.291439, mean_absolute_error: 5.334840, mean_q: 6.027995
378 (array([22]),) False
 129880/500000: episode: 3247, duration: 32.933s, episode steps: 40, steps per second: 1, episode reward: 35.106, mean reward: 0.878 [0.032, 1.000], mean action: 23.150 [4.000, 56.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.256733, mean_absolute_error: 5.430658, mean_q: 6.130043
143 (array([12]),) False
 129920/500000: episode: 3248, duration: 33.023s, episode steps: 40, steps per second: 1, episode reward: 31.694, mean reward: 0.792 [0.345, 1.000], mean action: 15.800 [0.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.290754, mean_absolute_error: 5.372252, mean_q: 6.066403
615 (array([36]),) False
 129960/500000: episode: 3249, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 22.348, mean reward: 0.559 [0.128, 0.690], mean action: 19.225 [7.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.243038, mean_absolute_error: 5.441915, mean_q: 6.140994
385 (array([30]),) False
 130000/500000: episode: 3250, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 36.152, mean reward: 0.904 [0.217, 1.000], mean action: 21.250 [1.000, 33.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.275254, mean_absolute_error: 5.411623, mean_q: 6.108935
131 (array([22]),) False
 130040/500000: episode: 3251, duration: 32.138s, episode steps: 40, steps per second: 1, episode reward: 37.377, mean reward: 0.934 [0.395, 1.000], mean action: 23.300 [12.000, 46.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.257202, mean_absolute_error: 5.397643, mean_q: 6.087963
207 (array([36]),) False
 130080/500000: episode: 3252, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 24.223, mean reward: 0.606 [0.012, 1.000], mean action: 16.025 [3.000, 56.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.257183, mean_absolute_error: 5.473913, mean_q: 6.170598
135 (array([22]),) False
 130120/500000: episode: 3253, duration: 32.112s, episode steps: 40, steps per second: 1, episode reward: 36.084, mean reward: 0.902 [0.155, 1.000], mean action: 22.050 [2.000, 48.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.267411, mean_absolute_error: 5.417101, mean_q: 6.112820
37 (array([48]),) False
 130160/500000: episode: 3254, duration: 32.942s, episode steps: 40, steps per second: 1, episode reward: 32.938, mean reward: 0.823 [0.022, 1.000], mean action: 26.925 [10.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.274088, mean_absolute_error: 5.431792, mean_q: 6.129830
859 (array([22]),) False
 130200/500000: episode: 3255, duration: 32.920s, episode steps: 40, steps per second: 1, episode reward: 30.181, mean reward: 0.755 [0.106, 1.000], mean action: 19.800 [7.000, 52.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.236699, mean_absolute_error: 5.429034, mean_q: 6.135465
846 (array([48]),) False
 130240/500000: episode: 3256, duration: 32.869s, episode steps: 40, steps per second: 1, episode reward: 37.191, mean reward: 0.930 [0.328, 1.000], mean action: 20.675 [12.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.275623, mean_absolute_error: 5.413422, mean_q: 6.117777
459 (array([22]),) False
 130280/500000: episode: 3257, duration: 32.872s, episode steps: 40, steps per second: 1, episode reward: 36.003, mean reward: 0.900 [0.158, 1.000], mean action: 22.850 [0.000, 60.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.254541, mean_absolute_error: 5.471156, mean_q: 6.172257
89 (array([58]),) False
 130320/500000: episode: 3258, duration: 32.183s, episode steps: 40, steps per second: 1, episode reward: 15.371, mean reward: 0.384 [0.000, 0.998], mean action: 25.525 [3.000, 60.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.277292, mean_absolute_error: 5.439574, mean_q: 6.147368
615 (array([36]),) False
 130360/500000: episode: 3259, duration: 31.896s, episode steps: 40, steps per second: 1, episode reward: 24.081, mean reward: 0.602 [0.385, 0.748], mean action: 23.825 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.246216, mean_absolute_error: 5.398929, mean_q: 6.109917
745 (array([22]),) False
 130400/500000: episode: 3260, duration: 31.944s, episode steps: 40, steps per second: 1, episode reward: 32.863, mean reward: 0.822 [0.702, 0.962], mean action: 16.550 [5.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.256497, mean_absolute_error: 5.391860, mean_q: 6.099669
453 (array([22]),) False
 130440/500000: episode: 3261, duration: 31.778s, episode steps: 40, steps per second: 1, episode reward: 31.709, mean reward: 0.793 [0.209, 1.000], mean action: 23.000 [12.000, 56.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.253711, mean_absolute_error: 5.502020, mean_q: 6.215026
660 (array([2]),) False
 130480/500000: episode: 3262, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 17.558, mean reward: 0.439 [0.097, 0.838], mean action: 36.475 [1.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.270396, mean_absolute_error: 5.430771, mean_q: 6.144883
212 (array([36]),) False
 130520/500000: episode: 3263, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 22.314, mean reward: 0.558 [0.425, 0.994], mean action: 21.475 [12.000, 53.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.288869, mean_absolute_error: 5.458838, mean_q: 6.163014
180 (array([48]),) False
 130560/500000: episode: 3264, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 33.358, mean reward: 0.834 [0.112, 1.000], mean action: 19.025 [12.000, 60.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.291853, mean_absolute_error: 5.471291, mean_q: 6.175352
426 (array([22]),) False
 130600/500000: episode: 3265, duration: 32.194s, episode steps: 40, steps per second: 1, episode reward: 37.468, mean reward: 0.937 [0.114, 1.000], mean action: 23.200 [8.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.259735, mean_absolute_error: 5.477389, mean_q: 6.175172
405 (array([22]),) False
 130640/500000: episode: 3266, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 37.525, mean reward: 0.938 [0.072, 1.000], mean action: 23.375 [12.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.249502, mean_absolute_error: 5.405508, mean_q: 6.092566
809 (array([48]),) False
 130680/500000: episode: 3267, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 30.385, mean reward: 0.760 [0.038, 1.000], mean action: 35.725 [11.000, 58.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.276258, mean_absolute_error: 5.383178, mean_q: 6.074521
350 (array([12]),) False
 130720/500000: episode: 3268, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 24.972, mean reward: 0.624 [0.044, 0.845], mean action: 23.075 [2.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.282634, mean_absolute_error: 5.463719, mean_q: 6.162436
529 (array([3]),) False
 130760/500000: episode: 3269, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 18.358, mean reward: 0.459 [0.005, 1.000], mean action: 28.450 [3.000, 57.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.252604, mean_absolute_error: 5.397899, mean_q: 6.100804
669 (array([15]),) False
 130800/500000: episode: 3270, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 32.584, mean reward: 0.815 [0.186, 0.916], mean action: 21.400 [12.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.272692, mean_absolute_error: 5.442590, mean_q: 6.137302
552 (array([22]),) False
 130840/500000: episode: 3271, duration: 32.955s, episode steps: 40, steps per second: 1, episode reward: 36.862, mean reward: 0.922 [0.505, 1.000], mean action: 15.500 [12.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.238485, mean_absolute_error: 5.530774, mean_q: 6.237103
165 (array([34]),) False
 130880/500000: episode: 3272, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 32.684, mean reward: 0.817 [0.256, 1.000], mean action: 20.175 [12.000, 56.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.278888, mean_absolute_error: 5.423581, mean_q: 6.128436
186 (array([22]),) False
 130920/500000: episode: 3273, duration: 32.180s, episode steps: 40, steps per second: 1, episode reward: 32.074, mean reward: 0.802 [0.250, 0.879], mean action: 14.075 [12.000, 58.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.300690, mean_absolute_error: 5.486889, mean_q: 6.184672
505 (array([22]),) False
 130960/500000: episode: 3274, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 36.044, mean reward: 0.901 [0.396, 1.000], mean action: 20.650 [12.000, 52.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.265661, mean_absolute_error: 5.451839, mean_q: 6.150788
557 (array([22]),) False
 131000/500000: episode: 3275, duration: 32.131s, episode steps: 40, steps per second: 1, episode reward: 30.577, mean reward: 0.764 [0.191, 1.000], mean action: 20.875 [2.000, 54.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.298180, mean_absolute_error: 5.416237, mean_q: 6.120916
509 (array([22]),) False
 131040/500000: episode: 3276, duration: 33.016s, episode steps: 40, steps per second: 1, episode reward: 39.293, mean reward: 0.982 [0.293, 1.000], mean action: 22.200 [22.000, 30.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.255479, mean_absolute_error: 5.413594, mean_q: 6.112018
272 (array([12]),) False
 131080/500000: episode: 3277, duration: 32.132s, episode steps: 40, steps per second: 1, episode reward: 35.426, mean reward: 0.886 [0.079, 0.988], mean action: 26.700 [22.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.258853, mean_absolute_error: 5.472297, mean_q: 6.168307
350 (array([12]),) False
 131120/500000: episode: 3278, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 25.906, mean reward: 0.648 [0.027, 0.845], mean action: 22.575 [3.000, 51.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.239891, mean_absolute_error: 5.464649, mean_q: 6.151732
435 (array([22]),) False
 131160/500000: episode: 3279, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 33.797, mean reward: 0.845 [0.075, 1.000], mean action: 33.700 [0.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.272784, mean_absolute_error: 5.511523, mean_q: 6.197762
139 (array([48]),) False
 131200/500000: episode: 3280, duration: 32.918s, episode steps: 40, steps per second: 1, episode reward: 32.434, mean reward: 0.811 [0.161, 1.000], mean action: 18.275 [10.000, 55.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.263280, mean_absolute_error: 5.468323, mean_q: 6.165875
795 (array([3]),) False
 131240/500000: episode: 3281, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 20.766, mean reward: 0.519 [0.314, 0.902], mean action: 14.050 [5.000, 51.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.264861, mean_absolute_error: 5.417462, mean_q: 6.124990
117 (array([44]),) False
 131280/500000: episode: 3282, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 30.041, mean reward: 0.751 [0.587, 0.918], mean action: 34.275 [12.000, 52.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.283432, mean_absolute_error: 5.487708, mean_q: 6.195977
121 (array([22]),) False
 131320/500000: episode: 3283, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 35.058, mean reward: 0.876 [0.207, 1.000], mean action: 16.100 [12.000, 53.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.280744, mean_absolute_error: 5.454611, mean_q: 6.163963
396 (array([48]),) False
 131360/500000: episode: 3284, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 35.645, mean reward: 0.891 [0.024, 0.973], mean action: 21.375 [5.000, 39.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.255577, mean_absolute_error: 5.407459, mean_q: 6.111251
143 (array([12]),) False
 131400/500000: episode: 3285, duration: 32.240s, episode steps: 40, steps per second: 1, episode reward: 32.543, mean reward: 0.814 [0.203, 1.000], mean action: 16.900 [4.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.255049, mean_absolute_error: 5.530178, mean_q: 6.244328
8 (array([22]),) False
 131440/500000: episode: 3286, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 32.341, mean reward: 0.809 [0.040, 1.000], mean action: 24.650 [12.000, 53.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.264937, mean_absolute_error: 5.461176, mean_q: 6.171495
249 (array([22]),) False
 131480/500000: episode: 3287, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 31.625, mean reward: 0.791 [0.254, 1.000], mean action: 24.700 [0.000, 57.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.253545, mean_absolute_error: 5.547954, mean_q: 6.266967
229 (array([48]),) False
 131520/500000: episode: 3288, duration: 33.016s, episode steps: 40, steps per second: 1, episode reward: 30.486, mean reward: 0.762 [0.176, 1.000], mean action: 26.075 [2.000, 57.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.292227, mean_absolute_error: 5.578271, mean_q: 6.299911
65 (array([48]),) False
 131560/500000: episode: 3289, duration: 32.178s, episode steps: 40, steps per second: 1, episode reward: 36.007, mean reward: 0.900 [0.000, 1.000], mean action: 39.200 [8.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.298576, mean_absolute_error: 5.488208, mean_q: 6.202910
542 (array([44]),) False
 131600/500000: episode: 3290, duration: 32.952s, episode steps: 40, steps per second: 1, episode reward: 33.106, mean reward: 0.828 [0.427, 1.000], mean action: 24.475 [12.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.257725, mean_absolute_error: 5.461685, mean_q: 6.170786
251 (array([3]),) False
 131640/500000: episode: 3291, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 15.441, mean reward: 0.386 [0.004, 1.000], mean action: 27.350 [1.000, 55.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.273228, mean_absolute_error: 5.476177, mean_q: 6.189001
414 (array([48]),) False
 131680/500000: episode: 3292, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 31.555, mean reward: 0.789 [0.224, 1.000], mean action: 22.700 [12.000, 55.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.287489, mean_absolute_error: 5.427339, mean_q: 6.138286
50 (array([22]),) False
 131720/500000: episode: 3293, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 34.165, mean reward: 0.854 [0.136, 1.000], mean action: 22.475 [4.000, 49.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.278373, mean_absolute_error: 5.416611, mean_q: 6.124688
504 (array([48]),) False
 131760/500000: episode: 3294, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 25.746, mean reward: 0.644 [0.517, 0.656], mean action: 21.250 [12.000, 42.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.301412, mean_absolute_error: 5.473172, mean_q: 6.186332
300 (array([22]),) False
 131800/500000: episode: 3295, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 35.190, mean reward: 0.880 [0.074, 1.000], mean action: 24.800 [19.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.250435, mean_absolute_error: 5.527389, mean_q: 6.239821
521 (array([22]),) False
 131840/500000: episode: 3296, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 36.133, mean reward: 0.903 [0.134, 1.000], mean action: 20.875 [12.000, 53.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.311689, mean_absolute_error: 5.470252, mean_q: 6.171419
769 (array([12]),) False
 131880/500000: episode: 3297, duration: 32.096s, episode steps: 40, steps per second: 1, episode reward: 33.575, mean reward: 0.839 [0.052, 1.000], mean action: 22.225 [5.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.267832, mean_absolute_error: 5.486810, mean_q: 6.199069
281 (array([48]),) False
 131920/500000: episode: 3298, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 37.791, mean reward: 0.945 [0.000, 1.000], mean action: 23.525 [4.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.298960, mean_absolute_error: 5.396535, mean_q: 6.101260
828 (array([48]),) False
 131960/500000: episode: 3299, duration: 32.187s, episode steps: 40, steps per second: 1, episode reward: 33.539, mean reward: 0.838 [0.000, 1.000], mean action: 27.500 [3.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.286078, mean_absolute_error: 5.463975, mean_q: 6.173619
809 (array([48]),) False
 132000/500000: episode: 3300, duration: 32.928s, episode steps: 40, steps per second: 1, episode reward: 29.916, mean reward: 0.748 [0.079, 1.000], mean action: 33.600 [0.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.274186, mean_absolute_error: 5.513102, mean_q: 6.221598
818 (array([48]),) False
 132040/500000: episode: 3301, duration: 32.074s, episode steps: 40, steps per second: 1, episode reward: 31.773, mean reward: 0.794 [0.095, 1.000], mean action: 27.625 [3.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.298643, mean_absolute_error: 5.518149, mean_q: 6.219236
98 (array([12]),) False
 132080/500000: episode: 3302, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 33.445, mean reward: 0.836 [0.096, 1.000], mean action: 25.150 [9.000, 60.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.279979, mean_absolute_error: 5.531226, mean_q: 6.236257
261 (array([44]),) False
 132120/500000: episode: 3303, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 28.984, mean reward: 0.725 [0.349, 0.941], mean action: 21.750 [3.000, 51.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.241690, mean_absolute_error: 5.633391, mean_q: 6.342653
580 (array([22]),) False
 132160/500000: episode: 3304, duration: 32.977s, episode steps: 40, steps per second: 1, episode reward: 35.110, mean reward: 0.878 [0.010, 1.000], mean action: 23.225 [12.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.266101, mean_absolute_error: 5.532148, mean_q: 6.232054
582 (array([44]),) False
 132200/500000: episode: 3305, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 36.233, mean reward: 0.906 [0.418, 1.000], mean action: 18.200 [7.000, 49.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.239182, mean_absolute_error: 5.613706, mean_q: 6.322656
214 (array([22]),) False
 132240/500000: episode: 3306, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 35.131, mean reward: 0.878 [0.217, 1.000], mean action: 22.475 [10.000, 57.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.289211, mean_absolute_error: 5.596408, mean_q: 6.299098
594 (array([48]),) False
 132280/500000: episode: 3307, duration: 32.914s, episode steps: 40, steps per second: 1, episode reward: 32.396, mean reward: 0.810 [0.030, 1.000], mean action: 17.250 [12.000, 43.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.292793, mean_absolute_error: 5.589170, mean_q: 6.287115
767 (array([48]),) False
 132320/500000: episode: 3308, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 31.472, mean reward: 0.787 [0.111, 1.000], mean action: 31.750 [2.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.282833, mean_absolute_error: 5.548355, mean_q: 6.253310
372 (array([22]),) False
 132360/500000: episode: 3309, duration: 32.225s, episode steps: 40, steps per second: 1, episode reward: 37.046, mean reward: 0.926 [0.142, 1.000], mean action: 23.450 [12.000, 59.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.278052, mean_absolute_error: 5.532951, mean_q: 6.237687
542 (array([44]),) False
 132400/500000: episode: 3310, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 32.074, mean reward: 0.802 [0.056, 0.901], mean action: 21.300 [2.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.265861, mean_absolute_error: 5.632792, mean_q: 6.342578
603 (array([58]),) False
 132440/500000: episode: 3311, duration: 32.195s, episode steps: 40, steps per second: 1, episode reward: 24.154, mean reward: 0.604 [0.000, 0.835], mean action: 21.500 [12.000, 50.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.258836, mean_absolute_error: 5.588844, mean_q: 6.289081
652 (array([22]),) False
 132480/500000: episode: 3312, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 34.659, mean reward: 0.866 [0.024, 1.000], mean action: 23.925 [2.000, 58.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.291968, mean_absolute_error: 5.572629, mean_q: 6.275835
782 (array([22]),) False
 132520/500000: episode: 3313, duration: 32.063s, episode steps: 40, steps per second: 1, episode reward: 35.942, mean reward: 0.899 [0.267, 1.000], mean action: 22.175 [6.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.296171, mean_absolute_error: 5.656090, mean_q: 6.359528
380 (array([22]),) False
 132560/500000: episode: 3314, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 36.983, mean reward: 0.925 [0.238, 1.000], mean action: 23.050 [1.000, 56.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.278197, mean_absolute_error: 5.575095, mean_q: 6.274594
34 (array([22]),) False
 132600/500000: episode: 3315, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 36.974, mean reward: 0.924 [0.155, 1.000], mean action: 23.325 [6.000, 58.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.256915, mean_absolute_error: 5.526655, mean_q: 6.233687
479 (array([22]),) False
 132640/500000: episode: 3316, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 34.165, mean reward: 0.854 [0.080, 1.000], mean action: 28.675 [2.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.264093, mean_absolute_error: 5.622682, mean_q: 6.326849
831 (array([3]),) False
 132680/500000: episode: 3317, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 23.832, mean reward: 0.596 [0.142, 0.946], mean action: 40.050 [4.000, 54.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.271618, mean_absolute_error: 5.548513, mean_q: 6.258429
499 (array([8]),) False
 132720/500000: episode: 3318, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 15.847, mean reward: 0.396 [0.086, 0.595], mean action: 22.725 [6.000, 57.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.269569, mean_absolute_error: 5.534770, mean_q: 6.237951
750 (array([22]),) False
 132760/500000: episode: 3319, duration: 32.889s, episode steps: 40, steps per second: 1, episode reward: 34.791, mean reward: 0.870 [0.070, 1.000], mean action: 21.700 [3.000, 48.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.270338, mean_absolute_error: 5.539332, mean_q: 6.241120
778 (array([12]),) False
 132800/500000: episode: 3320, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 29.498, mean reward: 0.737 [0.000, 1.000], mean action: 26.800 [12.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.246063, mean_absolute_error: 5.516603, mean_q: 6.214433
471 (array([12]),) False
 132840/500000: episode: 3321, duration: 32.189s, episode steps: 40, steps per second: 1, episode reward: 31.715, mean reward: 0.793 [0.340, 1.000], mean action: 23.900 [10.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.261210, mean_absolute_error: 5.541068, mean_q: 6.239038
570 (array([47]),) False
 132880/500000: episode: 3322, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 33.061, mean reward: 0.827 [0.232, 1.000], mean action: 38.375 [5.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.274268, mean_absolute_error: 5.559070, mean_q: 6.255114
121 (array([22]),) False
 132920/500000: episode: 3323, duration: 32.108s, episode steps: 40, steps per second: 1, episode reward: 35.587, mean reward: 0.890 [0.233, 1.000], mean action: 14.575 [9.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.242743, mean_absolute_error: 5.652518, mean_q: 6.355801
545 (array([22]),) False
 132960/500000: episode: 3324, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 33.104, mean reward: 0.828 [0.321, 1.000], mean action: 20.075 [2.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.275206, mean_absolute_error: 5.594419, mean_q: 6.293678
677 (array([48]),) False
 133000/500000: episode: 3325, duration: 32.249s, episode steps: 40, steps per second: 1, episode reward: 33.351, mean reward: 0.834 [0.000, 1.000], mean action: 25.175 [3.000, 51.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.251986, mean_absolute_error: 5.630563, mean_q: 6.339194
360 (array([22]),) False
 133040/500000: episode: 3326, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 30.756, mean reward: 0.769 [0.397, 1.000], mean action: 26.850 [22.000, 53.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.243214, mean_absolute_error: 5.598723, mean_q: 6.304028
409 (array([22]),) False
 133080/500000: episode: 3327, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 31.378, mean reward: 0.784 [0.131, 1.000], mean action: 25.700 [7.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.289925, mean_absolute_error: 5.574540, mean_q: 6.275723
241 (array([22]),) False
 133120/500000: episode: 3328, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 37.089, mean reward: 0.927 [0.142, 1.000], mean action: 21.425 [7.000, 38.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.250042, mean_absolute_error: 5.559983, mean_q: 6.270179
110 (array([22]),) False
 133160/500000: episode: 3329, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 33.180, mean reward: 0.830 [0.178, 1.000], mean action: 24.075 [4.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.267115, mean_absolute_error: 5.585517, mean_q: 6.296212
712 (array([22]),) False
 133200/500000: episode: 3330, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 34.413, mean reward: 0.860 [0.000, 1.000], mean action: 17.925 [2.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.278543, mean_absolute_error: 5.616733, mean_q: 6.330390
327 (array([22]),) False
 133240/500000: episode: 3331, duration: 32.957s, episode steps: 40, steps per second: 1, episode reward: 32.243, mean reward: 0.806 [0.172, 1.000], mean action: 26.000 [8.000, 49.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.282819, mean_absolute_error: 5.586673, mean_q: 6.297348
63 (array([18]),) False
 133280/500000: episode: 3332, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 36.493, mean reward: 0.912 [0.323, 0.990], mean action: 14.875 [1.000, 57.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.306933, mean_absolute_error: 5.566866, mean_q: 6.273994
691 (array([22]),) False
 133320/500000: episode: 3333, duration: 32.163s, episode steps: 40, steps per second: 1, episode reward: 35.281, mean reward: 0.882 [0.185, 1.000], mean action: 23.550 [9.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.320629, mean_absolute_error: 5.624190, mean_q: 6.333364
40 (array([22]),) False
 133360/500000: episode: 3334, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 37.133, mean reward: 0.928 [0.202, 1.000], mean action: 23.300 [10.000, 51.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.275785, mean_absolute_error: 5.564843, mean_q: 6.263284
161 (array([22]),) False
 133400/500000: episode: 3335, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 33.377, mean reward: 0.834 [0.177, 1.000], mean action: 23.775 [3.000, 49.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.237546, mean_absolute_error: 5.540021, mean_q: 6.249587
172 (array([12]),) False
 133440/500000: episode: 3336, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 33.182, mean reward: 0.830 [0.406, 1.000], mean action: 19.125 [12.000, 55.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.265677, mean_absolute_error: 5.591716, mean_q: 6.305885
69 (array([12]),) False
 133480/500000: episode: 3337, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 37.712, mean reward: 0.943 [0.348, 1.000], mean action: 13.425 [12.000, 32.000], mean observation: -0.089 [-1.000, 1.000], loss: 0.248992, mean_absolute_error: 5.571063, mean_q: 6.281054
55 (array([22]),) False
 133520/500000: episode: 3338, duration: 32.097s, episode steps: 40, steps per second: 1, episode reward: 33.111, mean reward: 0.828 [0.120, 1.000], mean action: 23.875 [2.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.267141, mean_absolute_error: 5.486761, mean_q: 6.185192
453 (array([22]),) False
 133560/500000: episode: 3339, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 31.623, mean reward: 0.791 [0.356, 1.000], mean action: 23.400 [12.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.270823, mean_absolute_error: 5.589497, mean_q: 6.296539
263 (array([8]),) False
 133600/500000: episode: 3340, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 21.653, mean reward: 0.541 [0.297, 0.938], mean action: 33.925 [0.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.281625, mean_absolute_error: 5.590076, mean_q: 6.302510
193 (array([36]),) False
 133640/500000: episode: 3341, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 33.449, mean reward: 0.836 [0.470, 1.000], mean action: 29.700 [6.000, 47.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.289192, mean_absolute_error: 5.547442, mean_q: 6.253833
813 (array([22]),) False
 133680/500000: episode: 3342, duration: 32.903s, episode steps: 40, steps per second: 1, episode reward: 37.927, mean reward: 0.948 [0.495, 1.000], mean action: 32.050 [12.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.323238, mean_absolute_error: 5.586223, mean_q: 6.291406
545 (array([22]),) False
 133720/500000: episode: 3343, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 35.370, mean reward: 0.884 [0.185, 1.000], mean action: 21.875 [1.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.267792, mean_absolute_error: 5.503332, mean_q: 6.212381
345 (array([22]),) False
 133760/500000: episode: 3344, duration: 32.981s, episode steps: 40, steps per second: 1, episode reward: 36.835, mean reward: 0.921 [0.328, 1.000], mean action: 21.550 [1.000, 44.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.281952, mean_absolute_error: 5.500689, mean_q: 6.202158
799 (array([36]),) False
 133800/500000: episode: 3345, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 28.050, mean reward: 0.701 [0.132, 1.000], mean action: 23.875 [2.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.312382, mean_absolute_error: 5.526663, mean_q: 6.227231
434 (array([22]),) False
 133840/500000: episode: 3346, duration: 32.176s, episode steps: 40, steps per second: 1, episode reward: 38.347, mean reward: 0.959 [0.276, 1.000], mean action: 22.775 [5.000, 59.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.260529, mean_absolute_error: 5.529257, mean_q: 6.229476
79 (array([22]),) False
 133880/500000: episode: 3347, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 38.832, mean reward: 0.971 [0.400, 1.000], mean action: 22.800 [17.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.282905, mean_absolute_error: 5.508980, mean_q: 6.205518
758 (array([38]),) False
 133920/500000: episode: 3348, duration: 32.122s, episode steps: 40, steps per second: 1, episode reward: 37.355, mean reward: 0.934 [0.292, 0.966], mean action: 28.800 [22.000, 49.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.285762, mean_absolute_error: 5.482950, mean_q: 6.174890
143 (array([12]),) False
 133960/500000: episode: 3349, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 33.844, mean reward: 0.846 [0.146, 1.000], mean action: 13.900 [6.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.252132, mean_absolute_error: 5.499570, mean_q: 6.196371
541 (array([57]),) False
 134000/500000: episode: 3350, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 20.665, mean reward: 0.517 [0.116, 0.902], mean action: 23.350 [2.000, 59.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.239338, mean_absolute_error: 5.550628, mean_q: 6.248664
353 (array([22]),) False
 134040/500000: episode: 3351, duration: 32.959s, episode steps: 40, steps per second: 1, episode reward: 36.280, mean reward: 0.907 [0.289, 1.000], mean action: 23.500 [12.000, 58.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.242460, mean_absolute_error: 5.528272, mean_q: 6.215120
260 (array([22]),) False
 134080/500000: episode: 3352, duration: 32.734s, episode steps: 40, steps per second: 1, episode reward: 36.574, mean reward: 0.914 [0.159, 1.000], mean action: 24.275 [8.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.279276, mean_absolute_error: 5.533460, mean_q: 6.220551
843 (array([3]),) False
 134120/500000: episode: 3353, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 9.330, mean reward: 0.233 [0.000, 0.883], mean action: 18.000 [4.000, 50.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.263073, mean_absolute_error: 5.487394, mean_q: 6.179145
454 (array([12]),) False
 134160/500000: episode: 3354, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 33.138, mean reward: 0.828 [0.132, 0.890], mean action: 23.275 [1.000, 52.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.266160, mean_absolute_error: 5.564160, mean_q: 6.261508
407 (array([22]),) False
 134200/500000: episode: 3355, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 37.143, mean reward: 0.929 [0.084, 1.000], mean action: 21.600 [0.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.277880, mean_absolute_error: 5.502490, mean_q: 6.199155
361 (array([22]),) False
 134240/500000: episode: 3356, duration: 32.987s, episode steps: 40, steps per second: 1, episode reward: 36.709, mean reward: 0.918 [0.047, 1.000], mean action: 23.475 [4.000, 50.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.246599, mean_absolute_error: 5.508579, mean_q: 6.206879
601 (array([14]),) False
 134280/500000: episode: 3357, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 31.492, mean reward: 0.787 [0.140, 1.000], mean action: 20.925 [1.000, 54.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.277480, mean_absolute_error: 5.565965, mean_q: 6.271288
198 (array([22]),) False
 134320/500000: episode: 3358, duration: 32.214s, episode steps: 40, steps per second: 1, episode reward: 29.493, mean reward: 0.737 [0.170, 1.000], mean action: 30.650 [4.000, 49.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.252798, mean_absolute_error: 5.439342, mean_q: 6.133129
787 (array([3]),) False
 134360/500000: episode: 3359, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 23.749, mean reward: 0.594 [0.150, 1.000], mean action: 24.025 [22.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.313696, mean_absolute_error: 5.513635, mean_q: 6.216362
807 (array([22]),) False
 134400/500000: episode: 3360, duration: 32.153s, episode steps: 40, steps per second: 1, episode reward: 37.275, mean reward: 0.932 [0.212, 1.000], mean action: 41.375 [19.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.293513, mean_absolute_error: 5.501996, mean_q: 6.201154
448 (array([12]),) False
 134440/500000: episode: 3361, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 29.494, mean reward: 0.737 [0.336, 0.964], mean action: 22.325 [7.000, 40.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.261490, mean_absolute_error: 5.527489, mean_q: 6.225208
841 (array([21]),) False
 134480/500000: episode: 3362, duration: 32.107s, episode steps: 40, steps per second: 1, episode reward: 25.017, mean reward: 0.625 [0.052, 0.897], mean action: 22.200 [8.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.275615, mean_absolute_error: 5.503924, mean_q: 6.197861
566 (array([12]),) False
 134520/500000: episode: 3363, duration: 32.965s, episode steps: 40, steps per second: 1, episode reward: 35.293, mean reward: 0.882 [0.466, 1.000], mean action: 13.350 [1.000, 44.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.270811, mean_absolute_error: 5.577729, mean_q: 6.270124
668 (array([22]),) False
 134560/500000: episode: 3364, duration: 32.935s, episode steps: 40, steps per second: 1, episode reward: 24.842, mean reward: 0.621 [0.202, 0.981], mean action: 42.425 [1.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.261557, mean_absolute_error: 5.608040, mean_q: 6.304745
663 (array([22]),) False
 134600/500000: episode: 3365, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 20.509, mean reward: 0.513 [0.100, 1.000], mean action: 45.225 [3.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.262900, mean_absolute_error: 5.581707, mean_q: 6.273997
71 (array([58]),) False
 134640/500000: episode: 3366, duration: 32.878s, episode steps: 40, steps per second: 1, episode reward: 17.389, mean reward: 0.435 [0.036, 1.000], mean action: 32.200 [2.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.265050, mean_absolute_error: 5.503720, mean_q: 6.199240
402 (array([22]),) False
 134680/500000: episode: 3367, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 34.658, mean reward: 0.866 [0.192, 1.000], mean action: 24.800 [12.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.279912, mean_absolute_error: 5.539608, mean_q: 6.228463
172 (array([12]),) False
 134720/500000: episode: 3368, duration: 32.958s, episode steps: 40, steps per second: 1, episode reward: 33.039, mean reward: 0.826 [0.454, 1.000], mean action: 20.875 [12.000, 52.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.253335, mean_absolute_error: 5.537213, mean_q: 6.230408
452 (array([22]),) False
 134760/500000: episode: 3369, duration: 32.787s, episode steps: 40, steps per second: 1, episode reward: 34.248, mean reward: 0.856 [0.466, 1.000], mean action: 23.275 [1.000, 56.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.263130, mean_absolute_error: 5.485694, mean_q: 6.178616
407 (array([22]),) False
 134800/500000: episode: 3370, duration: 31.941s, episode steps: 40, steps per second: 1, episode reward: 38.875, mean reward: 0.972 [0.409, 1.000], mean action: 23.375 [21.000, 51.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.241862, mean_absolute_error: 5.510137, mean_q: 6.196177
526 (array([22]),) False
 134840/500000: episode: 3371, duration: 32.447s, episode steps: 40, steps per second: 1, episode reward: 37.922, mean reward: 0.948 [0.243, 1.000], mean action: 27.175 [0.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.332286, mean_absolute_error: 5.561791, mean_q: 6.254540
133 (array([22]),) False
 134880/500000: episode: 3372, duration: 31.524s, episode steps: 40, steps per second: 1, episode reward: 34.968, mean reward: 0.874 [0.065, 1.000], mean action: 23.875 [2.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.237467, mean_absolute_error: 5.502001, mean_q: 6.196166
795 (array([3]),) False
 134920/500000: episode: 3373, duration: 31.996s, episode steps: 40, steps per second: 1, episode reward: 21.291, mean reward: 0.532 [0.364, 0.739], mean action: 20.550 [5.000, 55.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.257725, mean_absolute_error: 5.465316, mean_q: 6.159328
756 (array([48]),) False
 134960/500000: episode: 3374, duration: 31.559s, episode steps: 40, steps per second: 1, episode reward: 36.878, mean reward: 0.922 [0.259, 1.000], mean action: 25.175 [13.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.287643, mean_absolute_error: 5.560122, mean_q: 6.254009
432 (array([22]),) False
 135000/500000: episode: 3375, duration: 32.926s, episode steps: 40, steps per second: 1, episode reward: 38.370, mean reward: 0.959 [0.350, 1.000], mean action: 23.975 [22.000, 48.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.258281, mean_absolute_error: 5.533727, mean_q: 6.222376
533 (array([22]),) False
 135040/500000: episode: 3376, duration: 33.046s, episode steps: 40, steps per second: 1, episode reward: 35.202, mean reward: 0.880 [0.271, 1.000], mean action: 21.225 [12.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.256138, mean_absolute_error: 5.516811, mean_q: 6.206642
781 (array([8]),) False
 135080/500000: episode: 3377, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 34.986, mean reward: 0.875 [0.470, 1.000], mean action: 22.400 [12.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.240852, mean_absolute_error: 5.574029, mean_q: 6.268311
415 (array([22]),) False
 135120/500000: episode: 3378, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 36.645, mean reward: 0.916 [0.065, 1.000], mean action: 24.000 [10.000, 59.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.298351, mean_absolute_error: 5.505472, mean_q: 6.203865
273 (array([22]),) False
 135160/500000: episode: 3379, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 35.666, mean reward: 0.892 [0.000, 1.000], mean action: 21.550 [1.000, 49.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.268287, mean_absolute_error: 5.564215, mean_q: 6.260629
753 (array([22]),) False
 135200/500000: episode: 3380, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 32.200, mean reward: 0.805 [0.107, 1.000], mean action: 24.150 [0.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.279680, mean_absolute_error: 5.521367, mean_q: 6.224600
567 (array([22]),) False
 135240/500000: episode: 3381, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 23.767, mean reward: 0.594 [0.091, 0.845], mean action: 21.325 [12.000, 48.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.248939, mean_absolute_error: 5.488201, mean_q: 6.190662
638 (array([22]),) False
 135280/500000: episode: 3382, duration: 32.109s, episode steps: 40, steps per second: 1, episode reward: 33.203, mean reward: 0.830 [0.367, 1.000], mean action: 28.825 [12.000, 52.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.262896, mean_absolute_error: 5.580630, mean_q: 6.277120
557 (array([22]),) False
 135320/500000: episode: 3383, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 32.989, mean reward: 0.825 [0.398, 1.000], mean action: 17.825 [12.000, 49.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.301159, mean_absolute_error: 5.555824, mean_q: 6.250988
126 (array([22]),) False
 135360/500000: episode: 3384, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 30.580, mean reward: 0.764 [0.240, 1.000], mean action: 26.175 [0.000, 59.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.270176, mean_absolute_error: 5.549116, mean_q: 6.247327
776 (array([22]),) False
 135400/500000: episode: 3385, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 32.109, mean reward: 0.803 [0.089, 1.000], mean action: 29.775 [6.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.286440, mean_absolute_error: 5.574881, mean_q: 6.273705
783 (array([22]),) False
 135440/500000: episode: 3386, duration: 32.088s, episode steps: 40, steps per second: 1, episode reward: 36.689, mean reward: 0.917 [0.291, 1.000], mean action: 24.525 [12.000, 49.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.279091, mean_absolute_error: 5.558134, mean_q: 6.245515
251 (array([3]),) False
 135480/500000: episode: 3387, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 14.196, mean reward: 0.355 [0.005, 1.000], mean action: 29.875 [3.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.270908, mean_absolute_error: 5.598251, mean_q: 6.294594
591 (array([22]),) False
 135520/500000: episode: 3388, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 27.732, mean reward: 0.693 [0.047, 0.801], mean action: 15.850 [1.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.266473, mean_absolute_error: 5.612299, mean_q: 6.315921
583 (array([22]),) False
 135560/500000: episode: 3389, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 32.332, mean reward: 0.808 [0.090, 1.000], mean action: 19.425 [4.000, 56.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.298649, mean_absolute_error: 5.533803, mean_q: 6.224667
362 (array([22]),) False
 135600/500000: episode: 3390, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 38.125, mean reward: 0.953 [0.400, 1.000], mean action: 22.825 [7.000, 51.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.278608, mean_absolute_error: 5.550599, mean_q: 6.246396
789 (array([22]),) False
 135640/500000: episode: 3391, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 38.515, mean reward: 0.963 [0.000, 1.000], mean action: 47.425 [35.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.262485, mean_absolute_error: 5.570479, mean_q: 6.271995
16 (array([22]),) False
 135680/500000: episode: 3392, duration: 32.909s, episode steps: 40, steps per second: 1, episode reward: 36.989, mean reward: 0.925 [0.154, 1.000], mean action: 25.425 [18.000, 58.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.250339, mean_absolute_error: 5.499697, mean_q: 6.204463
332 (array([22]),) False
 135720/500000: episode: 3393, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 32.541, mean reward: 0.814 [0.293, 0.969], mean action: 24.350 [12.000, 49.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.281992, mean_absolute_error: 5.511280, mean_q: 6.215251
617 (array([22]),) False
 135760/500000: episode: 3394, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 36.930, mean reward: 0.923 [0.217, 1.000], mean action: 19.175 [12.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.247691, mean_absolute_error: 5.563759, mean_q: 6.271227
710 (array([12]),) False
 135800/500000: episode: 3395, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 32.756, mean reward: 0.819 [0.135, 1.000], mean action: 13.475 [0.000, 46.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.267239, mean_absolute_error: 5.518145, mean_q: 6.220482
338 (array([12]),) False
 135840/500000: episode: 3396, duration: 32.073s, episode steps: 40, steps per second: 1, episode reward: 36.778, mean reward: 0.919 [0.165, 1.000], mean action: 20.650 [2.000, 48.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.248823, mean_absolute_error: 5.562854, mean_q: 6.267107
793 (array([12]),) False
 135880/500000: episode: 3397, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 34.152, mean reward: 0.854 [0.106, 1.000], mean action: 17.575 [9.000, 57.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.263283, mean_absolute_error: 5.501729, mean_q: 6.204652
145 (array([19]),) False
 135920/500000: episode: 3398, duration: 32.122s, episode steps: 40, steps per second: 1, episode reward: 24.516, mean reward: 0.613 [0.072, 0.807], mean action: 18.750 [5.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.264177, mean_absolute_error: 5.538189, mean_q: 6.241454
419 (array([40]),) False
 135960/500000: episode: 3399, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 37.570, mean reward: 0.939 [0.355, 1.000], mean action: 23.700 [12.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.269092, mean_absolute_error: 5.543291, mean_q: 6.260512
25 (array([48]),) False
 136000/500000: episode: 3400, duration: 33.038s, episode steps: 40, steps per second: 1, episode reward: 31.514, mean reward: 0.788 [0.067, 1.000], mean action: 23.975 [3.000, 59.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.302602, mean_absolute_error: 5.595488, mean_q: 6.317046
831 (array([3]),) False
 136040/500000: episode: 3401, duration: 33.023s, episode steps: 40, steps per second: 1, episode reward: 24.174, mean reward: 0.604 [0.096, 1.000], mean action: 34.550 [3.000, 59.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.234961, mean_absolute_error: 5.516819, mean_q: 6.221913
449 (array([22]),) False
 136080/500000: episode: 3402, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 38.548, mean reward: 0.964 [0.268, 1.000], mean action: 21.050 [5.000, 22.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.254631, mean_absolute_error: 5.601343, mean_q: 6.310589
67 (array([8]),) False
 136120/500000: episode: 3403, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 22.735, mean reward: 0.568 [0.351, 0.978], mean action: 26.875 [3.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.278196, mean_absolute_error: 5.628045, mean_q: 6.336083
389 (array([48]),) False
 136160/500000: episode: 3404, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 37.217, mean reward: 0.930 [0.438, 0.977], mean action: 24.025 [16.000, 53.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.285183, mean_absolute_error: 5.626607, mean_q: 6.335227
545 (array([22]),) False
 136200/500000: episode: 3405, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 34.872, mean reward: 0.872 [0.186, 1.000], mean action: 21.200 [0.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.291687, mean_absolute_error: 5.637011, mean_q: 6.341182
244 (array([14]),) False
 136240/500000: episode: 3406, duration: 32.171s, episode steps: 40, steps per second: 1, episode reward: 33.553, mean reward: 0.839 [0.436, 1.000], mean action: 25.300 [14.000, 50.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.276104, mean_absolute_error: 5.622399, mean_q: 6.328783
513 (array([12]),) False
 136280/500000: episode: 3407, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 36.175, mean reward: 0.904 [0.122, 1.000], mean action: 17.050 [6.000, 48.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.270755, mean_absolute_error: 5.675103, mean_q: 6.383446
794 (array([22]),) False
 136320/500000: episode: 3408, duration: 32.121s, episode steps: 40, steps per second: 1, episode reward: 35.337, mean reward: 0.883 [0.141, 1.000], mean action: 26.375 [9.000, 49.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.304721, mean_absolute_error: 5.609941, mean_q: 6.321157
565 (array([12]),) False
 136360/500000: episode: 3409, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 36.693, mean reward: 0.917 [0.229, 1.000], mean action: 13.450 [0.000, 34.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.263114, mean_absolute_error: 5.636970, mean_q: 6.349424
511 (array([22]),) False
 136400/500000: episode: 3410, duration: 32.093s, episode steps: 40, steps per second: 1, episode reward: 35.663, mean reward: 0.892 [0.248, 1.000], mean action: 20.725 [0.000, 51.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.322629, mean_absolute_error: 5.570406, mean_q: 6.278647
663 (array([22]),) False
 136440/500000: episode: 3411, duration: 33.009s, episode steps: 40, steps per second: 1, episode reward: 21.648, mean reward: 0.541 [0.139, 0.866], mean action: 23.950 [0.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.314061, mean_absolute_error: 5.638031, mean_q: 6.357338
297 (array([15]),) False
 136480/500000: episode: 3412, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 33.537, mean reward: 0.838 [0.138, 0.920], mean action: 21.825 [10.000, 37.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.285859, mean_absolute_error: 5.585229, mean_q: 6.293379
264 (array([12]),) False
 136520/500000: episode: 3413, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 36.492, mean reward: 0.912 [0.132, 1.000], mean action: 22.275 [3.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.298800, mean_absolute_error: 5.579634, mean_q: 6.292811
298 (array([22]),) False
 136560/500000: episode: 3414, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 36.663, mean reward: 0.917 [0.219, 1.000], mean action: 24.225 [12.000, 53.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.308986, mean_absolute_error: 5.601111, mean_q: 6.307301
788 (array([3]),) False
 136600/500000: episode: 3415, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 17.425, mean reward: 0.436 [0.062, 1.000], mean action: 46.175 [3.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.275775, mean_absolute_error: 5.595117, mean_q: 6.298816
150 (array([22]),) False
 136640/500000: episode: 3416, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 35.270, mean reward: 0.882 [0.404, 0.917], mean action: 15.075 [12.000, 59.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.276578, mean_absolute_error: 5.666848, mean_q: 6.373236
491 (array([22]),) False
 136680/500000: episode: 3417, duration: 33.146s, episode steps: 40, steps per second: 1, episode reward: 37.287, mean reward: 0.932 [0.248, 1.000], mean action: 23.325 [7.000, 46.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.303956, mean_absolute_error: 5.593549, mean_q: 6.302096
383 (array([22]),) False
 136720/500000: episode: 3418, duration: 32.209s, episode steps: 40, steps per second: 1, episode reward: 38.191, mean reward: 0.955 [0.445, 1.000], mean action: 25.575 [22.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.239049, mean_absolute_error: 5.565452, mean_q: 6.271216
420 (array([22]),) False
 136760/500000: episode: 3419, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 35.023, mean reward: 0.876 [0.176, 1.000], mean action: 24.250 [12.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.272504, mean_absolute_error: 5.643083, mean_q: 6.353143
649 (array([22]),) False
 136800/500000: episode: 3420, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 37.201, mean reward: 0.930 [0.101, 1.000], mean action: 21.600 [9.000, 35.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.290263, mean_absolute_error: 5.579923, mean_q: 6.290927
67 (array([8]),) False
 136840/500000: episode: 3421, duration: 32.980s, episode steps: 40, steps per second: 1, episode reward: 24.480, mean reward: 0.612 [0.242, 0.956], mean action: 34.475 [0.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.269464, mean_absolute_error: 5.565860, mean_q: 6.277220
601 (array([14]),) False
 136880/500000: episode: 3422, duration: 32.213s, episode steps: 40, steps per second: 1, episode reward: 32.248, mean reward: 0.806 [0.358, 0.953], mean action: 19.500 [7.000, 59.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.265816, mean_absolute_error: 5.598370, mean_q: 6.316199
550 (array([12]),) False
 136920/500000: episode: 3423, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 34.117, mean reward: 0.853 [0.397, 1.000], mean action: 19.200 [0.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.283756, mean_absolute_error: 5.632736, mean_q: 6.348325
675 (array([22]),) False
 136960/500000: episode: 3424, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 39.133, mean reward: 0.978 [0.477, 1.000], mean action: 21.525 [11.000, 22.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.247974, mean_absolute_error: 5.600940, mean_q: 6.313519
146 (array([12]),) False
 137000/500000: episode: 3425, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 36.216, mean reward: 0.905 [0.326, 1.000], mean action: 17.375 [12.000, 45.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.291954, mean_absolute_error: 5.593145, mean_q: 6.299624
438 (array([22]),) False
 137040/500000: episode: 3426, duration: 32.959s, episode steps: 40, steps per second: 1, episode reward: 37.270, mean reward: 0.932 [0.088, 1.000], mean action: 21.575 [0.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.294354, mean_absolute_error: 5.651852, mean_q: 6.362194
244 (array([14]),) False
 137080/500000: episode: 3427, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 33.493, mean reward: 0.837 [0.386, 1.000], mean action: 22.825 [9.000, 50.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.249118, mean_absolute_error: 5.611087, mean_q: 6.327267
446 (array([22]),) False
 137120/500000: episode: 3428, duration: 32.977s, episode steps: 40, steps per second: 1, episode reward: 37.203, mean reward: 0.930 [0.277, 1.000], mean action: 21.425 [12.000, 22.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.307905, mean_absolute_error: 5.625496, mean_q: 6.335401
607 (array([12]),) False
 137160/500000: episode: 3429, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 35.028, mean reward: 0.876 [0.246, 1.000], mean action: 23.075 [12.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.265569, mean_absolute_error: 5.614871, mean_q: 6.324474
677 (array([48]),) False
 137200/500000: episode: 3430, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 36.799, mean reward: 0.920 [0.696, 1.000], mean action: 23.025 [12.000, 49.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.279343, mean_absolute_error: 5.628607, mean_q: 6.343400
177 (array([22]),) False
 137240/500000: episode: 3431, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 34.949, mean reward: 0.874 [0.218, 1.000], mean action: 24.475 [0.000, 48.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.272276, mean_absolute_error: 5.599489, mean_q: 6.318622
159 (array([48]),) False
 137280/500000: episode: 3432, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 32.102, mean reward: 0.803 [0.000, 1.000], mean action: 24.000 [1.000, 59.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.263559, mean_absolute_error: 5.688731, mean_q: 6.407428
244 (array([14]),) False
 137320/500000: episode: 3433, duration: 33.007s, episode steps: 40, steps per second: 1, episode reward: 30.980, mean reward: 0.775 [0.204, 1.000], mean action: 24.200 [0.000, 55.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.300055, mean_absolute_error: 5.616475, mean_q: 6.318601
402 (array([22]),) False
 137360/500000: episode: 3434, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 35.713, mean reward: 0.893 [0.564, 1.000], mean action: 24.400 [12.000, 51.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.257003, mean_absolute_error: 5.682751, mean_q: 6.384904
591 (array([22]),) False
 137400/500000: episode: 3435, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 30.353, mean reward: 0.759 [0.262, 1.000], mean action: 17.825 [12.000, 53.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.279863, mean_absolute_error: 5.598965, mean_q: 6.299060
777 (array([48]),) False
 137440/500000: episode: 3436, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 33.576, mean reward: 0.839 [0.087, 1.000], mean action: 39.500 [2.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.280288, mean_absolute_error: 5.593649, mean_q: 6.300847
379 (array([22]),) False
 137480/500000: episode: 3437, duration: 32.877s, episode steps: 40, steps per second: 1, episode reward: 36.266, mean reward: 0.907 [0.141, 1.000], mean action: 22.725 [1.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.255858, mean_absolute_error: 5.673271, mean_q: 6.391057
646 (array([44]),) False
 137520/500000: episode: 3438, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 12.129, mean reward: 0.303 [0.000, 1.000], mean action: 36.150 [6.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.283052, mean_absolute_error: 5.670555, mean_q: 6.382043
454 (array([12]),) False
 137560/500000: episode: 3439, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 30.605, mean reward: 0.765 [0.033, 0.890], mean action: 24.650 [8.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.310893, mean_absolute_error: 5.647616, mean_q: 6.359943
252 (array([22]),) False
 137600/500000: episode: 3440, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 36.161, mean reward: 0.904 [0.064, 1.000], mean action: 24.100 [10.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.255854, mean_absolute_error: 5.636096, mean_q: 6.346306
110 (array([22]),) False
 137640/500000: episode: 3441, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 34.271, mean reward: 0.857 [0.266, 1.000], mean action: 21.750 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.283389, mean_absolute_error: 5.635710, mean_q: 6.346255
848 (array([44]),) False
 137680/500000: episode: 3442, duration: 32.212s, episode steps: 40, steps per second: 1, episode reward: 26.318, mean reward: 0.658 [0.209, 0.931], mean action: 29.250 [12.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.246625, mean_absolute_error: 5.541070, mean_q: 6.248822
789 (array([22]),) False
 137720/500000: episode: 3443, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 36.721, mean reward: 0.918 [0.141, 1.000], mean action: 42.125 [2.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.261792, mean_absolute_error: 5.631337, mean_q: 6.340440
347 (array([22]),) False
 137760/500000: episode: 3444, duration: 32.211s, episode steps: 40, steps per second: 1, episode reward: 19.803, mean reward: 0.495 [0.097, 0.527], mean action: 49.700 [8.000, 60.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.282034, mean_absolute_error: 5.565450, mean_q: 6.275453
8 (array([22]),) False
 137800/500000: episode: 3445, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 31.554, mean reward: 0.789 [0.158, 1.000], mean action: 23.025 [10.000, 59.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.262166, mean_absolute_error: 5.571530, mean_q: 6.283808
284 (array([12]),) False
 137840/500000: episode: 3446, duration: 32.167s, episode steps: 40, steps per second: 1, episode reward: 29.905, mean reward: 0.748 [0.208, 1.000], mean action: 23.450 [12.000, 48.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.295604, mean_absolute_error: 5.616001, mean_q: 6.331830
174 (array([33]),) False
 137880/500000: episode: 3447, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 22.485, mean reward: 0.562 [0.239, 0.997], mean action: 23.975 [4.000, 48.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.295646, mean_absolute_error: 5.527841, mean_q: 6.240192
104 (array([22]),) False
 137920/500000: episode: 3448, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 36.624, mean reward: 0.916 [0.034, 1.000], mean action: 24.175 [12.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.282418, mean_absolute_error: 5.616105, mean_q: 6.326272
308 (array([22]),) False
 137960/500000: episode: 3449, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 33.249, mean reward: 0.831 [0.250, 1.000], mean action: 23.800 [7.000, 54.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.267092, mean_absolute_error: 5.516965, mean_q: 6.229150
703 (array([3]),) False
 138000/500000: episode: 3450, duration: 32.963s, episode steps: 40, steps per second: 1, episode reward: 33.584, mean reward: 0.840 [0.036, 1.000], mean action: 10.950 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.253490, mean_absolute_error: 5.666027, mean_q: 6.381002
475 (array([22]),) False
 138040/500000: episode: 3451, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 37.947, mean reward: 0.949 [0.271, 1.000], mean action: 18.250 [5.000, 32.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.317613, mean_absolute_error: 5.553618, mean_q: 6.256272
198 (array([22]),) False
 138080/500000: episode: 3452, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 29.308, mean reward: 0.733 [0.098, 1.000], mean action: 29.875 [3.000, 49.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.259662, mean_absolute_error: 5.628252, mean_q: 6.335368
555 (array([22]),) False
 138120/500000: episode: 3453, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 33.684, mean reward: 0.842 [0.000, 1.000], mean action: 13.575 [10.000, 28.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.275381, mean_absolute_error: 5.643806, mean_q: 6.347954
363 (array([36]),) False
 138160/500000: episode: 3454, duration: 32.211s, episode steps: 40, steps per second: 1, episode reward: 35.675, mean reward: 0.892 [0.000, 1.000], mean action: 24.825 [13.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.273604, mean_absolute_error: 5.526158, mean_q: 6.228045
841 (array([21]),) False
 138200/500000: episode: 3455, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 27.844, mean reward: 0.696 [0.272, 0.897], mean action: 26.500 [12.000, 60.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.267233, mean_absolute_error: 5.640958, mean_q: 6.333540
296 (array([22]),) False
 138240/500000: episode: 3456, duration: 32.186s, episode steps: 40, steps per second: 1, episode reward: 33.879, mean reward: 0.847 [0.057, 1.000], mean action: 25.800 [3.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.277852, mean_absolute_error: 5.603351, mean_q: 6.301939
249 (array([22]),) False
 138280/500000: episode: 3457, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 37.195, mean reward: 0.930 [0.189, 1.000], mean action: 26.425 [22.000, 49.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.255502, mean_absolute_error: 5.526930, mean_q: 6.220571
24 (array([22]),) False
 138320/500000: episode: 3458, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 32.005, mean reward: 0.800 [0.229, 1.000], mean action: 25.275 [5.000, 51.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.288031, mean_absolute_error: 5.592622, mean_q: 6.282767
841 (array([21]),) False
 138360/500000: episode: 3459, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 26.838, mean reward: 0.671 [0.128, 1.000], mean action: 24.600 [12.000, 54.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.283609, mean_absolute_error: 5.543003, mean_q: 6.236320
700 (array([44]),) False
 138400/500000: episode: 3460, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 31.181, mean reward: 0.780 [0.454, 1.000], mean action: 31.000 [12.000, 49.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.264427, mean_absolute_error: 5.679897, mean_q: 6.393094
487 (array([48]),) False
 138440/500000: episode: 3461, duration: 33.023s, episode steps: 40, steps per second: 1, episode reward: 34.438, mean reward: 0.861 [0.161, 1.000], mean action: 22.425 [5.000, 46.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.277116, mean_absolute_error: 5.561131, mean_q: 6.257022
153 (array([44]),) False
 138480/500000: episode: 3462, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 31.334, mean reward: 0.783 [0.127, 0.938], mean action: 18.500 [10.000, 49.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.263819, mean_absolute_error: 5.625545, mean_q: 6.334706
620 (array([44]),) False
 138520/500000: episode: 3463, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 28.212, mean reward: 0.705 [0.241, 1.000], mean action: 39.700 [15.000, 60.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.272910, mean_absolute_error: 5.716663, mean_q: 6.429021
13 (array([48]),) False
 138560/500000: episode: 3464, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 34.454, mean reward: 0.861 [0.020, 0.973], mean action: 28.075 [6.000, 58.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.291393, mean_absolute_error: 5.614311, mean_q: 6.315176
645 (array([48]),) False
 138600/500000: episode: 3465, duration: 33.010s, episode steps: 40, steps per second: 1, episode reward: 33.389, mean reward: 0.835 [0.078, 0.920], mean action: 22.450 [2.000, 42.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.281810, mean_absolute_error: 5.551344, mean_q: 6.251280
345 (array([22]),) False
 138640/500000: episode: 3466, duration: 32.169s, episode steps: 40, steps per second: 1, episode reward: 33.769, mean reward: 0.844 [0.149, 1.000], mean action: 27.850 [11.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.314937, mean_absolute_error: 5.604661, mean_q: 6.309955
33 (array([48]),) False
 138680/500000: episode: 3467, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 38.429, mean reward: 0.961 [0.443, 1.000], mean action: 22.200 [15.000, 36.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.220161, mean_absolute_error: 5.703565, mean_q: 6.405486
790 (array([48]),) False
 138720/500000: episode: 3468, duration: 32.119s, episode steps: 40, steps per second: 1, episode reward: 35.818, mean reward: 0.895 [0.134, 1.000], mean action: 36.425 [6.000, 49.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.319474, mean_absolute_error: 5.674694, mean_q: 6.381387
246 (array([22]),) False
 138760/500000: episode: 3469, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 38.250, mean reward: 0.956 [0.516, 1.000], mean action: 22.625 [4.000, 55.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.292215, mean_absolute_error: 5.516892, mean_q: 6.217209
51 (array([22]),) False
 138800/500000: episode: 3470, duration: 32.135s, episode steps: 40, steps per second: 1, episode reward: 37.504, mean reward: 0.938 [0.464, 1.000], mean action: 23.450 [7.000, 53.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.268940, mean_absolute_error: 5.624319, mean_q: 6.330948
827 (array([14]),) False
 138840/500000: episode: 3471, duration: 33.038s, episode steps: 40, steps per second: 1, episode reward: 32.909, mean reward: 0.823 [0.386, 1.000], mean action: 23.725 [9.000, 50.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.281135, mean_absolute_error: 5.635578, mean_q: 6.342896
391 (array([22]),) False
 138880/500000: episode: 3472, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 36.367, mean reward: 0.909 [0.071, 1.000], mean action: 25.125 [20.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.245337, mean_absolute_error: 5.619227, mean_q: 6.311470
278 (array([48]),) False
 138920/500000: episode: 3473, duration: 33.006s, episode steps: 40, steps per second: 1, episode reward: 33.662, mean reward: 0.842 [0.068, 1.000], mean action: 24.125 [9.000, 44.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.252699, mean_absolute_error: 5.721908, mean_q: 6.427811
7 (array([22]),) False
 138960/500000: episode: 3474, duration: 32.986s, episode steps: 40, steps per second: 1, episode reward: 37.714, mean reward: 0.943 [0.190, 1.000], mean action: 22.900 [22.000, 37.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.275013, mean_absolute_error: 5.675723, mean_q: 6.371060
576 (array([58]),) False
 139000/500000: episode: 3475, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 19.757, mean reward: 0.494 [0.289, 0.791], mean action: 26.800 [12.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.271676, mean_absolute_error: 5.609928, mean_q: 6.305738
396 (array([48]),) False
 139040/500000: episode: 3476, duration: 32.956s, episode steps: 40, steps per second: 1, episode reward: 36.441, mean reward: 0.911 [0.106, 0.973], mean action: 22.375 [0.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.272100, mean_absolute_error: 5.622957, mean_q: 6.325707
196 (array([22]),) False
 139080/500000: episode: 3477, duration: 33.078s, episode steps: 40, steps per second: 1, episode reward: 32.201, mean reward: 0.805 [0.151, 1.000], mean action: 17.950 [6.000, 51.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.278020, mean_absolute_error: 5.682530, mean_q: 6.391232
639 (array([22]),) False
 139120/500000: episode: 3478, duration: 32.158s, episode steps: 40, steps per second: 1, episode reward: 32.110, mean reward: 0.803 [0.037, 1.000], mean action: 21.650 [2.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.290982, mean_absolute_error: 5.610921, mean_q: 6.313663
376 (array([22]),) False
 139160/500000: episode: 3479, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 33.832, mean reward: 0.846 [0.092, 1.000], mean action: 23.675 [1.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.291321, mean_absolute_error: 5.611365, mean_q: 6.311993
627 (array([48]),) False
 139200/500000: episode: 3480, duration: 32.145s, episode steps: 40, steps per second: 1, episode reward: 36.851, mean reward: 0.921 [0.461, 0.955], mean action: 25.625 [22.000, 39.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.309111, mean_absolute_error: 5.713691, mean_q: 6.421056
554 (array([22]),) False
 139240/500000: episode: 3481, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 36.588, mean reward: 0.915 [0.136, 1.000], mean action: 20.700 [12.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.264609, mean_absolute_error: 5.582869, mean_q: 6.284782
517 (array([22]),) False
 139280/500000: episode: 3482, duration: 32.165s, episode steps: 40, steps per second: 1, episode reward: 34.153, mean reward: 0.854 [0.653, 1.000], mean action: 18.575 [12.000, 51.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.288916, mean_absolute_error: 5.675092, mean_q: 6.385615
508 (array([22]),) False
 139320/500000: episode: 3483, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 33.195, mean reward: 0.830 [0.095, 1.000], mean action: 22.600 [4.000, 50.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.255053, mean_absolute_error: 5.619218, mean_q: 6.327289
200 (array([22]),) False
 139360/500000: episode: 3484, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 21.128, mean reward: 0.528 [0.068, 1.000], mean action: 20.125 [1.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.258395, mean_absolute_error: 5.596971, mean_q: 6.302923
856 (array([48]),) False
 139400/500000: episode: 3485, duration: 32.986s, episode steps: 40, steps per second: 1, episode reward: 36.760, mean reward: 0.919 [0.371, 0.976], mean action: 15.625 [0.000, 22.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.291000, mean_absolute_error: 5.592253, mean_q: 6.293902
579 (array([58]),) False
 139440/500000: episode: 3486, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 20.990, mean reward: 0.525 [0.378, 0.890], mean action: 26.400 [0.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.247307, mean_absolute_error: 5.688718, mean_q: 6.388899
90 (array([22]),) False
 139480/500000: episode: 3487, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 36.374, mean reward: 0.909 [0.349, 1.000], mean action: 23.550 [12.000, 51.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.310007, mean_absolute_error: 5.606324, mean_q: 6.303267
165 (array([34]),) False
 139520/500000: episode: 3488, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 31.873, mean reward: 0.797 [0.256, 1.000], mean action: 16.725 [1.000, 22.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.279314, mean_absolute_error: 5.554599, mean_q: 6.253800
112 (array([12]),) False
 139560/500000: episode: 3489, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 33.139, mean reward: 0.828 [0.156, 1.000], mean action: 26.800 [7.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.291360, mean_absolute_error: 5.602697, mean_q: 6.306443
28 (array([58]),) False
 139600/500000: episode: 3490, duration: 32.211s, episode steps: 40, steps per second: 1, episode reward: 20.226, mean reward: 0.506 [0.000, 1.000], mean action: 23.450 [22.000, 51.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.261668, mean_absolute_error: 5.645520, mean_q: 6.339353
277 (array([56]),) False
 139640/500000: episode: 3491, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 30.475, mean reward: 0.762 [0.376, 1.000], mean action: 23.250 [3.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.255377, mean_absolute_error: 5.514975, mean_q: 6.206172
139 (array([48]),) False
 139680/500000: episode: 3492, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 32.014, mean reward: 0.800 [0.266, 1.000], mean action: 19.750 [6.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.294166, mean_absolute_error: 5.631389, mean_q: 6.334369
141 (array([44]),) False
 139720/500000: episode: 3493, duration: 32.889s, episode steps: 40, steps per second: 1, episode reward: 23.693, mean reward: 0.592 [0.000, 0.830], mean action: 17.575 [0.000, 45.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.282584, mean_absolute_error: 5.719599, mean_q: 6.420349
705 (array([22]),) False
 139760/500000: episode: 3494, duration: 32.135s, episode steps: 40, steps per second: 1, episode reward: 33.712, mean reward: 0.843 [0.239, 1.000], mean action: 14.025 [8.000, 32.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.267851, mean_absolute_error: 5.626707, mean_q: 6.331246
247 (array([14]),) False
 139800/500000: episode: 3495, duration: 33.000s, episode steps: 40, steps per second: 1, episode reward: 33.137, mean reward: 0.828 [0.242, 1.000], mean action: 24.550 [15.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.283591, mean_absolute_error: 5.741260, mean_q: 6.448841
224 (array([12]),) False
 139840/500000: episode: 3496, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 36.524, mean reward: 0.913 [0.159, 1.000], mean action: 20.775 [3.000, 49.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.274969, mean_absolute_error: 5.730856, mean_q: 6.435796
11 (array([22]),) False
 139880/500000: episode: 3497, duration: 32.947s, episode steps: 40, steps per second: 1, episode reward: 33.978, mean reward: 0.849 [0.088, 1.000], mean action: 31.975 [3.000, 59.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.270100, mean_absolute_error: 5.664336, mean_q: 6.368733
543 (array([12]),) False
 139920/500000: episode: 3498, duration: 32.933s, episode steps: 40, steps per second: 1, episode reward: 35.224, mean reward: 0.881 [0.250, 1.000], mean action: 18.150 [10.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.302850, mean_absolute_error: 5.674796, mean_q: 6.386644
101 (array([22]),) False
 139960/500000: episode: 3499, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 38.023, mean reward: 0.951 [0.324, 1.000], mean action: 20.875 [1.000, 22.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.282294, mean_absolute_error: 5.629640, mean_q: 6.346753
505 (array([22]),) False
 140000/500000: episode: 3500, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 36.423, mean reward: 0.911 [0.053, 1.000], mean action: 23.100 [9.000, 58.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.336368, mean_absolute_error: 5.596204, mean_q: 6.315303
314 (array([22]),) False
 140040/500000: episode: 3501, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 37.107, mean reward: 0.928 [0.427, 1.000], mean action: 21.900 [11.000, 49.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.283548, mean_absolute_error: 5.632028, mean_q: 6.348161
135 (array([22]),) False
 140080/500000: episode: 3502, duration: 32.081s, episode steps: 40, steps per second: 1, episode reward: 37.247, mean reward: 0.931 [0.131, 1.000], mean action: 23.675 [12.000, 57.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.270628, mean_absolute_error: 5.681747, mean_q: 6.404012
67 (array([8]),) False
 140120/500000: episode: 3503, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 26.849, mean reward: 0.671 [0.381, 0.978], mean action: 26.500 [3.000, 57.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.280263, mean_absolute_error: 5.621148, mean_q: 6.337905
485 (array([22]),) False
 140160/500000: episode: 3504, duration: 32.043s, episode steps: 40, steps per second: 1, episode reward: 35.567, mean reward: 0.889 [0.216, 1.000], mean action: 38.450 [19.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.294844, mean_absolute_error: 5.664285, mean_q: 6.372045
252 (array([22]),) False
 140200/500000: episode: 3505, duration: 32.754s, episode steps: 40, steps per second: 1, episode reward: 35.945, mean reward: 0.899 [0.246, 1.000], mean action: 23.850 [0.000, 46.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.275622, mean_absolute_error: 5.675373, mean_q: 6.393834
494 (array([48]),) False
 140240/500000: episode: 3506, duration: 32.116s, episode steps: 40, steps per second: 1, episode reward: 29.648, mean reward: 0.741 [0.253, 0.769], mean action: 22.700 [15.000, 47.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.263742, mean_absolute_error: 5.689531, mean_q: 6.409253
587 (array([14]),) False
 140280/500000: episode: 3507, duration: 32.660s, episode steps: 40, steps per second: 1, episode reward: 32.453, mean reward: 0.811 [0.207, 1.000], mean action: 20.025 [7.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.253817, mean_absolute_error: 5.559220, mean_q: 6.277430
128 (array([22]),) False
 140320/500000: episode: 3508, duration: 32.088s, episode steps: 40, steps per second: 1, episode reward: 35.942, mean reward: 0.899 [0.038, 1.000], mean action: 21.775 [5.000, 44.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.282560, mean_absolute_error: 5.632777, mean_q: 6.354107
625 (array([22]),) False
 140360/500000: episode: 3509, duration: 31.982s, episode steps: 40, steps per second: 1, episode reward: 36.933, mean reward: 0.923 [0.423, 1.000], mean action: 44.525 [20.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.295842, mean_absolute_error: 5.637019, mean_q: 6.353754
238 (array([22]),) False
 140400/500000: episode: 3510, duration: 32.061s, episode steps: 40, steps per second: 1, episode reward: 38.426, mean reward: 0.961 [0.106, 1.000], mean action: 22.175 [22.000, 29.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.264878, mean_absolute_error: 5.631297, mean_q: 6.342734
718 (array([12]),) False
 140440/500000: episode: 3511, duration: 32.728s, episode steps: 40, steps per second: 1, episode reward: 36.920, mean reward: 0.923 [0.206, 1.000], mean action: 18.000 [0.000, 46.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.274523, mean_absolute_error: 5.626485, mean_q: 6.348342
112 (array([12]),) False
 140480/500000: episode: 3512, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 27.678, mean reward: 0.692 [0.050, 1.000], mean action: 36.675 [4.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.281093, mean_absolute_error: 5.664411, mean_q: 6.382396
451 (array([38]),) False
 140520/500000: episode: 3513, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 31.223, mean reward: 0.781 [0.391, 1.000], mean action: 22.650 [22.000, 45.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.276937, mean_absolute_error: 5.724437, mean_q: 6.450960
745 (array([22]),) False
 140560/500000: episode: 3514, duration: 32.194s, episode steps: 40, steps per second: 1, episode reward: 31.805, mean reward: 0.795 [0.355, 1.000], mean action: 16.425 [0.000, 53.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.275360, mean_absolute_error: 5.675089, mean_q: 6.396823
322 (array([12]),) False
 140600/500000: episode: 3515, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 38.380, mean reward: 0.959 [0.398, 1.000], mean action: 15.800 [12.000, 59.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.294802, mean_absolute_error: 5.718706, mean_q: 6.446501
485 (array([22]),) False
 140640/500000: episode: 3516, duration: 32.137s, episode steps: 40, steps per second: 1, episode reward: 32.393, mean reward: 0.810 [0.056, 1.000], mean action: 34.425 [9.000, 49.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.281832, mean_absolute_error: 5.659205, mean_q: 6.378943
766 (array([12]),) False
 140680/500000: episode: 3517, duration: 32.992s, episode steps: 40, steps per second: 1, episode reward: 34.611, mean reward: 0.865 [0.000, 1.000], mean action: 33.525 [12.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.271470, mean_absolute_error: 5.630338, mean_q: 6.349221
75 (array([22]),) False
 140720/500000: episode: 3518, duration: 32.167s, episode steps: 40, steps per second: 1, episode reward: 35.229, mean reward: 0.881 [0.050, 1.000], mean action: 20.975 [3.000, 38.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.288122, mean_absolute_error: 5.730012, mean_q: 6.451143
232 (array([22]),) False
 140760/500000: episode: 3519, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 35.725, mean reward: 0.893 [0.337, 1.000], mean action: 20.325 [12.000, 43.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.279529, mean_absolute_error: 5.712202, mean_q: 6.429395
387 (array([22]),) False
 140800/500000: episode: 3520, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 37.171, mean reward: 0.929 [0.283, 1.000], mean action: 23.700 [22.000, 51.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.270947, mean_absolute_error: 5.755594, mean_q: 6.471182
620 (array([44]),) False
 140840/500000: episode: 3521, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 28.657, mean reward: 0.716 [0.387, 0.941], mean action: 35.725 [3.000, 54.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.292285, mean_absolute_error: 5.698267, mean_q: 6.415563
854 (array([12]),) False
 140880/500000: episode: 3522, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 31.660, mean reward: 0.791 [0.004, 1.000], mean action: 21.500 [12.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.272390, mean_absolute_error: 5.698346, mean_q: 6.409914
761 (array([3]),) False
 140920/500000: episode: 3523, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 17.783, mean reward: 0.445 [0.335, 1.000], mean action: 22.625 [2.000, 54.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.270068, mean_absolute_error: 5.664575, mean_q: 6.386575
368 (array([22]),) False
 140960/500000: episode: 3524, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 36.772, mean reward: 0.919 [0.410, 1.000], mean action: 34.375 [12.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.322266, mean_absolute_error: 5.743843, mean_q: 6.468097
341 (array([22]),) False
 141000/500000: episode: 3525, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 36.892, mean reward: 0.922 [0.351, 1.000], mean action: 31.350 [13.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.277706, mean_absolute_error: 5.706392, mean_q: 6.423673
239 (array([22]),) False
 141040/500000: episode: 3526, duration: 32.227s, episode steps: 40, steps per second: 1, episode reward: 36.009, mean reward: 0.900 [0.111, 1.000], mean action: 24.950 [9.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.297519, mean_absolute_error: 5.719218, mean_q: 6.433820
783 (array([22]),) False
 141080/500000: episode: 3527, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 37.465, mean reward: 0.937 [0.497, 1.000], mean action: 22.375 [12.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.296006, mean_absolute_error: 5.723158, mean_q: 6.428873
175 (array([22]),) False
 141120/500000: episode: 3528, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 36.576, mean reward: 0.914 [0.064, 1.000], mean action: 22.925 [3.000, 49.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.268449, mean_absolute_error: 5.688079, mean_q: 6.395706
9 (array([14]),) False
 141160/500000: episode: 3529, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 35.302, mean reward: 0.883 [0.469, 0.906], mean action: 22.850 [22.000, 46.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.303721, mean_absolute_error: 5.643505, mean_q: 6.347782
302 (array([22]),) False
 141200/500000: episode: 3530, duration: 32.299s, episode steps: 40, steps per second: 1, episode reward: 38.791, mean reward: 0.970 [0.430, 1.000], mean action: 22.175 [0.000, 38.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.264727, mean_absolute_error: 5.768991, mean_q: 6.481719
268 (array([22]),) False
 141240/500000: episode: 3531, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 36.043, mean reward: 0.901 [0.111, 1.000], mean action: 22.000 [5.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.310533, mean_absolute_error: 5.789874, mean_q: 6.506795
314 (array([22]),) False
 141280/500000: episode: 3532, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 36.799, mean reward: 0.920 [0.104, 1.000], mean action: 22.550 [12.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.266895, mean_absolute_error: 5.735345, mean_q: 6.447140
443 (array([22]),) False
 141320/500000: episode: 3533, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 38.091, mean reward: 0.952 [0.073, 1.000], mean action: 21.450 [5.000, 33.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.285669, mean_absolute_error: 5.632507, mean_q: 6.341886
321 (array([22]),) False
 141360/500000: episode: 3534, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 39.757, mean reward: 0.994 [0.905, 1.000], mean action: 21.200 [12.000, 48.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.265338, mean_absolute_error: 5.795347, mean_q: 6.509535
42 (array([22]),) False
 141400/500000: episode: 3535, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 37.018, mean reward: 0.925 [0.129, 1.000], mean action: 25.000 [22.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.340129, mean_absolute_error: 5.733943, mean_q: 6.445715
573 (array([22]),) False
 141440/500000: episode: 3536, duration: 33.000s, episode steps: 40, steps per second: 1, episode reward: 27.766, mean reward: 0.694 [0.033, 1.000], mean action: 25.425 [2.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.315621, mean_absolute_error: 5.709632, mean_q: 6.418275
439 (array([12]),) False
 141480/500000: episode: 3537, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 37.262, mean reward: 0.932 [0.413, 0.987], mean action: 23.575 [21.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.274063, mean_absolute_error: 5.657569, mean_q: 6.380536
687 (array([44]),) False
 141520/500000: episode: 3538, duration: 32.232s, episode steps: 40, steps per second: 1, episode reward: 33.844, mean reward: 0.846 [0.038, 0.953], mean action: 25.850 [9.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.242577, mean_absolute_error: 5.775260, mean_q: 6.487783
158 (array([22]),) False
 141560/500000: episode: 3539, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 36.169, mean reward: 0.904 [0.470, 1.000], mean action: 17.350 [12.000, 44.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.288194, mean_absolute_error: 5.792897, mean_q: 6.511816
763 (array([48]),) False
 141600/500000: episode: 3540, duration: 32.188s, episode steps: 40, steps per second: 1, episode reward: 36.813, mean reward: 0.920 [0.036, 1.000], mean action: 23.850 [7.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.327654, mean_absolute_error: 5.733191, mean_q: 6.447615
251 (array([3]),) False
 141640/500000: episode: 3541, duration: 32.965s, episode steps: 40, steps per second: 1, episode reward: 18.771, mean reward: 0.469 [0.000, 1.000], mean action: 18.750 [3.000, 56.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.276137, mean_absolute_error: 5.745432, mean_q: 6.468558
169 (array([22]),) False
 141680/500000: episode: 3542, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 34.292, mean reward: 0.857 [0.176, 1.000], mean action: 18.750 [12.000, 45.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.305181, mean_absolute_error: 5.749398, mean_q: 6.464915
736 (array([22]),) False
 141720/500000: episode: 3543, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 36.558, mean reward: 0.914 [0.271, 1.000], mean action: 19.125 [1.000, 40.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.294191, mean_absolute_error: 5.764970, mean_q: 6.477675
75 (array([22]),) False
 141760/500000: episode: 3544, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 37.673, mean reward: 0.942 [0.009, 1.000], mean action: 21.925 [12.000, 58.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.301825, mean_absolute_error: 5.761640, mean_q: 6.472000
224 (array([12]),) False
 141800/500000: episode: 3545, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 31.547, mean reward: 0.789 [0.082, 1.000], mean action: 23.775 [3.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.265390, mean_absolute_error: 5.758440, mean_q: 6.467326
495 (array([48]),) False
 141840/500000: episode: 3546, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 35.904, mean reward: 0.898 [0.336, 1.000], mean action: 23.250 [17.000, 48.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.250850, mean_absolute_error: 5.691593, mean_q: 6.402901
213 (array([22]),) False
 141880/500000: episode: 3547, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 34.714, mean reward: 0.868 [0.095, 1.000], mean action: 22.950 [12.000, 49.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.267711, mean_absolute_error: 5.690326, mean_q: 6.401053
722 (array([22]),) False
 141920/500000: episode: 3548, duration: 32.972s, episode steps: 40, steps per second: 1, episode reward: 34.523, mean reward: 0.863 [0.000, 1.000], mean action: 16.125 [9.000, 58.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.270033, mean_absolute_error: 5.667819, mean_q: 6.382325
6 (array([58]),) False
 141960/500000: episode: 3549, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 37.107, mean reward: 0.928 [0.087, 1.000], mean action: 23.250 [22.000, 47.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.271416, mean_absolute_error: 5.762628, mean_q: 6.484849
31 (array([48]),) False
 142000/500000: episode: 3550, duration: 32.151s, episode steps: 40, steps per second: 1, episode reward: 32.144, mean reward: 0.804 [0.222, 0.897], mean action: 21.425 [6.000, 25.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.278555, mean_absolute_error: 5.779066, mean_q: 6.498096
742 (array([33]),) False
 142040/500000: episode: 3551, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 27.348, mean reward: 0.684 [0.511, 0.839], mean action: 18.425 [12.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.324814, mean_absolute_error: 5.695732, mean_q: 6.400281
832 (array([22]),) False
 142080/500000: episode: 3552, duration: 32.124s, episode steps: 40, steps per second: 1, episode reward: 34.282, mean reward: 0.857 [0.192, 1.000], mean action: 22.725 [11.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.267457, mean_absolute_error: 5.649816, mean_q: 6.353602
770 (array([22]),) False
 142120/500000: episode: 3553, duration: 32.986s, episode steps: 40, steps per second: 1, episode reward: 31.202, mean reward: 0.780 [0.000, 1.000], mean action: 28.025 [9.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.287521, mean_absolute_error: 5.704541, mean_q: 6.412823
60 (array([22]),) False
 142160/500000: episode: 3554, duration: 32.142s, episode steps: 40, steps per second: 1, episode reward: 37.842, mean reward: 0.946 [0.286, 1.000], mean action: 21.900 [12.000, 32.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.298943, mean_absolute_error: 5.693694, mean_q: 6.400847
842 (array([22]),) False
 142200/500000: episode: 3555, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 32.400, mean reward: 0.810 [0.084, 1.000], mean action: 18.550 [1.000, 38.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.342561, mean_absolute_error: 5.687604, mean_q: 6.385650
307 (array([22]),) False
 142240/500000: episode: 3556, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 38.310, mean reward: 0.958 [0.418, 1.000], mean action: 22.950 [22.000, 35.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.278317, mean_absolute_error: 5.708498, mean_q: 6.413255
12 (array([22]),) False
 142280/500000: episode: 3557, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 34.990, mean reward: 0.875 [0.059, 1.000], mean action: 25.925 [7.000, 57.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.273181, mean_absolute_error: 5.730358, mean_q: 6.441313
351 (array([22]),) False
 142320/500000: episode: 3558, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 39.564, mean reward: 0.989 [0.726, 1.000], mean action: 22.250 [5.000, 49.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.285123, mean_absolute_error: 5.740184, mean_q: 6.442278
254 (array([22]),) False
 142360/500000: episode: 3559, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 34.577, mean reward: 0.864 [0.172, 1.000], mean action: 23.750 [0.000, 59.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.318294, mean_absolute_error: 5.742638, mean_q: 6.443101
31 (array([48]),) False
 142400/500000: episode: 3560, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 31.365, mean reward: 0.784 [0.000, 0.897], mean action: 21.900 [2.000, 51.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.301564, mean_absolute_error: 5.760965, mean_q: 6.469840
472 (array([22]),) False
 142440/500000: episode: 3561, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 33.766, mean reward: 0.844 [0.231, 1.000], mean action: 24.575 [12.000, 60.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.288963, mean_absolute_error: 5.746146, mean_q: 6.459154
710 (array([12]),) False
 142480/500000: episode: 3562, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 35.139, mean reward: 0.878 [0.319, 1.000], mean action: 18.000 [12.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.315798, mean_absolute_error: 5.799677, mean_q: 6.507623
826 (array([22]),) False
 142520/500000: episode: 3563, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 37.008, mean reward: 0.925 [0.000, 1.000], mean action: 24.450 [4.000, 53.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.285802, mean_absolute_error: 5.663761, mean_q: 6.356122
337 (array([22]),) False
 142560/500000: episode: 3564, duration: 32.118s, episode steps: 40, steps per second: 1, episode reward: 32.884, mean reward: 0.822 [0.012, 1.000], mean action: 24.775 [4.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.264026, mean_absolute_error: 5.702708, mean_q: 6.401968
291 (array([22]),) False
 142600/500000: episode: 3565, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 32.098, mean reward: 0.802 [0.000, 1.000], mean action: 24.600 [3.000, 59.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.297444, mean_absolute_error: 5.718653, mean_q: 6.420498
25 (array([48]),) False
 142640/500000: episode: 3566, duration: 32.143s, episode steps: 40, steps per second: 1, episode reward: 30.381, mean reward: 0.760 [0.290, 1.000], mean action: 21.725 [13.000, 51.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.236721, mean_absolute_error: 5.659178, mean_q: 6.358139
503 (array([3]),) False
 142680/500000: episode: 3567, duration: 33.007s, episode steps: 40, steps per second: 1, episode reward: 13.314, mean reward: 0.333 [0.212, 0.869], mean action: 22.975 [8.000, 58.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.267214, mean_absolute_error: 5.710334, mean_q: 6.412538
313 (array([22]),) False
 142720/500000: episode: 3568, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 36.283, mean reward: 0.907 [0.222, 1.000], mean action: 22.175 [7.000, 49.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.318355, mean_absolute_error: 5.723561, mean_q: 6.429614
755 (array([22]),) False
 142760/500000: episode: 3569, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 39.322, mean reward: 0.983 [0.322, 1.000], mean action: 22.925 [22.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.278411, mean_absolute_error: 5.735929, mean_q: 6.447011
348 (array([22]),) False
 142800/500000: episode: 3570, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 37.470, mean reward: 0.937 [0.334, 1.000], mean action: 28.275 [20.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.291184, mean_absolute_error: 5.773577, mean_q: 6.493867
319 (array([33]),) False
 142840/500000: episode: 3571, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 27.523, mean reward: 0.688 [0.149, 1.000], mean action: 25.575 [12.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.343393, mean_absolute_error: 5.763440, mean_q: 6.473588
535 (array([22]),) False
 142880/500000: episode: 3572, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 37.921, mean reward: 0.948 [0.442, 1.000], mean action: 23.425 [12.000, 49.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.301581, mean_absolute_error: 5.661231, mean_q: 6.372073
549 (array([22]),) False
 142920/500000: episode: 3573, duration: 32.986s, episode steps: 40, steps per second: 1, episode reward: 33.975, mean reward: 0.849 [0.227, 1.000], mean action: 25.425 [11.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.267972, mean_absolute_error: 5.633996, mean_q: 6.342511
134 (array([58]),) False
 142960/500000: episode: 3574, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 5.110, mean reward: 0.128 [0.000, 0.728], mean action: 25.850 [3.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.256574, mean_absolute_error: 5.742609, mean_q: 6.448760
695 (array([22]),) False
 143000/500000: episode: 3575, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 36.475, mean reward: 0.912 [0.200, 1.000], mean action: 23.100 [0.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.328573, mean_absolute_error: 5.749410, mean_q: 6.456650
825 (array([22]),) False
 143040/500000: episode: 3576, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 29.754, mean reward: 0.744 [0.180, 1.000], mean action: 21.775 [10.000, 54.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.293179, mean_absolute_error: 5.769979, mean_q: 6.478169
367 (array([12]),) False
 143080/500000: episode: 3577, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 35.741, mean reward: 0.894 [0.123, 0.996], mean action: 25.425 [22.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.293690, mean_absolute_error: 5.693639, mean_q: 6.397034
553 (array([22]),) False
 143120/500000: episode: 3578, duration: 32.156s, episode steps: 40, steps per second: 1, episode reward: 35.838, mean reward: 0.896 [0.300, 1.000], mean action: 17.325 [12.000, 55.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.256346, mean_absolute_error: 5.736566, mean_q: 6.440047
256 (array([22]),) False
 143160/500000: episode: 3579, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 35.990, mean reward: 0.900 [0.081, 1.000], mean action: 21.450 [0.000, 47.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.297116, mean_absolute_error: 5.752267, mean_q: 6.455453
504 (array([48]),) False
 143200/500000: episode: 3580, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 25.564, mean reward: 0.639 [0.114, 0.656], mean action: 21.575 [12.000, 25.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.326420, mean_absolute_error: 5.789784, mean_q: 6.497180
382 (array([22]),) False
 143240/500000: episode: 3581, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 34.179, mean reward: 0.854 [0.000, 1.000], mean action: 24.800 [11.000, 43.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.305297, mean_absolute_error: 5.723545, mean_q: 6.434430
177 (array([22]),) False
 143280/500000: episode: 3582, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 36.566, mean reward: 0.914 [0.317, 1.000], mean action: 22.425 [12.000, 57.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.295247, mean_absolute_error: 5.757237, mean_q: 6.454221
296 (array([22]),) False
 143320/500000: episode: 3583, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 38.580, mean reward: 0.965 [0.387, 1.000], mean action: 23.450 [22.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.319438, mean_absolute_error: 5.732890, mean_q: 6.427989
766 (array([12]),) False
 143360/500000: episode: 3584, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 31.163, mean reward: 0.779 [0.103, 1.000], mean action: 30.600 [6.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.301335, mean_absolute_error: 5.849451, mean_q: 6.560265
721 (array([22]),) False
 143400/500000: episode: 3585, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 37.083, mean reward: 0.927 [0.247, 1.000], mean action: 22.725 [12.000, 60.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.285902, mean_absolute_error: 5.789627, mean_q: 6.495323
191 (array([38]),) False
 143440/500000: episode: 3586, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 26.197, mean reward: 0.655 [0.240, 1.000], mean action: 20.775 [10.000, 47.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.269410, mean_absolute_error: 5.741773, mean_q: 6.441907
327 (array([22]),) False
 143480/500000: episode: 3587, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 35.872, mean reward: 0.897 [0.310, 1.000], mean action: 19.375 [1.000, 45.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.270979, mean_absolute_error: 5.811217, mean_q: 6.511668
79 (array([22]),) False
 143520/500000: episode: 3588, duration: 32.114s, episode steps: 40, steps per second: 1, episode reward: 37.669, mean reward: 0.942 [0.133, 1.000], mean action: 22.925 [14.000, 46.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.272765, mean_absolute_error: 5.792315, mean_q: 6.505104
434 (array([22]),) False
 143560/500000: episode: 3589, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 38.263, mean reward: 0.957 [0.061, 1.000], mean action: 22.475 [3.000, 60.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.278755, mean_absolute_error: 5.736695, mean_q: 6.440903
481 (array([22]),) False
 143600/500000: episode: 3590, duration: 32.119s, episode steps: 40, steps per second: 1, episode reward: 34.839, mean reward: 0.871 [0.206, 1.000], mean action: 30.550 [10.000, 58.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.304247, mean_absolute_error: 5.771945, mean_q: 6.482217
25 (array([48]),) False
 143640/500000: episode: 3591, duration: 33.009s, episode steps: 40, steps per second: 1, episode reward: 31.140, mean reward: 0.778 [0.089, 1.000], mean action: 21.825 [15.000, 58.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.293739, mean_absolute_error: 5.775367, mean_q: 6.481714
808 (array([22]),) False
 143680/500000: episode: 3592, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 32.587, mean reward: 0.815 [0.168, 1.000], mean action: 34.150 [1.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.275244, mean_absolute_error: 5.798021, mean_q: 6.506413
121 (array([22]),) False
 143720/500000: episode: 3593, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 34.701, mean reward: 0.868 [0.000, 1.000], mean action: 16.750 [0.000, 49.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.296660, mean_absolute_error: 5.691379, mean_q: 6.405421
738 (array([12]),) False
 143760/500000: episode: 3594, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 33.189, mean reward: 0.830 [0.163, 1.000], mean action: 18.300 [10.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.311492, mean_absolute_error: 5.773766, mean_q: 6.490907
127 (array([22]),) False
 143800/500000: episode: 3595, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 29.509, mean reward: 0.738 [0.081, 1.000], mean action: 18.225 [3.000, 51.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.277906, mean_absolute_error: 5.658584, mean_q: 6.376479
35 (array([48]),) False
 143840/500000: episode: 3596, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 36.477, mean reward: 0.912 [0.129, 0.972], mean action: 21.875 [4.000, 35.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.291857, mean_absolute_error: 5.728762, mean_q: 6.444030
13 (array([48]),) False
 143880/500000: episode: 3597, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 35.339, mean reward: 0.883 [0.035, 0.973], mean action: 22.200 [0.000, 55.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.290550, mean_absolute_error: 5.758771, mean_q: 6.491751
332 (array([22]),) False
 143920/500000: episode: 3598, duration: 32.162s, episode steps: 40, steps per second: 1, episode reward: 34.254, mean reward: 0.856 [0.337, 0.987], mean action: 17.850 [12.000, 53.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.278814, mean_absolute_error: 5.781093, mean_q: 6.507286
351 (array([22]),) False
 143960/500000: episode: 3599, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 33.186, mean reward: 0.830 [0.052, 1.000], mean action: 27.200 [5.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.324132, mean_absolute_error: 5.688315, mean_q: 6.399648
305 (array([12]),) False
 144000/500000: episode: 3600, duration: 32.140s, episode steps: 40, steps per second: 1, episode reward: 31.614, mean reward: 0.790 [0.167, 0.838], mean action: 23.575 [8.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.334995, mean_absolute_error: 5.737120, mean_q: 6.456735
312 (array([12]),) False
 144040/500000: episode: 3601, duration: 33.009s, episode steps: 40, steps per second: 1, episode reward: 30.065, mean reward: 0.752 [0.087, 0.782], mean action: 24.400 [22.000, 60.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.290584, mean_absolute_error: 5.677666, mean_q: 6.396326
264 (array([12]),) False
 144080/500000: episode: 3602, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 35.557, mean reward: 0.889 [0.000, 1.000], mean action: 21.925 [5.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.310463, mean_absolute_error: 5.705150, mean_q: 6.420199
364 (array([14]),) False
 144120/500000: episode: 3603, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 32.573, mean reward: 0.814 [0.339, 0.860], mean action: 26.650 [0.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.336677, mean_absolute_error: 5.741736, mean_q: 6.457732
596 (array([22]),) False
 144160/500000: episode: 3604, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 35.757, mean reward: 0.894 [0.134, 1.000], mean action: 19.700 [0.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.309327, mean_absolute_error: 5.736413, mean_q: 6.444212
318 (array([48]),) False
 144200/500000: episode: 3605, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 36.025, mean reward: 0.901 [0.068, 1.000], mean action: 22.050 [12.000, 56.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.295569, mean_absolute_error: 5.755101, mean_q: 6.462939
704 (array([22]),) False
 144240/500000: episode: 3606, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 28.035, mean reward: 0.701 [0.395, 1.000], mean action: 14.125 [12.000, 52.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.307724, mean_absolute_error: 5.710700, mean_q: 6.417152
805 (array([22]),) False
 144280/500000: episode: 3607, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 34.029, mean reward: 0.851 [0.336, 1.000], mean action: 35.625 [9.000, 57.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.277608, mean_absolute_error: 5.718606, mean_q: 6.430009
673 (array([3]),) False
 144320/500000: episode: 3608, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 19.790, mean reward: 0.495 [0.115, 1.000], mean action: 26.150 [1.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.281345, mean_absolute_error: 5.688080, mean_q: 6.394132
713 (array([37]),) False
 144360/500000: episode: 3609, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 35.199, mean reward: 0.880 [0.052, 0.994], mean action: 22.050 [6.000, 56.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.246103, mean_absolute_error: 5.718236, mean_q: 6.430176
786 (array([22]),) False
 144400/500000: episode: 3610, duration: 32.125s, episode steps: 40, steps per second: 1, episode reward: 34.885, mean reward: 0.872 [0.399, 1.000], mean action: 21.625 [4.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.289171, mean_absolute_error: 5.669682, mean_q: 6.375774
41 (array([12]),) False
 144440/500000: episode: 3611, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 32.189, mean reward: 0.805 [0.143, 1.000], mean action: 22.025 [5.000, 55.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.270271, mean_absolute_error: 5.664916, mean_q: 6.370446
5 (array([37]),) False
 144480/500000: episode: 3612, duration: 32.211s, episode steps: 40, steps per second: 1, episode reward: 38.478, mean reward: 0.962 [0.355, 1.000], mean action: 36.900 [23.000, 50.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.297030, mean_absolute_error: 5.673586, mean_q: 6.377304
458 (array([22]),) False
 144520/500000: episode: 3613, duration: 33.051s, episode steps: 40, steps per second: 1, episode reward: 36.367, mean reward: 0.909 [0.046, 1.000], mean action: 22.525 [9.000, 42.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.306791, mean_absolute_error: 5.712188, mean_q: 6.412381
807 (array([22]),) False
 144560/500000: episode: 3614, duration: 32.128s, episode steps: 40, steps per second: 1, episode reward: 37.848, mean reward: 0.946 [0.523, 1.000], mean action: 40.625 [12.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.298257, mean_absolute_error: 5.687293, mean_q: 6.386205
693 (array([22]),) False
 144600/500000: episode: 3615, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 31.460, mean reward: 0.786 [0.103, 1.000], mean action: 30.550 [3.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.274861, mean_absolute_error: 5.675010, mean_q: 6.368408
763 (array([48]),) False
 144640/500000: episode: 3616, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 36.633, mean reward: 0.916 [0.103, 1.000], mean action: 27.350 [4.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.260658, mean_absolute_error: 5.682226, mean_q: 6.381391
852 (array([44]),) False
 144680/500000: episode: 3617, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 34.233, mean reward: 0.856 [0.533, 1.000], mean action: 17.325 [12.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.265945, mean_absolute_error: 5.673840, mean_q: 6.378907
519 (array([58]),) False
 144720/500000: episode: 3618, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 16.474, mean reward: 0.412 [0.238, 0.778], mean action: 14.100 [5.000, 56.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.272773, mean_absolute_error: 5.692138, mean_q: 6.396569
6 (array([58]),) False
 144760/500000: episode: 3619, duration: 33.054s, episode steps: 40, steps per second: 1, episode reward: 33.301, mean reward: 0.833 [0.087, 1.000], mean action: 22.050 [0.000, 51.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.249422, mean_absolute_error: 5.605920, mean_q: 6.308668
313 (array([22]),) False
 144800/500000: episode: 3620, duration: 32.987s, episode steps: 40, steps per second: 1, episode reward: 37.550, mean reward: 0.939 [0.323, 1.000], mean action: 23.400 [1.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.300879, mean_absolute_error: 5.699911, mean_q: 6.398838
133 (array([22]),) False
 144840/500000: episode: 3621, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 36.848, mean reward: 0.921 [0.207, 1.000], mean action: 22.350 [3.000, 53.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.298700, mean_absolute_error: 5.710423, mean_q: 6.415706
144 (array([22]),) False
 144880/500000: episode: 3622, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 34.758, mean reward: 0.869 [0.463, 1.000], mean action: 18.775 [5.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.252369, mean_absolute_error: 5.735871, mean_q: 6.444952
264 (array([12]),) False
 144920/500000: episode: 3623, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 38.179, mean reward: 0.954 [0.397, 1.000], mean action: 23.900 [12.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.243037, mean_absolute_error: 5.719035, mean_q: 6.421564
577 (array([12]),) False
 144960/500000: episode: 3624, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 37.159, mean reward: 0.929 [0.166, 1.000], mean action: 22.575 [2.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.282800, mean_absolute_error: 5.728216, mean_q: 6.432934
211 (array([22]),) False
 145000/500000: episode: 3625, duration: 32.981s, episode steps: 40, steps per second: 1, episode reward: 31.924, mean reward: 0.798 [0.032, 1.000], mean action: 15.550 [12.000, 33.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.282349, mean_absolute_error: 5.681077, mean_q: 6.378748
268 (array([22]),) False
 145040/500000: episode: 3626, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 34.931, mean reward: 0.873 [0.115, 1.000], mean action: 24.375 [6.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.268415, mean_absolute_error: 5.761261, mean_q: 6.468337
296 (array([22]),) False
 145080/500000: episode: 3627, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 36.824, mean reward: 0.921 [0.194, 1.000], mean action: 21.175 [6.000, 34.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.255731, mean_absolute_error: 5.762465, mean_q: 6.465181
307 (array([22]),) False
 145120/500000: episode: 3628, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 36.478, mean reward: 0.912 [0.035, 1.000], mean action: 23.350 [9.000, 54.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.257661, mean_absolute_error: 5.729499, mean_q: 6.434434
314 (array([22]),) False
 145160/500000: episode: 3629, duration: 33.030s, episode steps: 40, steps per second: 1, episode reward: 35.733, mean reward: 0.893 [0.227, 1.000], mean action: 23.825 [2.000, 59.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.265183, mean_absolute_error: 5.821651, mean_q: 6.530144
89 (array([58]),) False
 145200/500000: episode: 3630, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 23.146, mean reward: 0.579 [0.063, 0.998], mean action: 25.700 [0.000, 49.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.272037, mean_absolute_error: 5.699895, mean_q: 6.400411
57 (array([37]),) False
 145240/500000: episode: 3631, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 30.627, mean reward: 0.766 [0.174, 0.829], mean action: 25.200 [14.000, 60.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.297836, mean_absolute_error: 5.686656, mean_q: 6.385806
1 (array([22]),) False
 145280/500000: episode: 3632, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 31.630, mean reward: 0.791 [0.030, 1.000], mean action: 24.875 [22.000, 59.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.276979, mean_absolute_error: 5.749254, mean_q: 6.456268
249 (array([22]),) False
 145320/500000: episode: 3633, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 37.822, mean reward: 0.946 [0.128, 1.000], mean action: 23.575 [21.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.287573, mean_absolute_error: 5.758342, mean_q: 6.461061
660 (array([2]),) False
 145360/500000: episode: 3634, duration: 32.140s, episode steps: 40, steps per second: 1, episode reward: 20.206, mean reward: 0.505 [0.118, 1.000], mean action: 29.650 [4.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.268669, mean_absolute_error: 5.779075, mean_q: 6.480214
739 (array([22]),) False
 145400/500000: episode: 3635, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 36.944, mean reward: 0.924 [0.195, 1.000], mean action: 21.400 [10.000, 48.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.268607, mean_absolute_error: 5.689340, mean_q: 6.392908
424 (array([22]),) False
 145440/500000: episode: 3636, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 38.123, mean reward: 0.953 [0.454, 1.000], mean action: 22.125 [15.000, 44.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.303343, mean_absolute_error: 5.812579, mean_q: 6.534745
296 (array([22]),) False
 145480/500000: episode: 3637, duration: 33.014s, episode steps: 40, steps per second: 1, episode reward: 36.302, mean reward: 0.908 [0.000, 1.000], mean action: 21.675 [3.000, 42.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.264259, mean_absolute_error: 5.819257, mean_q: 6.531310
190 (array([3]),) False
 145520/500000: episode: 3638, duration: 32.142s, episode steps: 40, steps per second: 1, episode reward: 23.295, mean reward: 0.582 [0.230, 1.000], mean action: 31.575 [3.000, 59.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.289321, mean_absolute_error: 5.738438, mean_q: 6.446630
726 (array([12]),) False
 145560/500000: episode: 3639, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 36.189, mean reward: 0.905 [0.232, 1.000], mean action: 19.975 [4.000, 50.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.261463, mean_absolute_error: 5.660079, mean_q: 6.372533
557 (array([22]),) False
 145600/500000: episode: 3640, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 31.912, mean reward: 0.798 [0.230, 1.000], mean action: 17.175 [0.000, 44.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.256029, mean_absolute_error: 5.780969, mean_q: 6.496037
168 (array([22]),) False
 145640/500000: episode: 3641, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 34.792, mean reward: 0.870 [0.022, 1.000], mean action: 20.200 [1.000, 60.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.275972, mean_absolute_error: 5.744189, mean_q: 6.449432
243 (array([12]),) False
 145680/500000: episode: 3642, duration: 32.922s, episode steps: 40, steps per second: 1, episode reward: 35.864, mean reward: 0.897 [0.091, 1.000], mean action: 25.250 [1.000, 57.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.267037, mean_absolute_error: 5.700401, mean_q: 6.395612
387 (array([22]),) False
 145720/500000: episode: 3643, duration: 32.966s, episode steps: 40, steps per second: 1, episode reward: 38.470, mean reward: 0.962 [0.153, 1.000], mean action: 22.275 [18.000, 38.000], mean observation: -0.042 [-1.000, 1.000], loss: 0.287487, mean_absolute_error: 5.732978, mean_q: 6.441350
428 (array([22]),) False
 145760/500000: episode: 3644, duration: 32.910s, episode steps: 40, steps per second: 1, episode reward: 37.581, mean reward: 0.940 [0.141, 1.000], mean action: 21.750 [0.000, 48.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.320339, mean_absolute_error: 5.838672, mean_q: 6.551170
13 (array([48]),) False
 145800/500000: episode: 3645, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 34.637, mean reward: 0.866 [0.000, 0.973], mean action: 28.150 [3.000, 49.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.250947, mean_absolute_error: 5.744872, mean_q: 6.448110
682 (array([22]),) False
 145840/500000: episode: 3646, duration: 32.165s, episode steps: 40, steps per second: 1, episode reward: 36.630, mean reward: 0.916 [0.174, 1.000], mean action: 14.725 [5.000, 38.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.264707, mean_absolute_error: 5.798843, mean_q: 6.509059
504 (array([48]),) False
 145880/500000: episode: 3647, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 25.459, mean reward: 0.636 [0.375, 0.656], mean action: 21.950 [5.000, 51.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.287526, mean_absolute_error: 5.816363, mean_q: 6.530243
58 (array([48]),) False
 145920/500000: episode: 3648, duration: 32.073s, episode steps: 40, steps per second: 1, episode reward: 28.618, mean reward: 0.715 [0.209, 0.734], mean action: 17.650 [9.000, 18.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.282433, mean_absolute_error: 5.734881, mean_q: 6.445813
810 (array([12]),) False
 145960/500000: episode: 3649, duration: 32.968s, episode steps: 40, steps per second: 1, episode reward: 35.376, mean reward: 0.884 [0.399, 1.000], mean action: 30.450 [12.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.284912, mean_absolute_error: 5.836596, mean_q: 6.549585
71 (array([58]),) False
 146000/500000: episode: 3650, duration: 32.082s, episode steps: 40, steps per second: 1, episode reward: 11.532, mean reward: 0.288 [0.036, 1.000], mean action: 26.675 [22.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.284230, mean_absolute_error: 5.770295, mean_q: 6.488245
374 (array([22]),) False
 146040/500000: episode: 3651, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 37.997, mean reward: 0.950 [0.116, 1.000], mean action: 22.025 [2.000, 44.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.279579, mean_absolute_error: 5.728463, mean_q: 6.442780
82 (array([22]),) False
 146080/500000: episode: 3652, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 38.905, mean reward: 0.973 [0.238, 1.000], mean action: 22.450 [14.000, 56.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.278280, mean_absolute_error: 5.727510, mean_q: 6.442886
429 (array([22]),) False
 146120/500000: episode: 3653, duration: 32.927s, episode steps: 40, steps per second: 1, episode reward: 38.184, mean reward: 0.955 [0.308, 1.000], mean action: 21.750 [10.000, 32.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.291978, mean_absolute_error: 5.791358, mean_q: 6.506346
98 (array([12]),) False
 146160/500000: episode: 3654, duration: 32.954s, episode steps: 40, steps per second: 1, episode reward: 35.787, mean reward: 0.895 [0.000, 0.987], mean action: 20.150 [4.000, 22.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.280567, mean_absolute_error: 5.792135, mean_q: 6.511153
208 (array([22]),) False
 146200/500000: episode: 3655, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 35.987, mean reward: 0.900 [0.000, 1.000], mean action: 13.125 [2.000, 22.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.261033, mean_absolute_error: 5.697355, mean_q: 6.413033
684 (array([22]),) False
 146240/500000: episode: 3656, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 37.427, mean reward: 0.936 [0.210, 1.000], mean action: 23.075 [12.000, 51.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.256512, mean_absolute_error: 5.801894, mean_q: 6.512964
481 (array([22]),) False
 146280/500000: episode: 3657, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 34.926, mean reward: 0.873 [0.381, 1.000], mean action: 38.075 [12.000, 53.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.309921, mean_absolute_error: 5.716481, mean_q: 6.427733
40 (array([22]),) False
 146320/500000: episode: 3658, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 36.557, mean reward: 0.914 [0.213, 1.000], mean action: 25.100 [3.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.242924, mean_absolute_error: 5.794196, mean_q: 6.509329
7 (array([22]),) False
 146360/500000: episode: 3659, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 38.181, mean reward: 0.955 [0.285, 1.000], mean action: 22.825 [12.000, 55.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.308031, mean_absolute_error: 5.727736, mean_q: 6.440542
191 (array([38]),) False
 146400/500000: episode: 3660, duration: 32.140s, episode steps: 40, steps per second: 1, episode reward: 26.582, mean reward: 0.665 [0.215, 1.000], mean action: 17.550 [12.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.290516, mean_absolute_error: 5.853012, mean_q: 6.570113
318 (array([48]),) False
 146440/500000: episode: 3661, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 37.182, mean reward: 0.930 [0.000, 1.000], mean action: 21.300 [12.000, 57.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.331043, mean_absolute_error: 5.794663, mean_q: 6.511898
172 (array([12]),) False
 146480/500000: episode: 3662, duration: 32.059s, episode steps: 40, steps per second: 1, episode reward: 32.008, mean reward: 0.800 [0.000, 1.000], mean action: 17.275 [1.000, 58.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.294211, mean_absolute_error: 5.761955, mean_q: 6.473756
779 (array([12]),) False
 146520/500000: episode: 3663, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 38.775, mean reward: 0.969 [0.642, 1.000], mean action: 13.600 [12.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.294475, mean_absolute_error: 5.816026, mean_q: 6.529310
626 (array([22]),) False
 146560/500000: episode: 3664, duration: 32.907s, episode steps: 40, steps per second: 1, episode reward: 21.470, mean reward: 0.537 [0.160, 0.905], mean action: 27.325 [3.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.263005, mean_absolute_error: 5.792258, mean_q: 6.505427
705 (array([22]),) False
 146600/500000: episode: 3665, duration: 32.922s, episode steps: 40, steps per second: 1, episode reward: 32.978, mean reward: 0.824 [0.262, 1.000], mean action: 15.775 [7.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.281921, mean_absolute_error: 5.848614, mean_q: 6.562304
753 (array([22]),) False
 146640/500000: episode: 3666, duration: 32.959s, episode steps: 40, steps per second: 1, episode reward: 35.190, mean reward: 0.880 [0.027, 1.000], mean action: 22.100 [6.000, 50.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.275090, mean_absolute_error: 5.850359, mean_q: 6.568133
380 (array([22]),) False
 146680/500000: episode: 3667, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 36.713, mean reward: 0.918 [0.015, 1.000], mean action: 21.525 [4.000, 42.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.265820, mean_absolute_error: 5.848938, mean_q: 6.552768
230 (array([22]),) False
 146720/500000: episode: 3668, duration: 32.996s, episode steps: 40, steps per second: 1, episode reward: 34.586, mean reward: 0.865 [0.107, 1.000], mean action: 23.400 [3.000, 57.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.295281, mean_absolute_error: 5.775807, mean_q: 6.480547
344 (array([22]),) False
 146760/500000: episode: 3669, duration: 33.075s, episode steps: 40, steps per second: 1, episode reward: 35.909, mean reward: 0.898 [0.205, 1.000], mean action: 23.600 [12.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.281764, mean_absolute_error: 5.802351, mean_q: 6.502090
404 (array([12]),) False
 146800/500000: episode: 3670, duration: 32.157s, episode steps: 40, steps per second: 1, episode reward: 29.282, mean reward: 0.732 [0.110, 1.000], mean action: 21.725 [0.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.269765, mean_absolute_error: 5.798358, mean_q: 6.506845
228 (array([44]),) False
 146840/500000: episode: 3671, duration: 32.968s, episode steps: 40, steps per second: 1, episode reward: 34.500, mean reward: 0.862 [0.074, 1.000], mean action: 22.625 [1.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.253070, mean_absolute_error: 5.798181, mean_q: 6.504817
281 (array([48]),) False
 146880/500000: episode: 3672, duration: 32.069s, episode steps: 40, steps per second: 1, episode reward: 36.895, mean reward: 0.922 [0.018, 1.000], mean action: 23.350 [4.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.262567, mean_absolute_error: 5.846690, mean_q: 6.552428
313 (array([22]),) False
 146920/500000: episode: 3673, duration: 32.980s, episode steps: 40, steps per second: 1, episode reward: 36.045, mean reward: 0.901 [0.298, 1.000], mean action: 22.500 [5.000, 52.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.326747, mean_absolute_error: 5.859123, mean_q: 6.555445
196 (array([22]),) False
 146960/500000: episode: 3674, duration: 32.115s, episode steps: 40, steps per second: 1, episode reward: 32.265, mean reward: 0.807 [0.128, 1.000], mean action: 18.800 [9.000, 57.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.313129, mean_absolute_error: 5.822628, mean_q: 6.520198
788 (array([3]),) False
 147000/500000: episode: 3675, duration: 32.888s, episode steps: 40, steps per second: 1, episode reward: 23.407, mean reward: 0.585 [0.053, 1.000], mean action: 28.025 [3.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.251791, mean_absolute_error: 5.794572, mean_q: 6.500951
334 (array([48]),) False
 147040/500000: episode: 3676, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 33.429, mean reward: 0.836 [0.000, 1.000], mean action: 24.450 [22.000, 57.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.301472, mean_absolute_error: 5.818446, mean_q: 6.533690
188 (array([22]),) False
 147080/500000: episode: 3677, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 38.139, mean reward: 0.953 [0.636, 1.000], mean action: 17.200 [12.000, 22.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.265758, mean_absolute_error: 5.806769, mean_q: 6.525159
58 (array([48]),) False
 147120/500000: episode: 3678, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 28.192, mean reward: 0.705 [0.355, 0.734], mean action: 21.075 [18.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.243951, mean_absolute_error: 5.817683, mean_q: 6.534684
331 (array([22]),) False
 147160/500000: episode: 3679, duration: 33.032s, episode steps: 40, steps per second: 1, episode reward: 32.920, mean reward: 0.823 [0.409, 1.000], mean action: 21.700 [12.000, 49.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.306425, mean_absolute_error: 5.797216, mean_q: 6.506569
604 (array([40]),) False
 147200/500000: episode: 3680, duration: 32.900s, episode steps: 40, steps per second: 1, episode reward: 35.441, mean reward: 0.886 [0.562, 0.959], mean action: 17.700 [12.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.294360, mean_absolute_error: 5.811360, mean_q: 6.520461
479 (array([22]),) False
 147240/500000: episode: 3681, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 35.671, mean reward: 0.892 [0.098, 1.000], mean action: 33.350 [8.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.292688, mean_absolute_error: 5.848628, mean_q: 6.559928
162 (array([22]),) False
 147280/500000: episode: 3682, duration: 32.115s, episode steps: 40, steps per second: 1, episode reward: 37.358, mean reward: 0.934 [0.476, 1.000], mean action: 20.450 [12.000, 44.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.291060, mean_absolute_error: 5.757898, mean_q: 6.474067
670 (array([22]),) False
 147320/500000: episode: 3683, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 29.565, mean reward: 0.739 [0.197, 1.000], mean action: 23.775 [6.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.246846, mean_absolute_error: 5.860409, mean_q: 6.586655
544 (array([22]),) False
 147360/500000: episode: 3684, duration: 32.112s, episode steps: 40, steps per second: 1, episode reward: 37.376, mean reward: 0.934 [0.000, 1.000], mean action: 20.100 [6.000, 39.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.286758, mean_absolute_error: 5.811641, mean_q: 6.522307
70 (array([22]),) False
 147400/500000: episode: 3685, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 35.010, mean reward: 0.875 [0.039, 1.000], mean action: 21.100 [9.000, 59.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.337625, mean_absolute_error: 5.769722, mean_q: 6.482751
18 (array([22]),) False
 147440/500000: episode: 3686, duration: 32.073s, episode steps: 40, steps per second: 1, episode reward: 36.438, mean reward: 0.911 [0.175, 1.000], mean action: 23.925 [15.000, 54.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.257104, mean_absolute_error: 5.793139, mean_q: 6.493918
758 (array([38]),) False
 147480/500000: episode: 3687, duration: 32.987s, episode steps: 40, steps per second: 1, episode reward: 37.261, mean reward: 0.932 [0.402, 0.966], mean action: 23.275 [7.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.319539, mean_absolute_error: 5.835154, mean_q: 6.539731
388 (array([22]),) False
 147520/500000: episode: 3688, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 37.535, mean reward: 0.938 [0.032, 1.000], mean action: 21.100 [4.000, 22.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.272887, mean_absolute_error: 5.862710, mean_q: 6.562601
745 (array([22]),) False
 147560/500000: episode: 3689, duration: 32.899s, episode steps: 40, steps per second: 1, episode reward: 32.881, mean reward: 0.822 [0.563, 1.000], mean action: 18.350 [1.000, 54.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.262057, mean_absolute_error: 5.826406, mean_q: 6.527359
286 (array([22]),) False
 147600/500000: episode: 3690, duration: 32.901s, episode steps: 40, steps per second: 1, episode reward: 32.538, mean reward: 0.813 [0.093, 1.000], mean action: 20.300 [10.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.289666, mean_absolute_error: 5.856659, mean_q: 6.558063
454 (array([12]),) False
 147640/500000: episode: 3691, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 31.138, mean reward: 0.778 [0.006, 0.890], mean action: 23.275 [5.000, 58.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.264489, mean_absolute_error: 5.836005, mean_q: 6.536378
816 (array([4]),) False
 147680/500000: episode: 3692, duration: 32.900s, episode steps: 40, steps per second: 1, episode reward: 7.037, mean reward: 0.176 [0.000, 0.958], mean action: 26.575 [8.000, 57.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.265736, mean_absolute_error: 5.831781, mean_q: 6.537322
602 (array([36]),) False
 147720/500000: episode: 3693, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 14.317, mean reward: 0.358 [0.000, 0.790], mean action: 37.025 [3.000, 60.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.291532, mean_absolute_error: 5.982808, mean_q: 6.700648
144 (array([22]),) False
 147760/500000: episode: 3694, duration: 32.074s, episode steps: 40, steps per second: 1, episode reward: 35.037, mean reward: 0.876 [0.354, 1.000], mean action: 18.925 [12.000, 40.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.249878, mean_absolute_error: 5.810940, mean_q: 6.517889
63 (array([18]),) False
 147800/500000: episode: 3695, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 35.355, mean reward: 0.884 [0.014, 0.990], mean action: 13.625 [3.000, 60.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.264590, mean_absolute_error: 5.904400, mean_q: 6.616099
652 (array([22]),) False
 147840/500000: episode: 3696, duration: 32.054s, episode steps: 40, steps per second: 1, episode reward: 36.997, mean reward: 0.925 [0.217, 1.000], mean action: 23.075 [2.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.262007, mean_absolute_error: 5.900216, mean_q: 6.612087
197 (array([22]),) False
 147880/500000: episode: 3697, duration: 32.895s, episode steps: 40, steps per second: 1, episode reward: 34.236, mean reward: 0.856 [0.081, 1.000], mean action: 21.925 [12.000, 59.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.296717, mean_absolute_error: 5.848970, mean_q: 6.557736
320 (array([22]),) False
 147920/500000: episode: 3698, duration: 32.049s, episode steps: 40, steps per second: 1, episode reward: 36.186, mean reward: 0.905 [0.092, 1.000], mean action: 21.200 [3.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.264439, mean_absolute_error: 5.924640, mean_q: 6.641150
238 (array([22]),) False
 147960/500000: episode: 3699, duration: 32.969s, episode steps: 40, steps per second: 1, episode reward: 38.024, mean reward: 0.951 [0.381, 1.000], mean action: 22.550 [16.000, 50.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.274575, mean_absolute_error: 5.803842, mean_q: 6.515565
230 (array([22]),) False
 148000/500000: episode: 3700, duration: 32.981s, episode steps: 40, steps per second: 1, episode reward: 34.164, mean reward: 0.854 [0.035, 1.000], mean action: 25.100 [3.000, 58.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.304029, mean_absolute_error: 5.831583, mean_q: 6.542184
213 (array([22]),) False
 148040/500000: episode: 3701, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 35.470, mean reward: 0.887 [0.122, 1.000], mean action: 23.850 [5.000, 59.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.270486, mean_absolute_error: 5.805667, mean_q: 6.519190
852 (array([44]),) False
 148080/500000: episode: 3702, duration: 32.930s, episode steps: 40, steps per second: 1, episode reward: 33.492, mean reward: 0.837 [0.194, 1.000], mean action: 18.425 [6.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.283771, mean_absolute_error: 5.907098, mean_q: 6.630895
188 (array([22]),) False
 148120/500000: episode: 3703, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 32.926, mean reward: 0.823 [0.072, 1.000], mean action: 18.975 [11.000, 60.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.296132, mean_absolute_error: 5.857197, mean_q: 6.574971
638 (array([22]),) False
 148160/500000: episode: 3704, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 35.703, mean reward: 0.893 [0.004, 1.000], mean action: 24.800 [18.000, 49.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.282537, mean_absolute_error: 5.898504, mean_q: 6.617494
701 (array([48]),) False
 148200/500000: episode: 3705, duration: 32.988s, episode steps: 40, steps per second: 1, episode reward: 36.081, mean reward: 0.902 [0.463, 1.000], mean action: 31.000 [12.000, 48.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.251088, mean_absolute_error: 5.852519, mean_q: 6.572314
315 (array([12]),) False
 148240/500000: episode: 3706, duration: 32.118s, episode steps: 40, steps per second: 1, episode reward: 35.278, mean reward: 0.882 [0.095, 1.000], mean action: 21.525 [7.000, 28.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.284537, mean_absolute_error: 5.835654, mean_q: 6.550610
639 (array([22]),) False
 148280/500000: episode: 3707, duration: 32.980s, episode steps: 40, steps per second: 1, episode reward: 34.144, mean reward: 0.854 [0.152, 1.000], mean action: 19.275 [7.000, 32.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.290754, mean_absolute_error: 5.888771, mean_q: 6.613688
130 (array([22]),) False
 148320/500000: episode: 3708, duration: 32.056s, episode steps: 40, steps per second: 1, episode reward: 39.413, mean reward: 0.985 [0.416, 1.000], mean action: 21.475 [1.000, 22.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.266153, mean_absolute_error: 5.989070, mean_q: 6.717628
470 (array([22]),) False
 148360/500000: episode: 3709, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 35.994, mean reward: 0.900 [0.030, 1.000], mean action: 25.075 [20.000, 58.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.297645, mean_absolute_error: 5.852108, mean_q: 6.574154
284 (array([12]),) False
 148400/500000: episode: 3710, duration: 32.167s, episode steps: 40, steps per second: 1, episode reward: 28.131, mean reward: 0.703 [0.158, 1.000], mean action: 21.575 [11.000, 57.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.260590, mean_absolute_error: 5.848693, mean_q: 6.566621
43 (array([12]),) False
 148440/500000: episode: 3711, duration: 32.993s, episode steps: 40, steps per second: 1, episode reward: 33.623, mean reward: 0.841 [0.000, 0.998], mean action: 23.400 [8.000, 50.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.293954, mean_absolute_error: 5.877428, mean_q: 6.589772
467 (array([48]),) False
 148480/500000: episode: 3712, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 33.070, mean reward: 0.827 [0.050, 0.928], mean action: 24.075 [20.000, 57.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.267734, mean_absolute_error: 5.951344, mean_q: 6.667959
91 (array([48]),) False
 148520/500000: episode: 3713, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 35.359, mean reward: 0.884 [0.096, 1.000], mean action: 23.300 [12.000, 57.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.299169, mean_absolute_error: 5.977613, mean_q: 6.695437
559 (array([59]),) False
 148560/500000: episode: 3714, duration: 32.892s, episode steps: 40, steps per second: 1, episode reward: 23.162, mean reward: 0.579 [0.068, 1.000], mean action: 15.000 [12.000, 22.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.283184, mean_absolute_error: 5.909478, mean_q: 6.629901
103 (array([22]),) False
 148600/500000: episode: 3715, duration: 32.936s, episode steps: 40, steps per second: 1, episode reward: 33.669, mean reward: 0.842 [0.083, 1.000], mean action: 19.200 [1.000, 36.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.277957, mean_absolute_error: 5.952604, mean_q: 6.675895
324 (array([12]),) False
 148640/500000: episode: 3716, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 36.586, mean reward: 0.915 [0.089, 1.000], mean action: 18.975 [2.000, 38.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.297628, mean_absolute_error: 5.872694, mean_q: 6.595587
781 (array([8]),) False
 148680/500000: episode: 3717, duration: 32.989s, episode steps: 40, steps per second: 1, episode reward: 32.269, mean reward: 0.807 [0.424, 1.000], mean action: 22.500 [12.000, 47.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.339372, mean_absolute_error: 5.958649, mean_q: 6.686028
666 (array([22]),) False
 148720/500000: episode: 3718, duration: 32.109s, episode steps: 40, steps per second: 1, episode reward: 35.278, mean reward: 0.882 [0.218, 1.000], mean action: 33.700 [12.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.283389, mean_absolute_error: 5.859794, mean_q: 6.581285
692 (array([22]),) False
 148760/500000: episode: 3719, duration: 33.005s, episode steps: 40, steps per second: 1, episode reward: 35.268, mean reward: 0.882 [0.064, 1.000], mean action: 23.375 [6.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.268390, mean_absolute_error: 5.922497, mean_q: 6.653517
204 (array([22]),) False
 148800/500000: episode: 3720, duration: 32.067s, episode steps: 40, steps per second: 1, episode reward: 28.500, mean reward: 0.712 [0.172, 1.000], mean action: 19.600 [12.000, 59.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.305292, mean_absolute_error: 5.873081, mean_q: 6.591496
411 (array([22]),) False
 148840/500000: episode: 3721, duration: 32.965s, episode steps: 40, steps per second: 1, episode reward: 38.970, mean reward: 0.974 [0.550, 1.000], mean action: 23.025 [7.000, 50.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.299257, mean_absolute_error: 5.855339, mean_q: 6.569637
533 (array([22]),) False
 148880/500000: episode: 3722, duration: 32.073s, episode steps: 40, steps per second: 1, episode reward: 38.254, mean reward: 0.956 [0.429, 1.000], mean action: 21.675 [12.000, 47.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.299075, mean_absolute_error: 5.928525, mean_q: 6.642751
596 (array([22]),) False
 148920/500000: episode: 3723, duration: 32.967s, episode steps: 40, steps per second: 1, episode reward: 33.076, mean reward: 0.827 [0.343, 1.000], mean action: 23.775 [7.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.283179, mean_absolute_error: 5.944046, mean_q: 6.657366
314 (array([22]),) False
 148960/500000: episode: 3724, duration: 32.946s, episode steps: 40, steps per second: 1, episode reward: 37.439, mean reward: 0.936 [0.419, 1.000], mean action: 23.650 [12.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.288135, mean_absolute_error: 5.914811, mean_q: 6.628066
340 (array([12]),) False
 149000/500000: episode: 3725, duration: 32.852s, episode steps: 40, steps per second: 1, episode reward: 32.402, mean reward: 0.810 [0.148, 1.000], mean action: 22.925 [3.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.267095, mean_absolute_error: 5.905328, mean_q: 6.617665
785 (array([22]),) False
 149040/500000: episode: 3726, duration: 32.917s, episode steps: 40, steps per second: 1, episode reward: 33.294, mean reward: 0.832 [0.043, 1.000], mean action: 20.225 [12.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.279820, mean_absolute_error: 5.857251, mean_q: 6.565389
738 (array([12]),) False
 149080/500000: episode: 3727, duration: 32.964s, episode steps: 40, steps per second: 1, episode reward: 37.171, mean reward: 0.929 [0.292, 1.000], mean action: 17.425 [2.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.273480, mean_absolute_error: 5.902206, mean_q: 6.625206
455 (array([22]),) False
 149120/500000: episode: 3728, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 37.259, mean reward: 0.931 [0.098, 1.000], mean action: 20.750 [0.000, 22.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.296866, mean_absolute_error: 5.871249, mean_q: 6.590087
191 (array([38]),) False
 149160/500000: episode: 3729, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 26.385, mean reward: 0.660 [0.089, 1.000], mean action: 18.575 [2.000, 53.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.285379, mean_absolute_error: 5.876172, mean_q: 6.594767
742 (array([33]),) False
 149200/500000: episode: 3730, duration: 32.068s, episode steps: 40, steps per second: 1, episode reward: 29.768, mean reward: 0.744 [0.435, 0.914], mean action: 22.800 [12.000, 44.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.300408, mean_absolute_error: 5.885796, mean_q: 6.602735
580 (array([22]),) False
 149240/500000: episode: 3731, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 37.307, mean reward: 0.933 [0.274, 1.000], mean action: 28.625 [12.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.322379, mean_absolute_error: 5.893613, mean_q: 6.609153
719 (array([22]),) False
 149280/500000: episode: 3732, duration: 32.054s, episode steps: 40, steps per second: 1, episode reward: 33.248, mean reward: 0.831 [0.191, 1.000], mean action: 14.325 [0.000, 44.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.277254, mean_absolute_error: 5.951357, mean_q: 6.669838
808 (array([22]),) False
 149320/500000: episode: 3733, duration: 32.864s, episode steps: 40, steps per second: 1, episode reward: 32.932, mean reward: 0.823 [0.195, 1.000], mean action: 37.675 [2.000, 49.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.330190, mean_absolute_error: 5.933848, mean_q: 6.650843
692 (array([22]),) False
 149360/500000: episode: 3734, duration: 32.091s, episode steps: 40, steps per second: 1, episode reward: 38.092, mean reward: 0.952 [0.242, 1.000], mean action: 21.750 [12.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.266179, mean_absolute_error: 5.895842, mean_q: 6.616934
278 (array([48]),) False
 149400/500000: episode: 3735, duration: 32.940s, episode steps: 40, steps per second: 1, episode reward: 31.551, mean reward: 0.789 [0.034, 1.000], mean action: 23.600 [10.000, 57.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.287563, mean_absolute_error: 5.976868, mean_q: 6.702300
68 (array([22]),) False
 149440/500000: episode: 3736, duration: 33.066s, episode steps: 40, steps per second: 1, episode reward: 34.920, mean reward: 0.873 [0.236, 1.000], mean action: 18.850 [5.000, 28.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.286633, mean_absolute_error: 5.907643, mean_q: 6.632930
147 (array([44]),) False
 149480/500000: episode: 3737, duration: 32.873s, episode steps: 40, steps per second: 1, episode reward: 29.833, mean reward: 0.746 [0.488, 0.838], mean action: 17.575 [12.000, 52.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.298048, mean_absolute_error: 5.954808, mean_q: 6.677854
679 (array([44]),) False
 149520/500000: episode: 3738, duration: 32.838s, episode steps: 40, steps per second: 1, episode reward: 30.415, mean reward: 0.760 [0.000, 1.000], mean action: 18.950 [1.000, 58.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.285844, mean_absolute_error: 5.855688, mean_q: 6.575394
746 (array([37]),) False
 149560/500000: episode: 3739, duration: 32.918s, episode steps: 40, steps per second: 1, episode reward: 34.178, mean reward: 0.854 [0.148, 1.000], mean action: 23.050 [3.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.312152, mean_absolute_error: 5.910857, mean_q: 6.626480
634 (array([57]),) False
 149600/500000: episode: 3740, duration: 32.929s, episode steps: 40, steps per second: 1, episode reward: 29.261, mean reward: 0.732 [0.032, 1.000], mean action: 26.450 [12.000, 48.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.267825, mean_absolute_error: 5.921630, mean_q: 6.646581
479 (array([22]),) False
 149640/500000: episode: 3741, duration: 32.923s, episode steps: 40, steps per second: 1, episode reward: 37.030, mean reward: 0.926 [0.848, 1.000], mean action: 35.475 [22.000, 49.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.323454, mean_absolute_error: 5.832819, mean_q: 6.553563
251 (array([3]),) False
 149680/500000: episode: 3742, duration: 32.122s, episode steps: 40, steps per second: 1, episode reward: 27.333, mean reward: 0.683 [0.005, 1.000], mean action: 10.825 [0.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.323119, mean_absolute_error: 5.931664, mean_q: 6.653654
149 (array([8]),) False
 149720/500000: episode: 3743, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 36.108, mean reward: 0.903 [0.126, 0.992], mean action: 21.175 [5.000, 36.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.294527, mean_absolute_error: 5.943227, mean_q: 6.656981
537 (array([22]),) False
 149760/500000: episode: 3744, duration: 32.130s, episode steps: 40, steps per second: 1, episode reward: 35.816, mean reward: 0.895 [0.384, 1.000], mean action: 23.400 [12.000, 52.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.306458, mean_absolute_error: 5.845380, mean_q: 6.554929
598 (array([22]),) False
 149800/500000: episode: 3745, duration: 32.943s, episode steps: 40, steps per second: 1, episode reward: 37.506, mean reward: 0.938 [0.415, 1.000], mean action: 30.750 [12.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.326713, mean_absolute_error: 5.924815, mean_q: 6.643611
571 (array([48]),) False
 149840/500000: episode: 3746, duration: 32.066s, episode steps: 40, steps per second: 1, episode reward: 33.913, mean reward: 0.848 [0.347, 1.000], mean action: 33.525 [12.000, 51.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.299281, mean_absolute_error: 5.848744, mean_q: 6.567561
584 (array([36]),) False
 149880/500000: episode: 3747, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 18.292, mean reward: 0.457 [0.233, 0.815], mean action: 18.550 [4.000, 55.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.269867, mean_absolute_error: 5.871758, mean_q: 6.587923
427 (array([22]),) False
 149920/500000: episode: 3748, duration: 32.981s, episode steps: 40, steps per second: 1, episode reward: 34.045, mean reward: 0.851 [0.297, 1.000], mean action: 25.500 [20.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.286004, mean_absolute_error: 5.934918, mean_q: 6.651648
456 (array([22]),) False
 149960/500000: episode: 3749, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 39.084, mean reward: 0.977 [0.351, 1.000], mean action: 21.800 [7.000, 37.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.307001, mean_absolute_error: 5.881809, mean_q: 6.597763
594 (array([48]),) False
 150000/500000: episode: 3750, duration: 32.985s, episode steps: 40, steps per second: 1, episode reward: 32.325, mean reward: 0.808 [0.102, 1.000], mean action: 23.475 [5.000, 53.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.300238, mean_absolute_error: 5.833423, mean_q: 6.550337
220 (array([22]),) False
 150040/500000: episode: 3751, duration: 32.885s, episode steps: 40, steps per second: 1, episode reward: 38.305, mean reward: 0.958 [0.140, 1.000], mean action: 23.125 [22.000, 47.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.306833, mean_absolute_error: 5.845854, mean_q: 6.564847
122 (array([12]),) False
 150080/500000: episode: 3752, duration: 32.948s, episode steps: 40, steps per second: 1, episode reward: 32.078, mean reward: 0.802 [0.328, 1.000], mean action: 19.450 [7.000, 53.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.250195, mean_absolute_error: 5.918952, mean_q: 6.647865
204 (array([22]),) False
 150120/500000: episode: 3753, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 25.678, mean reward: 0.642 [0.127, 1.000], mean action: 21.525 [12.000, 59.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.306915, mean_absolute_error: 5.900798, mean_q: 6.628439
551 (array([22]),) False
 150160/500000: episode: 3754, duration: 32.107s, episode steps: 40, steps per second: 1, episode reward: 36.988, mean reward: 0.925 [0.260, 1.000], mean action: 17.400 [9.000, 56.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.274989, mean_absolute_error: 5.869720, mean_q: 6.598289
578 (array([22]),) False
 150200/500000: episode: 3755, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 36.400, mean reward: 0.910 [0.080, 1.000], mean action: 29.750 [8.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.302635, mean_absolute_error: 5.926448, mean_q: 6.651159
640 (array([22]),) False
 150240/500000: episode: 3756, duration: 32.091s, episode steps: 40, steps per second: 1, episode reward: 35.682, mean reward: 0.892 [0.110, 1.000], mean action: 28.925 [18.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.274929, mean_absolute_error: 5.883225, mean_q: 6.611957
386 (array([12]),) False
 150280/500000: episode: 3757, duration: 32.878s, episode steps: 40, steps per second: 1, episode reward: 33.961, mean reward: 0.849 [0.348, 0.924], mean action: 24.150 [17.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.339023, mean_absolute_error: 5.948186, mean_q: 6.671054
435 (array([22]),) False
 150320/500000: episode: 3758, duration: 32.107s, episode steps: 40, steps per second: 1, episode reward: 37.195, mean reward: 0.930 [0.292, 1.000], mean action: 23.075 [12.000, 44.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.290586, mean_absolute_error: 5.950768, mean_q: 6.680689
300 (array([22]),) False
 150360/500000: episode: 3759, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 34.048, mean reward: 0.851 [0.033, 1.000], mean action: 23.200 [4.000, 56.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.282009, mean_absolute_error: 5.966934, mean_q: 6.689484
185 (array([22]),) False
 150400/500000: episode: 3760, duration: 32.046s, episode steps: 40, steps per second: 1, episode reward: 32.179, mean reward: 0.804 [0.015, 1.000], mean action: 25.150 [2.000, 54.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.308412, mean_absolute_error: 5.932173, mean_q: 6.653706
643 (array([44]),) False
 150440/500000: episode: 3761, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 34.859, mean reward: 0.871 [0.000, 1.000], mean action: 21.825 [9.000, 38.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.299230, mean_absolute_error: 5.938457, mean_q: 6.653329
300 (array([22]),) False
 150480/500000: episode: 3762, duration: 32.953s, episode steps: 40, steps per second: 1, episode reward: 34.967, mean reward: 0.874 [0.079, 1.000], mean action: 24.100 [8.000, 59.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.297550, mean_absolute_error: 5.968509, mean_q: 6.692316
661 (array([48]),) False
 150520/500000: episode: 3763, duration: 33.031s, episode steps: 40, steps per second: 1, episode reward: 35.847, mean reward: 0.896 [0.182, 1.000], mean action: 43.500 [4.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.274073, mean_absolute_error: 5.803987, mean_q: 6.516901
237 (array([22]),) False
 150560/500000: episode: 3764, duration: 31.717s, episode steps: 40, steps per second: 1, episode reward: 37.875, mean reward: 0.947 [0.201, 1.000], mean action: 21.625 [2.000, 39.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.292671, mean_absolute_error: 5.867101, mean_q: 6.592782
35 (array([48]),) False
 150600/500000: episode: 3765, duration: 31.072s, episode steps: 40, steps per second: 1, episode reward: 36.213, mean reward: 0.905 [0.263, 0.972], mean action: 34.025 [7.000, 49.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.245326, mean_absolute_error: 5.935002, mean_q: 6.654311
500 (array([22]),) False
 150640/500000: episode: 3766, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 35.655, mean reward: 0.891 [0.591, 1.000], mean action: 24.600 [22.000, 54.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.290899, mean_absolute_error: 5.930186, mean_q: 6.660703
761 (array([3]),) False
 150680/500000: episode: 3767, duration: 31.015s, episode steps: 40, steps per second: 1, episode reward: 16.622, mean reward: 0.416 [0.273, 0.669], mean action: 26.375 [18.000, 58.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.285178, mean_absolute_error: 5.898883, mean_q: 6.625436
24 (array([22]),) False
 150720/500000: episode: 3768, duration: 30.417s, episode steps: 40, steps per second: 1, episode reward: 37.523, mean reward: 0.938 [0.165, 1.000], mean action: 23.575 [2.000, 49.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.288385, mean_absolute_error: 5.914720, mean_q: 6.642474
42 (array([22]),) False
 150760/500000: episode: 3769, duration: 31.057s, episode steps: 40, steps per second: 1, episode reward: 33.931, mean reward: 0.848 [0.000, 1.000], mean action: 24.325 [0.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.278461, mean_absolute_error: 5.946492, mean_q: 6.671323
850 (array([12]),) False
 150800/500000: episode: 3770, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 30.899, mean reward: 0.772 [0.199, 1.000], mean action: 26.500 [5.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.316639, mean_absolute_error: 5.919457, mean_q: 6.637595
337 (array([22]),) False
 150840/500000: episode: 3771, duration: 31.012s, episode steps: 40, steps per second: 1, episode reward: 37.962, mean reward: 0.949 [0.235, 1.000], mean action: 24.450 [22.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.291764, mean_absolute_error: 5.867532, mean_q: 6.580480
191 (array([38]),) False
 150880/500000: episode: 3772, duration: 30.246s, episode steps: 40, steps per second: 1, episode reward: 27.366, mean reward: 0.684 [0.048, 1.000], mean action: 18.800 [9.000, 41.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.248544, mean_absolute_error: 5.880789, mean_q: 6.597898
833 (array([22]),) False
 150920/500000: episode: 3773, duration: 30.985s, episode steps: 40, steps per second: 1, episode reward: 36.652, mean reward: 0.916 [0.265, 1.000], mean action: 30.150 [12.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.316788, mean_absolute_error: 5.969026, mean_q: 6.690257
317 (array([12]),) False
 150960/500000: episode: 3774, duration: 31.277s, episode steps: 40, steps per second: 1, episode reward: 30.307, mean reward: 0.758 [0.000, 1.000], mean action: 21.150 [8.000, 44.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.328019, mean_absolute_error: 5.940635, mean_q: 6.655421
776 (array([22]),) False
 151000/500000: episode: 3775, duration: 31.013s, episode steps: 40, steps per second: 1, episode reward: 38.076, mean reward: 0.952 [0.258, 1.000], mean action: 22.775 [13.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.286019, mean_absolute_error: 5.860892, mean_q: 6.575258
372 (array([22]),) False
 151040/500000: episode: 3776, duration: 30.333s, episode steps: 40, steps per second: 1, episode reward: 37.699, mean reward: 0.942 [0.370, 1.000], mean action: 21.175 [12.000, 32.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.319623, mean_absolute_error: 5.903614, mean_q: 6.625637
176 (array([3]),) False
 151080/500000: episode: 3777, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 19.981, mean reward: 0.500 [0.023, 0.802], mean action: 35.300 [7.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.303873, mean_absolute_error: 5.912343, mean_q: 6.632281
311 (array([22]),) False
 151120/500000: episode: 3778, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 39.140, mean reward: 0.979 [0.443, 1.000], mean action: 22.600 [12.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.296351, mean_absolute_error: 5.785126, mean_q: 6.496868
840 (array([12]),) False
 151160/500000: episode: 3779, duration: 31.257s, episode steps: 40, steps per second: 1, episode reward: 28.463, mean reward: 0.712 [0.000, 1.000], mean action: 21.725 [3.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.283521, mean_absolute_error: 5.881858, mean_q: 6.592191
766 (array([12]),) False
 151200/500000: episode: 3780, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 36.899, mean reward: 0.922 [0.114, 1.000], mean action: 20.050 [10.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.273320, mean_absolute_error: 5.917988, mean_q: 6.628772
284 (array([12]),) False
 151240/500000: episode: 3781, duration: 31.217s, episode steps: 40, steps per second: 1, episode reward: 29.605, mean reward: 0.740 [0.123, 1.000], mean action: 20.000 [0.000, 54.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.265307, mean_absolute_error: 5.902528, mean_q: 6.603163
729 (array([22]),) False
 151280/500000: episode: 3782, duration: 31.193s, episode steps: 40, steps per second: 1, episode reward: 31.854, mean reward: 0.796 [0.073, 1.000], mean action: 27.425 [9.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.267327, mean_absolute_error: 5.854000, mean_q: 6.560243
679 (array([44]),) False
 151320/500000: episode: 3783, duration: 31.023s, episode steps: 40, steps per second: 1, episode reward: 31.304, mean reward: 0.783 [0.000, 1.000], mean action: 18.025 [7.000, 38.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.252663, mean_absolute_error: 5.874641, mean_q: 6.584190
578 (array([22]),) False
 151360/500000: episode: 3784, duration: 30.205s, episode steps: 40, steps per second: 1, episode reward: 36.746, mean reward: 0.919 [0.050, 1.000], mean action: 28.925 [12.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.314507, mean_absolute_error: 5.879508, mean_q: 6.588369
242 (array([22]),) False
 151400/500000: episode: 3785, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 37.237, mean reward: 0.931 [0.157, 1.000], mean action: 22.400 [3.000, 43.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.297387, mean_absolute_error: 5.831243, mean_q: 6.546857
665 (array([12]),) False
 151440/500000: episode: 3786, duration: 31.157s, episode steps: 40, steps per second: 1, episode reward: 33.359, mean reward: 0.834 [0.027, 1.000], mean action: 21.975 [4.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.308406, mean_absolute_error: 5.819666, mean_q: 6.522865
740 (array([58]),) False
 151480/500000: episode: 3787, duration: 31.452s, episode steps: 40, steps per second: 1, episode reward: 18.690, mean reward: 0.467 [0.029, 0.831], mean action: 16.225 [3.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.244738, mean_absolute_error: 5.820857, mean_q: 6.519820
482 (array([22]),) False
 151520/500000: episode: 3788, duration: 30.830s, episode steps: 40, steps per second: 1, episode reward: 35.061, mean reward: 0.877 [0.229, 1.000], mean action: 32.250 [14.000, 60.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.252570, mean_absolute_error: 5.822415, mean_q: 6.520126
489 (array([22]),) False
 151560/500000: episode: 3789, duration: 31.377s, episode steps: 40, steps per second: 1, episode reward: 36.663, mean reward: 0.917 [0.000, 1.000], mean action: 23.025 [11.000, 46.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.287630, mean_absolute_error: 5.828977, mean_q: 6.521200
645 (array([48]),) False
 151600/500000: episode: 3790, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 33.557, mean reward: 0.839 [0.042, 0.920], mean action: 23.800 [10.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.289543, mean_absolute_error: 5.860123, mean_q: 6.566199
559 (array([59]),) False
 151640/500000: episode: 3791, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 24.468, mean reward: 0.612 [0.068, 1.000], mean action: 15.875 [4.000, 23.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.276779, mean_absolute_error: 5.760764, mean_q: 6.462386
531 (array([22]),) False
 151680/500000: episode: 3792, duration: 30.399s, episode steps: 40, steps per second: 1, episode reward: 38.135, mean reward: 0.953 [0.358, 1.000], mean action: 24.700 [5.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.300758, mean_absolute_error: 5.846098, mean_q: 6.546887
591 (array([22]),) False
 151720/500000: episode: 3793, duration: 31.257s, episode steps: 40, steps per second: 1, episode reward: 30.588, mean reward: 0.765 [0.212, 1.000], mean action: 17.625 [12.000, 56.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.229197, mean_absolute_error: 5.876585, mean_q: 6.584641
349 (array([48]),) False
 151760/500000: episode: 3794, duration: 31.424s, episode steps: 40, steps per second: 1, episode reward: 36.856, mean reward: 0.921 [0.134, 1.000], mean action: 26.450 [3.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.272861, mean_absolute_error: 5.709697, mean_q: 6.407682
490 (array([12]),) False
 151800/500000: episode: 3795, duration: 31.232s, episode steps: 40, steps per second: 1, episode reward: 29.904, mean reward: 0.748 [0.350, 1.000], mean action: 23.775 [12.000, 59.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.287048, mean_absolute_error: 5.810068, mean_q: 6.516995
120 (array([44]),) False
 151840/500000: episode: 3796, duration: 30.420s, episode steps: 40, steps per second: 1, episode reward: 34.344, mean reward: 0.859 [0.512, 1.000], mean action: 20.625 [12.000, 55.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.271239, mean_absolute_error: 5.816696, mean_q: 6.521883
668 (array([22]),) False
 151880/500000: episode: 3797, duration: 31.415s, episode steps: 40, steps per second: 1, episode reward: 26.191, mean reward: 0.655 [0.247, 1.000], mean action: 32.275 [4.000, 55.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.287330, mean_absolute_error: 5.776779, mean_q: 6.482494
354 (array([12]),) False
 151920/500000: episode: 3798, duration: 31.392s, episode steps: 40, steps per second: 1, episode reward: 28.739, mean reward: 0.718 [0.528, 1.000], mean action: 31.375 [19.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.265476, mean_absolute_error: 5.726589, mean_q: 6.434334
361 (array([22]),) False
 151960/500000: episode: 3799, duration: 31.209s, episode steps: 40, steps per second: 1, episode reward: 34.492, mean reward: 0.862 [0.020, 1.000], mean action: 28.425 [5.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.262541, mean_absolute_error: 5.815911, mean_q: 6.526964
82 (array([22]),) False
 152000/500000: episode: 3800, duration: 30.706s, episode steps: 40, steps per second: 1, episode reward: 37.748, mean reward: 0.944 [0.010, 1.000], mean action: 22.200 [2.000, 40.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.271138, mean_absolute_error: 5.779611, mean_q: 6.495216
497 (array([33]),) False
 152040/500000: episode: 3801, duration: 31.320s, episode steps: 40, steps per second: 1, episode reward: 22.624, mean reward: 0.566 [0.202, 0.625], mean action: 23.400 [11.000, 57.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.260217, mean_absolute_error: 5.815120, mean_q: 6.531113
854 (array([12]),) False
 152080/500000: episode: 3802, duration: 31.311s, episode steps: 40, steps per second: 1, episode reward: 28.961, mean reward: 0.724 [0.151, 1.000], mean action: 21.875 [8.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.287128, mean_absolute_error: 5.829153, mean_q: 6.546170
769 (array([12]),) False
 152120/500000: episode: 3803, duration: 31.384s, episode steps: 40, steps per second: 1, episode reward: 35.811, mean reward: 0.895 [0.168, 1.000], mean action: 22.075 [5.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.269505, mean_absolute_error: 5.860105, mean_q: 6.587586
47 (array([44]),) False
 152160/500000: episode: 3804, duration: 30.697s, episode steps: 40, steps per second: 1, episode reward: 34.858, mean reward: 0.871 [0.179, 1.000], mean action: 25.525 [22.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.246643, mean_absolute_error: 5.755604, mean_q: 6.474191
215 (array([22]),) False
 152200/500000: episode: 3805, duration: 31.159s, episode steps: 40, steps per second: 1, episode reward: 31.654, mean reward: 0.791 [0.080, 1.000], mean action: 21.150 [2.000, 54.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.312127, mean_absolute_error: 5.820788, mean_q: 6.536032
321 (array([22]),) False
 152240/500000: episode: 3806, duration: 31.206s, episode steps: 40, steps per second: 1, episode reward: 36.995, mean reward: 0.925 [0.010, 1.000], mean action: 20.850 [4.000, 60.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.267718, mean_absolute_error: 5.804940, mean_q: 6.509459
223 (array([48]),) False
 152280/500000: episode: 3807, duration: 31.604s, episode steps: 40, steps per second: 1, episode reward: 26.353, mean reward: 0.659 [0.348, 0.854], mean action: 19.800 [12.000, 22.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.264875, mean_absolute_error: 5.810631, mean_q: 6.518100
745 (array([22]),) False
 152320/500000: episode: 3808, duration: 31.114s, episode steps: 40, steps per second: 1, episode reward: 33.169, mean reward: 0.829 [0.213, 1.000], mean action: 14.375 [0.000, 45.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.289392, mean_absolute_error: 5.751014, mean_q: 6.464417
222 (array([22]),) False
 152360/500000: episode: 3809, duration: 31.726s, episode steps: 40, steps per second: 1, episode reward: 31.226, mean reward: 0.781 [0.209, 1.000], mean action: 20.425 [1.000, 43.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.281347, mean_absolute_error: 5.807901, mean_q: 6.518366
215 (array([22]),) False
 152400/500000: episode: 3810, duration: 31.335s, episode steps: 40, steps per second: 1, episode reward: 34.144, mean reward: 0.854 [0.232, 1.000], mean action: 20.150 [10.000, 55.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.283898, mean_absolute_error: 5.812471, mean_q: 6.517629
459 (array([22]),) False
 152440/500000: episode: 3811, duration: 31.546s, episode steps: 40, steps per second: 1, episode reward: 37.715, mean reward: 0.943 [0.438, 1.000], mean action: 25.950 [19.000, 53.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.294894, mean_absolute_error: 5.775815, mean_q: 6.473567
652 (array([22]),) False
 152480/500000: episode: 3812, duration: 31.069s, episode steps: 40, steps per second: 1, episode reward: 37.122, mean reward: 0.928 [0.259, 1.000], mean action: 25.075 [11.000, 59.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.288210, mean_absolute_error: 5.736814, mean_q: 6.434479
741 (array([22]),) False
 152520/500000: episode: 3813, duration: 31.503s, episode steps: 40, steps per second: 1, episode reward: 36.675, mean reward: 0.917 [0.184, 1.000], mean action: 18.175 [12.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.265130, mean_absolute_error: 5.842120, mean_q: 6.549219
180 (array([48]),) False
 152560/500000: episode: 3814, duration: 31.447s, episode steps: 40, steps per second: 1, episode reward: 33.771, mean reward: 0.844 [0.184, 0.978], mean action: 21.075 [12.000, 60.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.262967, mean_absolute_error: 5.708041, mean_q: 6.401573
744 (array([22]),) False
 152600/500000: episode: 3815, duration: 31.532s, episode steps: 40, steps per second: 1, episode reward: 31.143, mean reward: 0.779 [0.146, 1.000], mean action: 19.200 [4.000, 59.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.255562, mean_absolute_error: 5.686624, mean_q: 6.389222
156 (array([22]),) False
 152640/500000: episode: 3816, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 35.248, mean reward: 0.881 [0.223, 1.000], mean action: 20.025 [2.000, 39.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.279611, mean_absolute_error: 5.717221, mean_q: 6.418826
452 (array([22]),) False
 152680/500000: episode: 3817, duration: 31.382s, episode steps: 40, steps per second: 1, episode reward: 37.544, mean reward: 0.939 [0.527, 1.000], mean action: 22.450 [22.000, 39.000], mean observation: -0.053 [-1.000, 1.000], loss: 0.285187, mean_absolute_error: 5.848568, mean_q: 6.557394
802 (array([22]),) False
 152720/500000: episode: 3818, duration: 31.426s, episode steps: 40, steps per second: 1, episode reward: 31.612, mean reward: 0.790 [0.250, 1.000], mean action: 33.225 [13.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.260368, mean_absolute_error: 5.751505, mean_q: 6.454312
48 (array([12]),) False
 152760/500000: episode: 3819, duration: 31.673s, episode steps: 40, steps per second: 1, episode reward: 36.606, mean reward: 0.915 [0.256, 0.952], mean action: 21.725 [2.000, 45.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.253460, mean_absolute_error: 5.793004, mean_q: 6.504561
301 (array([22]),) False
 152800/500000: episode: 3820, duration: 31.396s, episode steps: 40, steps per second: 1, episode reward: 34.902, mean reward: 0.873 [0.135, 1.000], mean action: 23.700 [22.000, 51.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.269395, mean_absolute_error: 5.697328, mean_q: 6.402545
640 (array([22]),) False
 152840/500000: episode: 3821, duration: 31.543s, episode steps: 40, steps per second: 1, episode reward: 32.891, mean reward: 0.822 [0.012, 1.000], mean action: 26.525 [17.000, 58.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.264868, mean_absolute_error: 5.674582, mean_q: 6.385538
108 (array([48]),) False
 152880/500000: episode: 3822, duration: 31.528s, episode steps: 40, steps per second: 1, episode reward: 31.750, mean reward: 0.794 [0.239, 1.000], mean action: 18.975 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.286647, mean_absolute_error: 5.737277, mean_q: 6.447192
420 (array([22]),) False
 152920/500000: episode: 3823, duration: 31.464s, episode steps: 40, steps per second: 1, episode reward: 35.552, mean reward: 0.889 [0.252, 1.000], mean action: 21.450 [2.000, 51.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.272957, mean_absolute_error: 5.700490, mean_q: 6.409703
685 (array([22]),) False
 152960/500000: episode: 3824, duration: 31.104s, episode steps: 40, steps per second: 1, episode reward: 28.086, mean reward: 0.702 [0.000, 0.757], mean action: 43.800 [28.000, 58.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.263371, mean_absolute_error: 5.724947, mean_q: 6.435495
36 (array([22]),) False
 153000/500000: episode: 3825, duration: 31.571s, episode steps: 40, steps per second: 1, episode reward: 35.861, mean reward: 0.897 [0.187, 1.000], mean action: 20.425 [2.000, 41.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.279635, mean_absolute_error: 5.746303, mean_q: 6.463553
703 (array([3]),) False
 153040/500000: episode: 3826, duration: 31.418s, episode steps: 40, steps per second: 1, episode reward: 37.379, mean reward: 0.934 [0.198, 1.000], mean action: 6.400 [3.000, 52.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.269125, mean_absolute_error: 5.657063, mean_q: 6.365933
803 (array([58]),) False
 153080/500000: episode: 3827, duration: 31.436s, episode steps: 40, steps per second: 1, episode reward: 16.307, mean reward: 0.408 [0.117, 1.000], mean action: 36.900 [1.000, 49.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.290780, mean_absolute_error: 5.763398, mean_q: 6.468917
282 (array([22]),) False
 153120/500000: episode: 3828, duration: 31.188s, episode steps: 40, steps per second: 1, episode reward: 39.395, mean reward: 0.985 [0.395, 1.000], mean action: 22.275 [22.000, 33.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.267578, mean_absolute_error: 5.774729, mean_q: 6.495728
839 (array([22]),) False
 153160/500000: episode: 3829, duration: 31.933s, episode steps: 40, steps per second: 1, episode reward: 35.450, mean reward: 0.886 [0.114, 1.000], mean action: 21.100 [6.000, 53.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.275742, mean_absolute_error: 5.719467, mean_q: 6.434770
362 (array([22]),) False
 153200/500000: episode: 3830, duration: 31.258s, episode steps: 40, steps per second: 1, episode reward: 33.041, mean reward: 0.826 [0.089, 1.000], mean action: 27.075 [12.000, 57.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.321239, mean_absolute_error: 5.800940, mean_q: 6.518199
221 (array([22]),) False
 153240/500000: episode: 3831, duration: 31.411s, episode steps: 40, steps per second: 1, episode reward: 35.115, mean reward: 0.878 [0.079, 1.000], mean action: 20.425 [7.000, 42.000], mean observation: -0.190 [-1.000, 1.000], loss: 0.299507, mean_absolute_error: 5.797187, mean_q: 6.513486
860 (array([12]),) False
 153280/500000: episode: 3832, duration: 31.083s, episode steps: 40, steps per second: 1, episode reward: 33.929, mean reward: 0.848 [0.225, 1.000], mean action: 17.400 [2.000, 55.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.263453, mean_absolute_error: 5.779037, mean_q: 6.493126
0 (array([48]),) False
 153320/500000: episode: 3833, duration: 31.522s, episode steps: 40, steps per second: 1, episode reward: 33.042, mean reward: 0.826 [0.000, 1.000], mean action: 23.750 [5.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.304029, mean_absolute_error: 5.796867, mean_q: 6.508125
613 (array([22]),) False
 153360/500000: episode: 3834, duration: 31.541s, episode steps: 40, steps per second: 1, episode reward: 34.988, mean reward: 0.875 [0.294, 1.000], mean action: 22.775 [8.000, 49.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.321081, mean_absolute_error: 5.739777, mean_q: 6.437075
215 (array([22]),) False
 153400/500000: episode: 3835, duration: 31.585s, episode steps: 40, steps per second: 1, episode reward: 35.161, mean reward: 0.879 [0.381, 1.000], mean action: 18.500 [4.000, 28.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.286023, mean_absolute_error: 5.804701, mean_q: 6.507333
528 (array([12]),) False
 153440/500000: episode: 3836, duration: 31.456s, episode steps: 40, steps per second: 1, episode reward: 35.408, mean reward: 0.885 [0.691, 1.000], mean action: 18.025 [12.000, 48.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.324499, mean_absolute_error: 5.684227, mean_q: 6.379700
75 (array([22]),) False
 153480/500000: episode: 3837, duration: 31.422s, episode steps: 40, steps per second: 1, episode reward: 37.043, mean reward: 0.926 [0.281, 1.000], mean action: 21.225 [8.000, 52.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.250659, mean_absolute_error: 5.630612, mean_q: 6.327756
65 (array([48]),) False
 153520/500000: episode: 3838, duration: 31.228s, episode steps: 40, steps per second: 1, episode reward: 37.648, mean reward: 0.941 [0.491, 1.000], mean action: 23.900 [12.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.272998, mean_absolute_error: 5.750823, mean_q: 6.456131
246 (array([22]),) False
 153560/500000: episode: 3839, duration: 31.410s, episode steps: 40, steps per second: 1, episode reward: 35.782, mean reward: 0.895 [0.082, 1.000], mean action: 21.550 [3.000, 42.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.299400, mean_absolute_error: 5.744462, mean_q: 6.446815
661 (array([48]),) False
 153600/500000: episode: 3840, duration: 30.678s, episode steps: 40, steps per second: 1, episode reward: 34.875, mean reward: 0.872 [0.182, 1.000], mean action: 30.500 [4.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.267143, mean_absolute_error: 5.751152, mean_q: 6.452602
73 (array([22]),) False
 153640/500000: episode: 3841, duration: 31.576s, episode steps: 40, steps per second: 1, episode reward: 35.015, mean reward: 0.875 [0.000, 1.000], mean action: 18.225 [11.000, 57.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.268873, mean_absolute_error: 5.710132, mean_q: 6.412551
9 (array([14]),) False
 153680/500000: episode: 3842, duration: 30.786s, episode steps: 40, steps per second: 1, episode reward: 32.115, mean reward: 0.803 [0.004, 0.989], mean action: 22.950 [9.000, 59.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.242454, mean_absolute_error: 5.758060, mean_q: 6.460846
739 (array([22]),) False
 153720/500000: episode: 3843, duration: 31.344s, episode steps: 40, steps per second: 1, episode reward: 35.984, mean reward: 0.900 [0.183, 1.000], mean action: 21.325 [12.000, 60.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.274465, mean_absolute_error: 5.705801, mean_q: 6.408816
433 (array([22]),) False
 153760/500000: episode: 3844, duration: 30.880s, episode steps: 40, steps per second: 1, episode reward: 38.117, mean reward: 0.953 [0.136, 1.000], mean action: 22.325 [2.000, 44.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.251687, mean_absolute_error: 5.702991, mean_q: 6.402462
741 (array([22]),) False
 153800/500000: episode: 3845, duration: 31.338s, episode steps: 40, steps per second: 1, episode reward: 33.758, mean reward: 0.844 [0.069, 1.000], mean action: 22.550 [12.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.282007, mean_absolute_error: 5.709136, mean_q: 6.414197
215 (array([22]),) False
 153840/500000: episode: 3846, duration: 31.404s, episode steps: 40, steps per second: 1, episode reward: 34.911, mean reward: 0.873 [0.259, 1.000], mean action: 19.175 [4.000, 58.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.255134, mean_absolute_error: 5.713185, mean_q: 6.406912
68 (array([22]),) False
 153880/500000: episode: 3847, duration: 31.416s, episode steps: 40, steps per second: 1, episode reward: 29.652, mean reward: 0.741 [0.099, 1.000], mean action: 15.750 [9.000, 55.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.257952, mean_absolute_error: 5.620345, mean_q: 6.306130
151 (array([22]),) False
 153920/500000: episode: 3848, duration: 31.350s, episode steps: 40, steps per second: 1, episode reward: 33.544, mean reward: 0.839 [0.366, 0.961], mean action: 15.250 [5.000, 35.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.270293, mean_absolute_error: 5.614665, mean_q: 6.314087
632 (array([22]),) False
 153960/500000: episode: 3849, duration: 31.414s, episode steps: 40, steps per second: 1, episode reward: 35.057, mean reward: 0.876 [0.293, 1.000], mean action: 28.475 [12.000, 51.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.259828, mean_absolute_error: 5.657518, mean_q: 6.351662
432 (array([22]),) False
 154000/500000: episode: 3850, duration: 31.337s, episode steps: 40, steps per second: 1, episode reward: 39.270, mean reward: 0.982 [0.542, 1.000], mean action: 22.000 [7.000, 37.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.277218, mean_absolute_error: 5.616898, mean_q: 6.306174
340 (array([12]),) False
 154040/500000: episode: 3851, duration: 31.383s, episode steps: 40, steps per second: 1, episode reward: 32.944, mean reward: 0.824 [0.000, 1.000], mean action: 24.125 [5.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.311185, mean_absolute_error: 5.590315, mean_q: 6.274661
239 (array([22]),) False
 154080/500000: episode: 3852, duration: 31.551s, episode steps: 40, steps per second: 1, episode reward: 38.876, mean reward: 0.972 [0.506, 1.000], mean action: 21.825 [5.000, 47.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.295019, mean_absolute_error: 5.601150, mean_q: 6.291547
531 (array([22]),) False
 154120/500000: episode: 3853, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 36.566, mean reward: 0.914 [0.006, 1.000], mean action: 20.675 [0.000, 40.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.267647, mean_absolute_error: 5.644243, mean_q: 6.336343
448 (array([12]),) False
 154160/500000: episode: 3854, duration: 32.184s, episode steps: 40, steps per second: 1, episode reward: 29.257, mean reward: 0.731 [0.336, 0.964], mean action: 21.800 [7.000, 29.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.250531, mean_absolute_error: 5.614316, mean_q: 6.313499
349 (array([48]),) False
 154200/500000: episode: 3855, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 34.024, mean reward: 0.851 [0.069, 1.000], mean action: 28.950 [3.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.274689, mean_absolute_error: 5.622140, mean_q: 6.315113
77 (array([22]),) False
 154240/500000: episode: 3856, duration: 32.242s, episode steps: 40, steps per second: 1, episode reward: 33.730, mean reward: 0.843 [0.246, 1.000], mean action: 18.150 [5.000, 58.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.264413, mean_absolute_error: 5.647633, mean_q: 6.339276
274 (array([12]),) False
 154280/500000: episode: 3857, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 36.073, mean reward: 0.902 [0.035, 1.000], mean action: 19.525 [12.000, 49.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.271722, mean_absolute_error: 5.609446, mean_q: 6.304317
722 (array([22]),) False
 154320/500000: episode: 3858, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 36.785, mean reward: 0.920 [0.348, 1.000], mean action: 18.775 [12.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.284338, mean_absolute_error: 5.590253, mean_q: 6.281895
12 (array([22]),) False
 154360/500000: episode: 3859, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 37.880, mean reward: 0.947 [0.203, 1.000], mean action: 23.300 [20.000, 46.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.236842, mean_absolute_error: 5.653836, mean_q: 6.347208
694 (array([22]),) False
 154400/500000: episode: 3860, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 39.400, mean reward: 0.985 [0.400, 1.000], mean action: 22.475 [22.000, 41.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.252153, mean_absolute_error: 5.647045, mean_q: 6.333552
94 (array([44]),) False
 154440/500000: episode: 3861, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 32.463, mean reward: 0.812 [0.188, 0.864], mean action: 23.125 [8.000, 60.000], mean observation: -0.088 [-1.000, 1.000], loss: 0.233542, mean_absolute_error: 5.667520, mean_q: 6.354256
650 (array([22]),) False
 154480/500000: episode: 3862, duration: 33.074s, episode steps: 40, steps per second: 1, episode reward: 36.508, mean reward: 0.913 [0.109, 1.000], mean action: 25.125 [15.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.254790, mean_absolute_error: 5.699502, mean_q: 6.381017
29 (array([22]),) False
 154520/500000: episode: 3863, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 37.153, mean reward: 0.929 [0.130, 1.000], mean action: 22.525 [7.000, 51.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.248683, mean_absolute_error: 5.659625, mean_q: 6.347905
264 (array([12]),) False
 154560/500000: episode: 3864, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 36.484, mean reward: 0.912 [0.139, 1.000], mean action: 19.850 [4.000, 39.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.240261, mean_absolute_error: 5.623276, mean_q: 6.311153
711 (array([22]),) False
 154600/500000: episode: 3865, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 36.750, mean reward: 0.919 [0.013, 1.000], mean action: 23.400 [2.000, 56.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.291206, mean_absolute_error: 5.700013, mean_q: 6.392278
558 (array([40]),) False
 154640/500000: episode: 3866, duration: 32.112s, episode steps: 40, steps per second: 1, episode reward: 30.151, mean reward: 0.754 [0.146, 1.000], mean action: 17.950 [12.000, 46.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.249756, mean_absolute_error: 5.672257, mean_q: 6.365780
237 (array([22]),) False
 154680/500000: episode: 3867, duration: 33.102s, episode steps: 40, steps per second: 1, episode reward: 38.273, mean reward: 0.957 [0.433, 1.000], mean action: 23.225 [12.000, 53.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.257351, mean_absolute_error: 5.765917, mean_q: 6.462477
324 (array([12]),) False
 154720/500000: episode: 3868, duration: 32.211s, episode steps: 40, steps per second: 1, episode reward: 36.172, mean reward: 0.904 [0.212, 1.000], mean action: 18.925 [10.000, 46.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.233964, mean_absolute_error: 5.731805, mean_q: 6.415196
679 (array([44]),) False
 154760/500000: episode: 3869, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 30.381, mean reward: 0.760 [0.000, 1.000], mean action: 14.875 [0.000, 57.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.275552, mean_absolute_error: 5.699336, mean_q: 6.388246
672 (array([44]),) False
 154800/500000: episode: 3870, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 31.269, mean reward: 0.782 [0.340, 0.988], mean action: 27.600 [1.000, 59.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.233234, mean_absolute_error: 5.687067, mean_q: 6.372704
488 (array([22]),) False
 154840/500000: episode: 3871, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 37.066, mean reward: 0.927 [0.320, 1.000], mean action: 24.750 [5.000, 53.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.262468, mean_absolute_error: 5.679127, mean_q: 6.364603
443 (array([22]),) False
 154880/500000: episode: 3872, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 38.486, mean reward: 0.962 [0.331, 1.000], mean action: 22.775 [7.000, 47.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.283562, mean_absolute_error: 5.672746, mean_q: 6.361482
856 (array([48]),) False
 154920/500000: episode: 3873, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 34.236, mean reward: 0.856 [0.067, 0.976], mean action: 20.150 [12.000, 59.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.279911, mean_absolute_error: 5.598810, mean_q: 6.283198
182 (array([54]),) False
 154960/500000: episode: 3874, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 31.885, mean reward: 0.797 [0.355, 1.000], mean action: 36.700 [8.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.261339, mean_absolute_error: 5.619431, mean_q: 6.303552
161 (array([22]),) False
 155000/500000: episode: 3875, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 33.243, mean reward: 0.831 [0.000, 1.000], mean action: 23.700 [7.000, 60.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.303112, mean_absolute_error: 5.680642, mean_q: 6.370670
708 (array([40]),) False
 155040/500000: episode: 3876, duration: 32.209s, episode steps: 40, steps per second: 1, episode reward: 29.417, mean reward: 0.735 [0.197, 1.000], mean action: 16.850 [3.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.256311, mean_absolute_error: 5.688436, mean_q: 6.376825
123 (array([22]),) False
 155080/500000: episode: 3877, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 38.104, mean reward: 0.953 [0.095, 1.000], mean action: 22.500 [9.000, 49.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.255087, mean_absolute_error: 5.741427, mean_q: 6.424878
41 (array([12]),) False
 155120/500000: episode: 3878, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 32.873, mean reward: 0.822 [0.096, 1.000], mean action: 22.975 [17.000, 59.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.269326, mean_absolute_error: 5.679429, mean_q: 6.362641
797 (array([22]),) False
 155160/500000: episode: 3879, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 35.358, mean reward: 0.884 [0.228, 1.000], mean action: 21.425 [10.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.273259, mean_absolute_error: 5.702067, mean_q: 6.381587
213 (array([22]),) False
 155200/500000: episode: 3880, duration: 32.177s, episode steps: 40, steps per second: 1, episode reward: 38.813, mean reward: 0.970 [0.331, 1.000], mean action: 22.175 [9.000, 42.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.263863, mean_absolute_error: 5.713063, mean_q: 6.396035
602 (array([36]),) False
 155240/500000: episode: 3881, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 14.573, mean reward: 0.364 [0.000, 0.899], mean action: 19.750 [3.000, 38.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.280065, mean_absolute_error: 5.689260, mean_q: 6.372304
398 (array([22]),) False
 155280/500000: episode: 3882, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 35.606, mean reward: 0.890 [0.121, 1.000], mean action: 22.850 [8.000, 56.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.262014, mean_absolute_error: 5.708232, mean_q: 6.408998
446 (array([22]),) False
 155320/500000: episode: 3883, duration: 31.955s, episode steps: 40, steps per second: 1, episode reward: 36.834, mean reward: 0.921 [0.347, 1.000], mean action: 22.450 [5.000, 49.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.256948, mean_absolute_error: 5.704405, mean_q: 6.400131
124 (array([48]),) False
 155360/500000: episode: 3884, duration: 31.699s, episode steps: 40, steps per second: 1, episode reward: 32.533, mean reward: 0.813 [0.080, 1.000], mean action: 38.650 [2.000, 58.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.248710, mean_absolute_error: 5.715581, mean_q: 6.412008
793 (array([12]),) False
 155400/500000: episode: 3885, duration: 31.636s, episode steps: 40, steps per second: 1, episode reward: 37.827, mean reward: 0.946 [0.056, 1.000], mean action: 12.825 [6.000, 22.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.247985, mean_absolute_error: 5.704609, mean_q: 6.403473
330 (array([38]),) False
 155440/500000: episode: 3886, duration: 31.821s, episode steps: 40, steps per second: 1, episode reward: 36.981, mean reward: 0.925 [0.226, 1.000], mean action: 14.900 [5.000, 31.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.288986, mean_absolute_error: 5.719214, mean_q: 6.419613
170 (array([44]),) False
 155480/500000: episode: 3887, duration: 32.868s, episode steps: 40, steps per second: 1, episode reward: 22.797, mean reward: 0.570 [0.428, 0.802], mean action: 18.325 [3.000, 49.000], mean observation: -0.171 [-1.000, 1.000], loss: 0.259516, mean_absolute_error: 5.730085, mean_q: 6.434592
212 (array([36]),) False
 155520/500000: episode: 3888, duration: 32.182s, episode steps: 40, steps per second: 1, episode reward: 21.158, mean reward: 0.529 [0.346, 0.788], mean action: 21.000 [3.000, 54.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.256326, mean_absolute_error: 5.699142, mean_q: 6.405664
88 (array([22]),) False
 155560/500000: episode: 3889, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 33.830, mean reward: 0.846 [0.259, 1.000], mean action: 25.475 [10.000, 60.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.251809, mean_absolute_error: 5.715669, mean_q: 6.416684
540 (array([22]),) False
 155600/500000: episode: 3890, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 38.578, mean reward: 0.964 [0.219, 1.000], mean action: 29.875 [22.000, 56.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.258703, mean_absolute_error: 5.789851, mean_q: 6.484336
200 (array([22]),) False
 155640/500000: episode: 3891, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 23.508, mean reward: 0.588 [0.041, 1.000], mean action: 21.650 [0.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.271238, mean_absolute_error: 5.711276, mean_q: 6.408614
24 (array([22]),) False
 155680/500000: episode: 3892, duration: 32.093s, episode steps: 40, steps per second: 1, episode reward: 36.594, mean reward: 0.915 [0.096, 1.000], mean action: 26.125 [16.000, 49.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.252523, mean_absolute_error: 5.658209, mean_q: 6.354856
398 (array([22]),) False
 155720/500000: episode: 3893, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 36.297, mean reward: 0.907 [0.131, 1.000], mean action: 23.025 [3.000, 57.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.259759, mean_absolute_error: 5.734279, mean_q: 6.435668
568 (array([22]),) False
 155760/500000: episode: 3894, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 36.992, mean reward: 0.925 [0.213, 1.000], mean action: 28.200 [10.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.285099, mean_absolute_error: 5.731322, mean_q: 6.426802
349 (array([48]),) False
 155800/500000: episode: 3895, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 38.087, mean reward: 0.952 [0.386, 1.000], mean action: 23.000 [8.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.259116, mean_absolute_error: 5.751039, mean_q: 6.443994
72 (array([12]),) False
 155840/500000: episode: 3896, duration: 31.351s, episode steps: 40, steps per second: 1, episode reward: 35.448, mean reward: 0.886 [0.142, 1.000], mean action: 22.225 [12.000, 42.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.301257, mean_absolute_error: 5.790261, mean_q: 6.488504
833 (array([22]),) False
 155880/500000: episode: 3897, duration: 31.416s, episode steps: 40, steps per second: 1, episode reward: 34.000, mean reward: 0.850 [0.099, 1.000], mean action: 28.875 [12.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.288932, mean_absolute_error: 5.780515, mean_q: 6.482036
669 (array([15]),) False
 155920/500000: episode: 3898, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 34.854, mean reward: 0.871 [0.203, 0.916], mean action: 14.000 [1.000, 60.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.255688, mean_absolute_error: 5.673738, mean_q: 6.380789
682 (array([22]),) False
 155960/500000: episode: 3899, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 36.201, mean reward: 0.905 [0.194, 1.000], mean action: 15.300 [5.000, 55.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.257485, mean_absolute_error: 5.660246, mean_q: 6.359485
366 (array([22]),) False
 156000/500000: episode: 3900, duration: 32.270s, episode steps: 40, steps per second: 1, episode reward: 35.801, mean reward: 0.895 [0.028, 1.000], mean action: 31.675 [22.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.274272, mean_absolute_error: 5.698443, mean_q: 6.396188
533 (array([22]),) False
 156040/500000: episode: 3901, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 36.298, mean reward: 0.907 [0.199, 1.000], mean action: 22.225 [12.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.272351, mean_absolute_error: 5.758096, mean_q: 6.454672
506 (array([8]),) False
 156080/500000: episode: 3902, duration: 32.307s, episode steps: 40, steps per second: 1, episode reward: 12.029, mean reward: 0.301 [0.048, 0.926], mean action: 25.025 [10.000, 60.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.270999, mean_absolute_error: 5.682772, mean_q: 6.382178
819 (array([48]),) False
 156120/500000: episode: 3903, duration: 33.043s, episode steps: 40, steps per second: 1, episode reward: 27.880, mean reward: 0.697 [0.000, 1.000], mean action: 23.950 [5.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.248251, mean_absolute_error: 5.694817, mean_q: 6.397759
748 (array([22]),) False
 156160/500000: episode: 3904, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 37.098, mean reward: 0.927 [0.627, 1.000], mean action: 22.425 [5.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.270616, mean_absolute_error: 5.783709, mean_q: 6.488975
644 (array([12]),) False
 156200/500000: episode: 3905, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 32.272, mean reward: 0.807 [0.378, 1.000], mean action: 21.775 [11.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.244690, mean_absolute_error: 5.868647, mean_q: 6.581778
466 (array([22]),) False
 156240/500000: episode: 3906, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 36.937, mean reward: 0.923 [0.121, 1.000], mean action: 23.825 [8.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.269115, mean_absolute_error: 5.820634, mean_q: 6.531474
716 (array([48]),) False
 156280/500000: episode: 3907, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 30.767, mean reward: 0.769 [0.087, 0.993], mean action: 24.175 [2.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.282998, mean_absolute_error: 5.764953, mean_q: 6.469996
22 (array([37]),) False
 156320/500000: episode: 3908, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 30.461, mean reward: 0.762 [0.140, 0.823], mean action: 24.725 [21.000, 57.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.281246, mean_absolute_error: 5.745586, mean_q: 6.452107
572 (array([58]),) False
 156360/500000: episode: 3909, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 25.257, mean reward: 0.631 [0.016, 1.000], mean action: 30.750 [12.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.268938, mean_absolute_error: 5.838576, mean_q: 6.556026
5 (array([37]),) False
 156400/500000: episode: 3910, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 36.518, mean reward: 0.913 [0.240, 1.000], mean action: 36.550 [9.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.295080, mean_absolute_error: 5.711900, mean_q: 6.425149
455 (array([22]),) False
 156440/500000: episode: 3911, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 36.858, mean reward: 0.921 [0.094, 1.000], mean action: 22.625 [4.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.279252, mean_absolute_error: 5.754770, mean_q: 6.465326
183 (array([22]),) False
 156480/500000: episode: 3912, duration: 32.296s, episode steps: 40, steps per second: 1, episode reward: 23.744, mean reward: 0.594 [0.099, 1.000], mean action: 16.500 [12.000, 57.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.312987, mean_absolute_error: 5.851806, mean_q: 6.562274
87 (array([3]),) False
 156520/500000: episode: 3913, duration: 33.273s, episode steps: 40, steps per second: 1, episode reward: 27.115, mean reward: 0.678 [0.175, 1.000], mean action: 17.375 [3.000, 46.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.302531, mean_absolute_error: 5.680403, mean_q: 6.382628
815 (array([22]),) False
 156560/500000: episode: 3914, duration: 32.294s, episode steps: 40, steps per second: 1, episode reward: 33.920, mean reward: 0.848 [0.212, 1.000], mean action: 16.375 [12.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.281014, mean_absolute_error: 5.703452, mean_q: 6.404433
223 (array([48]),) False
 156600/500000: episode: 3915, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 32.185, mean reward: 0.805 [0.206, 0.854], mean action: 20.225 [0.000, 22.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.296928, mean_absolute_error: 5.702613, mean_q: 6.421506
239 (array([22]),) False
 156640/500000: episode: 3916, duration: 32.271s, episode steps: 40, steps per second: 1, episode reward: 38.163, mean reward: 0.954 [0.305, 1.000], mean action: 23.000 [12.000, 51.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.286840, mean_absolute_error: 5.691575, mean_q: 6.403441
857 (array([22]),) False
 156680/500000: episode: 3917, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 33.643, mean reward: 0.841 [0.363, 1.000], mean action: 18.625 [12.000, 53.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.264598, mean_absolute_error: 5.742173, mean_q: 6.450400
604 (array([40]),) False
 156720/500000: episode: 3918, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 33.203, mean reward: 0.830 [0.209, 0.959], mean action: 20.125 [3.000, 51.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.269913, mean_absolute_error: 5.752111, mean_q: 6.462989
618 (array([12]),) False
 156760/500000: episode: 3919, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 29.961, mean reward: 0.749 [0.028, 1.000], mean action: 28.850 [9.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.251341, mean_absolute_error: 5.714589, mean_q: 6.418009
838 (array([21]),) False
 156800/500000: episode: 3920, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 35.098, mean reward: 0.877 [0.329, 1.000], mean action: 20.450 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.275297, mean_absolute_error: 5.702748, mean_q: 6.400200
682 (array([22]),) False
 156840/500000: episode: 3921, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 35.293, mean reward: 0.882 [0.195, 1.000], mean action: 17.475 [12.000, 53.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.251630, mean_absolute_error: 5.744717, mean_q: 6.441829
790 (array([48]),) False
 156880/500000: episode: 3922, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 33.441, mean reward: 0.836 [0.365, 1.000], mean action: 30.275 [12.000, 53.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.265982, mean_absolute_error: 5.666265, mean_q: 6.362470
80 (array([42]),) False
 156920/500000: episode: 3923, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 34.624, mean reward: 0.866 [0.057, 1.000], mean action: 21.525 [1.000, 47.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.266787, mean_absolute_error: 5.755765, mean_q: 6.459697
542 (array([44]),) False
 156960/500000: episode: 3924, duration: 32.277s, episode steps: 40, steps per second: 1, episode reward: 31.696, mean reward: 0.792 [0.000, 0.920], mean action: 21.575 [3.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.281164, mean_absolute_error: 5.706559, mean_q: 6.401109
151 (array([22]),) False
 157000/500000: episode: 3925, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 31.522, mean reward: 0.788 [0.016, 0.948], mean action: 17.425 [1.000, 52.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.243063, mean_absolute_error: 5.777016, mean_q: 6.479358
13 (array([48]),) False
 157040/500000: episode: 3926, duration: 32.354s, episode steps: 40, steps per second: 1, episode reward: 35.220, mean reward: 0.881 [0.315, 0.973], mean action: 25.175 [2.000, 49.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.339397, mean_absolute_error: 5.682229, mean_q: 6.382041
653 (array([48]),) False
 157080/500000: episode: 3927, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 36.658, mean reward: 0.916 [0.413, 1.000], mean action: 23.350 [8.000, 49.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.268925, mean_absolute_error: 5.759096, mean_q: 6.465838
834 (array([44]),) False
 157120/500000: episode: 3928, duration: 32.280s, episode steps: 40, steps per second: 1, episode reward: 35.420, mean reward: 0.885 [0.243, 1.000], mean action: 28.400 [5.000, 57.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.321710, mean_absolute_error: 5.707637, mean_q: 6.408528
659 (array([40]),) False
 157160/500000: episode: 3929, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 33.700, mean reward: 0.842 [0.377, 1.000], mean action: 22.500 [12.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.276236, mean_absolute_error: 5.697632, mean_q: 6.393092
84 (array([22]),) False
 157200/500000: episode: 3930, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 37.823, mean reward: 0.946 [0.186, 1.000], mean action: 22.450 [2.000, 50.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.267665, mean_absolute_error: 5.680321, mean_q: 6.373748
621 (array([22]),) False
 157240/500000: episode: 3931, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 32.360, mean reward: 0.809 [0.119, 1.000], mean action: 35.525 [12.000, 48.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.268366, mean_absolute_error: 5.652922, mean_q: 6.344784
231 (array([22]),) False
 157280/500000: episode: 3932, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 37.807, mean reward: 0.945 [0.576, 1.000], mean action: 19.975 [12.000, 52.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.273724, mean_absolute_error: 5.709331, mean_q: 6.407361
162 (array([22]),) False
 157320/500000: episode: 3933, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 34.383, mean reward: 0.860 [0.165, 1.000], mean action: 23.275 [3.000, 60.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.267254, mean_absolute_error: 5.754927, mean_q: 6.446802
736 (array([22]),) False
 157360/500000: episode: 3934, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 37.497, mean reward: 0.937 [0.202, 1.000], mean action: 23.600 [12.000, 57.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.264202, mean_absolute_error: 5.766319, mean_q: 6.463412
754 (array([52]),) False
 157400/500000: episode: 3935, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 33.812, mean reward: 0.845 [0.277, 1.000], mean action: 17.550 [1.000, 52.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.296457, mean_absolute_error: 5.662848, mean_q: 6.362903
46 (array([22]),) False
 157440/500000: episode: 3936, duration: 32.288s, episode steps: 40, steps per second: 1, episode reward: 34.299, mean reward: 0.857 [0.120, 1.000], mean action: 23.550 [22.000, 44.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.267323, mean_absolute_error: 5.722654, mean_q: 6.421641
472 (array([22]),) False
 157480/500000: episode: 3937, duration: 33.235s, episode steps: 40, steps per second: 1, episode reward: 33.079, mean reward: 0.827 [0.037, 1.000], mean action: 23.650 [10.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.275251, mean_absolute_error: 5.758411, mean_q: 6.464849
157 (array([48]),) False
 157520/500000: episode: 3938, duration: 32.196s, episode steps: 40, steps per second: 1, episode reward: 37.884, mean reward: 0.947 [0.414, 0.999], mean action: 18.650 [12.000, 36.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.259257, mean_absolute_error: 5.739137, mean_q: 6.437837
833 (array([22]),) False
 157560/500000: episode: 3939, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 36.243, mean reward: 0.906 [0.335, 1.000], mean action: 28.925 [12.000, 55.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.285064, mean_absolute_error: 5.785704, mean_q: 6.485082
423 (array([22]),) False
 157600/500000: episode: 3940, duration: 32.280s, episode steps: 40, steps per second: 1, episode reward: 37.106, mean reward: 0.928 [0.129, 1.000], mean action: 22.225 [2.000, 50.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.267386, mean_absolute_error: 5.707503, mean_q: 6.409307
140 (array([12]),) False
 157640/500000: episode: 3941, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 31.307, mean reward: 0.783 [0.277, 0.947], mean action: 22.650 [6.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.288306, mean_absolute_error: 5.751256, mean_q: 6.446749
780 (array([22]),) False
 157680/500000: episode: 3942, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 36.914, mean reward: 0.923 [0.125, 1.000], mean action: 20.275 [3.000, 34.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.279659, mean_absolute_error: 5.743014, mean_q: 6.434534
237 (array([22]),) False
 157720/500000: episode: 3943, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 35.748, mean reward: 0.894 [0.020, 1.000], mean action: 21.950 [6.000, 57.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.319536, mean_absolute_error: 5.823942, mean_q: 6.517562
7 (array([22]),) False
 157760/500000: episode: 3944, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 38.102, mean reward: 0.953 [0.094, 1.000], mean action: 22.600 [5.000, 56.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.249502, mean_absolute_error: 5.812024, mean_q: 6.510839
87 (array([3]),) False
 157800/500000: episode: 3945, duration: 33.233s, episode steps: 40, steps per second: 1, episode reward: 15.134, mean reward: 0.378 [0.154, 1.000], mean action: 25.800 [3.000, 58.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.289253, mean_absolute_error: 5.792274, mean_q: 6.483918
700 (array([44]),) False
 157840/500000: episode: 3946, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 31.312, mean reward: 0.783 [0.361, 1.000], mean action: 27.025 [12.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.255336, mean_absolute_error: 5.745547, mean_q: 6.445014
481 (array([22]),) False
 157880/500000: episode: 3947, duration: 33.230s, episode steps: 40, steps per second: 1, episode reward: 35.052, mean reward: 0.876 [0.086, 1.000], mean action: 41.575 [9.000, 49.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.281531, mean_absolute_error: 5.733456, mean_q: 6.432436
753 (array([22]),) False
 157920/500000: episode: 3948, duration: 32.334s, episode steps: 40, steps per second: 1, episode reward: 36.781, mean reward: 0.920 [0.186, 1.000], mean action: 22.775 [2.000, 54.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.265388, mean_absolute_error: 5.765021, mean_q: 6.469304
655 (array([22]),) False
 157960/500000: episode: 3949, duration: 33.234s, episode steps: 40, steps per second: 1, episode reward: 37.190, mean reward: 0.930 [0.084, 1.000], mean action: 24.250 [8.000, 50.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.248207, mean_absolute_error: 5.738275, mean_q: 6.448628
605 (array([22]),) False
 158000/500000: episode: 3950, duration: 32.301s, episode steps: 40, steps per second: 1, episode reward: 38.655, mean reward: 0.966 [0.353, 1.000], mean action: 21.550 [3.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.279813, mean_absolute_error: 5.747795, mean_q: 6.457886
800 (array([22]),) False
 158040/500000: episode: 3951, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 30.523, mean reward: 0.763 [0.000, 1.000], mean action: 16.025 [0.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.254443, mean_absolute_error: 5.762199, mean_q: 6.474272
110 (array([22]),) False
 158080/500000: episode: 3952, duration: 32.262s, episode steps: 40, steps per second: 1, episode reward: 36.121, mean reward: 0.903 [0.589, 1.000], mean action: 22.100 [12.000, 36.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.259387, mean_absolute_error: 5.804852, mean_q: 6.524162
519 (array([58]),) False
 158120/500000: episode: 3953, duration: 33.145s, episode steps: 40, steps per second: 1, episode reward: 24.995, mean reward: 0.625 [0.000, 0.778], mean action: 19.850 [4.000, 47.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.296284, mean_absolute_error: 5.763773, mean_q: 6.485840
765 (array([48]),) False
 158160/500000: episode: 3954, duration: 32.910s, episode steps: 40, steps per second: 1, episode reward: 31.494, mean reward: 0.787 [0.137, 1.000], mean action: 27.800 [5.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.286044, mean_absolute_error: 5.829807, mean_q: 6.548585
538 (array([12]),) False
 158200/500000: episode: 3955, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 27.943, mean reward: 0.699 [0.434, 0.992], mean action: 44.875 [22.000, 52.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.316774, mean_absolute_error: 5.786934, mean_q: 6.503100
28 (array([58]),) False
 158240/500000: episode: 3956, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 23.530, mean reward: 0.588 [0.015, 1.000], mean action: 25.800 [3.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.344565, mean_absolute_error: 5.791923, mean_q: 6.496011
162 (array([22]),) False
 158280/500000: episode: 3957, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 33.649, mean reward: 0.841 [0.299, 1.000], mean action: 27.700 [12.000, 60.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.306820, mean_absolute_error: 5.763777, mean_q: 6.467352
377 (array([22]),) False
 158320/500000: episode: 3958, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 38.257, mean reward: 0.956 [0.320, 1.000], mean action: 22.925 [7.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.283703, mean_absolute_error: 5.816962, mean_q: 6.519895
46 (array([22]),) False
 158360/500000: episode: 3959, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 35.234, mean reward: 0.881 [0.022, 1.000], mean action: 22.825 [4.000, 49.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.237489, mean_absolute_error: 5.655904, mean_q: 6.356511
854 (array([12]),) False
 158400/500000: episode: 3960, duration: 32.298s, episode steps: 40, steps per second: 1, episode reward: 31.090, mean reward: 0.777 [0.000, 1.000], mean action: 19.375 [12.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.283659, mean_absolute_error: 5.833383, mean_q: 6.548094
654 (array([22]),) False
 158440/500000: episode: 3961, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 35.046, mean reward: 0.876 [0.049, 1.000], mean action: 22.475 [8.000, 55.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.263684, mean_absolute_error: 5.826398, mean_q: 6.535308
263 (array([8]),) False
 158480/500000: episode: 3962, duration: 32.231s, episode steps: 40, steps per second: 1, episode reward: 16.935, mean reward: 0.423 [0.000, 0.818], mean action: 21.175 [5.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.316069, mean_absolute_error: 5.779234, mean_q: 6.482616
150 (array([22]),) False
 158520/500000: episode: 3963, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 34.978, mean reward: 0.874 [0.361, 0.917], mean action: 15.750 [12.000, 53.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.240791, mean_absolute_error: 5.800103, mean_q: 6.505545
411 (array([22]),) False
 158560/500000: episode: 3964, duration: 32.236s, episode steps: 40, steps per second: 1, episode reward: 38.728, mean reward: 0.968 [0.432, 1.000], mean action: 22.725 [11.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.280089, mean_absolute_error: 5.797132, mean_q: 6.502120
567 (array([22]),) False
 158600/500000: episode: 3965, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 25.854, mean reward: 0.646 [0.431, 1.000], mean action: 35.275 [12.000, 48.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.283933, mean_absolute_error: 5.877149, mean_q: 6.582887
742 (array([33]),) False
 158640/500000: episode: 3966, duration: 33.221s, episode steps: 40, steps per second: 1, episode reward: 25.548, mean reward: 0.639 [0.206, 0.839], mean action: 20.950 [3.000, 45.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.252934, mean_absolute_error: 5.908603, mean_q: 6.621334
90 (array([22]),) False
 158680/500000: episode: 3967, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 39.556, mean reward: 0.989 [0.556, 1.000], mean action: 21.800 [14.000, 22.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.248138, mean_absolute_error: 5.820132, mean_q: 6.523782
8 (array([22]),) False
 158720/500000: episode: 3968, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 31.944, mean reward: 0.799 [0.134, 1.000], mean action: 19.475 [5.000, 27.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.261149, mean_absolute_error: 5.804689, mean_q: 6.506580
652 (array([22]),) False
 158760/500000: episode: 3969, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 37.077, mean reward: 0.927 [0.259, 1.000], mean action: 22.225 [0.000, 40.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.276074, mean_absolute_error: 5.889882, mean_q: 6.598167
120 (array([44]),) False
 158800/500000: episode: 3970, duration: 33.197s, episode steps: 40, steps per second: 1, episode reward: 34.274, mean reward: 0.857 [0.175, 1.000], mean action: 20.825 [4.000, 60.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.274036, mean_absolute_error: 5.879034, mean_q: 6.590326
146 (array([12]),) False
 158840/500000: episode: 3971, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 33.969, mean reward: 0.849 [0.159, 1.000], mean action: 16.975 [0.000, 30.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.287959, mean_absolute_error: 5.830251, mean_q: 6.528623
799 (array([36]),) False
 158880/500000: episode: 3972, duration: 32.204s, episode steps: 40, steps per second: 1, episode reward: 28.772, mean reward: 0.719 [0.523, 0.995], mean action: 23.425 [12.000, 35.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.267522, mean_absolute_error: 5.832025, mean_q: 6.527982
732 (array([12]),) False
 158920/500000: episode: 3973, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 34.593, mean reward: 0.865 [0.110, 1.000], mean action: 22.575 [7.000, 49.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.300058, mean_absolute_error: 5.838439, mean_q: 6.535974
857 (array([22]),) False
 158960/500000: episode: 3974, duration: 32.261s, episode steps: 40, steps per second: 1, episode reward: 31.195, mean reward: 0.780 [0.131, 1.000], mean action: 20.200 [12.000, 53.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.307262, mean_absolute_error: 5.819009, mean_q: 6.517195
246 (array([22]),) False
 159000/500000: episode: 3975, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 37.635, mean reward: 0.941 [0.082, 1.000], mean action: 23.475 [3.000, 52.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.281799, mean_absolute_error: 5.869683, mean_q: 6.579308
135 (array([22]),) False
 159040/500000: episode: 3976, duration: 32.256s, episode steps: 40, steps per second: 1, episode reward: 38.166, mean reward: 0.954 [0.385, 1.000], mean action: 24.350 [22.000, 53.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.277220, mean_absolute_error: 5.875163, mean_q: 6.591238
698 (array([22]),) False
 159080/500000: episode: 3977, duration: 33.229s, episode steps: 40, steps per second: 1, episode reward: 35.934, mean reward: 0.898 [0.309, 1.000], mean action: 21.675 [3.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.262226, mean_absolute_error: 5.892501, mean_q: 6.607759
673 (array([3]),) False
 159120/500000: episode: 3978, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 20.623, mean reward: 0.516 [0.200, 1.000], mean action: 29.550 [3.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.275514, mean_absolute_error: 5.909100, mean_q: 6.623869
711 (array([22]),) False
 159160/500000: episode: 3979, duration: 33.276s, episode steps: 40, steps per second: 1, episode reward: 37.542, mean reward: 0.939 [0.415, 1.000], mean action: 26.400 [12.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.269027, mean_absolute_error: 5.833753, mean_q: 6.534827
431 (array([22]),) False
 159200/500000: episode: 3980, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.251720, mean_absolute_error: 5.883367, mean_q: 6.592498
97 (array([22]),) False
 159240/500000: episode: 3981, duration: 33.263s, episode steps: 40, steps per second: 1, episode reward: 35.214, mean reward: 0.880 [0.047, 1.000], mean action: 24.100 [11.000, 56.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.296193, mean_absolute_error: 5.900421, mean_q: 6.607076
180 (array([48]),) False
 159280/500000: episode: 3982, duration: 33.183s, episode steps: 40, steps per second: 1, episode reward: 34.530, mean reward: 0.863 [0.028, 0.978], mean action: 22.225 [12.000, 56.000], mean observation: -0.169 [-1.000, 1.000], loss: 0.287588, mean_absolute_error: 5.904774, mean_q: 6.610703
47 (array([44]),) False
 159320/500000: episode: 3983, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 35.915, mean reward: 0.898 [0.547, 1.000], mean action: 22.125 [17.000, 32.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.273273, mean_absolute_error: 5.858785, mean_q: 6.557837
365 (array([22]),) False
 159360/500000: episode: 3984, duration: 32.352s, episode steps: 40, steps per second: 1, episode reward: 38.616, mean reward: 0.965 [0.254, 1.000], mean action: 22.450 [14.000, 55.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.301295, mean_absolute_error: 5.823569, mean_q: 6.531137
762 (array([22]),) False
 159400/500000: episode: 3985, duration: 33.264s, episode steps: 40, steps per second: 1, episode reward: 37.138, mean reward: 0.928 [0.299, 1.000], mean action: 29.000 [3.000, 52.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.322887, mean_absolute_error: 5.846427, mean_q: 6.550296
11 (array([22]),) False
 159440/500000: episode: 3986, duration: 32.255s, episode steps: 40, steps per second: 1, episode reward: 34.030, mean reward: 0.851 [0.166, 1.000], mean action: 30.700 [13.000, 57.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.262350, mean_absolute_error: 5.904405, mean_q: 6.618291
304 (array([22]),) False
 159480/500000: episode: 3987, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 33.511, mean reward: 0.838 [0.029, 1.000], mean action: 21.250 [1.000, 44.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.264234, mean_absolute_error: 5.766206, mean_q: 6.469752
589 (array([22]),) False
 159520/500000: episode: 3988, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 30.116, mean reward: 0.753 [0.079, 1.000], mean action: 15.800 [7.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.270664, mean_absolute_error: 5.813469, mean_q: 6.515805
397 (array([22]),) False
 159560/500000: episode: 3989, duration: 33.262s, episode steps: 40, steps per second: 1, episode reward: 34.136, mean reward: 0.853 [0.006, 1.000], mean action: 22.075 [15.000, 37.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.278715, mean_absolute_error: 5.841738, mean_q: 6.555827
439 (array([12]),) False
 159600/500000: episode: 3990, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 36.701, mean reward: 0.918 [0.165, 1.000], mean action: 23.275 [0.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.251993, mean_absolute_error: 5.763831, mean_q: 6.469725
862 (array([14]),) False
 159640/500000: episode: 3991, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 35.463, mean reward: 0.887 [0.430, 1.000], mean action: 18.000 [12.000, 46.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.298547, mean_absolute_error: 5.893890, mean_q: 6.611336
540 (array([22]),) False
 159680/500000: episode: 3992, duration: 33.162s, episode steps: 40, steps per second: 1, episode reward: 36.971, mean reward: 0.924 [0.409, 1.000], mean action: 25.475 [12.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.285164, mean_absolute_error: 5.756125, mean_q: 6.461347
662 (array([12]),) False
 159720/500000: episode: 3993, duration: 33.319s, episode steps: 40, steps per second: 1, episode reward: 36.958, mean reward: 0.924 [0.119, 1.000], mean action: 14.925 [2.000, 52.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.299203, mean_absolute_error: 5.783984, mean_q: 6.490802
231 (array([22]),) False
 159760/500000: episode: 3994, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 34.127, mean reward: 0.853 [0.000, 1.000], mean action: 19.625 [3.000, 55.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.298870, mean_absolute_error: 5.819949, mean_q: 6.534584
380 (array([22]),) False
 159800/500000: episode: 3995, duration: 33.320s, episode steps: 40, steps per second: 1, episode reward: 37.807, mean reward: 0.945 [0.322, 1.000], mean action: 22.450 [20.000, 37.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.274555, mean_absolute_error: 5.822057, mean_q: 6.516294
328 (array([12]),) False
 159840/500000: episode: 3996, duration: 32.275s, episode steps: 40, steps per second: 1, episode reward: 35.578, mean reward: 0.889 [0.060, 1.000], mean action: 15.525 [8.000, 48.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.305469, mean_absolute_error: 5.776712, mean_q: 6.473382
160 (array([12]),) False
 159880/500000: episode: 3997, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 35.830, mean reward: 0.896 [0.335, 1.000], mean action: 17.925 [7.000, 46.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.267658, mean_absolute_error: 5.869433, mean_q: 6.568556
154 (array([44]),) False
 159920/500000: episode: 3998, duration: 32.294s, episode steps: 40, steps per second: 1, episode reward: 37.109, mean reward: 0.928 [0.140, 0.998], mean action: 17.575 [1.000, 46.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.275143, mean_absolute_error: 5.755824, mean_q: 6.456228
392 (array([40]),) False
 159960/500000: episode: 3999, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 29.780, mean reward: 0.745 [0.354, 1.000], mean action: 22.325 [21.000, 36.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.319049, mean_absolute_error: 5.760526, mean_q: 6.461417
837 (array([48]),) False
 160000/500000: episode: 4000, duration: 32.272s, episode steps: 40, steps per second: 1, episode reward: 38.470, mean reward: 0.962 [0.494, 0.975], mean action: 22.825 [22.000, 55.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.288940, mean_absolute_error: 5.767019, mean_q: 6.464220
588 (array([22]),) False
 160040/500000: episode: 4001, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 35.659, mean reward: 0.891 [0.389, 1.000], mean action: 19.675 [7.000, 49.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.268675, mean_absolute_error: 5.738177, mean_q: 6.437273
215 (array([22]),) False
 160080/500000: episode: 4002, duration: 33.265s, episode steps: 40, steps per second: 1, episode reward: 34.824, mean reward: 0.871 [0.105, 1.000], mean action: 17.700 [9.000, 22.000], mean observation: -0.185 [-1.000, 1.000], loss: 0.249583, mean_absolute_error: 5.716398, mean_q: 6.417284
722 (array([22]),) False
 160120/500000: episode: 4003, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 38.812, mean reward: 0.970 [0.589, 1.000], mean action: 20.575 [12.000, 52.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.262946, mean_absolute_error: 5.737010, mean_q: 6.434386
608 (array([36]),) False
 160160/500000: episode: 4004, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 18.820, mean reward: 0.471 [0.175, 0.959], mean action: 27.275 [0.000, 59.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.279433, mean_absolute_error: 5.760731, mean_q: 6.470397
696 (array([36]),) False
 160200/500000: episode: 4005, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 19.682, mean reward: 0.492 [0.083, 1.000], mean action: 34.150 [3.000, 49.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.291353, mean_absolute_error: 5.761176, mean_q: 6.464797
635 (array([22]),) False
 160240/500000: episode: 4006, duration: 33.092s, episode steps: 40, steps per second: 1, episode reward: 34.547, mean reward: 0.864 [0.335, 1.000], mean action: 32.375 [0.000, 53.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.302851, mean_absolute_error: 5.797282, mean_q: 6.496957
845 (array([22]),) False
 160280/500000: episode: 4007, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 37.759, mean reward: 0.944 [0.110, 1.000], mean action: 23.275 [16.000, 52.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.266833, mean_absolute_error: 5.779089, mean_q: 6.477295
182 (array([54]),) False
 160320/500000: episode: 4008, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 26.214, mean reward: 0.655 [0.065, 1.000], mean action: 24.675 [2.000, 44.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.270917, mean_absolute_error: 5.651277, mean_q: 6.345018
414 (array([48]),) False
 160360/500000: episode: 4009, duration: 31.989s, episode steps: 40, steps per second: 1, episode reward: 29.123, mean reward: 0.728 [0.002, 0.845], mean action: 24.450 [3.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.295039, mean_absolute_error: 5.774192, mean_q: 6.471375
790 (array([48]),) False
 160400/500000: episode: 4010, duration: 31.160s, episode steps: 40, steps per second: 1, episode reward: 32.823, mean reward: 0.821 [0.090, 1.000], mean action: 27.525 [5.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.280803, mean_absolute_error: 5.739511, mean_q: 6.435286
21 (array([3]),) False
 160440/500000: episode: 4011, duration: 31.395s, episode steps: 40, steps per second: 1, episode reward: 26.795, mean reward: 0.670 [0.005, 1.000], mean action: 22.925 [20.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.244476, mean_absolute_error: 5.715972, mean_q: 6.410640
746 (array([37]),) False
 160480/500000: episode: 4012, duration: 30.920s, episode steps: 40, steps per second: 1, episode reward: 33.601, mean reward: 0.840 [0.240, 0.968], mean action: 23.475 [3.000, 55.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.255799, mean_absolute_error: 5.723384, mean_q: 6.427444
752 (array([3]),) False
 160520/500000: episode: 4013, duration: 31.503s, episode steps: 40, steps per second: 1, episode reward: 31.880, mean reward: 0.797 [0.092, 1.000], mean action: 12.225 [3.000, 45.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.284057, mean_absolute_error: 5.775195, mean_q: 6.476457
245 (array([22]),) False
 160560/500000: episode: 4014, duration: 31.416s, episode steps: 40, steps per second: 1, episode reward: 35.684, mean reward: 0.892 [0.079, 1.000], mean action: 25.600 [11.000, 49.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.260372, mean_absolute_error: 5.789626, mean_q: 6.495588
721 (array([22]),) False
 160600/500000: episode: 4015, duration: 31.401s, episode steps: 40, steps per second: 1, episode reward: 33.150, mean reward: 0.829 [0.097, 1.000], mean action: 23.350 [0.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.293557, mean_absolute_error: 5.720471, mean_q: 6.412793
81 (array([22]),) False
 160640/500000: episode: 4016, duration: 31.380s, episode steps: 40, steps per second: 1, episode reward: 35.760, mean reward: 0.894 [0.236, 1.000], mean action: 31.825 [22.000, 57.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.270242, mean_absolute_error: 5.717681, mean_q: 6.419047
391 (array([22]),) False
 160680/500000: episode: 4017, duration: 31.421s, episode steps: 40, steps per second: 1, episode reward: 37.476, mean reward: 0.937 [0.088, 1.000], mean action: 23.475 [9.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.289618, mean_absolute_error: 5.684816, mean_q: 6.377997
672 (array([44]),) False
 160720/500000: episode: 4018, duration: 31.382s, episode steps: 40, steps per second: 1, episode reward: 28.510, mean reward: 0.713 [0.446, 0.955], mean action: 22.625 [5.000, 50.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.272442, mean_absolute_error: 5.739762, mean_q: 6.442827
519 (array([58]),) False
 160760/500000: episode: 4019, duration: 31.407s, episode steps: 40, steps per second: 1, episode reward: 19.574, mean reward: 0.489 [0.100, 0.778], mean action: 18.000 [3.000, 56.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.251897, mean_absolute_error: 5.692749, mean_q: 6.385702
542 (array([44]),) False
 160800/500000: episode: 4020, duration: 30.931s, episode steps: 40, steps per second: 1, episode reward: 32.740, mean reward: 0.818 [0.705, 0.920], mean action: 22.550 [12.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.253354, mean_absolute_error: 5.707329, mean_q: 6.405881
284 (array([12]),) False
 160840/500000: episode: 4021, duration: 31.433s, episode steps: 40, steps per second: 1, episode reward: 31.103, mean reward: 0.778 [0.124, 1.000], mean action: 21.550 [12.000, 60.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.272289, mean_absolute_error: 5.776394, mean_q: 6.482196
629 (array([22]),) False
 160880/500000: episode: 4022, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 35.130, mean reward: 0.878 [0.446, 1.000], mean action: 23.500 [12.000, 53.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.294486, mean_absolute_error: 5.674822, mean_q: 6.372697
488 (array([22]),) False
 160920/500000: episode: 4023, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 35.908, mean reward: 0.898 [0.147, 1.000], mean action: 34.525 [22.000, 55.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.234597, mean_absolute_error: 5.714332, mean_q: 6.415980
385 (array([30]),) False
 160960/500000: episode: 4024, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 36.156, mean reward: 0.904 [0.169, 1.000], mean action: 21.425 [2.000, 32.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.275657, mean_absolute_error: 5.748175, mean_q: 6.444070
562 (array([22]),) False
 161000/500000: episode: 4025, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 36.266, mean reward: 0.907 [0.657, 1.000], mean action: 17.150 [12.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.265878, mean_absolute_error: 5.753306, mean_q: 6.456288
281 (array([48]),) False
 161040/500000: episode: 4026, duration: 33.191s, episode steps: 40, steps per second: 1, episode reward: 37.896, mean reward: 0.947 [0.309, 1.000], mean action: 22.625 [0.000, 49.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.257712, mean_absolute_error: 5.744240, mean_q: 6.445607
153 (array([44]),) False
 161080/500000: episode: 4027, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 32.014, mean reward: 0.800 [0.223, 0.878], mean action: 19.575 [3.000, 50.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.238616, mean_absolute_error: 5.749510, mean_q: 6.458392
105 (array([22]),) False
 161120/500000: episode: 4028, duration: 33.085s, episode steps: 40, steps per second: 1, episode reward: 38.234, mean reward: 0.956 [0.167, 1.000], mean action: 21.075 [11.000, 30.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.266608, mean_absolute_error: 5.715456, mean_q: 6.421213
380 (array([22]),) False
 161160/500000: episode: 4029, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 36.579, mean reward: 0.914 [0.210, 1.000], mean action: 23.600 [11.000, 51.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.281564, mean_absolute_error: 5.763184, mean_q: 6.468147
765 (array([48]),) False
 161200/500000: episode: 4030, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 31.954, mean reward: 0.799 [0.072, 1.000], mean action: 34.650 [11.000, 57.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.267595, mean_absolute_error: 5.793653, mean_q: 6.499603
313 (array([22]),) False
 161240/500000: episode: 4031, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 36.336, mean reward: 0.908 [0.051, 1.000], mean action: 22.450 [4.000, 46.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.282053, mean_absolute_error: 5.767844, mean_q: 6.470068
75 (array([22]),) False
 161280/500000: episode: 4032, duration: 32.263s, episode steps: 40, steps per second: 1, episode reward: 37.533, mean reward: 0.938 [0.298, 1.000], mean action: 22.000 [12.000, 42.000], mean observation: -0.082 [-1.000, 1.000], loss: 0.269897, mean_absolute_error: 5.710622, mean_q: 6.418144
335 (array([22]),) False
 161320/500000: episode: 4033, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 34.894, mean reward: 0.872 [0.131, 1.000], mean action: 23.800 [9.000, 49.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.246775, mean_absolute_error: 5.804942, mean_q: 6.525279
166 (array([22]),) False
 161360/500000: episode: 4034, duration: 32.179s, episode steps: 40, steps per second: 1, episode reward: 32.551, mean reward: 0.814 [0.171, 1.000], mean action: 16.825 [12.000, 58.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.286065, mean_absolute_error: 5.695943, mean_q: 6.400608
564 (array([22]),) False
 161400/500000: episode: 4035, duration: 33.025s, episode steps: 40, steps per second: 1, episode reward: 35.747, mean reward: 0.894 [0.019, 1.000], mean action: 16.275 [9.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.265204, mean_absolute_error: 5.755345, mean_q: 6.470278
749 (array([22]),) False
 161440/500000: episode: 4036, duration: 32.220s, episode steps: 40, steps per second: 1, episode reward: 36.918, mean reward: 0.923 [0.080, 1.000], mean action: 24.275 [6.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.275855, mean_absolute_error: 5.782603, mean_q: 6.496314
343 (array([22]),) False
 161480/500000: episode: 4037, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 38.761, mean reward: 0.969 [0.448, 1.000], mean action: 21.950 [20.000, 24.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.270823, mean_absolute_error: 5.740702, mean_q: 6.456467
473 (array([22]),) False
 161520/500000: episode: 4038, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 35.208, mean reward: 0.880 [0.151, 1.000], mean action: 22.900 [4.000, 54.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.266108, mean_absolute_error: 5.727319, mean_q: 6.437270
257 (array([22]),) False
 161560/500000: episode: 4039, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 34.201, mean reward: 0.855 [0.224, 1.000], mean action: 22.500 [15.000, 56.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.272903, mean_absolute_error: 5.732718, mean_q: 6.442266
136 (array([12]),) False
 161600/500000: episode: 4040, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 30.963, mean reward: 0.774 [0.212, 0.931], mean action: 21.050 [9.000, 22.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.248444, mean_absolute_error: 5.724069, mean_q: 6.435540
571 (array([48]),) False
 161640/500000: episode: 4041, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 36.057, mean reward: 0.901 [0.000, 1.000], mean action: 32.275 [10.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.300643, mean_absolute_error: 5.737210, mean_q: 6.451223
643 (array([44]),) False
 161680/500000: episode: 4042, duration: 33.120s, episode steps: 40, steps per second: 1, episode reward: 34.074, mean reward: 0.852 [0.199, 1.000], mean action: 32.375 [5.000, 53.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.244817, mean_absolute_error: 5.680239, mean_q: 6.400124
371 (array([14]),) False
 161720/500000: episode: 4043, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 34.308, mean reward: 0.858 [0.477, 1.000], mean action: 20.275 [1.000, 41.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.279843, mean_absolute_error: 5.727669, mean_q: 6.442496
288 (array([33]),) False
 161760/500000: episode: 4044, duration: 32.277s, episode steps: 40, steps per second: 1, episode reward: 22.263, mean reward: 0.557 [0.188, 1.000], mean action: 25.000 [22.000, 54.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.281536, mean_absolute_error: 5.754701, mean_q: 6.465903
176 (array([3]),) False
 161800/500000: episode: 4045, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 19.648, mean reward: 0.491 [0.039, 1.000], mean action: 35.475 [3.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.273516, mean_absolute_error: 5.757850, mean_q: 6.464593
681 (array([12]),) False
 161840/500000: episode: 4046, duration: 32.146s, episode steps: 40, steps per second: 1, episode reward: 35.980, mean reward: 0.899 [0.000, 1.000], mean action: 16.000 [1.000, 56.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.262264, mean_absolute_error: 5.690077, mean_q: 6.393238
276 (array([56]),) False
 161880/500000: episode: 4047, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 23.623, mean reward: 0.591 [0.000, 0.915], mean action: 20.100 [0.000, 49.000], mean observation: -0.153 [-1.000, 1.000], loss: 0.246969, mean_absolute_error: 5.785987, mean_q: 6.500330
342 (array([12]),) False
 161920/500000: episode: 4048, duration: 32.224s, episode steps: 40, steps per second: 1, episode reward: 35.159, mean reward: 0.879 [0.216, 1.000], mean action: 25.525 [2.000, 55.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.272336, mean_absolute_error: 5.739816, mean_q: 6.454155
3 (array([48]),) False
 161960/500000: episode: 4049, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 31.233, mean reward: 0.781 [0.061, 1.000], mean action: 22.950 [7.000, 60.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.279927, mean_absolute_error: 5.655956, mean_q: 6.366096
397 (array([22]),) False
 162000/500000: episode: 4050, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 32.299, mean reward: 0.807 [0.006, 1.000], mean action: 22.675 [2.000, 47.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.253188, mean_absolute_error: 5.707961, mean_q: 6.412233
848 (array([44]),) False
 162040/500000: episode: 4051, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 27.847, mean reward: 0.696 [0.340, 0.903], mean action: 22.400 [12.000, 58.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.270515, mean_absolute_error: 5.718870, mean_q: 6.419197
823 (array([58]),) False
 162080/500000: episode: 4052, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 24.958, mean reward: 0.624 [0.170, 1.000], mean action: 21.700 [1.000, 59.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.263306, mean_absolute_error: 5.679990, mean_q: 6.373959
35 (array([48]),) False
 162120/500000: episode: 4053, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 33.319, mean reward: 0.833 [0.129, 0.972], mean action: 32.700 [2.000, 59.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.262611, mean_absolute_error: 5.752271, mean_q: 6.438809
373 (array([22]),) False
 162160/500000: episode: 4054, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 37.452, mean reward: 0.936 [0.000, 1.000], mean action: 21.975 [11.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.274145, mean_absolute_error: 5.799689, mean_q: 6.491673
695 (array([22]),) False
 162200/500000: episode: 4055, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 36.457, mean reward: 0.911 [0.660, 1.000], mean action: 26.550 [12.000, 49.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.261188, mean_absolute_error: 5.772176, mean_q: 6.462944
201 (array([22]),) False
 162240/500000: episode: 4056, duration: 32.159s, episode steps: 40, steps per second: 1, episode reward: 34.549, mean reward: 0.864 [0.218, 1.000], mean action: 20.675 [7.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.304783, mean_absolute_error: 5.716673, mean_q: 6.407216
746 (array([37]),) False
 162280/500000: episode: 4057, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 35.266, mean reward: 0.882 [0.322, 0.968], mean action: 18.625 [7.000, 47.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.277011, mean_absolute_error: 5.699975, mean_q: 6.396559
432 (array([22]),) False
 162320/500000: episode: 4058, duration: 32.196s, episode steps: 40, steps per second: 1, episode reward: 39.633, mean reward: 0.991 [0.633, 1.000], mean action: 21.575 [5.000, 22.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.262030, mean_absolute_error: 5.762851, mean_q: 6.455270
88 (array([22]),) False
 162360/500000: episode: 4059, duration: 33.083s, episode steps: 40, steps per second: 1, episode reward: 37.761, mean reward: 0.944 [0.265, 1.000], mean action: 22.125 [10.000, 36.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.260489, mean_absolute_error: 5.708704, mean_q: 6.395728
434 (array([22]),) False
 162400/500000: episode: 4060, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 36.644, mean reward: 0.916 [0.173, 1.000], mean action: 25.275 [22.000, 57.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.273214, mean_absolute_error: 5.728547, mean_q: 6.418294
316 (array([12]),) False
 162440/500000: episode: 4061, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 36.647, mean reward: 0.916 [0.054, 1.000], mean action: 23.025 [10.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.258258, mean_absolute_error: 5.739095, mean_q: 6.430530
602 (array([36]),) False
 162480/500000: episode: 4062, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 16.410, mean reward: 0.410 [0.026, 1.000], mean action: 20.075 [0.000, 57.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.246266, mean_absolute_error: 5.721540, mean_q: 6.413823
347 (array([22]),) False
 162520/500000: episode: 4063, duration: 33.094s, episode steps: 40, steps per second: 1, episode reward: 11.533, mean reward: 0.288 [0.064, 0.579], mean action: 53.875 [3.000, 56.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.241203, mean_absolute_error: 5.736723, mean_q: 6.432701
8 (array([22]),) False
 162560/500000: episode: 4064, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 30.184, mean reward: 0.755 [0.000, 1.000], mean action: 21.375 [12.000, 55.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.249303, mean_absolute_error: 5.776148, mean_q: 6.478026
693 (array([22]),) False
 162600/500000: episode: 4065, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 33.965, mean reward: 0.849 [0.034, 1.000], mean action: 21.000 [5.000, 50.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.243887, mean_absolute_error: 5.725400, mean_q: 6.426044
546 (array([22]),) False
 162640/500000: episode: 4066, duration: 33.029s, episode steps: 40, steps per second: 1, episode reward: 38.453, mean reward: 0.961 [0.082, 1.000], mean action: 22.575 [18.000, 44.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.272586, mean_absolute_error: 5.739115, mean_q: 6.443196
466 (array([22]),) False
 162680/500000: episode: 4067, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 36.197, mean reward: 0.905 [0.092, 1.000], mean action: 20.725 [1.000, 32.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.248799, mean_absolute_error: 5.685407, mean_q: 6.378266
123 (array([22]),) False
 162720/500000: episode: 4068, duration: 32.299s, episode steps: 40, steps per second: 1, episode reward: 36.615, mean reward: 0.915 [0.372, 1.000], mean action: 22.625 [1.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.257087, mean_absolute_error: 5.758295, mean_q: 6.448804
456 (array([22]),) False
 162760/500000: episode: 4069, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 37.251, mean reward: 0.931 [0.121, 1.000], mean action: 23.150 [3.000, 58.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.283934, mean_absolute_error: 5.749092, mean_q: 6.440805
307 (array([22]),) False
 162800/500000: episode: 4070, duration: 32.139s, episode steps: 40, steps per second: 1, episode reward: 36.654, mean reward: 0.916 [0.245, 1.000], mean action: 23.825 [2.000, 56.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.316691, mean_absolute_error: 5.768246, mean_q: 6.451976
268 (array([22]),) False
 162840/500000: episode: 4071, duration: 33.022s, episode steps: 40, steps per second: 1, episode reward: 36.583, mean reward: 0.915 [0.078, 1.000], mean action: 18.700 [12.000, 36.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.242537, mean_absolute_error: 5.772444, mean_q: 6.453017
332 (array([22]),) False
 162880/500000: episode: 4072, duration: 32.218s, episode steps: 40, steps per second: 1, episode reward: 33.221, mean reward: 0.831 [0.302, 1.000], mean action: 22.525 [12.000, 60.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.251367, mean_absolute_error: 5.685648, mean_q: 6.371613
182 (array([54]),) False
 162920/500000: episode: 4073, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 31.140, mean reward: 0.779 [0.065, 1.000], mean action: 34.350 [3.000, 60.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.238435, mean_absolute_error: 5.754533, mean_q: 6.440052
605 (array([22]),) False
 162960/500000: episode: 4074, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 37.869, mean reward: 0.947 [0.041, 1.000], mean action: 22.325 [0.000, 52.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.263566, mean_absolute_error: 5.655711, mean_q: 6.338892
407 (array([22]),) False
 163000/500000: episode: 4075, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 36.583, mean reward: 0.915 [0.104, 1.000], mean action: 22.050 [0.000, 50.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.276099, mean_absolute_error: 5.718637, mean_q: 6.412872
15 (array([22]),) False
 163040/500000: episode: 4076, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 38.826, mean reward: 0.971 [0.051, 1.000], mean action: 22.150 [3.000, 47.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.230318, mean_absolute_error: 5.706334, mean_q: 6.399285
373 (array([22]),) False
 163080/500000: episode: 4077, duration: 33.218s, episode steps: 40, steps per second: 1, episode reward: 33.954, mean reward: 0.849 [0.285, 1.000], mean action: 21.975 [8.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.237446, mean_absolute_error: 5.732656, mean_q: 6.424948
854 (array([12]),) False
 163120/500000: episode: 4078, duration: 33.095s, episode steps: 40, steps per second: 1, episode reward: 28.985, mean reward: 0.725 [0.000, 1.000], mean action: 19.275 [3.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.230026, mean_absolute_error: 5.733143, mean_q: 6.428908
520 (array([22]),) False
 163160/500000: episode: 4079, duration: 33.101s, episode steps: 40, steps per second: 1, episode reward: 39.224, mean reward: 0.981 [0.821, 1.000], mean action: 20.425 [12.000, 22.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.264767, mean_absolute_error: 5.743246, mean_q: 6.428327
271 (array([18]),) False
 163200/500000: episode: 4080, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 34.513, mean reward: 0.863 [0.399, 1.000], mean action: 21.800 [0.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.245346, mean_absolute_error: 5.755991, mean_q: 6.445857
101 (array([22]),) False
 163240/500000: episode: 4081, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 36.851, mean reward: 0.921 [0.156, 1.000], mean action: 23.675 [3.000, 48.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.284679, mean_absolute_error: 5.795674, mean_q: 6.494038
518 (array([22]),) False
 163280/500000: episode: 4082, duration: 32.169s, episode steps: 40, steps per second: 1, episode reward: 36.601, mean reward: 0.915 [0.018, 1.000], mean action: 21.750 [12.000, 60.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.257346, mean_absolute_error: 5.709327, mean_q: 6.399126
218 (array([22]),) False
 163320/500000: episode: 4083, duration: 33.071s, episode steps: 40, steps per second: 1, episode reward: 38.332, mean reward: 0.958 [0.149, 1.000], mean action: 21.000 [2.000, 22.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.265867, mean_absolute_error: 5.773460, mean_q: 6.473911
247 (array([14]),) False
 163360/500000: episode: 4084, duration: 32.189s, episode steps: 40, steps per second: 1, episode reward: 33.500, mean reward: 0.838 [0.287, 1.000], mean action: 17.975 [5.000, 40.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.266297, mean_absolute_error: 5.788710, mean_q: 6.494910
510 (array([22]),) False
 163400/500000: episode: 4085, duration: 33.089s, episode steps: 40, steps per second: 1, episode reward: 35.903, mean reward: 0.898 [0.104, 1.000], mean action: 19.675 [12.000, 53.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.266640, mean_absolute_error: 5.764593, mean_q: 6.465983
672 (array([44]),) False
 163440/500000: episode: 4086, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 31.533, mean reward: 0.788 [0.515, 0.969], mean action: 23.400 [12.000, 57.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.286406, mean_absolute_error: 5.774995, mean_q: 6.483495
444 (array([22]),) False
 163480/500000: episode: 4087, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 36.454, mean reward: 0.911 [0.089, 1.000], mean action: 22.650 [5.000, 49.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.226841, mean_absolute_error: 5.732512, mean_q: 6.438097
330 (array([38]),) False
 163520/500000: episode: 4088, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 36.113, mean reward: 0.903 [0.199, 1.000], mean action: 16.550 [6.000, 52.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.280415, mean_absolute_error: 5.694080, mean_q: 6.395419
86 (array([22]),) False
 163560/500000: episode: 4089, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 36.165, mean reward: 0.904 [0.123, 1.000], mean action: 25.400 [0.000, 56.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.251237, mean_absolute_error: 5.762091, mean_q: 6.465281
345 (array([22]),) False
 163600/500000: episode: 4090, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 37.145, mean reward: 0.929 [0.000, 1.000], mean action: 22.950 [6.000, 49.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.248931, mean_absolute_error: 5.727754, mean_q: 6.428032
256 (array([22]),) False
 163640/500000: episode: 4091, duration: 33.112s, episode steps: 40, steps per second: 1, episode reward: 34.017, mean reward: 0.850 [0.161, 1.000], mean action: 20.525 [4.000, 50.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.274944, mean_absolute_error: 5.680803, mean_q: 6.378057
48 (array([12]),) False
 163680/500000: episode: 4092, duration: 32.206s, episode steps: 40, steps per second: 1, episode reward: 35.912, mean reward: 0.898 [0.235, 0.952], mean action: 21.700 [7.000, 31.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.276707, mean_absolute_error: 5.719989, mean_q: 6.412195
48 (array([12]),) False
 163720/500000: episode: 4093, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 36.642, mean reward: 0.916 [0.385, 0.952], mean action: 23.075 [6.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.269568, mean_absolute_error: 5.771280, mean_q: 6.454738
495 (array([48]),) False
 163760/500000: episode: 4094, duration: 32.180s, episode steps: 40, steps per second: 1, episode reward: 36.856, mean reward: 0.921 [0.336, 0.966], mean action: 22.550 [0.000, 55.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.269221, mean_absolute_error: 5.706895, mean_q: 6.390341
420 (array([22]),) False
 163800/500000: episode: 4095, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 35.997, mean reward: 0.900 [0.088, 1.000], mean action: 23.125 [12.000, 50.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.252647, mean_absolute_error: 5.739198, mean_q: 6.435962
186 (array([22]),) False
 163840/500000: episode: 4096, duration: 32.264s, episode steps: 40, steps per second: 1, episode reward: 34.244, mean reward: 0.856 [0.409, 1.000], mean action: 15.775 [12.000, 43.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.256022, mean_absolute_error: 5.773262, mean_q: 6.467223
856 (array([48]),) False
 163880/500000: episode: 4097, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 36.935, mean reward: 0.923 [0.324, 0.976], mean action: 19.250 [12.000, 59.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.266308, mean_absolute_error: 5.782126, mean_q: 6.484966
30 (array([22]),) False
 163920/500000: episode: 4098, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 36.954, mean reward: 0.924 [0.353, 1.000], mean action: 27.125 [14.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.267775, mean_absolute_error: 5.785011, mean_q: 6.484495
130 (array([22]),) False
 163960/500000: episode: 4099, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 37.110, mean reward: 0.928 [0.028, 1.000], mean action: 22.500 [4.000, 53.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.255919, mean_absolute_error: 5.801072, mean_q: 6.501195
569 (array([22]),) False
 164000/500000: episode: 4100, duration: 33.176s, episode steps: 40, steps per second: 1, episode reward: 30.971, mean reward: 0.774 [0.521, 1.000], mean action: 31.675 [2.000, 49.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.256821, mean_absolute_error: 5.716210, mean_q: 6.418130
127 (array([22]),) False
 164040/500000: episode: 4101, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 35.488, mean reward: 0.887 [0.224, 1.000], mean action: 19.225 [12.000, 60.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.246036, mean_absolute_error: 5.803264, mean_q: 6.523077
553 (array([22]),) False
 164080/500000: episode: 4102, duration: 31.874s, episode steps: 40, steps per second: 1, episode reward: 37.740, mean reward: 0.944 [0.492, 1.000], mean action: 20.100 [12.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.253728, mean_absolute_error: 5.740327, mean_q: 6.455752
83 (array([22]),) False
 164120/500000: episode: 4103, duration: 31.379s, episode steps: 40, steps per second: 1, episode reward: 38.835, mean reward: 0.971 [0.347, 1.000], mean action: 22.375 [19.000, 40.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.243643, mean_absolute_error: 5.831882, mean_q: 6.549243
516 (array([48]),) False
 164160/500000: episode: 4104, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 36.140, mean reward: 0.903 [0.296, 1.000], mean action: 15.650 [7.000, 44.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.282465, mean_absolute_error: 5.772171, mean_q: 6.490004
610 (array([48]),) False
 164200/500000: episode: 4105, duration: 32.484s, episode steps: 40, steps per second: 1, episode reward: 35.992, mean reward: 0.900 [0.057, 1.000], mean action: 19.050 [4.000, 42.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.284344, mean_absolute_error: 5.828060, mean_q: 6.543946
294 (array([22]),) False
 164240/500000: episode: 4106, duration: 32.153s, episode steps: 40, steps per second: 1, episode reward: 39.019, mean reward: 0.975 [0.420, 1.000], mean action: 22.725 [22.000, 39.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.240070, mean_absolute_error: 5.822568, mean_q: 6.544411
823 (array([58]),) False
 164280/500000: episode: 4107, duration: 32.962s, episode steps: 40, steps per second: 1, episode reward: 25.289, mean reward: 0.632 [0.170, 1.000], mean action: 19.350 [12.000, 38.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.285755, mean_absolute_error: 5.824717, mean_q: 6.536107
709 (array([41]),) False
 164320/500000: episode: 4108, duration: 32.107s, episode steps: 40, steps per second: 1, episode reward: 20.896, mean reward: 0.522 [0.323, 0.752], mean action: 13.175 [3.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.257892, mean_absolute_error: 5.798573, mean_q: 6.508308
36 (array([22]),) False
 164360/500000: episode: 4109, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 33.278, mean reward: 0.832 [0.126, 1.000], mean action: 24.050 [5.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.289052, mean_absolute_error: 5.850317, mean_q: 6.563550
662 (array([12]),) False
 164400/500000: episode: 4110, duration: 33.063s, episode steps: 40, steps per second: 1, episode reward: 39.500, mean reward: 0.988 [0.733, 1.000], mean action: 12.375 [12.000, 21.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.273813, mean_absolute_error: 5.858060, mean_q: 6.575851
529 (array([3]),) False
 164440/500000: episode: 4111, duration: 33.059s, episode steps: 40, steps per second: 1, episode reward: 19.120, mean reward: 0.478 [0.078, 1.000], mean action: 25.225 [1.000, 49.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.261979, mean_absolute_error: 5.788190, mean_q: 6.502937
537 (array([22]),) False
 164480/500000: episode: 4112, duration: 32.942s, episode steps: 40, steps per second: 1, episode reward: 32.893, mean reward: 0.822 [0.306, 1.000], mean action: 15.825 [12.000, 58.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.296489, mean_absolute_error: 5.807524, mean_q: 6.519734
2 (array([12]),) False
 164520/500000: episode: 4113, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 28.675, mean reward: 0.717 [0.025, 0.832], mean action: 23.075 [3.000, 56.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.246224, mean_absolute_error: 5.774619, mean_q: 6.485635
342 (array([12]),) False
 164560/500000: episode: 4114, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 36.090, mean reward: 0.902 [0.286, 1.000], mean action: 27.525 [14.000, 54.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.271918, mean_absolute_error: 5.896750, mean_q: 6.606908
470 (array([22]),) False
 164600/500000: episode: 4115, duration: 33.209s, episode steps: 40, steps per second: 1, episode reward: 35.743, mean reward: 0.894 [0.147, 1.000], mean action: 24.275 [17.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.266014, mean_absolute_error: 5.899145, mean_q: 6.615808
314 (array([22]),) False
 164640/500000: episode: 4116, duration: 32.258s, episode steps: 40, steps per second: 1, episode reward: 38.070, mean reward: 0.952 [0.272, 1.000], mean action: 22.775 [17.000, 58.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.268966, mean_absolute_error: 5.842702, mean_q: 6.559409
174 (array([33]),) False
 164680/500000: episode: 4117, duration: 33.186s, episode steps: 40, steps per second: 1, episode reward: 21.614, mean reward: 0.540 [0.283, 0.770], mean action: 26.000 [1.000, 57.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.261595, mean_absolute_error: 5.868532, mean_q: 6.586380
624 (array([48]),) False
 164720/500000: episode: 4118, duration: 32.111s, episode steps: 40, steps per second: 1, episode reward: 34.014, mean reward: 0.850 [0.277, 1.000], mean action: 25.175 [5.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.272968, mean_absolute_error: 5.803507, mean_q: 6.528290
537 (array([22]),) False
 164760/500000: episode: 4119, duration: 33.012s, episode steps: 40, steps per second: 1, episode reward: 34.868, mean reward: 0.872 [0.426, 1.000], mean action: 17.975 [7.000, 38.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.269946, mean_absolute_error: 5.849074, mean_q: 6.573678
353 (array([22]),) False
 164800/500000: episode: 4120, duration: 32.121s, episode steps: 40, steps per second: 1, episode reward: 37.177, mean reward: 0.929 [0.077, 1.000], mean action: 23.100 [5.000, 55.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.328443, mean_absolute_error: 5.889461, mean_q: 6.606477
668 (array([22]),) False
 164840/500000: episode: 4121, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 31.230, mean reward: 0.781 [0.063, 1.000], mean action: 21.925 [2.000, 46.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.252077, mean_absolute_error: 5.875167, mean_q: 6.587913
457 (array([38]),) False
 164880/500000: episode: 4122, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 32.046, mean reward: 0.801 [0.541, 0.945], mean action: 23.425 [22.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.285281, mean_absolute_error: 5.748187, mean_q: 6.458543
244 (array([14]),) False
 164920/500000: episode: 4123, duration: 32.311s, episode steps: 40, steps per second: 1, episode reward: 32.944, mean reward: 0.824 [0.371, 1.000], mean action: 23.050 [5.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.277863, mean_absolute_error: 5.900591, mean_q: 6.614295
618 (array([12]),) False
 164960/500000: episode: 4124, duration: 31.444s, episode steps: 40, steps per second: 1, episode reward: 34.794, mean reward: 0.870 [0.303, 1.000], mean action: 25.350 [12.000, 56.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.250890, mean_absolute_error: 5.834881, mean_q: 6.543582
194 (array([44]),) False
 165000/500000: episode: 4125, duration: 31.460s, episode steps: 40, steps per second: 1, episode reward: 25.783, mean reward: 0.645 [0.000, 0.760], mean action: 18.975 [8.000, 22.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.300801, mean_absolute_error: 5.885100, mean_q: 6.596408
197 (array([22]),) False
 165040/500000: episode: 4126, duration: 31.458s, episode steps: 40, steps per second: 1, episode reward: 35.911, mean reward: 0.898 [0.147, 1.000], mean action: 18.850 [11.000, 53.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.218639, mean_absolute_error: 5.850071, mean_q: 6.556975
175 (array([22]),) False
 165080/500000: episode: 4127, duration: 31.434s, episode steps: 40, steps per second: 1, episode reward: 34.908, mean reward: 0.873 [0.102, 1.000], mean action: 22.275 [12.000, 60.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.298863, mean_absolute_error: 5.838859, mean_q: 6.539099
574 (array([8]),) False
 165120/500000: episode: 4128, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 35.004, mean reward: 0.875 [0.088, 1.000], mean action: 25.700 [22.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.269801, mean_absolute_error: 5.824136, mean_q: 6.521024
698 (array([22]),) False
 165160/500000: episode: 4129, duration: 31.389s, episode steps: 40, steps per second: 1, episode reward: 34.537, mean reward: 0.863 [0.325, 1.000], mean action: 26.275 [12.000, 47.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.291912, mean_absolute_error: 5.825131, mean_q: 6.526009
793 (array([12]),) False
 165200/500000: episode: 4130, duration: 30.891s, episode steps: 40, steps per second: 1, episode reward: 36.079, mean reward: 0.902 [0.087, 1.000], mean action: 17.025 [12.000, 56.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.261254, mean_absolute_error: 5.808575, mean_q: 6.496663
438 (array([22]),) False
 165240/500000: episode: 4131, duration: 31.347s, episode steps: 40, steps per second: 1, episode reward: 36.592, mean reward: 0.915 [0.041, 1.000], mean action: 23.450 [22.000, 57.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.257633, mean_absolute_error: 5.816691, mean_q: 6.502280
753 (array([22]),) False
 165280/500000: episode: 4132, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 35.967, mean reward: 0.899 [0.000, 1.000], mean action: 19.475 [9.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.278070, mean_absolute_error: 5.733687, mean_q: 6.414313
516 (array([48]),) False
 165320/500000: episode: 4133, duration: 31.369s, episode steps: 40, steps per second: 1, episode reward: 36.022, mean reward: 0.901 [0.103, 1.000], mean action: 18.600 [10.000, 46.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.266834, mean_absolute_error: 5.798676, mean_q: 6.491693
407 (array([22]),) False
 165360/500000: episode: 4134, duration: 31.431s, episode steps: 40, steps per second: 1, episode reward: 36.342, mean reward: 0.909 [0.000, 1.000], mean action: 24.175 [22.000, 57.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.281574, mean_absolute_error: 5.904503, mean_q: 6.600387
789 (array([22]),) False
 165400/500000: episode: 4135, duration: 31.421s, episode steps: 40, steps per second: 1, episode reward: 36.188, mean reward: 0.905 [0.123, 1.000], mean action: 27.650 [12.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.277349, mean_absolute_error: 5.799773, mean_q: 6.488193
558 (array([40]),) False
 165440/500000: episode: 4136, duration: 31.746s, episode steps: 40, steps per second: 1, episode reward: 32.270, mean reward: 0.807 [0.308, 1.000], mean action: 20.000 [6.000, 48.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.272402, mean_absolute_error: 5.844544, mean_q: 6.534818
460 (array([36]),) False
 165480/500000: episode: 4137, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 35.340, mean reward: 0.883 [0.104, 1.000], mean action: 24.475 [10.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.224552, mean_absolute_error: 5.734340, mean_q: 6.426549
110 (array([22]),) False
 165520/500000: episode: 4138, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 34.192, mean reward: 0.855 [0.288, 1.000], mean action: 25.475 [22.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.256448, mean_absolute_error: 5.822062, mean_q: 6.512410
47 (array([44]),) False
 165560/500000: episode: 4139, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 34.766, mean reward: 0.869 [0.217, 1.000], mean action: 22.050 [6.000, 39.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.269228, mean_absolute_error: 5.838285, mean_q: 6.531693
444 (array([22]),) False
 165600/500000: episode: 4140, duration: 32.226s, episode steps: 40, steps per second: 1, episode reward: 38.457, mean reward: 0.961 [0.138, 1.000], mean action: 22.850 [14.000, 40.000], mean observation: -0.039 [-1.000, 1.000], loss: 0.239814, mean_absolute_error: 5.931783, mean_q: 6.637819
666 (array([22]),) False
 165640/500000: episode: 4141, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 37.395, mean reward: 0.935 [0.195, 1.000], mean action: 20.225 [5.000, 51.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.256247, mean_absolute_error: 5.813550, mean_q: 6.516368
787 (array([3]),) False
 165680/500000: episode: 4142, duration: 32.292s, episode steps: 40, steps per second: 1, episode reward: 24.078, mean reward: 0.602 [0.150, 1.000], mean action: 23.100 [12.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.272325, mean_absolute_error: 5.794927, mean_q: 6.501975
524 (array([22]),) False
 165720/500000: episode: 4143, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 36.021, mean reward: 0.901 [0.254, 1.000], mean action: 19.175 [10.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.289536, mean_absolute_error: 5.832789, mean_q: 6.531157
456 (array([22]),) False
 165760/500000: episode: 4144, duration: 32.175s, episode steps: 40, steps per second: 1, episode reward: 38.184, mean reward: 0.955 [0.256, 1.000], mean action: 22.800 [13.000, 55.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.275594, mean_absolute_error: 5.905254, mean_q: 6.607516
664 (array([22]),) False
 165800/500000: episode: 4145, duration: 33.154s, episode steps: 40, steps per second: 1, episode reward: 31.009, mean reward: 0.775 [0.057, 1.000], mean action: 18.350 [12.000, 57.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.251606, mean_absolute_error: 5.836543, mean_q: 6.536874
613 (array([22]),) False
 165840/500000: episode: 4146, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 34.751, mean reward: 0.869 [0.099, 1.000], mean action: 25.950 [9.000, 59.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.299886, mean_absolute_error: 5.848667, mean_q: 6.542176
60 (array([22]),) False
 165880/500000: episode: 4147, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 34.431, mean reward: 0.861 [0.204, 1.000], mean action: 22.575 [12.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.274897, mean_absolute_error: 5.816869, mean_q: 6.505606
118 (array([22]),) False
 165920/500000: episode: 4148, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 35.778, mean reward: 0.894 [0.000, 1.000], mean action: 22.175 [6.000, 53.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.249601, mean_absolute_error: 5.776949, mean_q: 6.471083
22 (array([37]),) False
 165960/500000: episode: 4149, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 28.730, mean reward: 0.718 [0.002, 0.899], mean action: 29.200 [5.000, 57.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.286772, mean_absolute_error: 5.747988, mean_q: 6.439489
807 (array([22]),) False
 166000/500000: episode: 4150, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 35.264, mean reward: 0.882 [0.137, 1.000], mean action: 37.950 [5.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.239603, mean_absolute_error: 5.772675, mean_q: 6.468708
545 (array([22]),) False
 166040/500000: episode: 4151, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 35.379, mean reward: 0.884 [0.184, 1.000], mean action: 20.125 [5.000, 59.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.264875, mean_absolute_error: 5.797487, mean_q: 6.500780
490 (array([12]),) False
 166080/500000: episode: 4152, duration: 32.194s, episode steps: 40, steps per second: 1, episode reward: 28.830, mean reward: 0.721 [0.189, 1.000], mean action: 21.225 [1.000, 22.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.239575, mean_absolute_error: 5.791669, mean_q: 6.499205
107 (array([22]),) False
 166120/500000: episode: 4153, duration: 33.196s, episode steps: 40, steps per second: 1, episode reward: 37.881, mean reward: 0.947 [0.000, 1.000], mean action: 21.950 [3.000, 50.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.261185, mean_absolute_error: 5.808245, mean_q: 6.515773
518 (array([22]),) False
 166160/500000: episode: 4154, duration: 32.140s, episode steps: 40, steps per second: 1, episode reward: 38.483, mean reward: 0.962 [0.367, 1.000], mean action: 22.025 [12.000, 46.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.260026, mean_absolute_error: 5.756132, mean_q: 6.448175
377 (array([22]),) False
 166200/500000: episode: 4155, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.277133, mean_absolute_error: 5.823013, mean_q: 6.515826
22 (array([37]),) False
 166240/500000: episode: 4156, duration: 32.185s, episode steps: 40, steps per second: 1, episode reward: 30.540, mean reward: 0.764 [0.489, 0.823], mean action: 31.750 [14.000, 49.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.261270, mean_absolute_error: 5.763806, mean_q: 6.457902
474 (array([22]),) False
 166280/500000: episode: 4157, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 36.499, mean reward: 0.912 [0.280, 1.000], mean action: 28.900 [12.000, 49.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.277901, mean_absolute_error: 5.775774, mean_q: 6.474967
787 (array([3]),) False
 166320/500000: episode: 4158, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 22.028, mean reward: 0.551 [0.114, 1.000], mean action: 18.875 [12.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.294416, mean_absolute_error: 5.770673, mean_q: 6.465426
489 (array([22]),) False
 166360/500000: episode: 4159, duration: 33.039s, episode steps: 40, steps per second: 1, episode reward: 38.398, mean reward: 0.960 [0.105, 1.000], mean action: 25.575 [3.000, 49.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.252851, mean_absolute_error: 5.808579, mean_q: 6.513665
165 (array([34]),) False
 166400/500000: episode: 4160, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 29.873, mean reward: 0.747 [0.126, 1.000], mean action: 24.825 [5.000, 47.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.289139, mean_absolute_error: 5.750565, mean_q: 6.452131
647 (array([22]),) False
 166440/500000: episode: 4161, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 37.829, mean reward: 0.946 [0.370, 1.000], mean action: 24.525 [18.000, 59.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.239357, mean_absolute_error: 5.766449, mean_q: 6.475195
328 (array([12]),) False
 166480/500000: episode: 4162, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 33.708, mean reward: 0.843 [0.023, 1.000], mean action: 16.300 [2.000, 48.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.234304, mean_absolute_error: 5.856998, mean_q: 6.563973
137 (array([22]),) False
 166520/500000: episode: 4163, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 35.674, mean reward: 0.892 [0.171, 1.000], mean action: 20.325 [12.000, 59.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.276094, mean_absolute_error: 5.801341, mean_q: 6.509777
785 (array([22]),) False
 166560/500000: episode: 4164, duration: 32.214s, episode steps: 40, steps per second: 1, episode reward: 32.745, mean reward: 0.819 [0.037, 1.000], mean action: 18.575 [12.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.256801, mean_absolute_error: 5.680125, mean_q: 6.373870
40 (array([22]),) False
 166600/500000: episode: 4165, duration: 33.169s, episode steps: 40, steps per second: 1, episode reward: 34.575, mean reward: 0.864 [0.233, 1.000], mean action: 23.750 [1.000, 52.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.275218, mean_absolute_error: 5.761222, mean_q: 6.461919
266 (array([12]),) False
 166640/500000: episode: 4166, duration: 32.084s, episode steps: 40, steps per second: 1, episode reward: 27.208, mean reward: 0.680 [0.000, 0.857], mean action: 23.975 [10.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.258372, mean_absolute_error: 5.848311, mean_q: 6.551779
260 (array([22]),) False
 166680/500000: episode: 4167, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 37.078, mean reward: 0.927 [0.276, 1.000], mean action: 23.900 [19.000, 55.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.238625, mean_absolute_error: 5.754338, mean_q: 6.447768
405 (array([22]),) False
 166720/500000: episode: 4168, duration: 32.256s, episode steps: 40, steps per second: 1, episode reward: 38.347, mean reward: 0.959 [0.279, 1.000], mean action: 22.125 [16.000, 36.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.251266, mean_absolute_error: 5.774724, mean_q: 6.470117
702 (array([22]),) False
 166760/500000: episode: 4169, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 33.710, mean reward: 0.843 [0.370, 1.000], mean action: 25.400 [12.000, 44.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.258221, mean_absolute_error: 5.783910, mean_q: 6.482646
13 (array([48]),) False
 166800/500000: episode: 4170, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 35.844, mean reward: 0.896 [0.229, 1.000], mean action: 27.600 [4.000, 49.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.256508, mean_absolute_error: 5.804804, mean_q: 6.504700
265 (array([22]),) False
 166840/500000: episode: 4171, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 36.109, mean reward: 0.903 [0.354, 1.000], mean action: 20.675 [11.000, 59.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.304545, mean_absolute_error: 5.854947, mean_q: 6.558454
106 (array([22]),) False
 166880/500000: episode: 4172, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 33.995, mean reward: 0.850 [0.080, 1.000], mean action: 21.250 [5.000, 48.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.253052, mean_absolute_error: 5.803583, mean_q: 6.503900
675 (array([22]),) False
 166920/500000: episode: 4173, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 33.465, mean reward: 0.837 [0.243, 1.000], mean action: 20.600 [4.000, 48.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.239307, mean_absolute_error: 5.868955, mean_q: 6.572314
188 (array([22]),) False
 166960/500000: episode: 4174, duration: 33.041s, episode steps: 40, steps per second: 1, episode reward: 34.731, mean reward: 0.868 [0.212, 1.000], mean action: 15.825 [1.000, 44.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.282339, mean_absolute_error: 5.813961, mean_q: 6.522748
688 (array([22]),) False
 167000/500000: episode: 4175, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 36.596, mean reward: 0.915 [0.186, 1.000], mean action: 19.825 [7.000, 40.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.260630, mean_absolute_error: 5.784216, mean_q: 6.492988
107 (array([22]),) False
 167040/500000: episode: 4176, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 39.047, mean reward: 0.976 [0.152, 1.000], mean action: 21.900 [12.000, 28.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.258888, mean_absolute_error: 5.810493, mean_q: 6.518332
261 (array([44]),) False
 167080/500000: episode: 4177, duration: 31.070s, episode steps: 40, steps per second: 1, episode reward: 30.190, mean reward: 0.755 [0.542, 0.877], mean action: 24.425 [12.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.245610, mean_absolute_error: 5.879021, mean_q: 6.579629
392 (array([40]),) False
 167120/500000: episode: 4178, duration: 30.115s, episode steps: 40, steps per second: 1, episode reward: 28.599, mean reward: 0.715 [0.000, 1.000], mean action: 23.000 [2.000, 48.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.276529, mean_absolute_error: 5.786780, mean_q: 6.484601
756 (array([48]),) False
 167160/500000: episode: 4179, duration: 31.006s, episode steps: 40, steps per second: 1, episode reward: 31.599, mean reward: 0.790 [0.367, 1.000], mean action: 30.650 [21.000, 48.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.280251, mean_absolute_error: 5.894980, mean_q: 6.603522
740 (array([58]),) False
 167200/500000: episode: 4180, duration: 30.084s, episode steps: 40, steps per second: 1, episode reward: 14.705, mean reward: 0.368 [0.000, 1.000], mean action: 18.675 [1.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.251368, mean_absolute_error: 5.891428, mean_q: 6.592082
584 (array([36]),) False
 167240/500000: episode: 4181, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 13.664, mean reward: 0.342 [0.103, 0.781], mean action: 24.475 [12.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.275583, mean_absolute_error: 5.842631, mean_q: 6.542327
232 (array([22]),) False
 167280/500000: episode: 4182, duration: 31.042s, episode steps: 40, steps per second: 1, episode reward: 37.430, mean reward: 0.936 [0.073, 1.000], mean action: 24.050 [12.000, 60.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.245192, mean_absolute_error: 5.904250, mean_q: 6.614500
303 (array([22]),) False
 167320/500000: episode: 4183, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 36.897, mean reward: 0.922 [0.180, 1.000], mean action: 23.600 [7.000, 53.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.260695, mean_absolute_error: 5.786738, mean_q: 6.488695
801 (array([58]),) False
 167360/500000: episode: 4184, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 18.857, mean reward: 0.471 [0.000, 0.916], mean action: 36.650 [16.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.275987, mean_absolute_error: 5.770432, mean_q: 6.467990
666 (array([22]),) False
 167400/500000: episode: 4185, duration: 31.028s, episode steps: 40, steps per second: 1, episode reward: 36.618, mean reward: 0.915 [0.042, 1.000], mean action: 19.675 [4.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.255558, mean_absolute_error: 5.906547, mean_q: 6.610381
483 (array([48]),) False
 167440/500000: episode: 4186, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 33.708, mean reward: 0.843 [0.174, 1.000], mean action: 42.950 [3.000, 49.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.302214, mean_absolute_error: 5.819484, mean_q: 6.520686
626 (array([22]),) False
 167480/500000: episode: 4187, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 32.187, mean reward: 0.805 [0.269, 1.000], mean action: 34.150 [17.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.249445, mean_absolute_error: 5.917717, mean_q: 6.621583
724 (array([58]),) False
 167520/500000: episode: 4188, duration: 30.100s, episode steps: 40, steps per second: 1, episode reward: 17.947, mean reward: 0.449 [0.008, 0.796], mean action: 21.925 [3.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.260979, mean_absolute_error: 5.878182, mean_q: 6.581584
507 (array([44]),) False
 167560/500000: episode: 4189, duration: 31.082s, episode steps: 40, steps per second: 1, episode reward: 33.413, mean reward: 0.835 [0.050, 0.988], mean action: 19.575 [3.000, 22.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.243233, mean_absolute_error: 5.768130, mean_q: 6.478279
719 (array([22]),) False
 167600/500000: episode: 4190, duration: 30.107s, episode steps: 40, steps per second: 1, episode reward: 31.063, mean reward: 0.777 [0.029, 1.000], mean action: 19.575 [5.000, 44.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.242460, mean_absolute_error: 5.825527, mean_q: 6.540513
392 (array([40]),) False
 167640/500000: episode: 4191, duration: 31.034s, episode steps: 40, steps per second: 1, episode reward: 29.266, mean reward: 0.732 [0.269, 1.000], mean action: 23.375 [10.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.237870, mean_absolute_error: 5.797048, mean_q: 6.510129
412 (array([16]),) False
 167680/500000: episode: 4192, duration: 30.221s, episode steps: 40, steps per second: 1, episode reward: 34.759, mean reward: 0.869 [0.386, 0.925], mean action: 21.050 [2.000, 22.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.295705, mean_absolute_error: 5.881742, mean_q: 6.589676
417 (array([12]),) False
 167720/500000: episode: 4193, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 28.393, mean reward: 0.710 [0.539, 1.000], mean action: 24.025 [12.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.252570, mean_absolute_error: 5.777353, mean_q: 6.474852
855 (array([12]),) False
 167760/500000: episode: 4194, duration: 30.965s, episode steps: 40, steps per second: 1, episode reward: 32.208, mean reward: 0.805 [0.188, 1.000], mean action: 20.225 [12.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.259205, mean_absolute_error: 5.843930, mean_q: 6.549614
164 (array([22]),) False
 167800/500000: episode: 4195, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 33.791, mean reward: 0.845 [0.341, 1.000], mean action: 20.300 [6.000, 49.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.235218, mean_absolute_error: 5.815627, mean_q: 6.515080
308 (array([22]),) False
 167840/500000: episode: 4196, duration: 30.988s, episode steps: 40, steps per second: 1, episode reward: 34.027, mean reward: 0.851 [0.132, 1.000], mean action: 22.850 [2.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.286021, mean_absolute_error: 5.817368, mean_q: 6.517105
612 (array([22]),) False
 167880/500000: episode: 4197, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 32.569, mean reward: 0.814 [0.064, 1.000], mean action: 18.000 [5.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.291811, mean_absolute_error: 5.830584, mean_q: 6.528336
840 (array([12]),) False
 167920/500000: episode: 4198, duration: 31.281s, episode steps: 40, steps per second: 1, episode reward: 36.085, mean reward: 0.902 [0.234, 1.000], mean action: 14.825 [8.000, 49.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.274630, mean_absolute_error: 5.906203, mean_q: 6.604503
417 (array([12]),) False
 167960/500000: episode: 4199, duration: 31.454s, episode steps: 40, steps per second: 1, episode reward: 28.486, mean reward: 0.712 [0.649, 1.000], mean action: 23.775 [12.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.267540, mean_absolute_error: 5.923396, mean_q: 6.627808
719 (array([22]),) False
 168000/500000: episode: 4200, duration: 31.010s, episode steps: 40, steps per second: 1, episode reward: 34.261, mean reward: 0.857 [0.492, 1.000], mean action: 18.925 [5.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.234499, mean_absolute_error: 5.918130, mean_q: 6.619098
63 (array([18]),) False
 168040/500000: episode: 4201, duration: 31.317s, episode steps: 40, steps per second: 1, episode reward: 37.062, mean reward: 0.927 [0.014, 0.990], mean action: 14.025 [3.000, 50.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.275880, mean_absolute_error: 5.837765, mean_q: 6.534615
852 (array([44]),) False
 168080/500000: episode: 4202, duration: 30.872s, episode steps: 40, steps per second: 1, episode reward: 33.810, mean reward: 0.845 [0.405, 1.000], mean action: 16.400 [8.000, 53.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.231393, mean_absolute_error: 5.811091, mean_q: 6.498693
291 (array([22]),) False
 168120/500000: episode: 4203, duration: 31.419s, episode steps: 40, steps per second: 1, episode reward: 37.477, mean reward: 0.937 [0.269, 1.000], mean action: 18.400 [12.000, 53.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.247588, mean_absolute_error: 5.802385, mean_q: 6.494376
477 (array([22]),) False
 168160/500000: episode: 4204, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 34.565, mean reward: 0.864 [0.060, 1.000], mean action: 28.800 [0.000, 58.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.243606, mean_absolute_error: 5.862769, mean_q: 6.554749
64 (array([12]),) False
 168200/500000: episode: 4205, duration: 31.438s, episode steps: 40, steps per second: 1, episode reward: 37.394, mean reward: 0.935 [0.211, 1.000], mean action: 23.575 [12.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.301164, mean_absolute_error: 5.866092, mean_q: 6.557496
565 (array([12]),) False
 168240/500000: episode: 4206, duration: 31.323s, episode steps: 40, steps per second: 1, episode reward: 38.001, mean reward: 0.950 [0.465, 1.000], mean action: 19.900 [12.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.295614, mean_absolute_error: 5.801092, mean_q: 6.495076
570 (array([47]),) False
 168280/500000: episode: 4207, duration: 31.430s, episode steps: 40, steps per second: 1, episode reward: 38.501, mean reward: 0.963 [0.634, 1.000], mean action: 34.325 [12.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.251486, mean_absolute_error: 5.802122, mean_q: 6.499139
18 (array([22]),) False
 168320/500000: episode: 4208, duration: 32.714s, episode steps: 40, steps per second: 1, episode reward: 36.641, mean reward: 0.916 [0.146, 1.000], mean action: 22.200 [1.000, 43.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.251945, mean_absolute_error: 5.818043, mean_q: 6.516006
521 (array([22]),) False
 168360/500000: episode: 4209, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 37.596, mean reward: 0.940 [0.206, 1.000], mean action: 17.900 [2.000, 52.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.236401, mean_absolute_error: 5.756853, mean_q: 6.457751
569 (array([22]),) False
 168400/500000: episode: 4210, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 31.591, mean reward: 0.790 [0.330, 1.000], mean action: 26.575 [1.000, 56.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.254437, mean_absolute_error: 5.780372, mean_q: 6.485664
188 (array([22]),) False
 168440/500000: episode: 4211, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 37.500, mean reward: 0.938 [0.865, 1.000], mean action: 17.450 [12.000, 48.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.266371, mean_absolute_error: 5.766051, mean_q: 6.469478
550 (array([12]),) False
 168480/500000: episode: 4212, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 33.127, mean reward: 0.828 [0.218, 1.000], mean action: 19.875 [4.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.241632, mean_absolute_error: 5.752023, mean_q: 6.447338
213 (array([22]),) False
 168520/500000: episode: 4213, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 35.915, mean reward: 0.898 [0.115, 1.000], mean action: 22.400 [11.000, 49.000], mean observation: -0.186 [-1.000, 1.000], loss: 0.290711, mean_absolute_error: 5.789622, mean_q: 6.486149
84 (array([22]),) False
 168560/500000: episode: 4214, duration: 32.196s, episode steps: 40, steps per second: 1, episode reward: 38.985, mean reward: 0.975 [0.414, 1.000], mean action: 22.250 [14.000, 42.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.299321, mean_absolute_error: 5.838968, mean_q: 6.539829
435 (array([22]),) False
 168600/500000: episode: 4215, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 35.858, mean reward: 0.896 [0.180, 1.000], mean action: 23.525 [9.000, 53.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.252671, mean_absolute_error: 5.818942, mean_q: 6.512074
419 (array([40]),) False
 168640/500000: episode: 4216, duration: 32.101s, episode steps: 40, steps per second: 1, episode reward: 36.894, mean reward: 0.922 [0.140, 1.000], mean action: 22.550 [3.000, 55.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.232969, mean_absolute_error: 5.840844, mean_q: 6.539078
479 (array([22]),) False
 168680/500000: episode: 4217, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 32.831, mean reward: 0.821 [0.062, 1.000], mean action: 41.450 [14.000, 54.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.261963, mean_absolute_error: 5.852042, mean_q: 6.548007
413 (array([22]),) False
 168720/500000: episode: 4218, duration: 31.413s, episode steps: 40, steps per second: 1, episode reward: 37.431, mean reward: 0.936 [0.180, 1.000], mean action: 22.900 [22.000, 58.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.238091, mean_absolute_error: 5.783808, mean_q: 6.474364
766 (array([12]),) False
 168760/500000: episode: 4219, duration: 31.439s, episode steps: 40, steps per second: 1, episode reward: 36.800, mean reward: 0.920 [0.412, 1.000], mean action: 16.650 [12.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.226764, mean_absolute_error: 5.936067, mean_q: 6.641556
232 (array([22]),) False
 168800/500000: episode: 4220, duration: 31.390s, episode steps: 40, steps per second: 1, episode reward: 36.449, mean reward: 0.911 [0.000, 1.000], mean action: 22.325 [11.000, 53.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.235625, mean_absolute_error: 5.788419, mean_q: 6.480895
40 (array([22]),) False
 168840/500000: episode: 4221, duration: 31.612s, episode steps: 40, steps per second: 1, episode reward: 37.311, mean reward: 0.933 [0.077, 1.000], mean action: 22.800 [0.000, 51.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.229670, mean_absolute_error: 5.833749, mean_q: 6.518706
320 (array([22]),) False
 168880/500000: episode: 4222, duration: 31.557s, episode steps: 40, steps per second: 1, episode reward: 37.766, mean reward: 0.944 [0.297, 1.000], mean action: 21.250 [12.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.261750, mean_absolute_error: 5.879462, mean_q: 6.568294
270 (array([3]),) False
 168920/500000: episode: 4223, duration: 31.540s, episode steps: 40, steps per second: 1, episode reward: 10.320, mean reward: 0.258 [0.000, 1.000], mean action: 28.550 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.265756, mean_absolute_error: 5.815428, mean_q: 6.501962
250 (array([22]),) False
 168960/500000: episode: 4224, duration: 29.972s, episode steps: 40, steps per second: 1, episode reward: 33.264, mean reward: 0.832 [0.076, 1.000], mean action: 22.075 [3.000, 56.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.280844, mean_absolute_error: 5.865589, mean_q: 6.559688
257 (array([22]),) False
 169000/500000: episode: 4225, duration: 30.837s, episode steps: 40, steps per second: 1, episode reward: 37.968, mean reward: 0.949 [0.304, 1.000], mean action: 23.350 [14.000, 55.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.244356, mean_absolute_error: 5.828043, mean_q: 6.520741
310 (array([12]),) False
 169040/500000: episode: 4226, duration: 29.984s, episode steps: 40, steps per second: 1, episode reward: 35.604, mean reward: 0.890 [0.073, 1.000], mean action: 13.525 [1.000, 42.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.264102, mean_absolute_error: 5.827971, mean_q: 6.519488
518 (array([22]),) False
 169080/500000: episode: 4227, duration: 30.792s, episode steps: 40, steps per second: 1, episode reward: 36.530, mean reward: 0.913 [0.162, 1.000], mean action: 23.950 [8.000, 59.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.219242, mean_absolute_error: 5.840491, mean_q: 6.528729
729 (array([22]),) False
 169120/500000: episode: 4228, duration: 29.998s, episode steps: 40, steps per second: 1, episode reward: 34.323, mean reward: 0.858 [0.098, 1.000], mean action: 33.775 [9.000, 48.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.240847, mean_absolute_error: 5.816976, mean_q: 6.512568
740 (array([58]),) False
 169160/500000: episode: 4229, duration: 30.902s, episode steps: 40, steps per second: 1, episode reward: 14.394, mean reward: 0.360 [0.000, 1.000], mean action: 18.425 [2.000, 58.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.272987, mean_absolute_error: 5.808978, mean_q: 6.507353
93 (array([22]),) False
 169200/500000: episode: 4230, duration: 30.774s, episode steps: 40, steps per second: 1, episode reward: 37.112, mean reward: 0.928 [0.280, 1.000], mean action: 20.675 [1.000, 24.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.291528, mean_absolute_error: 5.762498, mean_q: 6.447563
524 (array([22]),) False
 169240/500000: episode: 4231, duration: 30.818s, episode steps: 40, steps per second: 1, episode reward: 38.130, mean reward: 0.953 [0.520, 1.000], mean action: 18.050 [12.000, 23.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.218049, mean_absolute_error: 5.781879, mean_q: 6.473697
463 (array([22]),) False
 169280/500000: episode: 4232, duration: 30.815s, episode steps: 40, steps per second: 1, episode reward: 38.242, mean reward: 0.956 [0.307, 1.000], mean action: 24.025 [19.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.246587, mean_absolute_error: 5.787903, mean_q: 6.481169
639 (array([22]),) False
 169320/500000: episode: 4233, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 36.096, mean reward: 0.902 [0.403, 1.000], mean action: 22.800 [10.000, 44.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.239712, mean_absolute_error: 5.829851, mean_q: 6.522371
324 (array([12]),) False
 169360/500000: episode: 4234, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 38.274, mean reward: 0.957 [0.048, 1.000], mean action: 21.625 [12.000, 27.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.230272, mean_absolute_error: 5.807039, mean_q: 6.507181
328 (array([12]),) False
 169400/500000: episode: 4235, duration: 30.874s, episode steps: 40, steps per second: 1, episode reward: 35.642, mean reward: 0.891 [0.422, 1.000], mean action: 16.175 [12.000, 49.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.243376, mean_absolute_error: 5.818240, mean_q: 6.510396
470 (array([22]),) False
 169440/500000: episode: 4236, duration: 30.729s, episode steps: 40, steps per second: 1, episode reward: 37.510, mean reward: 0.938 [0.330, 1.000], mean action: 23.925 [22.000, 43.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.220975, mean_absolute_error: 5.742557, mean_q: 6.429221
370 (array([58]),) False
 169480/500000: episode: 4237, duration: 30.819s, episode steps: 40, steps per second: 1, episode reward: 21.421, mean reward: 0.536 [0.000, 1.000], mean action: 25.500 [5.000, 60.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.243186, mean_absolute_error: 5.835572, mean_q: 6.525482
431 (array([22]),) False
 169520/500000: episode: 4238, duration: 29.944s, episode steps: 40, steps per second: 1, episode reward: 38.287, mean reward: 0.957 [0.083, 1.000], mean action: 23.225 [22.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.272879, mean_absolute_error: 5.706773, mean_q: 6.390479
688 (array([22]),) False
 169560/500000: episode: 4239, duration: 30.825s, episode steps: 40, steps per second: 1, episode reward: 35.363, mean reward: 0.884 [0.098, 1.000], mean action: 22.200 [12.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.271971, mean_absolute_error: 5.777375, mean_q: 6.458590
593 (array([37]),) False
 169600/500000: episode: 4240, duration: 30.861s, episode steps: 40, steps per second: 1, episode reward: 36.617, mean reward: 0.915 [0.103, 1.000], mean action: 19.200 [5.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.241162, mean_absolute_error: 5.819213, mean_q: 6.495949
567 (array([22]),) False
 169640/500000: episode: 4241, duration: 30.790s, episode steps: 40, steps per second: 1, episode reward: 24.846, mean reward: 0.621 [0.181, 1.000], mean action: 30.925 [5.000, 48.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.242920, mean_absolute_error: 5.761724, mean_q: 6.439479
204 (array([22]),) False
 169680/500000: episode: 4242, duration: 29.904s, episode steps: 40, steps per second: 1, episode reward: 28.660, mean reward: 0.716 [0.107, 0.976], mean action: 16.325 [12.000, 51.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.251417, mean_absolute_error: 5.830234, mean_q: 6.505881
385 (array([30]),) False
 169720/500000: episode: 4243, duration: 30.795s, episode steps: 40, steps per second: 1, episode reward: 38.146, mean reward: 0.954 [0.318, 1.000], mean action: 23.550 [22.000, 59.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.251017, mean_absolute_error: 5.760378, mean_q: 6.434054
459 (array([22]),) False
 169760/500000: episode: 4244, duration: 30.867s, episode steps: 40, steps per second: 1, episode reward: 36.618, mean reward: 0.915 [0.160, 1.000], mean action: 21.225 [0.000, 38.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.250836, mean_absolute_error: 5.813971, mean_q: 6.501269
122 (array([12]),) False
 169800/500000: episode: 4245, duration: 30.803s, episode steps: 40, steps per second: 1, episode reward: 34.031, mean reward: 0.851 [0.595, 1.000], mean action: 18.575 [12.000, 25.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.247376, mean_absolute_error: 5.761015, mean_q: 6.441644
84 (array([22]),) False
 169840/500000: episode: 4246, duration: 29.952s, episode steps: 40, steps per second: 1, episode reward: 36.781, mean reward: 0.920 [0.099, 1.000], mean action: 22.675 [4.000, 51.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.246140, mean_absolute_error: 5.734517, mean_q: 6.413275
185 (array([22]),) False
 169880/500000: episode: 4247, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 34.037, mean reward: 0.851 [0.177, 1.000], mean action: 20.950 [10.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.256542, mean_absolute_error: 5.803767, mean_q: 6.488753
6 (array([58]),) False
 169920/500000: episode: 4248, duration: 30.827s, episode steps: 40, steps per second: 1, episode reward: 33.507, mean reward: 0.838 [0.087, 1.000], mean action: 26.200 [19.000, 49.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.289663, mean_absolute_error: 5.814208, mean_q: 6.505580
325 (array([22]),) False
 169960/500000: episode: 4249, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 38.735, mean reward: 0.968 [0.222, 1.000], mean action: 21.950 [18.000, 27.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.274443, mean_absolute_error: 5.783891, mean_q: 6.467059
542 (array([44]),) False
 170000/500000: episode: 4250, duration: 29.964s, episode steps: 40, steps per second: 1, episode reward: 32.028, mean reward: 0.801 [0.056, 0.917], mean action: 19.100 [2.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.234233, mean_absolute_error: 5.818417, mean_q: 6.512573
242 (array([22]),) False
 170040/500000: episode: 4251, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 37.623, mean reward: 0.941 [0.086, 1.000], mean action: 24.225 [2.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.243389, mean_absolute_error: 5.719018, mean_q: 6.414950
789 (array([22]),) False
 170080/500000: episode: 4252, duration: 30.782s, episode steps: 40, steps per second: 1, episode reward: 38.113, mean reward: 0.953 [0.420, 1.000], mean action: 37.775 [7.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.221891, mean_absolute_error: 5.749587, mean_q: 6.437547
376 (array([22]),) False
 170120/500000: episode: 4253, duration: 30.859s, episode steps: 40, steps per second: 1, episode reward: 37.767, mean reward: 0.944 [0.374, 1.000], mean action: 24.950 [21.000, 52.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.288649, mean_absolute_error: 5.784332, mean_q: 6.473347
441 (array([22]),) False
 170160/500000: episode: 4254, duration: 29.969s, episode steps: 40, steps per second: 1, episode reward: 35.561, mean reward: 0.889 [0.396, 1.000], mean action: 23.025 [22.000, 56.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.279361, mean_absolute_error: 5.697153, mean_q: 6.384804
768 (array([22]),) False
 170200/500000: episode: 4255, duration: 30.883s, episode steps: 40, steps per second: 1, episode reward: 33.554, mean reward: 0.839 [0.247, 1.000], mean action: 23.100 [12.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.262238, mean_absolute_error: 5.827801, mean_q: 6.526541
558 (array([40]),) False
 170240/500000: episode: 4256, duration: 30.724s, episode steps: 40, steps per second: 1, episode reward: 31.833, mean reward: 0.796 [0.372, 1.000], mean action: 21.800 [12.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.254860, mean_absolute_error: 5.709638, mean_q: 6.395779
352 (array([22]),) False
 170280/500000: episode: 4257, duration: 30.924s, episode steps: 40, steps per second: 1, episode reward: 32.898, mean reward: 0.822 [0.100, 1.000], mean action: 33.200 [2.000, 59.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.239916, mean_absolute_error: 5.772959, mean_q: 6.459412
238 (array([22]),) False
 170320/500000: episode: 4258, duration: 29.943s, episode steps: 40, steps per second: 1, episode reward: 37.358, mean reward: 0.934 [0.095, 1.000], mean action: 21.875 [3.000, 42.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.258858, mean_absolute_error: 5.801465, mean_q: 6.493066
599 (array([48]),) False
 170360/500000: episode: 4259, duration: 30.865s, episode steps: 40, steps per second: 1, episode reward: 30.179, mean reward: 0.754 [0.054, 1.000], mean action: 21.450 [8.000, 58.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.236167, mean_absolute_error: 5.816691, mean_q: 6.511470
705 (array([22]),) False
 170400/500000: episode: 4260, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 19.653, mean reward: 0.491 [0.248, 0.988], mean action: 9.875 [3.000, 50.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.265901, mean_absolute_error: 5.857393, mean_q: 6.552467
196 (array([22]),) False
 170440/500000: episode: 4261, duration: 30.843s, episode steps: 40, steps per second: 1, episode reward: 35.690, mean reward: 0.892 [0.162, 1.000], mean action: 19.525 [9.000, 57.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.256254, mean_absolute_error: 5.822233, mean_q: 6.521669
329 (array([12]),) False
 170480/500000: episode: 4262, duration: 30.796s, episode steps: 40, steps per second: 1, episode reward: 32.465, mean reward: 0.812 [0.083, 1.000], mean action: 18.100 [9.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.264199, mean_absolute_error: 5.822643, mean_q: 6.516738
684 (array([22]),) False
 170520/500000: episode: 4263, duration: 30.818s, episode steps: 40, steps per second: 1, episode reward: 34.094, mean reward: 0.852 [0.144, 1.000], mean action: 24.000 [9.000, 60.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.288045, mean_absolute_error: 5.818442, mean_q: 6.513282
593 (array([37]),) False
 170560/500000: episode: 4264, duration: 30.739s, episode steps: 40, steps per second: 1, episode reward: 36.906, mean reward: 0.923 [0.119, 1.000], mean action: 20.725 [12.000, 53.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.283157, mean_absolute_error: 5.820846, mean_q: 6.526364
301 (array([22]),) False
 170600/500000: episode: 4265, duration: 30.853s, episode steps: 40, steps per second: 1, episode reward: 35.218, mean reward: 0.880 [0.078, 1.000], mean action: 25.175 [3.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.257687, mean_absolute_error: 5.794903, mean_q: 6.495841
692 (array([22]),) False
 170640/500000: episode: 4266, duration: 29.926s, episode steps: 40, steps per second: 1, episode reward: 37.847, mean reward: 0.946 [0.293, 1.000], mean action: 16.325 [12.000, 35.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.269519, mean_absolute_error: 5.798041, mean_q: 6.492665
779 (array([12]),) False
 170680/500000: episode: 4267, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 36.915, mean reward: 0.923 [0.131, 1.000], mean action: 15.900 [10.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.260531, mean_absolute_error: 5.895729, mean_q: 6.588474
150 (array([22]),) False
 170720/500000: episode: 4268, duration: 29.990s, episode steps: 40, steps per second: 1, episode reward: 34.816, mean reward: 0.870 [0.219, 1.000], mean action: 17.050 [12.000, 54.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.257606, mean_absolute_error: 5.803877, mean_q: 6.500901
701 (array([48]),) False
 170760/500000: episode: 4269, duration: 30.824s, episode steps: 40, steps per second: 1, episode reward: 35.923, mean reward: 0.898 [0.003, 1.000], mean action: 22.175 [3.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.281403, mean_absolute_error: 5.749007, mean_q: 6.452740
334 (array([48]),) False
 170800/500000: episode: 4270, duration: 29.901s, episode steps: 40, steps per second: 1, episode reward: 36.634, mean reward: 0.916 [0.175, 0.988], mean action: 23.225 [0.000, 60.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.269644, mean_absolute_error: 5.832348, mean_q: 6.538920
693 (array([22]),) False
 170840/500000: episode: 4271, duration: 30.779s, episode steps: 40, steps per second: 1, episode reward: 37.031, mean reward: 0.926 [0.086, 1.000], mean action: 18.975 [9.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.255966, mean_absolute_error: 5.854558, mean_q: 6.569473
619 (array([3]),) False
 170880/500000: episode: 4272, duration: 30.761s, episode steps: 40, steps per second: 1, episode reward: 35.601, mean reward: 0.890 [0.080, 1.000], mean action: 8.350 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.282707, mean_absolute_error: 5.826096, mean_q: 6.530995
715 (array([22]),) False
 170920/500000: episode: 4273, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 35.943, mean reward: 0.899 [0.050, 1.000], mean action: 20.900 [3.000, 41.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.270534, mean_absolute_error: 5.865541, mean_q: 6.567107
47 (array([44]),) False
 170960/500000: episode: 4274, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 33.719, mean reward: 0.843 [0.096, 1.000], mean action: 23.550 [17.000, 44.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.305143, mean_absolute_error: 5.879553, mean_q: 6.579133
26 (array([22]),) False
 171000/500000: episode: 4275, duration: 30.791s, episode steps: 40, steps per second: 1, episode reward: 31.030, mean reward: 0.776 [0.093, 1.000], mean action: 32.475 [0.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.260466, mean_absolute_error: 5.818933, mean_q: 6.510441
660 (array([2]),) False
 171040/500000: episode: 4276, duration: 30.793s, episode steps: 40, steps per second: 1, episode reward: 17.221, mean reward: 0.431 [0.000, 1.000], mean action: 32.525 [12.000, 56.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.280365, mean_absolute_error: 5.904352, mean_q: 6.602404
735 (array([22]),) False
 171080/500000: episode: 4277, duration: 30.852s, episode steps: 40, steps per second: 1, episode reward: 37.427, mean reward: 0.936 [0.455, 1.000], mean action: 23.800 [12.000, 49.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.264895, mean_absolute_error: 5.839643, mean_q: 6.537495
369 (array([48]),) False
 171120/500000: episode: 4278, duration: 30.017s, episode steps: 40, steps per second: 1, episode reward: 35.970, mean reward: 0.899 [0.033, 0.973], mean action: 20.050 [4.000, 42.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.257498, mean_absolute_error: 5.875704, mean_q: 6.579233
241 (array([22]),) False
 171160/500000: episode: 4279, duration: 30.893s, episode steps: 40, steps per second: 1, episode reward: 37.964, mean reward: 0.949 [0.290, 1.000], mean action: 24.475 [22.000, 58.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.271258, mean_absolute_error: 5.765273, mean_q: 6.461413
218 (array([22]),) False
 171200/500000: episode: 4280, duration: 29.942s, episode steps: 40, steps per second: 1, episode reward: 36.309, mean reward: 0.908 [0.020, 1.000], mean action: 22.200 [3.000, 33.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.237842, mean_absolute_error: 5.918641, mean_q: 6.625783
645 (array([48]),) False
 171240/500000: episode: 4281, duration: 30.836s, episode steps: 40, steps per second: 1, episode reward: 34.322, mean reward: 0.858 [0.135, 1.000], mean action: 23.175 [8.000, 53.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.265021, mean_absolute_error: 5.839748, mean_q: 6.538638
650 (array([22]),) False
 171280/500000: episode: 4282, duration: 29.935s, episode steps: 40, steps per second: 1, episode reward: 36.227, mean reward: 0.906 [0.212, 1.000], mean action: 22.975 [4.000, 54.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.306814, mean_absolute_error: 5.793954, mean_q: 6.492887
799 (array([36]),) False
 171320/500000: episode: 4283, duration: 31.205s, episode steps: 40, steps per second: 1, episode reward: 24.206, mean reward: 0.605 [0.192, 0.991], mean action: 27.925 [11.000, 56.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.250905, mean_absolute_error: 5.806451, mean_q: 6.509716
466 (array([22]),) False
 171360/500000: episode: 4284, duration: 31.071s, episode steps: 40, steps per second: 1, episode reward: 36.159, mean reward: 0.904 [0.130, 1.000], mean action: 21.750 [1.000, 42.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.270049, mean_absolute_error: 5.866309, mean_q: 6.567946
193 (array([36]),) False
 171400/500000: episode: 4285, duration: 31.119s, episode steps: 40, steps per second: 1, episode reward: 33.621, mean reward: 0.841 [0.301, 1.000], mean action: 26.375 [0.000, 36.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.243425, mean_absolute_error: 5.878773, mean_q: 6.579102
409 (array([22]),) False
 171440/500000: episode: 4286, duration: 31.398s, episode steps: 40, steps per second: 1, episode reward: 37.794, mean reward: 0.945 [0.000, 1.000], mean action: 22.925 [3.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.264363, mean_absolute_error: 5.906348, mean_q: 6.608814
477 (array([22]),) False
 171480/500000: episode: 4287, duration: 31.398s, episode steps: 40, steps per second: 1, episode reward: 38.429, mean reward: 0.961 [0.159, 1.000], mean action: 25.150 [5.000, 59.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.248749, mean_absolute_error: 5.900440, mean_q: 6.601126
690 (array([22]),) False
 171520/500000: episode: 4288, duration: 31.392s, episode steps: 40, steps per second: 1, episode reward: 35.445, mean reward: 0.886 [0.136, 1.000], mean action: 20.175 [7.000, 45.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.284195, mean_absolute_error: 5.909380, mean_q: 6.610153
510 (array([22]),) False
 171560/500000: episode: 4289, duration: 31.364s, episode steps: 40, steps per second: 1, episode reward: 37.463, mean reward: 0.937 [0.260, 1.000], mean action: 18.550 [12.000, 32.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.257145, mean_absolute_error: 5.980657, mean_q: 6.687228
324 (array([12]),) False
 171600/500000: episode: 4290, duration: 31.416s, episode steps: 40, steps per second: 1, episode reward: 36.747, mean reward: 0.919 [0.319, 1.000], mean action: 20.825 [12.000, 34.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.276463, mean_absolute_error: 5.934577, mean_q: 6.641860
414 (array([48]),) False
 171640/500000: episode: 4291, duration: 31.439s, episode steps: 40, steps per second: 1, episode reward: 30.002, mean reward: 0.750 [0.052, 0.843], mean action: 22.300 [10.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.256406, mean_absolute_error: 5.890930, mean_q: 6.594429
513 (array([12]),) False
 171680/500000: episode: 4292, duration: 31.412s, episode steps: 40, steps per second: 1, episode reward: 37.917, mean reward: 0.948 [0.140, 1.000], mean action: 14.250 [2.000, 32.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.244496, mean_absolute_error: 5.919296, mean_q: 6.627264
843 (array([3]),) False
 171720/500000: episode: 4293, duration: 31.364s, episode steps: 40, steps per second: 1, episode reward: 5.537, mean reward: 0.138 [0.000, 0.471], mean action: 21.775 [12.000, 53.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.253578, mean_absolute_error: 5.911125, mean_q: 6.621423
17 (array([22]),) False
 171760/500000: episode: 4294, duration: 30.911s, episode steps: 40, steps per second: 1, episode reward: 33.621, mean reward: 0.841 [0.285, 1.000], mean action: 24.175 [21.000, 54.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.253251, mean_absolute_error: 5.906045, mean_q: 6.617366
173 (array([3]),) False
 171800/500000: episode: 4295, duration: 31.280s, episode steps: 40, steps per second: 1, episode reward: 23.102, mean reward: 0.578 [0.037, 1.000], mean action: 11.700 [3.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.316186, mean_absolute_error: 5.882300, mean_q: 6.595061
842 (array([22]),) False
 171840/500000: episode: 4296, duration: 31.328s, episode steps: 40, steps per second: 1, episode reward: 32.693, mean reward: 0.817 [0.227, 1.000], mean action: 19.550 [12.000, 52.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.287297, mean_absolute_error: 5.921533, mean_q: 6.638345
190 (array([3]),) False
 171880/500000: episode: 4297, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 25.448, mean reward: 0.636 [0.194, 1.000], mean action: 23.425 [2.000, 58.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.295815, mean_absolute_error: 5.844671, mean_q: 6.551179
257 (array([22]),) False
 171920/500000: episode: 4298, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 38.359, mean reward: 0.959 [0.081, 1.000], mean action: 22.250 [22.000, 28.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.275718, mean_absolute_error: 5.870055, mean_q: 6.581737
300 (array([22]),) False
 171960/500000: episode: 4299, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 35.417, mean reward: 0.885 [0.021, 1.000], mean action: 25.600 [6.000, 41.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.281140, mean_absolute_error: 5.863545, mean_q: 6.567419
435 (array([22]),) False
 172000/500000: episode: 4300, duration: 33.170s, episode steps: 40, steps per second: 1, episode reward: 36.961, mean reward: 0.924 [0.109, 1.000], mean action: 24.500 [14.000, 56.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.272139, mean_absolute_error: 5.858480, mean_q: 6.559539
413 (array([22]),) False
 172040/500000: episode: 4301, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 37.154, mean reward: 0.929 [0.031, 1.000], mean action: 21.550 [3.000, 23.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.314880, mean_absolute_error: 5.944565, mean_q: 6.640576
546 (array([22]),) False
 172080/500000: episode: 4302, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 36.441, mean reward: 0.911 [0.113, 1.000], mean action: 13.975 [9.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.255803, mean_absolute_error: 5.882656, mean_q: 6.580127
304 (array([22]),) False
 172120/500000: episode: 4303, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 34.113, mean reward: 0.853 [0.000, 1.000], mean action: 23.675 [7.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.292822, mean_absolute_error: 5.814718, mean_q: 6.515381
573 (array([22]),) False
 172160/500000: episode: 4304, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 28.765, mean reward: 0.719 [0.069, 0.966], mean action: 28.325 [7.000, 50.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.255653, mean_absolute_error: 5.844681, mean_q: 6.539012
446 (array([22]),) False
 172200/500000: episode: 4305, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 33.637, mean reward: 0.841 [0.052, 1.000], mean action: 21.875 [4.000, 37.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.241869, mean_absolute_error: 5.851673, mean_q: 6.552678
12 (array([22]),) False
 172240/500000: episode: 4306, duration: 32.182s, episode steps: 40, steps per second: 1, episode reward: 36.909, mean reward: 0.923 [0.215, 1.000], mean action: 28.625 [8.000, 49.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.295817, mean_absolute_error: 5.835203, mean_q: 6.534503
264 (array([12]),) False
 172280/500000: episode: 4307, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 36.108, mean reward: 0.903 [0.179, 1.000], mean action: 21.900 [12.000, 52.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.300665, mean_absolute_error: 5.879596, mean_q: 6.581683
665 (array([12]),) False
 172320/500000: episode: 4308, duration: 32.180s, episode steps: 40, steps per second: 1, episode reward: 34.271, mean reward: 0.857 [0.199, 1.000], mean action: 16.850 [2.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.254683, mean_absolute_error: 5.775874, mean_q: 6.474845
579 (array([58]),) False
 172360/500000: episode: 4309, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 20.487, mean reward: 0.512 [0.469, 0.758], mean action: 27.775 [1.000, 54.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.269286, mean_absolute_error: 5.850155, mean_q: 6.550465
689 (array([12]),) False
 172400/500000: episode: 4310, duration: 32.256s, episode steps: 40, steps per second: 1, episode reward: 38.047, mean reward: 0.951 [0.238, 1.000], mean action: 13.600 [2.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.242138, mean_absolute_error: 5.822026, mean_q: 6.510602
366 (array([22]),) False
 172440/500000: episode: 4311, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 35.381, mean reward: 0.885 [0.425, 1.000], mean action: 18.825 [12.000, 53.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.311229, mean_absolute_error: 5.855776, mean_q: 6.549814
610 (array([48]),) False
 172480/500000: episode: 4312, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 37.702, mean reward: 0.943 [0.138, 1.000], mean action: 23.875 [12.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.249462, mean_absolute_error: 5.840950, mean_q: 6.538838
728 (array([12]),) False
 172520/500000: episode: 4313, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 32.022, mean reward: 0.801 [0.330, 1.000], mean action: 18.500 [12.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.257117, mean_absolute_error: 5.883323, mean_q: 6.581717
274 (array([12]),) False
 172560/500000: episode: 4314, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 32.701, mean reward: 0.818 [0.104, 1.000], mean action: 22.025 [9.000, 56.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.267819, mean_absolute_error: 5.826086, mean_q: 6.518254
391 (array([22]),) False
 172600/500000: episode: 4315, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 38.448, mean reward: 0.961 [0.250, 1.000], mean action: 22.400 [18.000, 34.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.246835, mean_absolute_error: 5.823045, mean_q: 6.527246
385 (array([30]),) False
 172640/500000: episode: 4316, duration: 33.105s, episode steps: 40, steps per second: 1, episode reward: 37.150, mean reward: 0.929 [0.252, 1.000], mean action: 23.500 [12.000, 54.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.265619, mean_absolute_error: 5.936553, mean_q: 6.642044
642 (array([22]),) False
 172680/500000: episode: 4317, duration: 33.060s, episode steps: 40, steps per second: 1, episode reward: 26.784, mean reward: 0.670 [0.068, 1.000], mean action: 36.300 [18.000, 49.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.263770, mean_absolute_error: 5.802952, mean_q: 6.498312
269 (array([36]),) False
 172720/500000: episode: 4318, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 24.767, mean reward: 0.619 [0.113, 0.867], mean action: 21.750 [12.000, 49.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.243916, mean_absolute_error: 5.771113, mean_q: 6.461442
442 (array([22]),) False
 172760/500000: episode: 4319, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 37.633, mean reward: 0.941 [0.487, 1.000], mean action: 23.375 [18.000, 37.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.254810, mean_absolute_error: 5.893838, mean_q: 6.594994
244 (array([14]),) False
 172800/500000: episode: 4320, duration: 32.163s, episode steps: 40, steps per second: 1, episode reward: 32.018, mean reward: 0.800 [0.292, 1.000], mean action: 25.725 [3.000, 60.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.278726, mean_absolute_error: 5.901564, mean_q: 6.603364
568 (array([22]),) False
 172840/500000: episode: 4321, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 36.697, mean reward: 0.917 [0.106, 1.000], mean action: 30.100 [5.000, 49.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.255289, mean_absolute_error: 5.882579, mean_q: 6.588387
497 (array([33]),) False
 172880/500000: episode: 4322, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 19.050, mean reward: 0.476 [0.229, 0.602], mean action: 34.000 [5.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.263366, mean_absolute_error: 5.888739, mean_q: 6.593417
156 (array([22]),) False
 172920/500000: episode: 4323, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 33.422, mean reward: 0.836 [0.000, 1.000], mean action: 22.375 [12.000, 57.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.281102, mean_absolute_error: 5.862395, mean_q: 6.557766
329 (array([12]),) False
 172960/500000: episode: 4324, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 35.108, mean reward: 0.878 [0.063, 1.000], mean action: 14.425 [0.000, 38.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.268443, mean_absolute_error: 5.911460, mean_q: 6.611835
235 (array([14]),) False
 173000/500000: episode: 4325, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 35.997, mean reward: 0.900 [0.273, 1.000], mean action: 22.850 [22.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.251242, mean_absolute_error: 5.913213, mean_q: 6.614865
19 (array([12]),) False
 173040/500000: episode: 4326, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 37.633, mean reward: 0.941 [0.275, 1.000], mean action: 22.600 [10.000, 40.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.284465, mean_absolute_error: 5.850681, mean_q: 6.549151
561 (array([22]),) False
 173080/500000: episode: 4327, duration: 33.103s, episode steps: 40, steps per second: 1, episode reward: 28.934, mean reward: 0.723 [0.208, 1.000], mean action: 23.300 [12.000, 56.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.282857, mean_absolute_error: 5.870676, mean_q: 6.573873
781 (array([8]),) False
 173120/500000: episode: 4328, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 28.952, mean reward: 0.724 [0.288, 1.000], mean action: 20.725 [12.000, 47.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.278445, mean_absolute_error: 5.909521, mean_q: 6.617282
636 (array([12]),) False
 173160/500000: episode: 4329, duration: 33.119s, episode steps: 40, steps per second: 1, episode reward: 35.386, mean reward: 0.885 [0.000, 1.000], mean action: 23.300 [12.000, 53.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.271029, mean_absolute_error: 5.819323, mean_q: 6.523329
521 (array([22]),) False
 173200/500000: episode: 4330, duration: 32.238s, episode steps: 40, steps per second: 1, episode reward: 38.196, mean reward: 0.955 [0.190, 1.000], mean action: 18.300 [5.000, 30.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.274480, mean_absolute_error: 5.895433, mean_q: 6.607306
619 (array([3]),) False
 173240/500000: episode: 4331, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 36.260, mean reward: 0.907 [0.044, 1.000], mean action: 8.675 [3.000, 60.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.292959, mean_absolute_error: 5.847849, mean_q: 6.552857
247 (array([14]),) False
 173280/500000: episode: 4332, duration: 31.162s, episode steps: 40, steps per second: 1, episode reward: 33.382, mean reward: 0.835 [0.205, 1.000], mean action: 20.350 [0.000, 56.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.277758, mean_absolute_error: 5.833344, mean_q: 6.537418
507 (array([44]),) False
 173320/500000: episode: 4333, duration: 31.348s, episode steps: 40, steps per second: 1, episode reward: 35.424, mean reward: 0.886 [0.737, 0.988], mean action: 23.300 [22.000, 50.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.276253, mean_absolute_error: 5.853002, mean_q: 6.552820
173 (array([3]),) False
 173360/500000: episode: 4334, duration: 30.536s, episode steps: 40, steps per second: 1, episode reward: 30.836, mean reward: 0.771 [0.037, 1.000], mean action: 8.200 [1.000, 55.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.266987, mean_absolute_error: 5.861587, mean_q: 6.558827
641 (array([22]),) False
 173400/500000: episode: 4335, duration: 31.367s, episode steps: 40, steps per second: 1, episode reward: 37.731, mean reward: 0.943 [0.253, 1.000], mean action: 21.800 [12.000, 42.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.286455, mean_absolute_error: 5.816680, mean_q: 6.510788
556 (array([48]),) False
 173440/500000: episode: 4336, duration: 31.383s, episode steps: 40, steps per second: 1, episode reward: 23.198, mean reward: 0.580 [0.138, 1.000], mean action: 16.125 [12.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.265548, mean_absolute_error: 5.855631, mean_q: 6.552496
775 (array([58]),) False
 173480/500000: episode: 4337, duration: 31.509s, episode steps: 40, steps per second: 1, episode reward: 6.958, mean reward: 0.174 [0.000, 0.412], mean action: 21.725 [12.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.244447, mean_absolute_error: 5.803659, mean_q: 6.496012
482 (array([22]),) False
 173520/500000: episode: 4338, duration: 31.388s, episode steps: 40, steps per second: 1, episode reward: 30.766, mean reward: 0.769 [0.276, 1.000], mean action: 42.850 [13.000, 54.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.227763, mean_absolute_error: 5.823089, mean_q: 6.516370
172 (array([12]),) False
 173560/500000: episode: 4339, duration: 31.456s, episode steps: 40, steps per second: 1, episode reward: 37.876, mean reward: 0.947 [0.565, 1.000], mean action: 13.075 [12.000, 22.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.298040, mean_absolute_error: 5.828815, mean_q: 6.523774
770 (array([22]),) False
 173600/500000: episode: 4340, duration: 31.335s, episode steps: 40, steps per second: 1, episode reward: 34.373, mean reward: 0.859 [0.144, 1.000], mean action: 16.975 [1.000, 49.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.253267, mean_absolute_error: 5.814633, mean_q: 6.511491
163 (array([44]),) False
 173640/500000: episode: 4341, duration: 31.389s, episode steps: 40, steps per second: 1, episode reward: 34.730, mean reward: 0.868 [0.019, 1.000], mean action: 20.400 [0.000, 45.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.251135, mean_absolute_error: 5.912267, mean_q: 6.609860
737 (array([15]),) False
 173680/500000: episode: 4342, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 25.901, mean reward: 0.648 [0.194, 0.842], mean action: 15.825 [12.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.247455, mean_absolute_error: 5.862171, mean_q: 6.560071
110 (array([22]),) False
 173720/500000: episode: 4343, duration: 31.364s, episode steps: 40, steps per second: 1, episode reward: 35.463, mean reward: 0.887 [0.535, 1.000], mean action: 23.525 [22.000, 53.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.274790, mean_absolute_error: 5.826650, mean_q: 6.533333
122 (array([12]),) False
 173760/500000: episode: 4344, duration: 30.951s, episode steps: 40, steps per second: 1, episode reward: 32.242, mean reward: 0.806 [0.376, 1.000], mean action: 20.400 [1.000, 52.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.255639, mean_absolute_error: 5.888553, mean_q: 6.597630
590 (array([22]),) False
 173800/500000: episode: 4345, duration: 31.701s, episode steps: 40, steps per second: 1, episode reward: 35.748, mean reward: 0.894 [0.133, 1.000], mean action: 19.900 [12.000, 57.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.267025, mean_absolute_error: 5.913222, mean_q: 6.629141
746 (array([37]),) False
 173840/500000: episode: 4346, duration: 32.197s, episode steps: 40, steps per second: 1, episode reward: 33.087, mean reward: 0.827 [0.144, 1.000], mean action: 20.625 [4.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.264813, mean_absolute_error: 5.791526, mean_q: 6.489163
425 (array([22]),) False
 173880/500000: episode: 4347, duration: 33.172s, episode steps: 40, steps per second: 1, episode reward: 36.093, mean reward: 0.902 [0.026, 1.000], mean action: 23.575 [11.000, 52.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.261812, mean_absolute_error: 5.943368, mean_q: 6.645760
843 (array([3]),) False
 173920/500000: episode: 4348, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 12.337, mean reward: 0.308 [0.000, 1.000], mean action: 18.350 [2.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.255402, mean_absolute_error: 5.888172, mean_q: 6.588785
267 (array([22]),) False
 173960/500000: episode: 4349, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 35.221, mean reward: 0.881 [0.108, 1.000], mean action: 21.675 [8.000, 43.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.245911, mean_absolute_error: 5.857775, mean_q: 6.555956
619 (array([3]),) False
 174000/500000: episode: 4350, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 35.737, mean reward: 0.893 [0.028, 1.000], mean action: 8.775 [0.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.231761, mean_absolute_error: 5.804006, mean_q: 6.500829
368 (array([22]),) False
 174040/500000: episode: 4351, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 35.798, mean reward: 0.895 [0.284, 1.000], mean action: 18.900 [5.000, 52.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.270115, mean_absolute_error: 5.860480, mean_q: 6.563497
781 (array([8]),) False
 174080/500000: episode: 4352, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 24.508, mean reward: 0.613 [0.224, 1.000], mean action: 17.925 [12.000, 51.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.286002, mean_absolute_error: 5.838271, mean_q: 6.540194
586 (array([12]),) False
 174120/500000: episode: 4353, duration: 31.642s, episode steps: 40, steps per second: 1, episode reward: 37.866, mean reward: 0.947 [0.677, 1.000], mean action: 16.000 [12.000, 22.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.261472, mean_absolute_error: 5.871087, mean_q: 6.569955
144 (array([22]),) False
 174160/500000: episode: 4354, duration: 30.197s, episode steps: 40, steps per second: 1, episode reward: 32.022, mean reward: 0.801 [0.197, 1.000], mean action: 21.925 [1.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.267273, mean_absolute_error: 5.788965, mean_q: 6.494403
208 (array([22]),) False
 174200/500000: episode: 4355, duration: 31.065s, episode steps: 40, steps per second: 1, episode reward: 34.774, mean reward: 0.869 [0.069, 1.000], mean action: 14.750 [0.000, 59.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.269852, mean_absolute_error: 5.898428, mean_q: 6.597978
26 (array([22]),) False
 174240/500000: episode: 4356, duration: 30.642s, episode steps: 40, steps per second: 1, episode reward: 36.356, mean reward: 0.909 [0.137, 1.000], mean action: 29.225 [13.000, 59.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.256444, mean_absolute_error: 5.790408, mean_q: 6.485987
226 (array([22]),) False
 174280/500000: episode: 4357, duration: 32.208s, episode steps: 40, steps per second: 1, episode reward: 35.733, mean reward: 0.893 [0.200, 1.000], mean action: 20.550 [1.000, 56.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.290285, mean_absolute_error: 5.778709, mean_q: 6.477810
702 (array([22]),) False
 174320/500000: episode: 4358, duration: 32.227s, episode steps: 40, steps per second: 1, episode reward: 35.552, mean reward: 0.889 [0.229, 1.000], mean action: 23.650 [12.000, 52.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.294416, mean_absolute_error: 5.916527, mean_q: 6.624556
723 (array([48]),) False
 174360/500000: episode: 4359, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 34.457, mean reward: 0.861 [0.106, 1.000], mean action: 17.500 [2.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.286411, mean_absolute_error: 5.832288, mean_q: 6.533089
856 (array([48]),) False
 174400/500000: episode: 4360, duration: 33.008s, episode steps: 40, steps per second: 1, episode reward: 35.421, mean reward: 0.886 [0.067, 0.973], mean action: 15.775 [12.000, 39.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.287700, mean_absolute_error: 5.878600, mean_q: 6.575799
128 (array([22]),) False
 174440/500000: episode: 4361, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 37.930, mean reward: 0.948 [0.392, 1.000], mean action: 23.225 [16.000, 49.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.288595, mean_absolute_error: 5.902667, mean_q: 6.605396
673 (array([3]),) False
 174480/500000: episode: 4362, duration: 32.865s, episode steps: 40, steps per second: 1, episode reward: 24.987, mean reward: 0.625 [0.215, 1.000], mean action: 30.500 [1.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.262958, mean_absolute_error: 5.829371, mean_q: 6.533455
672 (array([44]),) False
 174520/500000: episode: 4363, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 30.577, mean reward: 0.764 [0.399, 0.982], mean action: 23.450 [10.000, 51.000], mean observation: -0.108 [-1.000, 1.000], loss: 0.298830, mean_absolute_error: 5.819156, mean_q: 6.521860
858 (array([12]),) False
 174560/500000: episode: 4364, duration: 33.013s, episode steps: 40, steps per second: 1, episode reward: 32.519, mean reward: 0.813 [0.262, 1.000], mean action: 17.700 [12.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.240445, mean_absolute_error: 5.879924, mean_q: 6.583247
31 (array([48]),) False
 174600/500000: episode: 4365, duration: 32.969s, episode steps: 40, steps per second: 1, episode reward: 32.011, mean reward: 0.800 [0.680, 0.891], mean action: 16.475 [5.000, 22.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.285009, mean_absolute_error: 5.894511, mean_q: 6.596896
811 (array([33]),) False
 174640/500000: episode: 4366, duration: 32.082s, episode steps: 40, steps per second: 1, episode reward: 30.732, mean reward: 0.768 [0.209, 1.000], mean action: 30.100 [12.000, 54.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.286948, mean_absolute_error: 5.815850, mean_q: 6.514784
238 (array([22]),) False
 174680/500000: episode: 4367, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 37.600, mean reward: 0.940 [0.317, 1.000], mean action: 22.475 [7.000, 46.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.256546, mean_absolute_error: 5.880553, mean_q: 6.580219
527 (array([58]),) False
 174720/500000: episode: 4368, duration: 32.196s, episode steps: 40, steps per second: 1, episode reward: 23.387, mean reward: 0.585 [0.236, 0.688], mean action: 24.000 [3.000, 52.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.263857, mean_absolute_error: 5.919839, mean_q: 6.624826
731 (array([21]),) False
 174760/500000: episode: 4369, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 34.484, mean reward: 0.862 [0.256, 1.000], mean action: 24.025 [12.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.274873, mean_absolute_error: 5.884252, mean_q: 6.586370
629 (array([22]),) False
 174800/500000: episode: 4370, duration: 32.192s, episode steps: 40, steps per second: 1, episode reward: 35.183, mean reward: 0.880 [0.010, 1.000], mean action: 19.925 [12.000, 27.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.276025, mean_absolute_error: 5.961017, mean_q: 6.667465
54 (array([8]),) False
 174840/500000: episode: 4371, duration: 32.979s, episode steps: 40, steps per second: 1, episode reward: 27.221, mean reward: 0.681 [0.337, 0.977], mean action: 29.000 [0.000, 55.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.236075, mean_absolute_error: 5.800708, mean_q: 6.492093
299 (array([12]),) False
 174880/500000: episode: 4372, duration: 33.033s, episode steps: 40, steps per second: 1, episode reward: 35.012, mean reward: 0.875 [0.465, 1.000], mean action: 24.175 [22.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.273640, mean_absolute_error: 5.849711, mean_q: 6.543106
426 (array([22]),) False
 174920/500000: episode: 4373, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 37.993, mean reward: 0.950 [0.239, 1.000], mean action: 22.050 [2.000, 37.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.260653, mean_absolute_error: 5.883722, mean_q: 6.585854
406 (array([48]),) False
 174960/500000: episode: 4374, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 35.620, mean reward: 0.891 [0.028, 1.000], mean action: 22.675 [10.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.275772, mean_absolute_error: 5.884047, mean_q: 6.585781
114 (array([22]),) False
 175000/500000: episode: 4375, duration: 33.037s, episode steps: 40, steps per second: 1, episode reward: 32.096, mean reward: 0.802 [0.024, 1.000], mean action: 23.400 [2.000, 60.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.254964, mean_absolute_error: 5.938715, mean_q: 6.643882
429 (array([22]),) False
 175040/500000: episode: 4376, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 33.390, mean reward: 0.835 [0.155, 1.000], mean action: 24.800 [1.000, 49.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.270900, mean_absolute_error: 5.817633, mean_q: 6.521062
512 (array([48]),) False
 175080/500000: episode: 4377, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 34.773, mean reward: 0.869 [0.000, 1.000], mean action: 19.100 [4.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.286425, mean_absolute_error: 5.848906, mean_q: 6.553973
631 (array([22]),) False
 175120/500000: episode: 4378, duration: 32.155s, episode steps: 40, steps per second: 1, episode reward: 36.885, mean reward: 0.922 [0.333, 1.000], mean action: 22.025 [10.000, 55.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.302389, mean_absolute_error: 5.837656, mean_q: 6.545124
511 (array([22]),) False
 175160/500000: episode: 4379, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 36.215, mean reward: 0.905 [0.140, 1.000], mean action: 21.250 [4.000, 59.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.269778, mean_absolute_error: 5.857839, mean_q: 6.567961
155 (array([22]),) False
 175200/500000: episode: 4380, duration: 32.153s, episode steps: 40, steps per second: 1, episode reward: 32.645, mean reward: 0.816 [0.131, 0.954], mean action: 16.375 [7.000, 56.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.271143, mean_absolute_error: 5.815705, mean_q: 6.518011
408 (array([12]),) False
 175240/500000: episode: 4381, duration: 32.926s, episode steps: 40, steps per second: 1, episode reward: 35.003, mean reward: 0.875 [0.148, 0.989], mean action: 22.525 [4.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.265785, mean_absolute_error: 5.869371, mean_q: 6.574402
841 (array([21]),) False
 175280/500000: episode: 4382, duration: 31.941s, episode steps: 40, steps per second: 1, episode reward: 33.230, mean reward: 0.831 [0.576, 0.966], mean action: 13.500 [12.000, 22.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.264233, mean_absolute_error: 5.861311, mean_q: 6.563943
343 (array([22]),) False
 175320/500000: episode: 4383, duration: 32.102s, episode steps: 40, steps per second: 1, episode reward: 31.470, mean reward: 0.787 [0.228, 1.000], mean action: 36.175 [16.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.264099, mean_absolute_error: 5.847314, mean_q: 6.552949
193 (array([36]),) False
 175360/500000: episode: 4384, duration: 32.054s, episode steps: 40, steps per second: 1, episode reward: 32.209, mean reward: 0.805 [0.000, 1.000], mean action: 28.075 [8.000, 54.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.250550, mean_absolute_error: 5.897192, mean_q: 6.613480
155 (array([22]),) False
 175400/500000: episode: 4385, duration: 32.026s, episode steps: 40, steps per second: 1, episode reward: 33.300, mean reward: 0.833 [0.298, 0.954], mean action: 15.125 [4.000, 35.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.248554, mean_absolute_error: 5.887793, mean_q: 6.605795
499 (array([8]),) False
 175440/500000: episode: 4386, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 15.884, mean reward: 0.397 [0.186, 0.876], mean action: 29.125 [2.000, 59.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.290114, mean_absolute_error: 5.842188, mean_q: 6.565145
30 (array([22]),) False
 175480/500000: episode: 4387, duration: 33.076s, episode steps: 40, steps per second: 1, episode reward: 37.447, mean reward: 0.936 [0.208, 1.000], mean action: 29.800 [10.000, 49.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.261697, mean_absolute_error: 5.956474, mean_q: 6.685342
195 (array([22]),) False
 175520/500000: episode: 4388, duration: 33.035s, episode steps: 40, steps per second: 1, episode reward: 34.519, mean reward: 0.863 [0.141, 1.000], mean action: 20.975 [1.000, 54.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.258499, mean_absolute_error: 5.927384, mean_q: 6.645792
12 (array([22]),) False
 175560/500000: episode: 4389, duration: 33.100s, episode steps: 40, steps per second: 1, episode reward: 35.710, mean reward: 0.893 [0.015, 1.000], mean action: 30.025 [9.000, 52.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.272855, mean_absolute_error: 6.029359, mean_q: 6.759541
36 (array([22]),) False
 175600/500000: episode: 4390, duration: 32.098s, episode steps: 40, steps per second: 1, episode reward: 37.211, mean reward: 0.930 [0.126, 1.000], mean action: 24.000 [22.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.257207, mean_absolute_error: 5.911752, mean_q: 6.631357
442 (array([22]),) False
 175640/500000: episode: 4391, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 37.674, mean reward: 0.942 [0.397, 1.000], mean action: 23.675 [12.000, 49.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.229132, mean_absolute_error: 5.905894, mean_q: 6.632825
507 (array([44]),) False
 175680/500000: episode: 4392, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 33.164, mean reward: 0.829 [0.365, 0.988], mean action: 19.325 [12.000, 29.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.279078, mean_absolute_error: 5.931662, mean_q: 6.656569
616 (array([22]),) False
 175720/500000: episode: 4393, duration: 33.084s, episode steps: 40, steps per second: 1, episode reward: 33.531, mean reward: 0.838 [0.170, 1.000], mean action: 18.800 [12.000, 51.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.302048, mean_absolute_error: 5.922740, mean_q: 6.649609
321 (array([22]),) False
 175760/500000: episode: 4394, duration: 32.120s, episode steps: 40, steps per second: 1, episode reward: 37.728, mean reward: 0.943 [0.202, 1.000], mean action: 22.425 [6.000, 42.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.350517, mean_absolute_error: 5.976045, mean_q: 6.702957
774 (array([57]),) False
 175800/500000: episode: 4395, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 21.876, mean reward: 0.547 [0.324, 0.903], mean action: 34.875 [4.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.255735, mean_absolute_error: 6.013645, mean_q: 6.733889
708 (array([40]),) False
 175840/500000: episode: 4396, duration: 32.998s, episode steps: 40, steps per second: 1, episode reward: 35.808, mean reward: 0.895 [0.496, 1.000], mean action: 20.125 [12.000, 51.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.319648, mean_absolute_error: 5.944029, mean_q: 6.664506
210 (array([58]),) False
 175880/500000: episode: 4397, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 10.423, mean reward: 0.261 [0.000, 0.802], mean action: 28.900 [8.000, 59.000], mean observation: -0.187 [-1.000, 1.000], loss: 0.269551, mean_absolute_error: 5.956919, mean_q: 6.683582
260 (array([22]),) False
 175920/500000: episode: 4398, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 37.904, mean reward: 0.948 [0.250, 1.000], mean action: 22.850 [20.000, 37.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.278902, mean_absolute_error: 5.939364, mean_q: 6.654913
119 (array([45]),) False
 175960/500000: episode: 4399, duration: 33.052s, episode steps: 40, steps per second: 1, episode reward: 35.031, mean reward: 0.876 [0.102, 1.000], mean action: 22.550 [9.000, 42.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.272398, mean_absolute_error: 5.931499, mean_q: 6.635422
417 (array([12]),) False
 176000/500000: episode: 4400, duration: 33.065s, episode steps: 40, steps per second: 1, episode reward: 25.823, mean reward: 0.646 [0.047, 1.000], mean action: 23.725 [6.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.254957, mean_absolute_error: 5.912961, mean_q: 6.629361
131 (array([22]),) False
 176040/500000: episode: 4401, duration: 32.965s, episode steps: 40, steps per second: 1, episode reward: 35.733, mean reward: 0.893 [0.103, 1.000], mean action: 23.325 [12.000, 47.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.227560, mean_absolute_error: 6.026490, mean_q: 6.748144
531 (array([22]),) False
 176080/500000: episode: 4402, duration: 32.077s, episode steps: 40, steps per second: 1, episode reward: 37.999, mean reward: 0.950 [0.324, 1.000], mean action: 23.700 [12.000, 47.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.267133, mean_absolute_error: 5.928905, mean_q: 6.640797
534 (array([22]),) False
 176120/500000: episode: 4403, duration: 33.068s, episode steps: 40, steps per second: 1, episode reward: 37.745, mean reward: 0.944 [0.318, 1.000], mean action: 23.475 [12.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.281838, mean_absolute_error: 5.895954, mean_q: 6.601644
649 (array([22]),) False
 176160/500000: episode: 4404, duration: 32.169s, episode steps: 40, steps per second: 1, episode reward: 37.750, mean reward: 0.944 [0.000, 1.000], mean action: 22.975 [11.000, 44.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.256356, mean_absolute_error: 5.916849, mean_q: 6.617801
148 (array([22]),) False
 176200/500000: episode: 4405, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 31.589, mean reward: 0.790 [0.098, 0.950], mean action: 19.000 [9.000, 59.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.297337, mean_absolute_error: 5.967990, mean_q: 6.667963
36 (array([22]),) False
 176240/500000: episode: 4406, duration: 32.158s, episode steps: 40, steps per second: 1, episode reward: 33.858, mean reward: 0.846 [0.073, 1.000], mean action: 24.400 [22.000, 43.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.287796, mean_absolute_error: 5.979672, mean_q: 6.693096
288 (array([33]),) False
 176280/500000: episode: 4407, duration: 33.058s, episode steps: 40, steps per second: 1, episode reward: 21.883, mean reward: 0.547 [0.175, 1.000], mean action: 20.975 [4.000, 22.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.259446, mean_absolute_error: 5.962756, mean_q: 6.676160
412 (array([16]),) False
 176320/500000: episode: 4408, duration: 33.021s, episode steps: 40, steps per second: 1, episode reward: 35.255, mean reward: 0.881 [0.618, 0.925], mean action: 22.350 [5.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.265877, mean_absolute_error: 5.954981, mean_q: 6.667105
792 (array([58]),) False
 176360/500000: episode: 4409, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 7.203, mean reward: 0.180 [0.000, 0.612], mean action: 18.850 [5.000, 48.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.265174, mean_absolute_error: 6.012864, mean_q: 6.727033
591 (array([22]),) False
 176400/500000: episode: 4410, duration: 33.050s, episode steps: 40, steps per second: 1, episode reward: 30.044, mean reward: 0.751 [0.045, 1.000], mean action: 16.050 [9.000, 39.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.241572, mean_absolute_error: 5.926776, mean_q: 6.629085
671 (array([57]),) False
 176440/500000: episode: 4411, duration: 33.004s, episode steps: 40, steps per second: 1, episode reward: 6.814, mean reward: 0.170 [0.000, 0.993], mean action: 38.325 [3.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.267819, mean_absolute_error: 5.905066, mean_q: 6.605443
798 (array([18]),) False
 176480/500000: episode: 4412, duration: 32.920s, episode steps: 40, steps per second: 1, episode reward: 25.182, mean reward: 0.630 [0.004, 0.993], mean action: 29.900 [3.000, 48.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.277844, mean_absolute_error: 5.918824, mean_q: 6.620505
241 (array([22]),) False
 176520/500000: episode: 4413, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 36.663, mean reward: 0.917 [0.155, 1.000], mean action: 24.625 [8.000, 58.000], mean observation: -0.117 [-1.000, 1.000], loss: 0.289275, mean_absolute_error: 5.953147, mean_q: 6.651223
625 (array([22]),) False
 176560/500000: episode: 4414, duration: 32.067s, episode steps: 40, steps per second: 1, episode reward: 34.869, mean reward: 0.872 [0.123, 1.000], mean action: 36.800 [0.000, 60.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.262974, mean_absolute_error: 5.908499, mean_q: 6.614474
600 (array([48]),) False
 176600/500000: episode: 4415, duration: 31.374s, episode steps: 40, steps per second: 1, episode reward: 31.298, mean reward: 0.782 [0.370, 1.000], mean action: 25.050 [12.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.296640, mean_absolute_error: 5.965800, mean_q: 6.664344
152 (array([58]),) False
 176640/500000: episode: 4416, duration: 30.048s, episode steps: 40, steps per second: 1, episode reward: 16.285, mean reward: 0.407 [0.000, 0.795], mean action: 19.800 [1.000, 47.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.292936, mean_absolute_error: 5.920745, mean_q: 6.628639
0 (array([48]),) False
 176680/500000: episode: 4417, duration: 30.449s, episode steps: 40, steps per second: 1, episode reward: 35.086, mean reward: 0.877 [0.111, 1.000], mean action: 21.775 [9.000, 26.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.259418, mean_absolute_error: 5.919897, mean_q: 6.630565
181 (array([22]),) False
 176720/500000: episode: 4418, duration: 29.768s, episode steps: 40, steps per second: 1, episode reward: 34.651, mean reward: 0.866 [0.117, 1.000], mean action: 19.600 [12.000, 49.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.271683, mean_absolute_error: 5.965371, mean_q: 6.671075
739 (array([22]),) False
 176760/500000: episode: 4419, duration: 30.485s, episode steps: 40, steps per second: 1, episode reward: 36.406, mean reward: 0.910 [0.242, 1.000], mean action: 18.775 [12.000, 48.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.282690, mean_absolute_error: 5.935866, mean_q: 6.640301
172 (array([12]),) False
 176800/500000: episode: 4420, duration: 30.938s, episode steps: 40, steps per second: 1, episode reward: 32.147, mean reward: 0.804 [0.130, 1.000], mean action: 17.375 [12.000, 48.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.264518, mean_absolute_error: 5.916257, mean_q: 6.614569
46 (array([22]),) False
 176840/500000: episode: 4421, duration: 30.932s, episode steps: 40, steps per second: 1, episode reward: 35.412, mean reward: 0.885 [0.054, 1.000], mean action: 22.525 [14.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.316569, mean_absolute_error: 6.023095, mean_q: 6.718361
359 (array([22]),) False
 176880/500000: episode: 4422, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 31.205, mean reward: 0.780 [0.080, 1.000], mean action: 23.775 [4.000, 51.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.294077, mean_absolute_error: 5.984241, mean_q: 6.675206
273 (array([22]),) False
 176920/500000: episode: 4423, duration: 30.959s, episode steps: 40, steps per second: 1, episode reward: 36.639, mean reward: 0.916 [0.260, 1.000], mean action: 18.425 [1.000, 33.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.273362, mean_absolute_error: 5.922223, mean_q: 6.603844
147 (array([44]),) False
 176960/500000: episode: 4424, duration: 31.019s, episode steps: 40, steps per second: 1, episode reward: 28.335, mean reward: 0.708 [0.281, 0.838], mean action: 18.050 [1.000, 57.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.311797, mean_absolute_error: 5.924518, mean_q: 6.621130
126 (array([22]),) False
 177000/500000: episode: 4425, duration: 30.983s, episode steps: 40, steps per second: 1, episode reward: 34.250, mean reward: 0.856 [0.122, 1.000], mean action: 23.825 [12.000, 57.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.269701, mean_absolute_error: 5.998786, mean_q: 6.690826
403 (array([12]),) False
 177040/500000: episode: 4426, duration: 30.049s, episode steps: 40, steps per second: 1, episode reward: 35.740, mean reward: 0.894 [0.183, 1.000], mean action: 22.225 [6.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.329563, mean_absolute_error: 5.993607, mean_q: 6.685971
385 (array([30]),) False
 177080/500000: episode: 4427, duration: 30.956s, episode steps: 40, steps per second: 1, episode reward: 32.563, mean reward: 0.814 [0.044, 1.000], mean action: 23.750 [3.000, 56.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.277300, mean_absolute_error: 6.030148, mean_q: 6.731343
812 (array([22]),) False
 177120/500000: episode: 4428, duration: 30.036s, episode steps: 40, steps per second: 1, episode reward: 33.760, mean reward: 0.844 [0.107, 1.000], mean action: 27.950 [12.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.302063, mean_absolute_error: 6.018602, mean_q: 6.715086
190 (array([3]),) False
 177160/500000: episode: 4429, duration: 31.027s, episode steps: 40, steps per second: 1, episode reward: 35.605, mean reward: 0.890 [0.227, 1.000], mean action: 6.825 [2.000, 52.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.260402, mean_absolute_error: 5.943855, mean_q: 6.636964
703 (array([3]),) False
 177200/500000: episode: 4430, duration: 30.113s, episode steps: 40, steps per second: 1, episode reward: 36.631, mean reward: 0.916 [0.158, 1.000], mean action: 6.350 [3.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.271334, mean_absolute_error: 6.025741, mean_q: 6.733134
505 (array([22]),) False
 177240/500000: episode: 4431, duration: 31.031s, episode steps: 40, steps per second: 1, episode reward: 36.257, mean reward: 0.906 [0.580, 1.000], mean action: 18.300 [12.000, 47.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.316033, mean_absolute_error: 5.935449, mean_q: 6.636330
605 (array([22]),) False
 177280/500000: episode: 4432, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 35.200, mean reward: 0.880 [0.180, 1.000], mean action: 24.450 [12.000, 58.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.275262, mean_absolute_error: 5.921536, mean_q: 6.625587
531 (array([22]),) False
 177320/500000: episode: 4433, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 38.646, mean reward: 0.966 [0.422, 1.000], mean action: 22.500 [0.000, 42.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.283154, mean_absolute_error: 6.002958, mean_q: 6.707025
80 (array([42]),) False
 177360/500000: episode: 4434, duration: 30.914s, episode steps: 40, steps per second: 1, episode reward: 35.800, mean reward: 0.895 [0.000, 1.000], mean action: 22.400 [12.000, 56.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.268777, mean_absolute_error: 5.966296, mean_q: 6.675654
380 (array([22]),) False
 177400/500000: episode: 4435, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 36.372, mean reward: 0.909 [0.023, 1.000], mean action: 23.950 [2.000, 57.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.264776, mean_absolute_error: 5.919779, mean_q: 6.632765
37 (array([48]),) False
 177440/500000: episode: 4436, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 36.710, mean reward: 0.918 [0.257, 1.000], mean action: 26.275 [5.000, 49.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.288776, mean_absolute_error: 5.969119, mean_q: 6.687477
769 (array([12]),) False
 177480/500000: episode: 4437, duration: 30.954s, episode steps: 40, steps per second: 1, episode reward: 35.221, mean reward: 0.881 [0.215, 1.000], mean action: 25.675 [5.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.274458, mean_absolute_error: 5.921691, mean_q: 6.632012
589 (array([22]),) False
 177520/500000: episode: 4438, duration: 30.141s, episode steps: 40, steps per second: 1, episode reward: 29.487, mean reward: 0.737 [0.414, 1.000], mean action: 14.000 [12.000, 37.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.262997, mean_absolute_error: 5.965797, mean_q: 6.685158
385 (array([30]),) False
 177560/500000: episode: 4439, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 35.801, mean reward: 0.895 [0.000, 1.000], mean action: 24.875 [11.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.302291, mean_absolute_error: 5.981707, mean_q: 6.693211
512 (array([48]),) False
 177600/500000: episode: 4440, duration: 30.140s, episode steps: 40, steps per second: 1, episode reward: 36.428, mean reward: 0.911 [0.188, 1.000], mean action: 17.850 [12.000, 46.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.257205, mean_absolute_error: 5.931961, mean_q: 6.642896
261 (array([44]),) False
 177640/500000: episode: 4441, duration: 30.964s, episode steps: 40, steps per second: 1, episode reward: 31.160, mean reward: 0.779 [0.030, 0.879], mean action: 29.800 [8.000, 49.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.272349, mean_absolute_error: 5.978955, mean_q: 6.698709
229 (array([48]),) False
 177680/500000: episode: 4442, duration: 30.119s, episode steps: 40, steps per second: 1, episode reward: 31.176, mean reward: 0.779 [0.089, 1.000], mean action: 24.350 [9.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.266576, mean_absolute_error: 5.977381, mean_q: 6.693185
853 (array([22]),) False
 177720/500000: episode: 4443, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 32.727, mean reward: 0.818 [0.305, 1.000], mean action: 28.150 [4.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.290467, mean_absolute_error: 5.962498, mean_q: 6.679240
287 (array([48]),) False
 177760/500000: episode: 4444, duration: 30.894s, episode steps: 40, steps per second: 1, episode reward: 33.743, mean reward: 0.844 [0.422, 1.000], mean action: 22.700 [7.000, 49.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.272906, mean_absolute_error: 5.978879, mean_q: 6.690463
741 (array([22]),) False
 177800/500000: episode: 4445, duration: 31.002s, episode steps: 40, steps per second: 1, episode reward: 36.203, mean reward: 0.905 [0.237, 1.000], mean action: 24.175 [0.000, 51.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.278136, mean_absolute_error: 5.938665, mean_q: 6.641585
204 (array([22]),) False
 177840/500000: episode: 4446, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 28.951, mean reward: 0.724 [0.309, 1.000], mean action: 17.800 [12.000, 48.000], mean observation: -0.188 [-1.000, 1.000], loss: 0.244859, mean_absolute_error: 5.983470, mean_q: 6.695010
339 (array([22]),) False
 177880/500000: episode: 4447, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 37.181, mean reward: 0.930 [0.157, 1.000], mean action: 23.075 [7.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.280160, mean_absolute_error: 5.998038, mean_q: 6.705286
697 (array([22]),) False
 177920/500000: episode: 4448, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 36.869, mean reward: 0.922 [0.223, 1.000], mean action: 21.100 [12.000, 49.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.251334, mean_absolute_error: 5.959573, mean_q: 6.668902
763 (array([48]),) False
 177960/500000: episode: 4449, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 13.201, mean reward: 0.330 [0.000, 0.959], mean action: 46.900 [8.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.331261, mean_absolute_error: 6.067594, mean_q: 6.780010
824 (array([22]),) False
 178000/500000: episode: 4450, duration: 30.078s, episode steps: 40, steps per second: 1, episode reward: 35.003, mean reward: 0.875 [0.202, 1.000], mean action: 17.300 [12.000, 52.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.276515, mean_absolute_error: 5.932390, mean_q: 6.634647
291 (array([22]),) False
 178040/500000: episode: 4451, duration: 30.901s, episode steps: 40, steps per second: 1, episode reward: 38.140, mean reward: 0.954 [0.394, 1.000], mean action: 21.025 [12.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.252835, mean_absolute_error: 5.990433, mean_q: 6.697458
774 (array([57]),) False
 178080/500000: episode: 4452, duration: 30.085s, episode steps: 40, steps per second: 1, episode reward: 31.305, mean reward: 0.783 [0.390, 0.819], mean action: 21.800 [12.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.275657, mean_absolute_error: 5.984345, mean_q: 6.692760
190 (array([3]),) False
 178120/500000: episode: 4453, duration: 30.982s, episode steps: 40, steps per second: 1, episode reward: 37.363, mean reward: 0.934 [0.197, 1.000], mean action: 5.425 [3.000, 38.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.257784, mean_absolute_error: 5.982518, mean_q: 6.686564
613 (array([22]),) False
 178160/500000: episode: 4454, duration: 30.162s, episode steps: 40, steps per second: 1, episode reward: 36.244, mean reward: 0.906 [0.152, 1.000], mean action: 23.400 [6.000, 57.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.287821, mean_absolute_error: 5.905115, mean_q: 6.612665
352 (array([22]),) False
 178200/500000: episode: 4455, duration: 31.030s, episode steps: 40, steps per second: 1, episode reward: 33.440, mean reward: 0.836 [0.191, 1.000], mean action: 36.300 [8.000, 56.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.299929, mean_absolute_error: 6.006742, mean_q: 6.719779
291 (array([22]),) False
 178240/500000: episode: 4456, duration: 30.949s, episode steps: 40, steps per second: 1, episode reward: 38.118, mean reward: 0.953 [0.412, 1.000], mean action: 20.175 [1.000, 55.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.297313, mean_absolute_error: 5.943131, mean_q: 6.652771
268 (array([22]),) False
 178280/500000: episode: 4457, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 34.882, mean reward: 0.872 [0.065, 1.000], mean action: 24.500 [6.000, 55.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.270925, mean_absolute_error: 5.920132, mean_q: 6.627779
41 (array([12]),) False
 178320/500000: episode: 4458, duration: 30.950s, episode steps: 40, steps per second: 1, episode reward: 32.104, mean reward: 0.803 [0.148, 1.000], mean action: 23.000 [18.000, 42.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.267570, mean_absolute_error: 5.965065, mean_q: 6.671356
619 (array([3]),) False
 178360/500000: episode: 4459, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 38.902, mean reward: 0.973 [0.378, 1.000], mean action: 4.725 [3.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.233578, mean_absolute_error: 5.951180, mean_q: 6.654195
118 (array([22]),) False
 178400/500000: episode: 4460, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 37.442, mean reward: 0.936 [0.083, 1.000], mean action: 22.775 [6.000, 41.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.257346, mean_absolute_error: 5.891981, mean_q: 6.599119
667 (array([48]),) False
 178440/500000: episode: 4461, duration: 31.051s, episode steps: 40, steps per second: 1, episode reward: 37.064, mean reward: 0.927 [0.290, 1.000], mean action: 22.275 [11.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.254799, mean_absolute_error: 5.960848, mean_q: 6.671887
756 (array([48]),) False
 178480/500000: episode: 4462, duration: 30.051s, episode steps: 40, steps per second: 1, episode reward: 37.012, mean reward: 0.925 [0.161, 1.000], mean action: 23.725 [7.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.284097, mean_absolute_error: 5.830573, mean_q: 6.531643
91 (array([48]),) False
 178520/500000: episode: 4463, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 34.524, mean reward: 0.863 [0.060, 0.951], mean action: 21.850 [5.000, 31.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.279937, mean_absolute_error: 5.995318, mean_q: 6.696153
245 (array([22]),) False
 178560/500000: episode: 4464, duration: 30.108s, episode steps: 40, steps per second: 1, episode reward: 35.471, mean reward: 0.887 [0.041, 1.000], mean action: 23.525 [1.000, 58.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.293355, mean_absolute_error: 5.961717, mean_q: 6.666331
290 (array([22]),) False
 178600/500000: episode: 4465, duration: 31.021s, episode steps: 40, steps per second: 1, episode reward: 36.174, mean reward: 0.904 [0.140, 1.000], mean action: 25.150 [0.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.287582, mean_absolute_error: 5.901860, mean_q: 6.608016
747 (array([22]),) False
 178640/500000: episode: 4466, duration: 30.112s, episode steps: 40, steps per second: 1, episode reward: 36.199, mean reward: 0.905 [0.391, 1.000], mean action: 21.175 [12.000, 48.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.228986, mean_absolute_error: 5.974184, mean_q: 6.676569
392 (array([40]),) False
 178680/500000: episode: 4467, duration: 31.017s, episode steps: 40, steps per second: 1, episode reward: 29.454, mean reward: 0.736 [0.351, 0.901], mean action: 26.050 [3.000, 54.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.239279, mean_absolute_error: 5.938819, mean_q: 6.642201
340 (array([12]),) False
 178720/500000: episode: 4468, duration: 30.997s, episode steps: 40, steps per second: 1, episode reward: 33.123, mean reward: 0.828 [0.053, 1.000], mean action: 31.025 [4.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.260172, mean_absolute_error: 5.897516, mean_q: 6.598821
265 (array([22]),) False
 178760/500000: episode: 4469, duration: 30.978s, episode steps: 40, steps per second: 1, episode reward: 35.304, mean reward: 0.883 [0.179, 1.000], mean action: 20.150 [2.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.244886, mean_absolute_error: 5.939343, mean_q: 6.643194
197 (array([22]),) False
 178800/500000: episode: 4470, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 35.442, mean reward: 0.886 [0.185, 1.000], mean action: 26.150 [12.000, 60.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.251165, mean_absolute_error: 5.955977, mean_q: 6.664021
455 (array([22]),) False
 178840/500000: episode: 4471, duration: 30.953s, episode steps: 40, steps per second: 1, episode reward: 36.289, mean reward: 0.907 [0.094, 1.000], mean action: 26.525 [5.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.280640, mean_absolute_error: 5.884779, mean_q: 6.592775
784 (array([22]),) False
 178880/500000: episode: 4472, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 34.591, mean reward: 0.865 [0.125, 1.000], mean action: 17.400 [4.000, 50.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.276396, mean_absolute_error: 6.026042, mean_q: 6.742583
838 (array([21]),) False
 178920/500000: episode: 4473, duration: 30.997s, episode steps: 40, steps per second: 1, episode reward: 31.800, mean reward: 0.795 [0.031, 1.000], mean action: 19.500 [7.000, 58.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.243869, mean_absolute_error: 5.943933, mean_q: 6.657172
746 (array([37]),) False
 178960/500000: episode: 4474, duration: 30.095s, episode steps: 40, steps per second: 1, episode reward: 35.159, mean reward: 0.879 [0.409, 0.968], mean action: 17.550 [5.000, 40.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.257134, mean_absolute_error: 5.966309, mean_q: 6.677322
256 (array([22]),) False
 179000/500000: episode: 4475, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 37.444, mean reward: 0.936 [0.157, 1.000], mean action: 22.750 [0.000, 41.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.236344, mean_absolute_error: 5.869274, mean_q: 6.578752
492 (array([22]),) False
 179040/500000: episode: 4476, duration: 30.179s, episode steps: 40, steps per second: 1, episode reward: 37.726, mean reward: 0.943 [0.159, 1.000], mean action: 21.800 [11.000, 29.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.258621, mean_absolute_error: 5.813196, mean_q: 6.520844
671 (array([57]),) False
 179080/500000: episode: 4477, duration: 31.004s, episode steps: 40, steps per second: 1, episode reward: 13.515, mean reward: 0.338 [0.000, 0.994], mean action: 25.475 [0.000, 57.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.330784, mean_absolute_error: 5.965803, mean_q: 6.678311
854 (array([12]),) False
 179120/500000: episode: 4478, duration: 30.077s, episode steps: 40, steps per second: 1, episode reward: 33.116, mean reward: 0.828 [0.362, 1.000], mean action: 15.525 [12.000, 53.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.273871, mean_absolute_error: 5.967241, mean_q: 6.679475
471 (array([12]),) False
 179160/500000: episode: 4479, duration: 30.926s, episode steps: 40, steps per second: 1, episode reward: 31.308, mean reward: 0.783 [0.007, 1.000], mean action: 24.225 [11.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.261731, mean_absolute_error: 5.986232, mean_q: 6.697541
665 (array([12]),) False
 179200/500000: episode: 4480, duration: 30.963s, episode steps: 40, steps per second: 1, episode reward: 36.172, mean reward: 0.904 [0.380, 1.000], mean action: 16.100 [1.000, 54.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.269631, mean_absolute_error: 5.964103, mean_q: 6.681282
197 (array([22]),) False
 179240/500000: episode: 4481, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 35.638, mean reward: 0.891 [0.121, 1.000], mean action: 22.700 [2.000, 58.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.305359, mean_absolute_error: 5.948650, mean_q: 6.665135
685 (array([22]),) False
 179280/500000: episode: 4482, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 36.025, mean reward: 0.901 [0.256, 1.000], mean action: 14.425 [1.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.275779, mean_absolute_error: 5.950627, mean_q: 6.667200
117 (array([44]),) False
 179320/500000: episode: 4483, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 31.692, mean reward: 0.792 [0.000, 1.000], mean action: 25.150 [8.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.272006, mean_absolute_error: 6.000710, mean_q: 6.730154
679 (array([44]),) False
 179360/500000: episode: 4484, duration: 30.952s, episode steps: 40, steps per second: 1, episode reward: 27.452, mean reward: 0.686 [0.000, 1.000], mean action: 15.750 [6.000, 49.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.274475, mean_absolute_error: 5.999048, mean_q: 6.726064
143 (array([12]),) False
 179400/500000: episode: 4485, duration: 30.896s, episode steps: 40, steps per second: 1, episode reward: 34.587, mean reward: 0.865 [0.351, 1.000], mean action: 14.675 [7.000, 47.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.305081, mean_absolute_error: 5.942807, mean_q: 6.661078
29 (array([22]),) False
 179440/500000: episode: 4486, duration: 30.128s, episode steps: 40, steps per second: 1, episode reward: 38.576, mean reward: 0.964 [0.486, 1.000], mean action: 27.975 [12.000, 55.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.318203, mean_absolute_error: 5.973435, mean_q: 6.692388
817 (array([12]),) False
 179480/500000: episode: 4487, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 37.132, mean reward: 0.928 [0.114, 1.000], mean action: 13.925 [10.000, 55.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.291874, mean_absolute_error: 5.949839, mean_q: 6.669718
675 (array([22]),) False
 179520/500000: episode: 4488, duration: 30.152s, episode steps: 40, steps per second: 1, episode reward: 36.241, mean reward: 0.906 [0.141, 1.000], mean action: 22.350 [12.000, 51.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.301105, mean_absolute_error: 5.925706, mean_q: 6.642201
196 (array([22]),) False
 179560/500000: episode: 4489, duration: 30.992s, episode steps: 40, steps per second: 1, episode reward: 33.730, mean reward: 0.843 [0.020, 1.000], mean action: 21.450 [3.000, 49.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.271659, mean_absolute_error: 5.940038, mean_q: 6.657498
312 (array([12]),) False
 179600/500000: episode: 4490, duration: 30.132s, episode steps: 40, steps per second: 1, episode reward: 30.405, mean reward: 0.760 [0.000, 0.808], mean action: 22.125 [5.000, 37.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.251091, mean_absolute_error: 5.963249, mean_q: 6.682610
343 (array([22]),) False
 179640/500000: episode: 4491, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 34.654, mean reward: 0.866 [0.056, 1.000], mean action: 24.725 [0.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.300846, mean_absolute_error: 5.954226, mean_q: 6.671571
857 (array([22]),) False
 179680/500000: episode: 4492, duration: 30.907s, episode steps: 40, steps per second: 1, episode reward: 34.517, mean reward: 0.863 [0.362, 1.000], mean action: 20.300 [5.000, 54.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.264406, mean_absolute_error: 5.921511, mean_q: 6.633658
175 (array([22]),) False
 179720/500000: episode: 4493, duration: 30.945s, episode steps: 40, steps per second: 1, episode reward: 37.261, mean reward: 0.932 [0.302, 1.000], mean action: 19.525 [12.000, 57.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.291853, mean_absolute_error: 6.024981, mean_q: 6.732322
581 (array([22]),) False
 179760/500000: episode: 4494, duration: 30.954s, episode steps: 40, steps per second: 1, episode reward: 34.876, mean reward: 0.872 [0.038, 1.000], mean action: 22.150 [4.000, 43.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.292964, mean_absolute_error: 5.911311, mean_q: 6.610162
321 (array([22]),) False
 179800/500000: episode: 4495, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 36.306, mean reward: 0.908 [0.288, 1.000], mean action: 23.450 [7.000, 56.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.282317, mean_absolute_error: 5.999176, mean_q: 6.698895
455 (array([22]),) False
 179840/500000: episode: 4496, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 34.681, mean reward: 0.867 [0.000, 1.000], mean action: 23.200 [5.000, 57.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.245869, mean_absolute_error: 5.917763, mean_q: 6.616948
606 (array([22]),) False
 179880/500000: episode: 4497, duration: 30.991s, episode steps: 40, steps per second: 1, episode reward: 34.471, mean reward: 0.862 [0.369, 1.000], mean action: 12.675 [1.000, 41.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.239282, mean_absolute_error: 5.918111, mean_q: 6.624771
843 (array([3]),) False
 179920/500000: episode: 4498, duration: 30.103s, episode steps: 40, steps per second: 1, episode reward: 15.748, mean reward: 0.394 [0.000, 1.000], mean action: 11.625 [4.000, 37.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.328084, mean_absolute_error: 5.940511, mean_q: 6.640580
93 (array([22]),) False
 179960/500000: episode: 4499, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 37.239, mean reward: 0.931 [0.238, 1.000], mean action: 22.700 [9.000, 40.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.259722, mean_absolute_error: 5.966993, mean_q: 6.667989
642 (array([22]),) False
 180000/500000: episode: 4500, duration: 30.130s, episode steps: 40, steps per second: 1, episode reward: 35.440, mean reward: 0.886 [0.044, 1.000], mean action: 21.900 [9.000, 47.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.269617, mean_absolute_error: 5.926860, mean_q: 6.627224
263 (array([8]),) False
 180040/500000: episode: 4501, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 23.450, mean reward: 0.586 [0.372, 0.781], mean action: 16.050 [1.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.292638, mean_absolute_error: 5.926030, mean_q: 6.622951
144 (array([22]),) False
 180080/500000: episode: 4502, duration: 30.134s, episode steps: 40, steps per second: 1, episode reward: 31.791, mean reward: 0.795 [0.000, 1.000], mean action: 21.250 [3.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.278933, mean_absolute_error: 5.935431, mean_q: 6.630805
380 (array([22]),) False
 180120/500000: episode: 4503, duration: 31.029s, episode steps: 40, steps per second: 1, episode reward: 36.263, mean reward: 0.907 [0.014, 1.000], mean action: 24.025 [4.000, 58.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.239228, mean_absolute_error: 5.942499, mean_q: 6.641374
469 (array([22]),) False
 180160/500000: episode: 4504, duration: 30.973s, episode steps: 40, steps per second: 1, episode reward: 34.854, mean reward: 0.871 [0.180, 1.000], mean action: 23.375 [6.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.226574, mean_absolute_error: 5.956855, mean_q: 6.662242
186 (array([22]),) False
 180200/500000: episode: 4505, duration: 31.102s, episode steps: 40, steps per second: 1, episode reward: 35.411, mean reward: 0.885 [0.464, 1.000], mean action: 15.825 [12.000, 45.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.288673, mean_absolute_error: 5.901803, mean_q: 6.607457
105 (array([22]),) False
 180240/500000: episode: 4506, duration: 31.054s, episode steps: 40, steps per second: 1, episode reward: 38.061, mean reward: 0.952 [0.190, 1.000], mean action: 22.300 [12.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.255798, mean_absolute_error: 5.916485, mean_q: 6.623331
860 (array([12]),) False
 180280/500000: episode: 4507, duration: 30.946s, episode steps: 40, steps per second: 1, episode reward: 32.707, mean reward: 0.818 [0.101, 1.000], mean action: 18.000 [2.000, 44.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.279078, mean_absolute_error: 5.895784, mean_q: 6.608819
135 (array([22]),) False
 180320/500000: episode: 4508, duration: 30.934s, episode steps: 40, steps per second: 1, episode reward: 35.085, mean reward: 0.877 [0.113, 1.000], mean action: 25.175 [12.000, 59.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.302044, mean_absolute_error: 5.890703, mean_q: 6.591702
816 (array([4]),) False
 180360/500000: episode: 4509, duration: 30.970s, episode steps: 40, steps per second: 1, episode reward: 14.771, mean reward: 0.369 [0.000, 0.977], mean action: 17.075 [0.000, 56.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.268088, mean_absolute_error: 5.935894, mean_q: 6.632410
780 (array([22]),) False
 180400/500000: episode: 4510, duration: 30.083s, episode steps: 40, steps per second: 1, episode reward: 33.709, mean reward: 0.843 [0.023, 1.000], mean action: 20.700 [12.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.293550, mean_absolute_error: 5.924214, mean_q: 6.621039
66 (array([22]),) False
 180440/500000: episode: 4511, duration: 30.898s, episode steps: 40, steps per second: 1, episode reward: 37.768, mean reward: 0.944 [0.452, 1.000], mean action: 20.575 [12.000, 37.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.275397, mean_absolute_error: 6.016545, mean_q: 6.724247
30 (array([22]),) False
 180480/500000: episode: 4512, duration: 30.139s, episode steps: 40, steps per second: 1, episode reward: 35.434, mean reward: 0.886 [0.070, 1.000], mean action: 24.325 [4.000, 50.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.257991, mean_absolute_error: 6.041638, mean_q: 6.756969
564 (array([22]),) False
 180520/500000: episode: 4513, duration: 30.975s, episode steps: 40, steps per second: 1, episode reward: 34.656, mean reward: 0.866 [0.157, 1.000], mean action: 14.100 [4.000, 41.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.288933, mean_absolute_error: 5.924998, mean_q: 6.635191
427 (array([22]),) False
 180560/500000: episode: 4514, duration: 30.110s, episode steps: 40, steps per second: 1, episode reward: 34.436, mean reward: 0.861 [0.063, 1.000], mean action: 26.150 [0.000, 50.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.287563, mean_absolute_error: 5.911017, mean_q: 6.621942
370 (array([58]),) False
 180600/500000: episode: 4515, duration: 30.993s, episode steps: 40, steps per second: 1, episode reward: 16.370, mean reward: 0.409 [0.000, 1.000], mean action: 22.300 [1.000, 59.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.244955, mean_absolute_error: 5.945947, mean_q: 6.665222
171 (array([22]),) False
 180640/500000: episode: 4516, duration: 30.919s, episode steps: 40, steps per second: 1, episode reward: 37.384, mean reward: 0.935 [0.671, 1.000], mean action: 15.100 [12.000, 48.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.297204, mean_absolute_error: 5.950492, mean_q: 6.668266
80 (array([42]),) False
 180680/500000: episode: 4517, duration: 31.038s, episode steps: 40, steps per second: 1, episode reward: 35.664, mean reward: 0.892 [0.323, 1.000], mean action: 20.250 [5.000, 25.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.291455, mean_absolute_error: 5.942895, mean_q: 6.665872
684 (array([22]),) False
 180720/500000: episode: 4518, duration: 30.980s, episode steps: 40, steps per second: 1, episode reward: 37.632, mean reward: 0.941 [0.415, 1.000], mean action: 21.050 [12.000, 37.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.243779, mean_absolute_error: 5.929432, mean_q: 6.648356
585 (array([48]),) False
 180760/500000: episode: 4519, duration: 30.908s, episode steps: 40, steps per second: 1, episode reward: 36.114, mean reward: 0.903 [0.047, 0.960], mean action: 16.625 [12.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.262692, mean_absolute_error: 5.927605, mean_q: 6.648749
460 (array([36]),) False
 180800/500000: episode: 4520, duration: 30.947s, episode steps: 40, steps per second: 1, episode reward: 34.429, mean reward: 0.861 [0.279, 1.000], mean action: 23.475 [5.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.247731, mean_absolute_error: 5.961201, mean_q: 6.675885
262 (array([22]),) False
 180840/500000: episode: 4521, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 29.886, mean reward: 0.747 [0.075, 1.000], mean action: 26.775 [22.000, 60.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.253595, mean_absolute_error: 5.947124, mean_q: 6.660964
466 (array([22]),) False
 180880/500000: episode: 4522, duration: 30.064s, episode steps: 40, steps per second: 1, episode reward: 35.516, mean reward: 0.888 [0.224, 1.000], mean action: 18.375 [1.000, 47.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.294063, mean_absolute_error: 6.000509, mean_q: 6.712033
195 (array([22]),) False
 180920/500000: episode: 4523, duration: 30.941s, episode steps: 40, steps per second: 1, episode reward: 36.026, mean reward: 0.901 [0.084, 1.000], mean action: 23.000 [9.000, 42.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.268778, mean_absolute_error: 5.959296, mean_q: 6.665835
833 (array([22]),) False
 180960/500000: episode: 4524, duration: 30.961s, episode steps: 40, steps per second: 1, episode reward: 37.543, mean reward: 0.939 [0.414, 1.000], mean action: 17.350 [12.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.315305, mean_absolute_error: 5.920005, mean_q: 6.620527
197 (array([22]),) False
 181000/500000: episode: 4525, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 37.245, mean reward: 0.931 [0.017, 1.000], mean action: 22.475 [8.000, 42.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.250027, mean_absolute_error: 5.948395, mean_q: 6.654129
16 (array([22]),) False
 181040/500000: episode: 4526, duration: 30.186s, episode steps: 40, steps per second: 1, episode reward: 37.533, mean reward: 0.938 [0.325, 1.000], mean action: 23.025 [15.000, 51.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.275988, mean_absolute_error: 5.883507, mean_q: 6.586348
199 (array([22]),) False
 181080/500000: episode: 4527, duration: 31.053s, episode steps: 40, steps per second: 1, episode reward: 36.160, mean reward: 0.904 [0.085, 1.000], mean action: 21.750 [0.000, 49.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.247100, mean_absolute_error: 5.908720, mean_q: 6.619493
392 (array([40]),) False
 181120/500000: episode: 4528, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 30.231, mean reward: 0.756 [0.351, 1.000], mean action: 23.425 [3.000, 47.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.289084, mean_absolute_error: 5.904388, mean_q: 6.608185
199 (array([22]),) False
 181160/500000: episode: 4529, duration: 30.912s, episode steps: 40, steps per second: 1, episode reward: 37.530, mean reward: 0.938 [0.237, 1.000], mean action: 21.550 [1.000, 48.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.266163, mean_absolute_error: 5.880337, mean_q: 6.583638
650 (array([22]),) False
 181200/500000: episode: 4530, duration: 30.092s, episode steps: 40, steps per second: 1, episode reward: 38.204, mean reward: 0.955 [0.167, 1.000], mean action: 21.925 [1.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.248722, mean_absolute_error: 5.864787, mean_q: 6.569858
439 (array([12]),) False
 181240/500000: episode: 4531, duration: 31.008s, episode steps: 40, steps per second: 1, episode reward: 36.540, mean reward: 0.913 [0.290, 1.000], mean action: 21.175 [10.000, 22.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.304973, mean_absolute_error: 5.880721, mean_q: 6.580625
109 (array([48]),) False
 181280/500000: episode: 4532, duration: 31.023s, episode steps: 40, steps per second: 1, episode reward: 37.106, mean reward: 0.928 [0.243, 1.000], mean action: 21.925 [1.000, 43.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.290465, mean_absolute_error: 5.896643, mean_q: 6.590836
736 (array([22]),) False
 181320/500000: episode: 4533, duration: 30.972s, episode steps: 40, steps per second: 1, episode reward: 37.489, mean reward: 0.937 [0.722, 1.000], mean action: 26.025 [12.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.299255, mean_absolute_error: 5.896839, mean_q: 6.599469
339 (array([22]),) False
 181360/500000: episode: 4534, duration: 30.139s, episode steps: 40, steps per second: 1, episode reward: 35.805, mean reward: 0.895 [0.000, 1.000], mean action: 22.925 [2.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.322682, mean_absolute_error: 5.915902, mean_q: 6.612031
467 (array([48]),) False
 181400/500000: episode: 4535, duration: 30.968s, episode steps: 40, steps per second: 1, episode reward: 33.718, mean reward: 0.843 [0.178, 0.928], mean action: 23.700 [10.000, 53.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.274783, mean_absolute_error: 5.927896, mean_q: 6.627374
160 (array([12]),) False
 181440/500000: episode: 4536, duration: 30.986s, episode steps: 40, steps per second: 1, episode reward: 36.012, mean reward: 0.900 [0.220, 1.000], mean action: 19.075 [1.000, 56.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.254586, mean_absolute_error: 5.871840, mean_q: 6.562364
607 (array([12]),) False
 181480/500000: episode: 4537, duration: 30.998s, episode steps: 40, steps per second: 1, episode reward: 35.963, mean reward: 0.899 [0.027, 1.000], mean action: 14.575 [1.000, 41.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.280504, mean_absolute_error: 5.874005, mean_q: 6.558614
317 (array([12]),) False
 181520/500000: episode: 4538, duration: 30.348s, episode steps: 40, steps per second: 1, episode reward: 30.709, mean reward: 0.768 [0.286, 1.000], mean action: 22.050 [10.000, 35.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.268964, mean_absolute_error: 5.817085, mean_q: 6.498237
25 (array([48]),) False
 181560/500000: episode: 4539, duration: 30.943s, episode steps: 40, steps per second: 1, episode reward: 36.435, mean reward: 0.911 [0.362, 1.000], mean action: 30.700 [14.000, 59.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.238476, mean_absolute_error: 5.943252, mean_q: 6.631410
850 (array([12]),) False
 181600/500000: episode: 4540, duration: 30.885s, episode steps: 40, steps per second: 1, episode reward: 31.846, mean reward: 0.796 [0.323, 1.000], mean action: 18.475 [12.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.242355, mean_absolute_error: 5.861765, mean_q: 6.558098
152 (array([58]),) False
 181640/500000: episode: 4541, duration: 31.319s, episode steps: 40, steps per second: 1, episode reward: 15.517, mean reward: 0.388 [0.087, 0.711], mean action: 17.975 [2.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.257904, mean_absolute_error: 5.872549, mean_q: 6.573078
84 (array([22]),) False
 181680/500000: episode: 4542, duration: 31.006s, episode steps: 40, steps per second: 1, episode reward: 36.869, mean reward: 0.922 [0.121, 1.000], mean action: 21.950 [1.000, 37.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.262727, mean_absolute_error: 6.000081, mean_q: 6.707304
264 (array([12]),) False
 181720/500000: episode: 4543, duration: 31.366s, episode steps: 40, steps per second: 1, episode reward: 37.561, mean reward: 0.939 [0.337, 1.000], mean action: 21.700 [0.000, 54.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.254241, mean_absolute_error: 5.970187, mean_q: 6.686990
829 (array([21]),) False
 181760/500000: episode: 4544, duration: 31.226s, episode steps: 40, steps per second: 1, episode reward: 31.012, mean reward: 0.775 [0.390, 0.884], mean action: 17.850 [6.000, 22.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.268116, mean_absolute_error: 5.945334, mean_q: 6.659532
725 (array([36]),) False
 181800/500000: episode: 4545, duration: 31.745s, episode steps: 40, steps per second: 1, episode reward: 19.276, mean reward: 0.482 [0.129, 0.890], mean action: 28.100 [7.000, 55.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.308596, mean_absolute_error: 5.962097, mean_q: 6.677518
469 (array([22]),) False
 181840/500000: episode: 4546, duration: 31.438s, episode steps: 40, steps per second: 1, episode reward: 33.863, mean reward: 0.847 [0.006, 1.000], mean action: 21.850 [2.000, 60.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.312276, mean_absolute_error: 5.966667, mean_q: 6.676077
297 (array([15]),) False
 181880/500000: episode: 4547, duration: 31.728s, episode steps: 40, steps per second: 1, episode reward: 34.856, mean reward: 0.871 [0.000, 0.920], mean action: 22.550 [6.000, 60.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.279508, mean_absolute_error: 5.941777, mean_q: 6.645287
491 (array([22]),) False
 181920/500000: episode: 4548, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 35.716, mean reward: 0.893 [0.044, 1.000], mean action: 26.475 [3.000, 49.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.243547, mean_absolute_error: 5.931629, mean_q: 6.643906
355 (array([22]),) False
 181960/500000: episode: 4549, duration: 33.064s, episode steps: 40, steps per second: 1, episode reward: 36.697, mean reward: 0.917 [0.087, 1.000], mean action: 31.050 [14.000, 49.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.290502, mean_absolute_error: 5.976489, mean_q: 6.692032
365 (array([22]),) False
 182000/500000: episode: 4550, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 33.629, mean reward: 0.841 [0.109, 1.000], mean action: 20.750 [14.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.262506, mean_absolute_error: 5.956050, mean_q: 6.663135
132 (array([22]),) False
 182040/500000: episode: 4551, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 37.364, mean reward: 0.934 [0.090, 1.000], mean action: 20.325 [0.000, 22.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.281328, mean_absolute_error: 5.939403, mean_q: 6.645957
811 (array([33]),) False
 182080/500000: episode: 4552, duration: 32.977s, episode steps: 40, steps per second: 1, episode reward: 27.985, mean reward: 0.700 [0.160, 1.000], mean action: 30.925 [2.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.276891, mean_absolute_error: 6.056027, mean_q: 6.765265
412 (array([16]),) False
 182120/500000: episode: 4553, duration: 32.951s, episode steps: 40, steps per second: 1, episode reward: 33.944, mean reward: 0.849 [0.189, 0.925], mean action: 22.975 [6.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.291964, mean_absolute_error: 5.981063, mean_q: 6.688619
697 (array([22]),) False
 182160/500000: episode: 4554, duration: 32.114s, episode steps: 40, steps per second: 1, episode reward: 38.933, mean reward: 0.973 [0.183, 1.000], mean action: 20.025 [3.000, 22.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.257882, mean_absolute_error: 5.906057, mean_q: 6.610647
42 (array([22]),) False
 182200/500000: episode: 4555, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 37.930, mean reward: 0.948 [0.000, 1.000], mean action: 20.775 [1.000, 22.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.326814, mean_absolute_error: 5.996610, mean_q: 6.702702
197 (array([22]),) False
 182240/500000: episode: 4556, duration: 33.045s, episode steps: 40, steps per second: 1, episode reward: 37.694, mean reward: 0.942 [0.082, 1.000], mean action: 20.925 [2.000, 22.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.265543, mean_absolute_error: 5.974643, mean_q: 6.681790
607 (array([12]),) False
 182280/500000: episode: 4557, duration: 33.042s, episode steps: 40, steps per second: 1, episode reward: 35.022, mean reward: 0.876 [0.256, 1.000], mean action: 15.825 [1.000, 49.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.280812, mean_absolute_error: 5.954215, mean_q: 6.661490
481 (array([22]),) False
 182320/500000: episode: 4558, duration: 32.264s, episode steps: 40, steps per second: 1, episode reward: 34.223, mean reward: 0.856 [0.334, 1.000], mean action: 41.525 [22.000, 51.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.248517, mean_absolute_error: 5.896392, mean_q: 6.601933
848 (array([44]),) False
 182360/500000: episode: 4559, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 29.055, mean reward: 0.726 [0.493, 0.931], mean action: 24.900 [1.000, 60.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.247899, mean_absolute_error: 5.957753, mean_q: 6.671458
509 (array([22]),) False
 182400/500000: episode: 4560, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 38.890, mean reward: 0.972 [0.386, 1.000], mean action: 23.500 [22.000, 53.000], mean observation: -0.102 [-1.000, 1.000], loss: 0.283074, mean_absolute_error: 5.866075, mean_q: 6.579066
161 (array([22]),) False
 182440/500000: episode: 4561, duration: 33.099s, episode steps: 40, steps per second: 1, episode reward: 36.356, mean reward: 0.909 [0.382, 1.000], mean action: 14.725 [1.000, 22.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.259476, mean_absolute_error: 5.890134, mean_q: 6.600337
590 (array([22]),) False
 182480/500000: episode: 4562, duration: 32.222s, episode steps: 40, steps per second: 1, episode reward: 35.567, mean reward: 0.889 [0.043, 1.000], mean action: 17.050 [2.000, 33.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.270139, mean_absolute_error: 5.978683, mean_q: 6.690878
294 (array([22]),) False
 182520/500000: episode: 4563, duration: 33.019s, episode steps: 40, steps per second: 1, episode reward: 37.220, mean reward: 0.930 [0.000, 1.000], mean action: 22.075 [4.000, 32.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.307465, mean_absolute_error: 5.891287, mean_q: 6.593854
49 (array([22]),) False
 182560/500000: episode: 4564, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 36.278, mean reward: 0.907 [0.150, 1.000], mean action: 23.000 [16.000, 58.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.301701, mean_absolute_error: 5.957228, mean_q: 6.674225
280 (array([48]),) False
 182600/500000: episode: 4565, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 35.460, mean reward: 0.887 [0.206, 1.000], mean action: 21.800 [2.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.284267, mean_absolute_error: 5.909728, mean_q: 6.620795
1 (array([22]),) False
 182640/500000: episode: 4566, duration: 32.302s, episode steps: 40, steps per second: 1, episode reward: 29.665, mean reward: 0.742 [0.000, 1.000], mean action: 21.650 [4.000, 27.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.268551, mean_absolute_error: 5.921234, mean_q: 6.629316
290 (array([22]),) False
 182680/500000: episode: 4567, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 22.000 [22.000, 22.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.270913, mean_absolute_error: 5.895148, mean_q: 6.605103
295 (array([22]),) False
 182720/500000: episode: 4568, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 38.447, mean reward: 0.961 [0.324, 1.000], mean action: 22.750 [12.000, 49.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.251332, mean_absolute_error: 5.959428, mean_q: 6.667851
613 (array([22]),) False
 182760/500000: episode: 4569, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 38.493, mean reward: 0.962 [0.502, 1.000], mean action: 22.350 [12.000, 47.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.256566, mean_absolute_error: 5.986270, mean_q: 6.707335
646 (array([44]),) False
 182800/500000: episode: 4570, duration: 32.220s, episode steps: 40, steps per second: 1, episode reward: 10.287, mean reward: 0.257 [0.000, 1.000], mean action: 21.250 [3.000, 48.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.283981, mean_absolute_error: 6.041934, mean_q: 6.767442
110 (array([22]),) False
 182840/500000: episode: 4571, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 32.142, mean reward: 0.804 [0.136, 1.000], mean action: 22.675 [3.000, 55.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.245872, mean_absolute_error: 5.980098, mean_q: 6.698831
142 (array([12]),) False
 182880/500000: episode: 4572, duration: 33.104s, episode steps: 40, steps per second: 1, episode reward: 35.776, mean reward: 0.894 [0.053, 1.000], mean action: 16.075 [6.000, 60.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.291701, mean_absolute_error: 5.937976, mean_q: 6.651237
250 (array([22]),) False
 182920/500000: episode: 4573, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 39.160, mean reward: 0.979 [0.461, 1.000], mean action: 21.800 [15.000, 22.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.292272, mean_absolute_error: 6.059323, mean_q: 6.773040
859 (array([22]),) False
 182960/500000: episode: 4574, duration: 32.252s, episode steps: 40, steps per second: 1, episode reward: 33.163, mean reward: 0.829 [0.063, 1.000], mean action: 21.125 [11.000, 44.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.276967, mean_absolute_error: 6.002143, mean_q: 6.716956
319 (array([33]),) False
 183000/500000: episode: 4575, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 32.120, mean reward: 0.803 [0.337, 1.000], mean action: 21.275 [0.000, 23.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.268489, mean_absolute_error: 5.984780, mean_q: 6.702342
476 (array([48]),) False
 183040/500000: episode: 4576, duration: 33.146s, episode steps: 40, steps per second: 1, episode reward: 38.290, mean reward: 0.957 [0.369, 1.000], mean action: 25.775 [8.000, 48.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.252630, mean_absolute_error: 5.967021, mean_q: 6.687244
214 (array([22]),) False
 183080/500000: episode: 4577, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 37.051, mean reward: 0.926 [0.134, 1.000], mean action: 23.025 [7.000, 57.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.278046, mean_absolute_error: 6.030059, mean_q: 6.751985
1 (array([22]),) False
 183120/500000: episode: 4578, duration: 32.234s, episode steps: 40, steps per second: 1, episode reward: 32.476, mean reward: 0.812 [0.053, 1.000], mean action: 22.325 [3.000, 60.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.311696, mean_absolute_error: 6.000178, mean_q: 6.726044
585 (array([48]),) False
 183160/500000: episode: 4579, duration: 33.244s, episode steps: 40, steps per second: 1, episode reward: 37.396, mean reward: 0.935 [0.499, 0.960], mean action: 16.125 [7.000, 22.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.271264, mean_absolute_error: 5.982556, mean_q: 6.707488
612 (array([22]),) False
 183200/500000: episode: 4580, duration: 33.133s, episode steps: 40, steps per second: 1, episode reward: 34.911, mean reward: 0.873 [0.070, 1.000], mean action: 20.700 [12.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.296859, mean_absolute_error: 6.031797, mean_q: 6.752543
824 (array([22]),) False
 183240/500000: episode: 4581, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 34.461, mean reward: 0.862 [0.221, 1.000], mean action: 20.100 [1.000, 54.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.299486, mean_absolute_error: 6.098826, mean_q: 6.820433
103 (array([22]),) False
 183280/500000: episode: 4582, duration: 32.188s, episode steps: 40, steps per second: 1, episode reward: 31.832, mean reward: 0.796 [0.251, 1.000], mean action: 22.100 [12.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.288096, mean_absolute_error: 5.985399, mean_q: 6.701639
41 (array([12]),) False
 183320/500000: episode: 4583, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 31.295, mean reward: 0.782 [0.179, 1.000], mean action: 23.825 [3.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.255526, mean_absolute_error: 5.930637, mean_q: 6.641590
447 (array([44]),) False
 183360/500000: episode: 4584, duration: 33.143s, episode steps: 40, steps per second: 1, episode reward: 29.908, mean reward: 0.748 [0.024, 1.000], mean action: 24.225 [10.000, 49.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.292138, mean_absolute_error: 6.056612, mean_q: 6.766693
731 (array([21]),) False
 183400/500000: episode: 4585, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 33.150, mean reward: 0.829 [0.190, 1.000], mean action: 34.725 [7.000, 58.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.282107, mean_absolute_error: 5.948622, mean_q: 6.652987
507 (array([44]),) False
 183440/500000: episode: 4586, duration: 32.219s, episode steps: 40, steps per second: 1, episode reward: 32.041, mean reward: 0.801 [0.186, 0.988], mean action: 20.725 [1.000, 38.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.279082, mean_absolute_error: 6.019695, mean_q: 6.741134
829 (array([21]),) False
 183480/500000: episode: 4587, duration: 33.155s, episode steps: 40, steps per second: 1, episode reward: 30.998, mean reward: 0.775 [0.281, 0.884], mean action: 18.000 [10.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.244578, mean_absolute_error: 5.978437, mean_q: 6.696921
438 (array([22]),) False
 183520/500000: episode: 4588, duration: 33.097s, episode steps: 40, steps per second: 1, episode reward: 38.492, mean reward: 0.962 [0.177, 1.000], mean action: 22.375 [9.000, 52.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.262671, mean_absolute_error: 6.005692, mean_q: 6.727300
554 (array([22]),) False
 183560/500000: episode: 4589, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 36.580, mean reward: 0.915 [0.087, 1.000], mean action: 18.575 [0.000, 37.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.258904, mean_absolute_error: 6.000990, mean_q: 6.729268
519 (array([58]),) False
 183600/500000: episode: 4590, duration: 32.240s, episode steps: 40, steps per second: 1, episode reward: 27.656, mean reward: 0.691 [0.321, 0.778], mean action: 23.025 [3.000, 51.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.282805, mean_absolute_error: 5.948430, mean_q: 6.675878
464 (array([22]),) False
 183640/500000: episode: 4591, duration: 33.123s, episode steps: 40, steps per second: 1, episode reward: 38.417, mean reward: 0.960 [0.217, 1.000], mean action: 23.100 [16.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.285000, mean_absolute_error: 5.990786, mean_q: 6.719750
264 (array([12]),) False
 183680/500000: episode: 4592, duration: 33.072s, episode steps: 40, steps per second: 1, episode reward: 38.037, mean reward: 0.951 [0.050, 1.000], mean action: 20.900 [1.000, 29.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.258928, mean_absolute_error: 5.982290, mean_q: 6.702666
267 (array([22]),) False
 183720/500000: episode: 4593, duration: 33.098s, episode steps: 40, steps per second: 1, episode reward: 33.702, mean reward: 0.843 [0.200, 1.000], mean action: 19.875 [12.000, 36.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.263717, mean_absolute_error: 6.015590, mean_q: 6.733946
36 (array([22]),) False
 183760/500000: episode: 4594, duration: 32.284s, episode steps: 40, steps per second: 1, episode reward: 32.372, mean reward: 0.809 [0.000, 1.000], mean action: 24.675 [4.000, 55.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.315353, mean_absolute_error: 6.023917, mean_q: 6.736271
211 (array([22]),) False
 183800/500000: episode: 4595, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 35.864, mean reward: 0.897 [0.060, 1.000], mean action: 21.975 [3.000, 52.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.293145, mean_absolute_error: 6.006155, mean_q: 6.715281
344 (array([22]),) False
 183840/500000: episode: 4596, duration: 32.953s, episode steps: 40, steps per second: 1, episode reward: 38.190, mean reward: 0.955 [0.245, 1.000], mean action: 23.525 [12.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.278651, mean_absolute_error: 5.998332, mean_q: 6.713319
236 (array([22]),) False
 183880/500000: episode: 4597, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 37.603, mean reward: 0.940 [0.160, 1.000], mean action: 20.850 [3.000, 44.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.242605, mean_absolute_error: 6.008715, mean_q: 6.723147
643 (array([44]),) False
 183920/500000: episode: 4598, duration: 32.219s, episode steps: 40, steps per second: 1, episode reward: 33.877, mean reward: 0.847 [0.372, 1.000], mean action: 25.550 [13.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.261859, mean_absolute_error: 5.988826, mean_q: 6.701833
380 (array([22]),) False
 183960/500000: episode: 4599, duration: 33.129s, episode steps: 40, steps per second: 1, episode reward: 38.217, mean reward: 0.955 [0.081, 1.000], mean action: 23.125 [2.000, 60.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.283895, mean_absolute_error: 5.997340, mean_q: 6.721291
119 (array([45]),) False
 184000/500000: episode: 4600, duration: 33.061s, episode steps: 40, steps per second: 1, episode reward: 36.441, mean reward: 0.911 [0.675, 1.000], mean action: 22.575 [22.000, 45.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.295695, mean_absolute_error: 5.953390, mean_q: 6.671930
555 (array([22]),) False
 184040/500000: episode: 4601, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 34.885, mean reward: 0.872 [0.053, 1.000], mean action: 17.775 [6.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.303529, mean_absolute_error: 6.025186, mean_q: 6.737007
510 (array([22]),) False
 184080/500000: episode: 4602, duration: 32.209s, episode steps: 40, steps per second: 1, episode reward: 33.483, mean reward: 0.837 [0.094, 1.000], mean action: 16.400 [0.000, 32.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.308557, mean_absolute_error: 5.966413, mean_q: 6.672999
733 (array([22]),) False
 184120/500000: episode: 4603, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 33.829, mean reward: 0.846 [0.129, 1.000], mean action: 30.275 [12.000, 54.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.270694, mean_absolute_error: 6.000237, mean_q: 6.710000
558 (array([40]),) False
 184160/500000: episode: 4604, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 32.728, mean reward: 0.818 [0.376, 1.000], mean action: 21.200 [6.000, 47.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.252873, mean_absolute_error: 6.014987, mean_q: 6.722473
811 (array([33]),) False
 184200/500000: episode: 4605, duration: 33.093s, episode steps: 40, steps per second: 1, episode reward: 28.475, mean reward: 0.712 [0.186, 1.000], mean action: 29.150 [8.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.281891, mean_absolute_error: 5.988544, mean_q: 6.692256
88 (array([22]),) False
 184240/500000: episode: 4606, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 36.211, mean reward: 0.905 [0.235, 1.000], mean action: 23.650 [11.000, 47.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.244575, mean_absolute_error: 5.939177, mean_q: 6.648383
42 (array([22]),) False
 184280/500000: episode: 4607, duration: 32.178s, episode steps: 40, steps per second: 1, episode reward: 35.558, mean reward: 0.889 [0.097, 1.000], mean action: 24.950 [1.000, 60.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.264985, mean_absolute_error: 5.956336, mean_q: 6.667211
493 (array([22]),) False
 184320/500000: episode: 4608, duration: 31.714s, episode steps: 40, steps per second: 1, episode reward: 37.111, mean reward: 0.928 [0.238, 1.000], mean action: 19.600 [5.000, 60.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.245128, mean_absolute_error: 5.988762, mean_q: 6.695723
837 (array([48]),) False
 184360/500000: episode: 4609, duration: 31.392s, episode steps: 40, steps per second: 1, episode reward: 37.331, mean reward: 0.933 [0.300, 0.975], mean action: 23.900 [12.000, 56.000], mean observation: -0.112 [-1.000, 1.000], loss: 0.286706, mean_absolute_error: 6.030746, mean_q: 6.741971
769 (array([12]),) False
 184400/500000: episode: 4610, duration: 30.935s, episode steps: 40, steps per second: 1, episode reward: 33.915, mean reward: 0.848 [0.359, 1.000], mean action: 23.375 [0.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.272645, mean_absolute_error: 5.976191, mean_q: 6.684117
78 (array([55]),) False
 184440/500000: episode: 4611, duration: 31.375s, episode steps: 40, steps per second: 1, episode reward: 34.096, mean reward: 0.852 [0.282, 1.000], mean action: 21.425 [4.000, 44.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.291939, mean_absolute_error: 6.024312, mean_q: 6.731032
503 (array([3]),) False
 184480/500000: episode: 4612, duration: 31.418s, episode steps: 40, steps per second: 1, episode reward: 12.200, mean reward: 0.305 [0.159, 0.591], mean action: 22.550 [5.000, 56.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.284610, mean_absolute_error: 5.952176, mean_q: 6.644444
521 (array([22]),) False
 184520/500000: episode: 4613, duration: 31.412s, episode steps: 40, steps per second: 1, episode reward: 37.293, mean reward: 0.932 [0.039, 1.000], mean action: 16.575 [10.000, 42.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.305582, mean_absolute_error: 5.920364, mean_q: 6.614174
545 (array([22]),) False
 184560/500000: episode: 4614, duration: 31.417s, episode steps: 40, steps per second: 1, episode reward: 37.342, mean reward: 0.934 [0.437, 1.000], mean action: 21.400 [12.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.249013, mean_absolute_error: 5.895213, mean_q: 6.592116
373 (array([22]),) False
 184600/500000: episode: 4615, duration: 33.082s, episode steps: 40, steps per second: 1, episode reward: 34.609, mean reward: 0.865 [0.381, 1.000], mean action: 20.300 [12.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.289257, mean_absolute_error: 5.995585, mean_q: 6.700469
426 (array([22]),) False
 184640/500000: episode: 4616, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 34.112, mean reward: 0.853 [0.187, 1.000], mean action: 24.900 [2.000, 58.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.312194, mean_absolute_error: 5.906232, mean_q: 6.606318
242 (array([22]),) False
 184680/500000: episode: 4617, duration: 33.017s, episode steps: 40, steps per second: 1, episode reward: 37.881, mean reward: 0.947 [0.107, 1.000], mean action: 22.175 [4.000, 49.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.306761, mean_absolute_error: 5.945108, mean_q: 6.639094
707 (array([48]),) False
 184720/500000: episode: 4618, duration: 32.101s, episode steps: 40, steps per second: 1, episode reward: 30.734, mean reward: 0.768 [0.082, 0.943], mean action: 17.400 [3.000, 35.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.270380, mean_absolute_error: 5.963429, mean_q: 6.668260
223 (array([48]),) False
 184760/500000: episode: 4619, duration: 33.157s, episode steps: 40, steps per second: 1, episode reward: 30.029, mean reward: 0.751 [0.044, 0.854], mean action: 20.925 [0.000, 40.000], mean observation: -0.195 [-1.000, 1.000], loss: 0.281075, mean_absolute_error: 6.001581, mean_q: 6.710236
137 (array([22]),) False
 184800/500000: episode: 4620, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 34.139, mean reward: 0.853 [0.215, 1.000], mean action: 24.975 [0.000, 55.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.304187, mean_absolute_error: 5.993528, mean_q: 6.703983
422 (array([48]),) False
 184840/500000: episode: 4621, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 36.552, mean reward: 0.914 [0.044, 1.000], mean action: 25.300 [18.000, 60.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.263404, mean_absolute_error: 5.911425, mean_q: 6.617793
647 (array([22]),) False
 184880/500000: episode: 4622, duration: 32.218s, episode steps: 40, steps per second: 1, episode reward: 37.552, mean reward: 0.939 [0.144, 1.000], mean action: 21.150 [3.000, 43.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.248799, mean_absolute_error: 5.959922, mean_q: 6.669536
835 (array([50]),) False
 184920/500000: episode: 4623, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 33.508, mean reward: 0.838 [0.000, 1.000], mean action: 25.850 [12.000, 58.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.255920, mean_absolute_error: 5.983326, mean_q: 6.691157
454 (array([12]),) False
 184960/500000: episode: 4624, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 29.002, mean reward: 0.725 [0.032, 0.890], mean action: 24.575 [10.000, 60.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.269670, mean_absolute_error: 5.980240, mean_q: 6.686341
596 (array([22]),) False
 185000/500000: episode: 4625, duration: 32.026s, episode steps: 40, steps per second: 1, episode reward: 34.978, mean reward: 0.874 [0.284, 1.000], mean action: 15.675 [8.000, 22.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.244279, mean_absolute_error: 5.937788, mean_q: 6.649402
631 (array([22]),) False
 185040/500000: episode: 4626, duration: 30.286s, episode steps: 40, steps per second: 1, episode reward: 38.416, mean reward: 0.960 [0.272, 1.000], mean action: 20.425 [0.000, 22.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.256875, mean_absolute_error: 5.919045, mean_q: 6.632329
194 (array([44]),) False
 185080/500000: episode: 4627, duration: 31.213s, episode steps: 40, steps per second: 1, episode reward: 26.908, mean reward: 0.673 [0.523, 0.844], mean action: 21.225 [0.000, 49.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.270068, mean_absolute_error: 5.955167, mean_q: 6.664219
606 (array([22]),) False
 185120/500000: episode: 4628, duration: 31.185s, episode steps: 40, steps per second: 1, episode reward: 35.336, mean reward: 0.883 [0.038, 1.000], mean action: 14.750 [5.000, 56.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.284409, mean_absolute_error: 5.947029, mean_q: 6.659577
404 (array([12]),) False
 185160/500000: episode: 4629, duration: 31.131s, episode steps: 40, steps per second: 1, episode reward: 32.575, mean reward: 0.814 [0.536, 1.000], mean action: 20.000 [12.000, 30.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.285455, mean_absolute_error: 5.927269, mean_q: 6.640141
437 (array([12]),) False
 185200/500000: episode: 4630, duration: 30.264s, episode steps: 40, steps per second: 1, episode reward: 34.949, mean reward: 0.874 [0.238, 0.974], mean action: 23.375 [1.000, 60.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.231310, mean_absolute_error: 5.963982, mean_q: 6.677068
372 (array([22]),) False
 185240/500000: episode: 4631, duration: 31.244s, episode steps: 40, steps per second: 1, episode reward: 33.689, mean reward: 0.842 [0.167, 1.000], mean action: 20.075 [12.000, 60.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.256064, mean_absolute_error: 5.998605, mean_q: 6.708846
347 (array([22]),) False
 185280/500000: episode: 4632, duration: 31.100s, episode steps: 40, steps per second: 1, episode reward: 31.176, mean reward: 0.779 [0.132, 0.842], mean action: 12.925 [4.000, 46.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.284230, mean_absolute_error: 5.940577, mean_q: 6.650937
2 (array([12]),) False
 185320/500000: episode: 4633, duration: 31.127s, episode steps: 40, steps per second: 1, episode reward: 29.584, mean reward: 0.740 [0.177, 0.832], mean action: 21.100 [0.000, 26.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.299856, mean_absolute_error: 5.954400, mean_q: 6.665120
788 (array([3]),) False
 185360/500000: episode: 4634, duration: 30.329s, episode steps: 40, steps per second: 1, episode reward: 16.359, mean reward: 0.409 [0.052, 1.000], mean action: 26.775 [3.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.274429, mean_absolute_error: 5.949904, mean_q: 6.658765
645 (array([48]),) False
 185400/500000: episode: 4635, duration: 31.245s, episode steps: 40, steps per second: 1, episode reward: 35.230, mean reward: 0.881 [0.431, 0.920], mean action: 20.850 [0.000, 38.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.244848, mean_absolute_error: 5.971279, mean_q: 6.672914
833 (array([22]),) False
 185440/500000: episode: 4636, duration: 31.098s, episode steps: 40, steps per second: 1, episode reward: 33.334, mean reward: 0.833 [0.090, 1.000], mean action: 15.700 [6.000, 51.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.270424, mean_absolute_error: 5.934298, mean_q: 6.638803
92 (array([22]),) False
 185480/500000: episode: 4637, duration: 31.148s, episode steps: 40, steps per second: 1, episode reward: 38.404, mean reward: 0.960 [0.304, 1.000], mean action: 22.150 [12.000, 33.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.263262, mean_absolute_error: 5.877241, mean_q: 6.582143
491 (array([22]),) False
 185520/500000: episode: 4638, duration: 30.349s, episode steps: 40, steps per second: 1, episode reward: 37.122, mean reward: 0.928 [0.301, 1.000], mean action: 24.850 [21.000, 49.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.238700, mean_absolute_error: 5.908026, mean_q: 6.616751
437 (array([12]),) False
 185560/500000: episode: 4639, duration: 31.170s, episode steps: 40, steps per second: 1, episode reward: 35.986, mean reward: 0.900 [0.084, 0.967], mean action: 22.875 [22.000, 57.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.244947, mean_absolute_error: 5.915098, mean_q: 6.627129
733 (array([22]),) False
 185600/500000: episode: 4640, duration: 31.138s, episode steps: 40, steps per second: 1, episode reward: 38.252, mean reward: 0.956 [0.454, 1.000], mean action: 23.175 [12.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.230983, mean_absolute_error: 5.904009, mean_q: 6.612767
857 (array([22]),) False
 185640/500000: episode: 4641, duration: 31.210s, episode steps: 40, steps per second: 1, episode reward: 35.184, mean reward: 0.880 [0.499, 1.000], mean action: 21.325 [12.000, 48.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.249447, mean_absolute_error: 5.914418, mean_q: 6.623522
288 (array([33]),) False
 185680/500000: episode: 4642, duration: 30.277s, episode steps: 40, steps per second: 1, episode reward: 22.890, mean reward: 0.572 [0.188, 1.000], mean action: 22.225 [12.000, 42.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.245826, mean_absolute_error: 5.962234, mean_q: 6.667527
55 (array([22]),) False
 185720/500000: episode: 4643, duration: 31.199s, episode steps: 40, steps per second: 1, episode reward: 34.146, mean reward: 0.854 [0.102, 1.000], mean action: 22.200 [2.000, 57.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.276999, mean_absolute_error: 5.933932, mean_q: 6.631979
324 (array([12]),) False
 185760/500000: episode: 4644, duration: 31.212s, episode steps: 40, steps per second: 1, episode reward: 36.484, mean reward: 0.912 [0.129, 1.000], mean action: 22.000 [3.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.290746, mean_absolute_error: 5.974488, mean_q: 6.683140
628 (array([22]),) False
 185800/500000: episode: 4645, duration: 31.207s, episode steps: 40, steps per second: 1, episode reward: 38.220, mean reward: 0.956 [0.416, 1.000], mean action: 22.300 [9.000, 38.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.264430, mean_absolute_error: 5.986736, mean_q: 6.704727
410 (array([22]),) False
 185840/500000: episode: 4646, duration: 30.305s, episode steps: 40, steps per second: 1, episode reward: 37.889, mean reward: 0.947 [0.149, 1.000], mean action: 23.650 [22.000, 60.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.264534, mean_absolute_error: 5.989945, mean_q: 6.702728
100 (array([22]),) False
 185880/500000: episode: 4647, duration: 31.180s, episode steps: 40, steps per second: 1, episode reward: 36.762, mean reward: 0.919 [0.000, 1.000], mean action: 23.075 [10.000, 53.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.263861, mean_absolute_error: 5.998209, mean_q: 6.707719
182 (array([54]),) False
 185920/500000: episode: 4648, duration: 31.133s, episode steps: 40, steps per second: 1, episode reward: 33.253, mean reward: 0.831 [0.278, 1.000], mean action: 33.275 [3.000, 54.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.257039, mean_absolute_error: 6.000913, mean_q: 6.712836
74 (array([22]),) False
 185960/500000: episode: 4649, duration: 31.094s, episode steps: 40, steps per second: 1, episode reward: 36.696, mean reward: 0.917 [0.322, 1.000], mean action: 21.975 [1.000, 51.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.266082, mean_absolute_error: 6.051398, mean_q: 6.769393
616 (array([22]),) False
 186000/500000: episode: 4650, duration: 30.309s, episode steps: 40, steps per second: 1, episode reward: 33.914, mean reward: 0.848 [0.352, 1.000], mean action: 18.875 [12.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.256630, mean_absolute_error: 5.989787, mean_q: 6.713895
0 (array([48]),) False
 186040/500000: episode: 4651, duration: 31.273s, episode steps: 40, steps per second: 1, episode reward: 35.672, mean reward: 0.892 [0.255, 1.000], mean action: 23.100 [22.000, 48.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.275198, mean_absolute_error: 5.944932, mean_q: 6.658811
22 (array([37]),) False
 186080/500000: episode: 4652, duration: 31.125s, episode steps: 40, steps per second: 1, episode reward: 28.071, mean reward: 0.702 [0.119, 0.807], mean action: 29.825 [2.000, 49.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.248651, mean_absolute_error: 5.922496, mean_q: 6.641942
250 (array([22]),) False
 186120/500000: episode: 4653, duration: 31.094s, episode steps: 40, steps per second: 1, episode reward: 36.524, mean reward: 0.913 [0.288, 1.000], mean action: 22.950 [3.000, 59.000], mean observation: -0.109 [-1.000, 1.000], loss: 0.269930, mean_absolute_error: 5.965335, mean_q: 6.686525
736 (array([22]),) False
 186160/500000: episode: 4654, duration: 30.258s, episode steps: 40, steps per second: 1, episode reward: 37.661, mean reward: 0.942 [0.701, 1.000], mean action: 37.000 [12.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.276820, mean_absolute_error: 5.980969, mean_q: 6.697891
639 (array([22]),) False
 186200/500000: episode: 4655, duration: 31.203s, episode steps: 40, steps per second: 1, episode reward: 34.737, mean reward: 0.868 [0.000, 1.000], mean action: 18.475 [1.000, 37.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.256061, mean_absolute_error: 5.963416, mean_q: 6.687026
682 (array([22]),) False
 186240/500000: episode: 4656, duration: 31.220s, episode steps: 40, steps per second: 1, episode reward: 36.530, mean reward: 0.913 [0.231, 1.000], mean action: 18.350 [12.000, 47.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.245317, mean_absolute_error: 5.972702, mean_q: 6.692441
546 (array([22]),) False
 186280/500000: episode: 4657, duration: 31.188s, episode steps: 40, steps per second: 1, episode reward: 37.445, mean reward: 0.936 [0.294, 1.000], mean action: 18.075 [1.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.257591, mean_absolute_error: 6.012547, mean_q: 6.731672
858 (array([12]),) False
 186320/500000: episode: 4658, duration: 30.223s, episode steps: 40, steps per second: 1, episode reward: 35.739, mean reward: 0.893 [0.286, 1.000], mean action: 16.725 [0.000, 22.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.293428, mean_absolute_error: 6.026846, mean_q: 6.742700
808 (array([22]),) False
 186360/500000: episode: 4659, duration: 31.175s, episode steps: 40, steps per second: 1, episode reward: 33.856, mean reward: 0.846 [0.163, 1.000], mean action: 34.225 [1.000, 53.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.274135, mean_absolute_error: 6.036134, mean_q: 6.752120
468 (array([22]),) False
 186400/500000: episode: 4660, duration: 31.163s, episode steps: 40, steps per second: 1, episode reward: 37.542, mean reward: 0.939 [0.043, 1.000], mean action: 22.650 [10.000, 57.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.263363, mean_absolute_error: 6.086526, mean_q: 6.804045
714 (array([22]),) False
 186440/500000: episode: 4661, duration: 31.151s, episode steps: 40, steps per second: 1, episode reward: 36.930, mean reward: 0.923 [0.019, 1.000], mean action: 20.950 [12.000, 58.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.284502, mean_absolute_error: 5.944683, mean_q: 6.657073
700 (array([44]),) False
 186480/500000: episode: 4662, duration: 30.392s, episode steps: 40, steps per second: 1, episode reward: 31.521, mean reward: 0.788 [0.479, 1.000], mean action: 23.975 [0.000, 44.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.251996, mean_absolute_error: 5.944497, mean_q: 6.655370
227 (array([22]),) False
 186520/500000: episode: 4663, duration: 31.229s, episode steps: 40, steps per second: 1, episode reward: 36.259, mean reward: 0.906 [0.006, 1.000], mean action: 22.850 [12.000, 60.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.271720, mean_absolute_error: 5.981812, mean_q: 6.707970
630 (array([22]),) False
 186560/500000: episode: 4664, duration: 31.076s, episode steps: 40, steps per second: 1, episode reward: 38.453, mean reward: 0.961 [0.399, 1.000], mean action: 22.975 [14.000, 52.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.292019, mean_absolute_error: 6.036373, mean_q: 6.766509
68 (array([22]),) False
 186600/500000: episode: 4665, duration: 31.150s, episode steps: 40, steps per second: 1, episode reward: 35.305, mean reward: 0.883 [0.130, 1.000], mean action: 19.950 [10.000, 39.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.262132, mean_absolute_error: 5.998282, mean_q: 6.721433
717 (array([22]),) False
 186640/500000: episode: 4666, duration: 30.279s, episode steps: 40, steps per second: 1, episode reward: 33.330, mean reward: 0.833 [0.282, 1.000], mean action: 21.950 [4.000, 55.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.289334, mean_absolute_error: 5.972338, mean_q: 6.694121
121 (array([22]),) False
 186680/500000: episode: 4667, duration: 31.244s, episode steps: 40, steps per second: 1, episode reward: 35.081, mean reward: 0.877 [0.187, 1.000], mean action: 19.725 [11.000, 49.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.259145, mean_absolute_error: 6.003600, mean_q: 6.735845
798 (array([18]),) False
 186720/500000: episode: 4668, duration: 31.134s, episode steps: 40, steps per second: 1, episode reward: 34.525, mean reward: 0.863 [0.270, 0.993], mean action: 19.500 [3.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.255851, mean_absolute_error: 5.981669, mean_q: 6.698307
407 (array([22]),) False
 186760/500000: episode: 4669, duration: 31.093s, episode steps: 40, steps per second: 1, episode reward: 38.677, mean reward: 0.967 [0.219, 1.000], mean action: 23.400 [22.000, 54.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.284401, mean_absolute_error: 5.972923, mean_q: 6.688264
814 (array([22]),) False
 186800/500000: episode: 4670, duration: 30.274s, episode steps: 40, steps per second: 1, episode reward: 37.207, mean reward: 0.930 [0.595, 1.000], mean action: 24.325 [12.000, 54.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.267480, mean_absolute_error: 6.075930, mean_q: 6.810600
348 (array([22]),) False
 186840/500000: episode: 4671, duration: 31.117s, episode steps: 40, steps per second: 1, episode reward: 38.134, mean reward: 0.953 [0.416, 1.000], mean action: 24.400 [16.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.259719, mean_absolute_error: 5.932990, mean_q: 6.659069
471 (array([12]),) False
 186880/500000: episode: 4672, duration: 31.164s, episode steps: 40, steps per second: 1, episode reward: 31.421, mean reward: 0.786 [0.139, 1.000], mean action: 24.375 [1.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.277542, mean_absolute_error: 5.971306, mean_q: 6.685670
317 (array([12]),) False
 186920/500000: episode: 4673, duration: 31.058s, episode steps: 40, steps per second: 1, episode reward: 31.181, mean reward: 0.780 [0.191, 1.000], mean action: 22.250 [7.000, 47.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.288225, mean_absolute_error: 5.986413, mean_q: 6.702145
440 (array([22]),) False
 186960/500000: episode: 4674, duration: 30.209s, episode steps: 40, steps per second: 1, episode reward: 36.522, mean reward: 0.913 [0.167, 1.000], mean action: 24.850 [3.000, 49.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.286210, mean_absolute_error: 5.941720, mean_q: 6.652808
399 (array([22]),) False
 187000/500000: episode: 4675, duration: 31.096s, episode steps: 40, steps per second: 1, episode reward: 32.176, mean reward: 0.804 [0.010, 1.000], mean action: 21.025 [1.000, 39.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.268938, mean_absolute_error: 5.951301, mean_q: 6.664784
129 (array([22]),) False
 187040/500000: episode: 4676, duration: 31.061s, episode steps: 40, steps per second: 1, episode reward: 35.766, mean reward: 0.894 [0.221, 1.000], mean action: 23.025 [15.000, 60.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.260754, mean_absolute_error: 5.890625, mean_q: 6.595005
742 (array([33]),) False
 187080/500000: episode: 4677, duration: 31.130s, episode steps: 40, steps per second: 1, episode reward: 25.342, mean reward: 0.634 [0.189, 0.888], mean action: 20.125 [12.000, 49.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.255534, mean_absolute_error: 5.961938, mean_q: 6.669047
277 (array([56]),) False
 187120/500000: episode: 4678, duration: 30.350s, episode steps: 40, steps per second: 1, episode reward: 29.658, mean reward: 0.741 [0.295, 0.873], mean action: 21.950 [12.000, 51.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.229914, mean_absolute_error: 5.949991, mean_q: 6.656992
3 (array([48]),) False
 187160/500000: episode: 4679, duration: 31.164s, episode steps: 40, steps per second: 1, episode reward: 34.667, mean reward: 0.867 [0.093, 1.000], mean action: 22.375 [3.000, 48.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.251037, mean_absolute_error: 5.953176, mean_q: 6.658493
840 (array([12]),) False
 187200/500000: episode: 4680, duration: 31.202s, episode steps: 40, steps per second: 1, episode reward: 30.966, mean reward: 0.774 [0.174, 1.000], mean action: 22.700 [3.000, 56.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.267989, mean_absolute_error: 5.904325, mean_q: 6.611581
357 (array([22]),) False
 187240/500000: episode: 4681, duration: 31.106s, episode steps: 40, steps per second: 1, episode reward: 28.504, mean reward: 0.713 [0.016, 1.000], mean action: 24.050 [10.000, 56.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.254859, mean_absolute_error: 5.840539, mean_q: 6.542090
202 (array([22]),) False
 187280/500000: episode: 4682, duration: 30.297s, episode steps: 40, steps per second: 1, episode reward: 34.285, mean reward: 0.857 [0.107, 1.000], mean action: 23.300 [1.000, 55.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.259674, mean_absolute_error: 5.907577, mean_q: 6.624742
695 (array([22]),) False
 187320/500000: episode: 4683, duration: 31.175s, episode steps: 40, steps per second: 1, episode reward: 36.709, mean reward: 0.918 [0.018, 1.000], mean action: 23.650 [6.000, 44.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.245035, mean_absolute_error: 5.846354, mean_q: 6.557466
624 (array([48]),) False
 187360/500000: episode: 4684, duration: 31.107s, episode steps: 40, steps per second: 1, episode reward: 33.692, mean reward: 0.842 [0.145, 1.000], mean action: 30.000 [3.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.247938, mean_absolute_error: 5.852750, mean_q: 6.566916
592 (array([22]),) False
 187400/500000: episode: 4685, duration: 31.132s, episode steps: 40, steps per second: 1, episode reward: 30.694, mean reward: 0.767 [0.433, 1.000], mean action: 15.150 [12.000, 42.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.262225, mean_absolute_error: 5.862685, mean_q: 6.570058
838 (array([21]),) False
 187440/500000: episode: 4686, duration: 30.330s, episode steps: 40, steps per second: 1, episode reward: 31.026, mean reward: 0.776 [0.002, 1.000], mean action: 26.850 [12.000, 60.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.265927, mean_absolute_error: 5.808396, mean_q: 6.506711
271 (array([18]),) False
 187480/500000: episode: 4687, duration: 31.200s, episode steps: 40, steps per second: 1, episode reward: 34.836, mean reward: 0.871 [0.329, 1.000], mean action: 25.550 [21.000, 60.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.274347, mean_absolute_error: 5.851149, mean_q: 6.549770
2 (array([12]),) False
 187520/500000: episode: 4688, duration: 31.128s, episode steps: 40, steps per second: 1, episode reward: 28.910, mean reward: 0.723 [0.088, 1.000], mean action: 21.600 [3.000, 28.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.252982, mean_absolute_error: 5.816537, mean_q: 6.509122
685 (array([22]),) False
 187560/500000: episode: 4689, duration: 31.106s, episode steps: 40, steps per second: 1, episode reward: 36.400, mean reward: 0.910 [0.022, 1.000], mean action: 14.325 [12.000, 49.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.269718, mean_absolute_error: 5.859442, mean_q: 6.555659
17 (array([22]),) False
 187600/500000: episode: 4690, duration: 30.273s, episode steps: 40, steps per second: 1, episode reward: 36.666, mean reward: 0.917 [0.000, 1.000], mean action: 23.775 [10.000, 53.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.255095, mean_absolute_error: 5.770115, mean_q: 6.468051
72 (array([12]),) False
 187640/500000: episode: 4691, duration: 31.130s, episode steps: 40, steps per second: 1, episode reward: 37.654, mean reward: 0.941 [0.222, 1.000], mean action: 22.900 [12.000, 54.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.278449, mean_absolute_error: 5.784969, mean_q: 6.484160
169 (array([22]),) False
 187680/500000: episode: 4692, duration: 31.096s, episode steps: 40, steps per second: 1, episode reward: 36.606, mean reward: 0.915 [0.447, 1.000], mean action: 17.625 [12.000, 48.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.260590, mean_absolute_error: 5.717062, mean_q: 6.416388
811 (array([33]),) False
 187720/500000: episode: 4693, duration: 31.062s, episode steps: 40, steps per second: 1, episode reward: 31.637, mean reward: 0.791 [0.131, 1.000], mean action: 26.875 [12.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.254581, mean_absolute_error: 5.774642, mean_q: 6.479750
625 (array([22]),) False
 187760/500000: episode: 4694, duration: 30.271s, episode steps: 40, steps per second: 1, episode reward: 35.446, mean reward: 0.886 [0.063, 1.000], mean action: 23.550 [6.000, 56.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.239148, mean_absolute_error: 5.800701, mean_q: 6.502370
7 (array([22]),) False
 187800/500000: episode: 4695, duration: 31.042s, episode steps: 40, steps per second: 1, episode reward: 37.009, mean reward: 0.925 [0.164, 1.000], mean action: 24.400 [15.000, 56.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.261823, mean_absolute_error: 5.852002, mean_q: 6.552183
809 (array([48]),) False
 187840/500000: episode: 4696, duration: 30.588s, episode steps: 40, steps per second: 1, episode reward: 34.221, mean reward: 0.856 [0.649, 1.000], mean action: 31.050 [5.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.265271, mean_absolute_error: 5.815187, mean_q: 6.508633
845 (array([22]),) False
 187880/500000: episode: 4697, duration: 30.410s, episode steps: 40, steps per second: 1, episode reward: 35.070, mean reward: 0.877 [0.102, 1.000], mean action: 29.150 [1.000, 57.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.248073, mean_absolute_error: 5.759885, mean_q: 6.451942
318 (array([48]),) False
 187920/500000: episode: 4698, duration: 29.969s, episode steps: 40, steps per second: 1, episode reward: 37.683, mean reward: 0.942 [0.015, 1.000], mean action: 22.975 [22.000, 56.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.255331, mean_absolute_error: 5.833161, mean_q: 6.527778
742 (array([33]),) False
 187960/500000: episode: 4699, duration: 30.614s, episode steps: 40, steps per second: 1, episode reward: 25.673, mean reward: 0.642 [0.221, 0.903], mean action: 16.200 [12.000, 53.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.243865, mean_absolute_error: 5.778985, mean_q: 6.476257
156 (array([22]),) False
 188000/500000: episode: 4700, duration: 31.113s, episode steps: 40, steps per second: 1, episode reward: 33.059, mean reward: 0.826 [0.016, 1.000], mean action: 20.600 [12.000, 58.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.267339, mean_absolute_error: 5.826869, mean_q: 6.527930
790 (array([48]),) False
 188040/500000: episode: 4701, duration: 31.160s, episode steps: 40, steps per second: 1, episode reward: 36.373, mean reward: 0.909 [0.105, 1.000], mean action: 41.200 [15.000, 54.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.277422, mean_absolute_error: 5.813244, mean_q: 6.519922
162 (array([22]),) False
 188080/500000: episode: 4702, duration: 30.286s, episode steps: 40, steps per second: 1, episode reward: 34.599, mean reward: 0.865 [0.269, 1.000], mean action: 25.050 [2.000, 60.000], mean observation: -0.164 [-1.000, 1.000], loss: 0.275684, mean_absolute_error: 5.881568, mean_q: 6.595595
42 (array([22]),) False
 188120/500000: episode: 4703, duration: 31.145s, episode steps: 40, steps per second: 1, episode reward: 36.297, mean reward: 0.907 [0.213, 1.000], mean action: 23.625 [21.000, 38.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.233549, mean_absolute_error: 5.885896, mean_q: 6.595997
604 (array([40]),) False
 188160/500000: episode: 4704, duration: 31.140s, episode steps: 40, steps per second: 1, episode reward: 33.035, mean reward: 0.826 [0.520, 0.951], mean action: 29.700 [1.000, 53.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.234770, mean_absolute_error: 5.815689, mean_q: 6.526900
815 (array([22]),) False
 188200/500000: episode: 4705, duration: 31.156s, episode steps: 40, steps per second: 1, episode reward: 32.663, mean reward: 0.817 [0.000, 1.000], mean action: 24.250 [10.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.250911, mean_absolute_error: 5.790057, mean_q: 6.500092
451 (array([38]),) False
 188240/500000: episode: 4706, duration: 30.321s, episode steps: 40, steps per second: 1, episode reward: 31.985, mean reward: 0.800 [0.219, 1.000], mean action: 22.600 [1.000, 50.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.264622, mean_absolute_error: 5.790494, mean_q: 6.489764
771 (array([12]),) False
 188280/500000: episode: 4707, duration: 31.166s, episode steps: 40, steps per second: 1, episode reward: 37.327, mean reward: 0.933 [0.177, 1.000], mean action: 12.875 [5.000, 37.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.276197, mean_absolute_error: 5.862285, mean_q: 6.568945
572 (array([58]),) False
 188320/500000: episode: 4708, duration: 31.139s, episode steps: 40, steps per second: 1, episode reward: 17.642, mean reward: 0.441 [0.000, 0.778], mean action: 18.575 [0.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.276965, mean_absolute_error: 5.867853, mean_q: 6.586511
802 (array([22]),) False
 188360/500000: episode: 4709, duration: 31.049s, episode steps: 40, steps per second: 1, episode reward: 30.773, mean reward: 0.769 [0.069, 1.000], mean action: 25.025 [4.000, 49.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.266873, mean_absolute_error: 5.852212, mean_q: 6.559937
847 (array([21]),) False
 188400/500000: episode: 4710, duration: 30.384s, episode steps: 40, steps per second: 1, episode reward: 34.272, mean reward: 0.857 [0.020, 1.000], mean action: 17.050 [7.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.261866, mean_absolute_error: 5.872994, mean_q: 6.580113
409 (array([22]),) False
 188440/500000: episode: 4711, duration: 31.171s, episode steps: 40, steps per second: 1, episode reward: 37.670, mean reward: 0.942 [0.379, 1.000], mean action: 21.950 [13.000, 34.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.243868, mean_absolute_error: 5.758900, mean_q: 6.454120
7 (array([22]),) False
 188480/500000: episode: 4712, duration: 31.172s, episode steps: 40, steps per second: 1, episode reward: 37.057, mean reward: 0.926 [0.089, 1.000], mean action: 25.175 [22.000, 59.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.253587, mean_absolute_error: 5.844930, mean_q: 6.544454
67 (array([8]),) False
 188520/500000: episode: 4713, duration: 31.143s, episode steps: 40, steps per second: 1, episode reward: 24.533, mean reward: 0.613 [0.342, 0.978], mean action: 30.050 [10.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.271187, mean_absolute_error: 5.905823, mean_q: 6.604340
2 (array([12]),) False
 188560/500000: episode: 4714, duration: 30.306s, episode steps: 40, steps per second: 1, episode reward: 29.782, mean reward: 0.745 [0.328, 0.832], mean action: 22.400 [22.000, 30.000], mean observation: -0.044 [-1.000, 1.000], loss: 0.239083, mean_absolute_error: 5.824637, mean_q: 6.524010
126 (array([22]),) False
 188600/500000: episode: 4715, duration: 31.194s, episode steps: 40, steps per second: 1, episode reward: 34.532, mean reward: 0.863 [0.052, 1.000], mean action: 19.475 [0.000, 38.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.284324, mean_absolute_error: 5.821305, mean_q: 6.515831
374 (array([22]),) False
 188640/500000: episode: 4716, duration: 31.116s, episode steps: 40, steps per second: 1, episode reward: 37.232, mean reward: 0.931 [0.179, 1.000], mean action: 21.200 [0.000, 49.000], mean observation: -0.049 [-1.000, 1.000], loss: 0.240314, mean_absolute_error: 5.801517, mean_q: 6.497270
158 (array([22]),) False
 188680/500000: episode: 4717, duration: 31.192s, episode steps: 40, steps per second: 1, episode reward: 34.077, mean reward: 0.852 [0.154, 1.000], mean action: 18.775 [0.000, 47.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.217863, mean_absolute_error: 5.840453, mean_q: 6.552004
606 (array([22]),) False
 188720/500000: episode: 4718, duration: 30.311s, episode steps: 40, steps per second: 1, episode reward: 35.584, mean reward: 0.890 [0.017, 1.000], mean action: 17.875 [10.000, 57.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.247974, mean_absolute_error: 5.872224, mean_q: 6.580128
445 (array([22]),) False
 188760/500000: episode: 4719, duration: 31.159s, episode steps: 40, steps per second: 1, episode reward: 38.691, mean reward: 0.967 [0.049, 1.000], mean action: 22.525 [12.000, 49.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.243125, mean_absolute_error: 5.771531, mean_q: 6.475680
836 (array([22]),) False
 188800/500000: episode: 4720, duration: 31.161s, episode steps: 40, steps per second: 1, episode reward: 33.628, mean reward: 0.841 [0.146, 1.000], mean action: 22.050 [3.000, 48.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.260869, mean_absolute_error: 5.889452, mean_q: 6.588402
640 (array([22]),) False
 188840/500000: episode: 4721, duration: 31.167s, episode steps: 40, steps per second: 1, episode reward: 36.531, mean reward: 0.913 [0.202, 1.000], mean action: 26.525 [6.000, 52.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.243032, mean_absolute_error: 5.847287, mean_q: 6.545239
298 (array([22]),) False
 188880/500000: episode: 4722, duration: 30.259s, episode steps: 40, steps per second: 1, episode reward: 36.462, mean reward: 0.912 [0.000, 1.000], mean action: 23.050 [12.000, 60.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.237951, mean_absolute_error: 5.858930, mean_q: 6.564523
316 (array([12]),) False
 188920/500000: episode: 4723, duration: 31.209s, episode steps: 40, steps per second: 1, episode reward: 35.559, mean reward: 0.889 [0.101, 0.987], mean action: 23.475 [8.000, 55.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.240101, mean_absolute_error: 5.801301, mean_q: 6.506853
199 (array([22]),) False
 188960/500000: episode: 4724, duration: 31.209s, episode steps: 40, steps per second: 1, episode reward: 36.672, mean reward: 0.917 [0.189, 1.000], mean action: 20.400 [0.000, 58.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.252437, mean_absolute_error: 5.883150, mean_q: 6.596972
553 (array([22]),) False
 189000/500000: episode: 4725, duration: 31.122s, episode steps: 40, steps per second: 1, episode reward: 37.468, mean reward: 0.937 [0.265, 1.000], mean action: 16.475 [1.000, 22.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.291821, mean_absolute_error: 5.795427, mean_q: 6.511496
650 (array([22]),) False
 189040/500000: episode: 4726, duration: 30.319s, episode steps: 40, steps per second: 1, episode reward: 35.858, mean reward: 0.896 [0.109, 1.000], mean action: 24.225 [5.000, 56.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.263274, mean_absolute_error: 5.840787, mean_q: 6.556252
849 (array([3]),) False
 189080/500000: episode: 4727, duration: 31.120s, episode steps: 40, steps per second: 1, episode reward: 10.959, mean reward: 0.274 [0.000, 0.735], mean action: 25.875 [3.000, 54.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.252306, mean_absolute_error: 5.956649, mean_q: 6.676147
495 (array([48]),) False
 189120/500000: episode: 4728, duration: 31.137s, episode steps: 40, steps per second: 1, episode reward: 38.061, mean reward: 0.952 [0.376, 0.966], mean action: 22.600 [22.000, 46.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.245268, mean_absolute_error: 5.844280, mean_q: 6.557096
217 (array([12]),) False
 189160/500000: episode: 4729, duration: 31.164s, episode steps: 40, steps per second: 1, episode reward: 29.923, mean reward: 0.748 [0.216, 1.000], mean action: 22.450 [12.000, 54.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.269232, mean_absolute_error: 5.862196, mean_q: 6.571039
362 (array([22]),) False
 189200/500000: episode: 4730, duration: 30.307s, episode steps: 40, steps per second: 1, episode reward: 36.947, mean reward: 0.924 [0.229, 1.000], mean action: 21.125 [12.000, 48.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.241960, mean_absolute_error: 5.922462, mean_q: 6.641923
674 (array([48]),) False
 189240/500000: episode: 4731, duration: 31.249s, episode steps: 40, steps per second: 1, episode reward: 32.028, mean reward: 0.801 [0.052, 1.000], mean action: 23.325 [11.000, 58.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.233353, mean_absolute_error: 5.931194, mean_q: 6.650729
158 (array([22]),) False
 189280/500000: episode: 4732, duration: 31.132s, episode steps: 40, steps per second: 1, episode reward: 36.429, mean reward: 0.911 [0.461, 1.000], mean action: 18.375 [12.000, 51.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.278613, mean_absolute_error: 5.857590, mean_q: 6.571571
522 (array([22]),) False
 189320/500000: episode: 4733, duration: 31.122s, episode steps: 40, steps per second: 1, episode reward: 32.963, mean reward: 0.824 [0.115, 1.000], mean action: 17.350 [12.000, 40.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.226843, mean_absolute_error: 5.917992, mean_q: 6.639960
637 (array([12]),) False
 189360/500000: episode: 4734, duration: 30.217s, episode steps: 40, steps per second: 1, episode reward: 35.115, mean reward: 0.878 [0.293, 1.000], mean action: 20.400 [12.000, 56.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.262488, mean_absolute_error: 5.870167, mean_q: 6.588759
364 (array([14]),) False
 189400/500000: episode: 4735, duration: 31.236s, episode steps: 40, steps per second: 1, episode reward: 33.762, mean reward: 0.844 [0.261, 0.919], mean action: 20.200 [9.000, 54.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.276633, mean_absolute_error: 5.870269, mean_q: 6.583413
274 (array([12]),) False
 189440/500000: episode: 4736, duration: 31.146s, episode steps: 40, steps per second: 1, episode reward: 34.133, mean reward: 0.853 [0.193, 1.000], mean action: 19.425 [12.000, 54.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.265678, mean_absolute_error: 5.921203, mean_q: 6.640284
622 (array([36]),) False
 189480/500000: episode: 4737, duration: 31.124s, episode steps: 40, steps per second: 1, episode reward: 23.071, mean reward: 0.577 [0.202, 0.948], mean action: 13.025 [3.000, 27.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.237344, mean_absolute_error: 5.807919, mean_q: 6.515535
753 (array([22]),) False
 189520/500000: episode: 4738, duration: 30.376s, episode steps: 40, steps per second: 1, episode reward: 35.467, mean reward: 0.887 [0.314, 1.000], mean action: 22.225 [0.000, 51.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.255161, mean_absolute_error: 5.908939, mean_q: 6.618181
45 (array([22]),) False
 189560/500000: episode: 4739, duration: 31.177s, episode steps: 40, steps per second: 1, episode reward: 34.486, mean reward: 0.862 [0.070, 1.000], mean action: 23.425 [5.000, 54.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.247812, mean_absolute_error: 5.928510, mean_q: 6.640744
353 (array([22]),) False
 189600/500000: episode: 4740, duration: 31.215s, episode steps: 40, steps per second: 1, episode reward: 37.261, mean reward: 0.932 [0.093, 1.000], mean action: 25.425 [8.000, 52.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.266357, mean_absolute_error: 5.870625, mean_q: 6.586698
28 (array([58]),) False
 189640/500000: episode: 4741, duration: 31.167s, episode steps: 40, steps per second: 1, episode reward: 20.724, mean reward: 0.518 [0.015, 1.000], mean action: 22.775 [15.000, 49.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.229454, mean_absolute_error: 5.802451, mean_q: 6.522339
105 (array([22]),) False
 189680/500000: episode: 4742, duration: 30.306s, episode steps: 40, steps per second: 1, episode reward: 37.090, mean reward: 0.927 [0.000, 1.000], mean action: 19.650 [6.000, 22.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.258129, mean_absolute_error: 5.859206, mean_q: 6.578664
795 (array([3]),) False
 189720/500000: episode: 4743, duration: 31.156s, episode steps: 40, steps per second: 1, episode reward: 21.945, mean reward: 0.549 [0.364, 0.967], mean action: 15.600 [7.000, 53.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.240903, mean_absolute_error: 5.926143, mean_q: 6.649873
694 (array([22]),) False
 189760/500000: episode: 4744, duration: 31.157s, episode steps: 40, steps per second: 1, episode reward: 37.572, mean reward: 0.939 [0.015, 1.000], mean action: 23.475 [8.000, 59.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.237394, mean_absolute_error: 5.939035, mean_q: 6.667333
820 (array([48]),) False
 189800/500000: episode: 4745, duration: 31.110s, episode steps: 40, steps per second: 1, episode reward: 30.050, mean reward: 0.751 [0.145, 1.000], mean action: 24.350 [2.000, 60.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.263420, mean_absolute_error: 5.864856, mean_q: 6.584240
44 (array([22]),) False
 189840/500000: episode: 4746, duration: 30.258s, episode steps: 40, steps per second: 1, episode reward: 37.284, mean reward: 0.932 [0.261, 1.000], mean action: 24.225 [19.000, 53.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.252286, mean_absolute_error: 5.877514, mean_q: 6.603421
790 (array([48]),) False
 189880/500000: episode: 4747, duration: 31.173s, episode steps: 40, steps per second: 1, episode reward: 38.321, mean reward: 0.958 [0.092, 1.000], mean action: 45.075 [1.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.292254, mean_absolute_error: 5.875343, mean_q: 6.598099
295 (array([22]),) False
 189920/500000: episode: 4748, duration: 31.147s, episode steps: 40, steps per second: 1, episode reward: 37.578, mean reward: 0.939 [0.233, 1.000], mean action: 22.450 [4.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.231258, mean_absolute_error: 5.907138, mean_q: 6.639947
544 (array([22]),) False
 189960/500000: episode: 4749, duration: 31.119s, episode steps: 40, steps per second: 1, episode reward: 36.022, mean reward: 0.901 [0.190, 1.000], mean action: 25.375 [8.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.245460, mean_absolute_error: 5.909643, mean_q: 6.635764
302 (array([22]),) False
 190000/500000: episode: 4750, duration: 30.281s, episode steps: 40, steps per second: 1, episode reward: 36.974, mean reward: 0.924 [0.243, 1.000], mean action: 24.600 [22.000, 60.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.231602, mean_absolute_error: 5.900084, mean_q: 6.623587
819 (array([48]),) False
 190040/500000: episode: 4751, duration: 31.167s, episode steps: 40, steps per second: 1, episode reward: 26.163, mean reward: 0.654 [0.068, 1.000], mean action: 25.300 [6.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.262261, mean_absolute_error: 5.999147, mean_q: 6.722051
449 (array([22]),) False
 190080/500000: episode: 4752, duration: 31.182s, episode steps: 40, steps per second: 1, episode reward: 36.577, mean reward: 0.914 [0.161, 1.000], mean action: 20.925 [0.000, 43.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.264043, mean_absolute_error: 5.952318, mean_q: 6.672525
586 (array([12]),) False
 190120/500000: episode: 4753, duration: 31.082s, episode steps: 40, steps per second: 1, episode reward: 34.441, mean reward: 0.861 [0.119, 1.000], mean action: 14.950 [0.000, 52.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.257656, mean_absolute_error: 5.984859, mean_q: 6.714110
357 (array([22]),) False
 190160/500000: episode: 4754, duration: 30.340s, episode steps: 40, steps per second: 1, episode reward: 30.202, mean reward: 0.755 [0.022, 1.000], mean action: 22.225 [0.000, 44.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.255325, mean_absolute_error: 5.914321, mean_q: 6.635831
831 (array([3]),) False
 190200/500000: episode: 4755, duration: 31.188s, episode steps: 40, steps per second: 1, episode reward: 12.915, mean reward: 0.323 [0.000, 1.000], mean action: 15.050 [4.000, 22.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.262682, mean_absolute_error: 5.944922, mean_q: 6.683217
386 (array([12]),) False
 190240/500000: episode: 4756, duration: 31.173s, episode steps: 40, steps per second: 1, episode reward: 34.836, mean reward: 0.871 [0.416, 0.897], mean action: 22.925 [1.000, 47.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.267041, mean_absolute_error: 5.926217, mean_q: 6.654736
74 (array([22]),) False
 190280/500000: episode: 4757, duration: 31.049s, episode steps: 40, steps per second: 1, episode reward: 36.540, mean reward: 0.913 [0.221, 1.000], mean action: 18.975 [7.000, 53.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.256264, mean_absolute_error: 5.912430, mean_q: 6.639368
547 (array([21]),) False
 190320/500000: episode: 4758, duration: 30.297s, episode steps: 40, steps per second: 1, episode reward: 27.174, mean reward: 0.679 [0.221, 1.000], mean action: 22.375 [3.000, 55.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.264405, mean_absolute_error: 5.878538, mean_q: 6.599304
146 (array([12]),) False
 190360/500000: episode: 4759, duration: 31.173s, episode steps: 40, steps per second: 1, episode reward: 37.067, mean reward: 0.927 [0.171, 1.000], mean action: 15.000 [2.000, 60.000], mean observation: -0.150 [-1.000, 1.000], loss: 0.244633, mean_absolute_error: 5.952486, mean_q: 6.683298
279 (array([22]),) False
 190400/500000: episode: 4760, duration: 31.168s, episode steps: 40, steps per second: 1, episode reward: 31.952, mean reward: 0.799 [0.035, 1.000], mean action: 17.875 [3.000, 23.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.299941, mean_absolute_error: 5.986911, mean_q: 6.719769
787 (array([3]),) False
 190440/500000: episode: 4761, duration: 31.228s, episode steps: 40, steps per second: 1, episode reward: 22.459, mean reward: 0.561 [0.150, 1.000], mean action: 19.950 [12.000, 46.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.253599, mean_absolute_error: 5.977244, mean_q: 6.705085
733 (array([22]),) False
 190480/500000: episode: 4762, duration: 30.306s, episode steps: 40, steps per second: 1, episode reward: 36.175, mean reward: 0.904 [0.140, 1.000], mean action: 26.200 [4.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.251872, mean_absolute_error: 5.898810, mean_q: 6.624906
78 (array([55]),) False
 190520/500000: episode: 4763, duration: 31.221s, episode steps: 40, steps per second: 1, episode reward: 34.153, mean reward: 0.854 [0.283, 1.000], mean action: 20.425 [10.000, 31.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.332109, mean_absolute_error: 5.953009, mean_q: 6.678941
585 (array([48]),) False
 190560/500000: episode: 4764, duration: 31.114s, episode steps: 40, steps per second: 1, episode reward: 37.403, mean reward: 0.935 [0.273, 1.000], mean action: 19.875 [12.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.261841, mean_absolute_error: 5.914157, mean_q: 6.631961
78 (array([55]),) False
 190600/500000: episode: 4765, duration: 31.185s, episode steps: 40, steps per second: 1, episode reward: 34.295, mean reward: 0.857 [0.195, 1.000], mean action: 23.650 [14.000, 55.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.265081, mean_absolute_error: 6.009632, mean_q: 6.736624
470 (array([22]),) False
 190640/500000: episode: 4766, duration: 30.330s, episode steps: 40, steps per second: 1, episode reward: 37.443, mean reward: 0.936 [0.171, 1.000], mean action: 22.150 [3.000, 48.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.269622, mean_absolute_error: 5.951774, mean_q: 6.670791
330 (array([38]),) False
 190680/500000: episode: 4767, duration: 31.018s, episode steps: 40, steps per second: 1, episode reward: 36.384, mean reward: 0.910 [0.075, 1.000], mean action: 14.925 [2.000, 48.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.250676, mean_absolute_error: 5.948778, mean_q: 6.657197
480 (array([22]),) False
 190720/500000: episode: 4768, duration: 31.201s, episode steps: 40, steps per second: 1, episode reward: 26.580, mean reward: 0.665 [0.251, 1.000], mean action: 36.600 [3.000, 59.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.281620, mean_absolute_error: 5.944080, mean_q: 6.657214
414 (array([48]),) False
 190760/500000: episode: 4769, duration: 31.156s, episode steps: 40, steps per second: 1, episode reward: 30.857, mean reward: 0.771 [0.168, 1.000], mean action: 21.600 [4.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.270062, mean_absolute_error: 5.976567, mean_q: 6.697958
114 (array([22]),) False
 190800/500000: episode: 4770, duration: 30.323s, episode steps: 40, steps per second: 1, episode reward: 34.290, mean reward: 0.857 [0.035, 1.000], mean action: 26.575 [11.000, 55.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.251165, mean_absolute_error: 5.927548, mean_q: 6.645543
710 (array([12]),) False
 190840/500000: episode: 4771, duration: 31.132s, episode steps: 40, steps per second: 1, episode reward: 29.605, mean reward: 0.740 [0.345, 1.000], mean action: 19.825 [5.000, 43.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.244189, mean_absolute_error: 5.851212, mean_q: 6.563405
507 (array([44]),) False
 190880/500000: episode: 4772, duration: 31.140s, episode steps: 40, steps per second: 1, episode reward: 35.409, mean reward: 0.885 [0.744, 0.986], mean action: 27.500 [22.000, 51.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.240502, mean_absolute_error: 5.841619, mean_q: 6.555575
184 (array([12]),) False
 190920/500000: episode: 4773, duration: 30.258s, episode steps: 40, steps per second: 1, episode reward: 33.907, mean reward: 0.848 [0.254, 1.000], mean action: 18.375 [6.000, 59.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.281915, mean_absolute_error: 5.840072, mean_q: 6.554524
59 (array([12]),) False
 190960/500000: episode: 4774, duration: 31.145s, episode steps: 40, steps per second: 1, episode reward: 35.228, mean reward: 0.881 [0.240, 1.000], mean action: 24.575 [5.000, 50.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.248534, mean_absolute_error: 5.968581, mean_q: 6.677350
112 (array([12]),) False
 191000/500000: episode: 4775, duration: 31.142s, episode steps: 40, steps per second: 1, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 12.000 [12.000, 12.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.285578, mean_absolute_error: 5.814270, mean_q: 6.516794
139 (array([48]),) False
 191040/500000: episode: 4776, duration: 31.250s, episode steps: 40, steps per second: 1, episode reward: 32.660, mean reward: 0.817 [0.325, 1.000], mean action: 17.900 [7.000, 58.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.243545, mean_absolute_error: 5.935986, mean_q: 6.649499
257 (array([22]),) False
 191080/500000: episode: 4777, duration: 30.302s, episode steps: 40, steps per second: 1, episode reward: 37.156, mean reward: 0.929 [0.174, 1.000], mean action: 24.525 [14.000, 57.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.244051, mean_absolute_error: 5.865724, mean_q: 6.576910
200 (array([22]),) False
 191120/500000: episode: 4778, duration: 31.206s, episode steps: 40, steps per second: 1, episode reward: 23.066, mean reward: 0.577 [0.041, 1.000], mean action: 19.775 [2.000, 55.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.246587, mean_absolute_error: 5.900721, mean_q: 6.610188
564 (array([22]),) False
 191160/500000: episode: 4779, duration: 31.310s, episode steps: 40, steps per second: 1, episode reward: 36.812, mean reward: 0.920 [0.143, 1.000], mean action: 14.850 [9.000, 49.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.285266, mean_absolute_error: 5.858981, mean_q: 6.568898
702 (array([22]),) False
 191200/500000: episode: 4780, duration: 31.427s, episode steps: 40, steps per second: 1, episode reward: 37.199, mean reward: 0.930 [0.322, 1.000], mean action: 22.825 [1.000, 53.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.261016, mean_absolute_error: 5.863337, mean_q: 6.568269
283 (array([34]),) False
 191240/500000: episode: 4781, duration: 31.320s, episode steps: 40, steps per second: 1, episode reward: 17.105, mean reward: 0.428 [0.070, 1.000], mean action: 20.850 [12.000, 54.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.239491, mean_absolute_error: 5.784302, mean_q: 6.483934
841 (array([21]),) False
 191280/500000: episode: 4782, duration: 31.561s, episode steps: 40, steps per second: 1, episode reward: 29.341, mean reward: 0.734 [0.253, 0.966], mean action: 20.300 [9.000, 51.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.284924, mean_absolute_error: 5.809049, mean_q: 6.501920
682 (array([22]),) False
 191320/500000: episode: 4783, duration: 31.706s, episode steps: 40, steps per second: 1, episode reward: 36.959, mean reward: 0.924 [0.216, 1.000], mean action: 18.700 [12.000, 49.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.257204, mean_absolute_error: 5.828196, mean_q: 6.534358
457 (array([38]),) False
 191360/500000: episode: 4784, duration: 31.369s, episode steps: 40, steps per second: 1, episode reward: 31.386, mean reward: 0.785 [0.193, 0.945], mean action: 20.675 [4.000, 25.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.229110, mean_absolute_error: 5.863782, mean_q: 6.563908
110 (array([22]),) False
 191400/500000: episode: 4785, duration: 30.900s, episode steps: 40, steps per second: 1, episode reward: 33.995, mean reward: 0.850 [0.151, 1.000], mean action: 25.025 [22.000, 51.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.254057, mean_absolute_error: 5.813437, mean_q: 6.513306
606 (array([22]),) False
 191440/500000: episode: 4786, duration: 31.379s, episode steps: 40, steps per second: 1, episode reward: 37.664, mean reward: 0.942 [0.450, 1.000], mean action: 18.525 [12.000, 59.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.238291, mean_absolute_error: 5.847097, mean_q: 6.543246
607 (array([12]),) False
 191480/500000: episode: 4787, duration: 31.401s, episode steps: 40, steps per second: 1, episode reward: 38.483, mean reward: 0.962 [0.178, 1.000], mean action: 15.850 [8.000, 38.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.252675, mean_absolute_error: 5.872632, mean_q: 6.569396
830 (array([22]),) False
 191520/500000: episode: 4788, duration: 31.376s, episode steps: 40, steps per second: 1, episode reward: 38.602, mean reward: 0.965 [0.167, 1.000], mean action: 20.700 [10.000, 22.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.260015, mean_absolute_error: 5.829564, mean_q: 6.524223
345 (array([22]),) False
 191560/500000: episode: 4789, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 37.688, mean reward: 0.942 [0.363, 1.000], mean action: 22.075 [0.000, 53.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.265088, mean_absolute_error: 5.886814, mean_q: 6.583902
574 (array([8]),) False
 191600/500000: episode: 4790, duration: 31.330s, episode steps: 40, steps per second: 1, episode reward: 34.548, mean reward: 0.864 [0.197, 1.000], mean action: 23.475 [11.000, 57.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.269900, mean_absolute_error: 5.896827, mean_q: 6.597356
539 (array([22]),) False
 191640/500000: episode: 4791, duration: 31.359s, episode steps: 40, steps per second: 1, episode reward: 37.920, mean reward: 0.948 [0.299, 1.000], mean action: 19.975 [12.000, 48.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.255678, mean_absolute_error: 5.829056, mean_q: 6.525014
473 (array([22]),) False
 191680/500000: episode: 4792, duration: 31.330s, episode steps: 40, steps per second: 1, episode reward: 31.281, mean reward: 0.782 [0.085, 1.000], mean action: 22.800 [5.000, 55.000], mean observation: -0.074 [-1.000, 1.000], loss: 0.249943, mean_absolute_error: 5.861365, mean_q: 6.558023
789 (array([22]),) False
 191720/500000: episode: 4793, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 36.087, mean reward: 0.902 [0.000, 1.000], mean action: 41.650 [4.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.252952, mean_absolute_error: 5.863631, mean_q: 6.565499
191 (array([38]),) False
 191760/500000: episode: 4794, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 26.447, mean reward: 0.661 [0.202, 1.000], mean action: 16.175 [3.000, 34.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.242747, mean_absolute_error: 5.913635, mean_q: 6.613423
323 (array([55]),) False
 191800/500000: episode: 4795, duration: 32.932s, episode steps: 40, steps per second: 1, episode reward: 27.473, mean reward: 0.687 [0.283, 0.811], mean action: 20.700 [0.000, 47.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.278225, mean_absolute_error: 5.816669, mean_q: 6.509700
491 (array([22]),) False
 191840/500000: episode: 4796, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 34.238, mean reward: 0.856 [0.146, 1.000], mean action: 27.075 [12.000, 56.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.265625, mean_absolute_error: 5.789893, mean_q: 6.486066
10 (array([3]),) False
 191880/500000: episode: 4797, duration: 32.104s, episode steps: 40, steps per second: 1, episode reward: 24.677, mean reward: 0.617 [0.000, 1.000], mean action: 22.875 [13.000, 53.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.253635, mean_absolute_error: 5.826949, mean_q: 6.522575
409 (array([22]),) False
 191920/500000: episode: 4798, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 37.777, mean reward: 0.944 [0.366, 1.000], mean action: 24.525 [16.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.252632, mean_absolute_error: 5.849120, mean_q: 6.551833
70 (array([22]),) False
 191960/500000: episode: 4799, duration: 32.943s, episode steps: 40, steps per second: 1, episode reward: 36.358, mean reward: 0.909 [0.006, 1.000], mean action: 18.125 [12.000, 37.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.239836, mean_absolute_error: 5.816227, mean_q: 6.520303
850 (array([12]),) False
 192000/500000: episode: 4800, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 31.954, mean reward: 0.799 [0.165, 1.000], mean action: 16.200 [1.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.273975, mean_absolute_error: 5.817509, mean_q: 6.523890
81 (array([22]),) False
 192040/500000: episode: 4801, duration: 32.164s, episode steps: 40, steps per second: 1, episode reward: 37.822, mean reward: 0.946 [0.264, 1.000], mean action: 24.425 [22.000, 59.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.253277, mean_absolute_error: 5.838847, mean_q: 6.538971
535 (array([22]),) False
 192080/500000: episode: 4802, duration: 33.055s, episode steps: 40, steps per second: 1, episode reward: 35.350, mean reward: 0.884 [0.119, 1.000], mean action: 22.700 [2.000, 54.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.234133, mean_absolute_error: 5.861881, mean_q: 6.556441
60 (array([22]),) False
 192120/500000: episode: 4803, duration: 32.970s, episode steps: 40, steps per second: 1, episode reward: 37.138, mean reward: 0.928 [0.299, 1.000], mean action: 22.575 [7.000, 46.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.256635, mean_absolute_error: 5.805638, mean_q: 6.503624
685 (array([22]),) False
 192160/500000: episode: 4804, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 37.055, mean reward: 0.926 [0.256, 0.989], mean action: 13.750 [12.000, 55.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.227690, mean_absolute_error: 5.780333, mean_q: 6.470532
567 (array([22]),) False
 192200/500000: episode: 4805, duration: 32.131s, episode steps: 40, steps per second: 1, episode reward: 23.593, mean reward: 0.590 [0.060, 1.000], mean action: 15.250 [9.000, 53.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.275891, mean_absolute_error: 5.776686, mean_q: 6.471410
663 (array([22]),) False
 192240/500000: episode: 4806, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 22.839, mean reward: 0.571 [0.149, 0.866], mean action: 14.475 [12.000, 43.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.258756, mean_absolute_error: 5.852443, mean_q: 6.552344
177 (array([22]),) False
 192280/500000: episode: 4807, duration: 32.984s, episode steps: 40, steps per second: 1, episode reward: 34.940, mean reward: 0.873 [0.044, 1.000], mean action: 20.325 [0.000, 60.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.267992, mean_absolute_error: 5.768995, mean_q: 6.466352
836 (array([22]),) False
 192320/500000: episode: 4808, duration: 33.070s, episode steps: 40, steps per second: 1, episode reward: 32.395, mean reward: 0.810 [0.263, 1.000], mean action: 23.275 [1.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.249400, mean_absolute_error: 5.762797, mean_q: 6.457305
28 (array([58]),) False
 192360/500000: episode: 4809, duration: 32.042s, episode steps: 40, steps per second: 1, episode reward: 25.196, mean reward: 0.630 [0.023, 1.000], mean action: 28.225 [9.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.255060, mean_absolute_error: 5.695115, mean_q: 6.389090
319 (array([33]),) False
 192400/500000: episode: 4810, duration: 33.038s, episode steps: 40, steps per second: 1, episode reward: 31.290, mean reward: 0.782 [0.085, 1.000], mean action: 23.850 [4.000, 48.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.275962, mean_absolute_error: 5.822700, mean_q: 6.517041
862 (array([14]),) False
 192440/500000: episode: 4811, duration: 33.026s, episode steps: 40, steps per second: 1, episode reward: 35.363, mean reward: 0.884 [0.268, 1.000], mean action: 20.975 [12.000, 51.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.260448, mean_absolute_error: 5.817994, mean_q: 6.514620
305 (array([12]),) False
 192480/500000: episode: 4812, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 31.851, mean reward: 0.796 [0.140, 0.838], mean action: 22.500 [11.000, 53.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.274860, mean_absolute_error: 5.801250, mean_q: 6.490071
696 (array([36]),) False
 192520/500000: episode: 4813, duration: 32.190s, episode steps: 40, steps per second: 1, episode reward: 24.258, mean reward: 0.606 [0.090, 1.000], mean action: 17.250 [3.000, 55.000], mean observation: -0.123 [-1.000, 1.000], loss: 0.263252, mean_absolute_error: 5.750591, mean_q: 6.438727
408 (array([12]),) False
 192560/500000: episode: 4814, duration: 32.963s, episode steps: 40, steps per second: 1, episode reward: 36.272, mean reward: 0.907 [0.701, 0.989], mean action: 22.650 [22.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.221413, mean_absolute_error: 5.758355, mean_q: 6.456323
622 (array([36]),) False
 192600/500000: episode: 4815, duration: 32.181s, episode steps: 40, steps per second: 1, episode reward: 25.262, mean reward: 0.632 [0.202, 0.963], mean action: 12.750 [3.000, 53.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.247645, mean_absolute_error: 5.727857, mean_q: 6.415309
805 (array([22]),) False
 192640/500000: episode: 4816, duration: 33.048s, episode steps: 40, steps per second: 1, episode reward: 36.968, mean reward: 0.924 [0.297, 1.000], mean action: 27.800 [12.000, 58.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.258823, mean_absolute_error: 5.773402, mean_q: 6.460516
857 (array([22]),) False
 192680/500000: episode: 4817, duration: 32.109s, episode steps: 40, steps per second: 1, episode reward: 35.087, mean reward: 0.877 [0.015, 1.000], mean action: 23.750 [12.000, 55.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.238894, mean_absolute_error: 5.744919, mean_q: 6.437624
734 (array([48]),) False
 192720/500000: episode: 4818, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 34.702, mean reward: 0.868 [0.106, 1.000], mean action: 32.125 [6.000, 49.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.249286, mean_absolute_error: 5.782329, mean_q: 6.483050
443 (array([22]),) False
 192760/500000: episode: 4819, duration: 33.117s, episode steps: 40, steps per second: 1, episode reward: 39.631, mean reward: 0.991 [0.877, 1.000], mean action: 24.025 [22.000, 49.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.229530, mean_absolute_error: 5.818329, mean_q: 6.515401
519 (array([58]),) False
 192800/500000: episode: 4820, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 23.241, mean reward: 0.581 [0.000, 0.778], mean action: 20.400 [5.000, 52.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.238239, mean_absolute_error: 5.807168, mean_q: 6.503192
366 (array([22]),) False
 192840/500000: episode: 4821, duration: 32.995s, episode steps: 40, steps per second: 1, episode reward: 36.190, mean reward: 0.905 [0.419, 1.000], mean action: 20.125 [12.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.259578, mean_absolute_error: 5.855077, mean_q: 6.553232
417 (array([12]),) False
 192880/500000: episode: 4822, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 28.539, mean reward: 0.713 [0.533, 1.000], mean action: 23.250 [0.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.275747, mean_absolute_error: 5.878767, mean_q: 6.573659
525 (array([22]),) False
 192920/500000: episode: 4823, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 37.000, mean reward: 0.925 [0.217, 1.000], mean action: 19.125 [12.000, 56.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.259991, mean_absolute_error: 5.791732, mean_q: 6.484691
561 (array([22]),) False
 192960/500000: episode: 4824, duration: 32.982s, episode steps: 40, steps per second: 1, episode reward: 33.629, mean reward: 0.841 [0.266, 1.000], mean action: 20.325 [12.000, 60.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.228096, mean_absolute_error: 5.787440, mean_q: 6.487933
497 (array([33]),) False
 193000/500000: episode: 4825, duration: 32.140s, episode steps: 40, steps per second: 1, episode reward: 21.252, mean reward: 0.531 [0.000, 0.760], mean action: 21.750 [2.000, 48.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.255696, mean_absolute_error: 5.793458, mean_q: 6.494478
163 (array([44]),) False
 193040/500000: episode: 4826, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 35.638, mean reward: 0.891 [0.426, 0.999], mean action: 19.950 [11.000, 56.000], mean observation: -0.167 [-1.000, 1.000], loss: 0.239579, mean_absolute_error: 5.818292, mean_q: 6.510334
349 (array([48]),) False
 193080/500000: episode: 4827, duration: 32.172s, episode steps: 40, steps per second: 1, episode reward: 36.251, mean reward: 0.906 [0.219, 1.000], mean action: 20.575 [0.000, 40.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.253536, mean_absolute_error: 5.838593, mean_q: 6.532465
35 (array([48]),) False
 193120/500000: episode: 4828, duration: 33.096s, episode steps: 40, steps per second: 1, episode reward: 35.875, mean reward: 0.897 [0.129, 0.972], mean action: 33.225 [6.000, 44.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.234417, mean_absolute_error: 5.816328, mean_q: 6.512242
631 (array([22]),) False
 193160/500000: episode: 4829, duration: 32.088s, episode steps: 40, steps per second: 1, episode reward: 39.233, mean reward: 0.981 [0.233, 1.000], mean action: 21.550 [4.000, 22.000], mean observation: -0.073 [-1.000, 1.000], loss: 0.254589, mean_absolute_error: 5.847190, mean_q: 6.539670
450 (array([8]),) False
 193200/500000: episode: 4830, duration: 33.128s, episode steps: 40, steps per second: 1, episode reward: 23.765, mean reward: 0.594 [0.072, 1.000], mean action: 24.200 [5.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.292155, mean_absolute_error: 5.766067, mean_q: 6.464046
38 (array([22]),) False
 193240/500000: episode: 4831, duration: 32.991s, episode steps: 40, steps per second: 1, episode reward: 34.184, mean reward: 0.855 [0.201, 1.000], mean action: 28.675 [1.000, 38.000], mean observation: -0.056 [-1.000, 1.000], loss: 0.250792, mean_absolute_error: 5.795124, mean_q: 6.493020
236 (array([22]),) False
 193280/500000: episode: 4832, duration: 33.047s, episode steps: 40, steps per second: 1, episode reward: 35.811, mean reward: 0.895 [0.125, 1.000], mean action: 22.550 [6.000, 60.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.275474, mean_absolute_error: 5.792861, mean_q: 6.488669
320 (array([22]),) False
 193320/500000: episode: 4833, duration: 33.036s, episode steps: 40, steps per second: 1, episode reward: 37.088, mean reward: 0.927 [0.224, 1.000], mean action: 25.525 [12.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.233217, mean_absolute_error: 5.812445, mean_q: 6.507965
533 (array([22]),) False
 193360/500000: episode: 4834, duration: 32.912s, episode steps: 40, steps per second: 1, episode reward: 39.353, mean reward: 0.984 [0.517, 1.000], mean action: 22.525 [12.000, 53.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.227480, mean_absolute_error: 5.823015, mean_q: 6.525144
1 (array([22]),) False
 193400/500000: episode: 4835, duration: 33.057s, episode steps: 40, steps per second: 1, episode reward: 31.650, mean reward: 0.791 [0.030, 1.000], mean action: 25.025 [22.000, 59.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.257811, mean_absolute_error: 5.815844, mean_q: 6.523817
692 (array([22]),) False
 193440/500000: episode: 4836, duration: 33.034s, episode steps: 40, steps per second: 1, episode reward: 35.136, mean reward: 0.878 [0.098, 1.000], mean action: 26.750 [5.000, 56.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.278289, mean_absolute_error: 5.858260, mean_q: 6.566051
426 (array([22]),) False
 193480/500000: episode: 4837, duration: 32.201s, episode steps: 40, steps per second: 1, episode reward: 34.793, mean reward: 0.870 [0.196, 1.000], mean action: 25.600 [5.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.247022, mean_absolute_error: 5.912566, mean_q: 6.623466
435 (array([22]),) False
 193520/500000: episode: 4838, duration: 32.975s, episode steps: 40, steps per second: 1, episode reward: 35.319, mean reward: 0.883 [0.031, 1.000], mean action: 24.425 [16.000, 54.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.244134, mean_absolute_error: 5.812816, mean_q: 6.523834
572 (array([58]),) False
 193560/500000: episode: 4839, duration: 31.417s, episode steps: 40, steps per second: 1, episode reward: 17.297, mean reward: 0.432 [0.000, 0.949], mean action: 19.325 [12.000, 59.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.284723, mean_absolute_error: 5.823218, mean_q: 6.531106
591 (array([22]),) False
 193600/500000: episode: 4840, duration: 31.466s, episode steps: 40, steps per second: 1, episode reward: 29.705, mean reward: 0.743 [0.048, 1.000], mean action: 17.400 [2.000, 53.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.277011, mean_absolute_error: 5.970761, mean_q: 6.675810
523 (array([22]),) False
 193640/500000: episode: 4841, duration: 30.981s, episode steps: 40, steps per second: 1, episode reward: 35.311, mean reward: 0.883 [0.201, 1.000], mean action: 21.800 [4.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.266345, mean_absolute_error: 5.840575, mean_q: 6.543729
65 (array([48]),) False
 193680/500000: episode: 4842, duration: 31.405s, episode steps: 40, steps per second: 1, episode reward: 36.074, mean reward: 0.902 [0.297, 1.000], mean action: 25.175 [6.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.216993, mean_absolute_error: 5.835889, mean_q: 6.536878
72 (array([12]),) False
 193720/500000: episode: 4843, duration: 31.404s, episode steps: 40, steps per second: 1, episode reward: 37.646, mean reward: 0.941 [0.387, 1.000], mean action: 24.225 [12.000, 48.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.244033, mean_absolute_error: 5.813084, mean_q: 6.514600
80 (array([42]),) False
 193760/500000: episode: 4844, duration: 31.433s, episode steps: 40, steps per second: 1, episode reward: 36.574, mean reward: 0.914 [0.182, 1.000], mean action: 23.000 [2.000, 37.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.252261, mean_absolute_error: 5.862719, mean_q: 6.568932
201 (array([22]),) False
 193800/500000: episode: 4845, duration: 31.367s, episode steps: 40, steps per second: 1, episode reward: 37.892, mean reward: 0.947 [0.435, 1.000], mean action: 23.200 [12.000, 50.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.274354, mean_absolute_error: 5.898177, mean_q: 6.605720
561 (array([22]),) False
 193840/500000: episode: 4846, duration: 31.398s, episode steps: 40, steps per second: 1, episode reward: 36.127, mean reward: 0.903 [0.197, 1.000], mean action: 20.725 [1.000, 38.000], mean observation: -0.127 [-1.000, 1.000], loss: 0.225901, mean_absolute_error: 5.890029, mean_q: 6.611432
343 (array([22]),) False
 193880/500000: episode: 4847, duration: 31.451s, episode steps: 40, steps per second: 1, episode reward: 32.195, mean reward: 0.805 [0.172, 1.000], mean action: 32.000 [7.000, 59.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.271899, mean_absolute_error: 5.811683, mean_q: 6.520991
68 (array([22]),) False
 193920/500000: episode: 4848, duration: 31.335s, episode steps: 40, steps per second: 1, episode reward: 32.639, mean reward: 0.816 [0.113, 1.000], mean action: 30.725 [5.000, 58.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.249820, mean_absolute_error: 5.872952, mean_q: 6.587002
412 (array([16]),) False
 193960/500000: episode: 4849, duration: 30.960s, episode steps: 40, steps per second: 1, episode reward: 35.035, mean reward: 0.876 [0.618, 0.925], mean action: 22.975 [11.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.245790, mean_absolute_error: 5.831589, mean_q: 6.545534
419 (array([40]),) False
 194000/500000: episode: 4850, duration: 31.359s, episode steps: 40, steps per second: 1, episode reward: 35.538, mean reward: 0.888 [0.040, 1.000], mean action: 27.400 [2.000, 52.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.263037, mean_absolute_error: 5.842062, mean_q: 6.563827
99 (array([22]),) False
 194040/500000: episode: 4851, duration: 32.111s, episode steps: 40, steps per second: 1, episode reward: 39.549, mean reward: 0.989 [0.549, 1.000], mean action: 21.625 [7.000, 22.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.256576, mean_absolute_error: 5.838844, mean_q: 6.563940
81 (array([22]),) False
 194080/500000: episode: 4852, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 37.602, mean reward: 0.940 [0.041, 1.000], mean action: 21.150 [7.000, 24.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.256105, mean_absolute_error: 5.887148, mean_q: 6.611861
765 (array([48]),) False
 194120/500000: episode: 4853, duration: 32.330s, episode steps: 40, steps per second: 1, episode reward: 35.246, mean reward: 0.881 [0.098, 1.000], mean action: 40.300 [3.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.273461, mean_absolute_error: 5.913186, mean_q: 6.637007
194 (array([44]),) False
 194160/500000: episode: 4854, duration: 33.115s, episode steps: 40, steps per second: 1, episode reward: 27.799, mean reward: 0.695 [0.555, 0.856], mean action: 27.075 [14.000, 50.000], mean observation: -0.176 [-1.000, 1.000], loss: 0.280145, mean_absolute_error: 5.817750, mean_q: 6.533463
838 (array([21]),) False
 194200/500000: episode: 4855, duration: 33.106s, episode steps: 40, steps per second: 1, episode reward: 33.091, mean reward: 0.827 [0.538, 1.000], mean action: 25.250 [12.000, 48.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.245575, mean_absolute_error: 5.965621, mean_q: 6.692870
138 (array([3]),) False
 194240/500000: episode: 4856, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 26.203, mean reward: 0.655 [0.180, 1.000], mean action: 23.750 [3.000, 44.000], mean observation: -0.130 [-1.000, 1.000], loss: 0.253091, mean_absolute_error: 5.892041, mean_q: 6.618833
21 (array([3]),) False
 194280/500000: episode: 4857, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 23.823, mean reward: 0.596 [0.005, 1.000], mean action: 22.250 [0.000, 56.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.260243, mean_absolute_error: 5.902926, mean_q: 6.633922
604 (array([40]),) False
 194320/500000: episode: 4858, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 32.496, mean reward: 0.812 [0.407, 0.951], mean action: 30.750 [12.000, 49.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.257987, mean_absolute_error: 5.851451, mean_q: 6.574361
220 (array([22]),) False
 194360/500000: episode: 4859, duration: 33.217s, episode steps: 40, steps per second: 1, episode reward: 37.008, mean reward: 0.925 [0.071, 1.000], mean action: 23.925 [4.000, 53.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.263986, mean_absolute_error: 5.923232, mean_q: 6.647756
552 (array([22]),) False
 194400/500000: episode: 4860, duration: 33.053s, episode steps: 40, steps per second: 1, episode reward: 38.263, mean reward: 0.957 [0.363, 1.000], mean action: 25.125 [12.000, 49.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.269389, mean_absolute_error: 5.926758, mean_q: 6.648656
187 (array([15]),) False
 194440/500000: episode: 4861, duration: 32.312s, episode steps: 40, steps per second: 1, episode reward: 34.330, mean reward: 0.858 [0.146, 1.000], mean action: 20.625 [0.000, 44.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.249870, mean_absolute_error: 5.838012, mean_q: 6.557910
434 (array([22]),) False
 194480/500000: episode: 4862, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 38.289, mean reward: 0.957 [0.313, 1.000], mean action: 22.450 [7.000, 43.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.248204, mean_absolute_error: 5.989512, mean_q: 6.716182
555 (array([22]),) False
 194520/500000: episode: 4863, duration: 32.256s, episode steps: 40, steps per second: 1, episode reward: 35.344, mean reward: 0.884 [0.207, 1.000], mean action: 14.825 [0.000, 34.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.340067, mean_absolute_error: 5.966854, mean_q: 6.689989
402 (array([22]),) False
 194560/500000: episode: 4864, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 34.706, mean reward: 0.868 [0.358, 1.000], mean action: 24.450 [12.000, 58.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.268767, mean_absolute_error: 5.844474, mean_q: 6.558743
557 (array([22]),) False
 194600/500000: episode: 4865, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 37.294, mean reward: 0.932 [0.275, 1.000], mean action: 21.400 [7.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.297059, mean_absolute_error: 5.879837, mean_q: 6.602470
664 (array([22]),) False
 194640/500000: episode: 4866, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 32.509, mean reward: 0.813 [0.324, 1.000], mean action: 25.925 [12.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.250721, mean_absolute_error: 5.908836, mean_q: 6.628908
601 (array([14]),) False
 194680/500000: episode: 4867, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 34.509, mean reward: 0.863 [0.547, 1.000], mean action: 28.850 [12.000, 48.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.272621, mean_absolute_error: 5.946959, mean_q: 6.665845
506 (array([8]),) False
 194720/500000: episode: 4868, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 20.692, mean reward: 0.517 [0.152, 1.000], mean action: 32.100 [3.000, 55.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.261570, mean_absolute_error: 5.926658, mean_q: 6.643981
749 (array([22]),) False
 194760/500000: episode: 4869, duration: 33.166s, episode steps: 40, steps per second: 1, episode reward: 36.767, mean reward: 0.919 [0.175, 1.000], mean action: 28.825 [10.000, 56.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.255228, mean_absolute_error: 5.880559, mean_q: 6.606069
829 (array([21]),) False
 194800/500000: episode: 4870, duration: 33.088s, episode steps: 40, steps per second: 1, episode reward: 32.142, mean reward: 0.804 [0.600, 0.884], mean action: 19.625 [12.000, 49.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.247355, mean_absolute_error: 5.931855, mean_q: 6.660033
520 (array([22]),) False
 194840/500000: episode: 4871, duration: 33.158s, episode steps: 40, steps per second: 1, episode reward: 36.993, mean reward: 0.925 [0.695, 1.000], mean action: 20.075 [12.000, 38.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.279221, mean_absolute_error: 5.957564, mean_q: 6.685519
140 (array([12]),) False
 194880/500000: episode: 4872, duration: 33.069s, episode steps: 40, steps per second: 1, episode reward: 31.382, mean reward: 0.785 [0.240, 0.947], mean action: 22.725 [6.000, 58.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.273325, mean_absolute_error: 5.892066, mean_q: 6.615856
643 (array([44]),) False
 194920/500000: episode: 4873, duration: 32.210s, episode steps: 40, steps per second: 1, episode reward: 31.564, mean reward: 0.789 [0.093, 1.000], mean action: 28.700 [3.000, 51.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.274293, mean_absolute_error: 5.931642, mean_q: 6.657681
607 (array([12]),) False
 194960/500000: episode: 4874, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 36.917, mean reward: 0.923 [0.156, 1.000], mean action: 16.625 [12.000, 48.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.253119, mean_absolute_error: 5.862354, mean_q: 6.586324
531 (array([22]),) False
 195000/500000: episode: 4875, duration: 31.472s, episode steps: 40, steps per second: 1, episode reward: 39.301, mean reward: 0.983 [0.762, 1.000], mean action: 21.975 [12.000, 49.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.276466, mean_absolute_error: 5.844563, mean_q: 6.568816
802 (array([22]),) False
 195040/500000: episode: 4876, duration: 31.377s, episode steps: 40, steps per second: 1, episode reward: 33.735, mean reward: 0.843 [0.497, 1.000], mean action: 28.950 [22.000, 50.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.234458, mean_absolute_error: 6.033274, mean_q: 6.766536
671 (array([57]),) False
 195080/500000: episode: 4877, duration: 30.973s, episode steps: 40, steps per second: 1, episode reward: 13.443, mean reward: 0.336 [0.000, 0.994], mean action: 22.625 [3.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.219695, mean_absolute_error: 5.897420, mean_q: 6.621276
391 (array([22]),) False
 195120/500000: episode: 4878, duration: 31.461s, episode steps: 40, steps per second: 1, episode reward: 35.818, mean reward: 0.895 [0.288, 1.000], mean action: 31.025 [22.000, 52.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.284408, mean_absolute_error: 5.928433, mean_q: 6.650302
130 (array([22]),) False
 195160/500000: episode: 4879, duration: 31.336s, episode steps: 40, steps per second: 1, episode reward: 38.128, mean reward: 0.953 [0.187, 1.000], mean action: 23.250 [15.000, 49.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.273942, mean_absolute_error: 5.882799, mean_q: 6.604636
840 (array([12]),) False
 195200/500000: episode: 4880, duration: 31.367s, episode steps: 40, steps per second: 1, episode reward: 35.575, mean reward: 0.889 [0.106, 1.000], mean action: 14.525 [1.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.286324, mean_absolute_error: 5.959931, mean_q: 6.689925
555 (array([22]),) False
 195240/500000: episode: 4881, duration: 31.437s, episode steps: 40, steps per second: 1, episode reward: 34.335, mean reward: 0.858 [0.000, 1.000], mean action: 17.125 [11.000, 55.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.294380, mean_absolute_error: 5.973775, mean_q: 6.710049
618 (array([12]),) False
 195280/500000: episode: 4882, duration: 31.365s, episode steps: 40, steps per second: 1, episode reward: 35.151, mean reward: 0.879 [0.211, 1.000], mean action: 21.350 [12.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.256589, mean_absolute_error: 5.928127, mean_q: 6.659462
136 (array([12]),) False
 195320/500000: episode: 4883, duration: 31.389s, episode steps: 40, steps per second: 1, episode reward: 31.077, mean reward: 0.777 [0.122, 0.938], mean action: 21.575 [0.000, 40.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.246204, mean_absolute_error: 5.968001, mean_q: 6.701917
42 (array([22]),) False
 195360/500000: episode: 4884, duration: 31.401s, episode steps: 40, steps per second: 1, episode reward: 35.733, mean reward: 0.893 [0.063, 1.000], mean action: 23.600 [8.000, 56.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.256990, mean_absolute_error: 5.949642, mean_q: 6.679025
384 (array([22]),) False
 195400/500000: episode: 4885, duration: 31.462s, episode steps: 40, steps per second: 1, episode reward: 38.701, mean reward: 0.968 [0.278, 1.000], mean action: 22.950 [22.000, 52.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.303743, mean_absolute_error: 5.972329, mean_q: 6.690886
42 (array([22]),) False
 195440/500000: episode: 4886, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 37.730, mean reward: 0.943 [0.071, 1.000], mean action: 21.250 [2.000, 39.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.263804, mean_absolute_error: 5.999518, mean_q: 6.714110
89 (array([58]),) False
 195480/500000: episode: 4887, duration: 32.238s, episode steps: 40, steps per second: 1, episode reward: 6.185, mean reward: 0.155 [0.020, 1.000], mean action: 25.350 [3.000, 58.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.248571, mean_absolute_error: 5.922771, mean_q: 6.645662
861 (array([22]),) False
 195520/500000: episode: 4888, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 37.487, mean reward: 0.937 [0.265, 1.000], mean action: 21.950 [13.000, 49.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.262777, mean_absolute_error: 5.996398, mean_q: 6.727113
555 (array([22]),) False
 195560/500000: episode: 4889, duration: 32.289s, episode steps: 40, steps per second: 1, episode reward: 35.757, mean reward: 0.894 [0.135, 1.000], mean action: 22.700 [12.000, 58.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.301779, mean_absolute_error: 5.938663, mean_q: 6.665529
471 (array([12]),) False
 195600/500000: episode: 4890, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 33.446, mean reward: 0.836 [0.240, 1.000], mean action: 22.475 [12.000, 57.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.324449, mean_absolute_error: 5.917490, mean_q: 6.640513
378 (array([22]),) False
 195640/500000: episode: 4891, duration: 33.073s, episode steps: 40, steps per second: 1, episode reward: 38.971, mean reward: 0.974 [0.555, 1.000], mean action: 23.825 [22.000, 55.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.245201, mean_absolute_error: 5.959515, mean_q: 6.678741
236 (array([22]),) False
 195680/500000: episode: 4892, duration: 33.227s, episode steps: 40, steps per second: 1, episode reward: 38.041, mean reward: 0.951 [0.213, 1.000], mean action: 24.125 [16.000, 57.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.276714, mean_absolute_error: 6.021297, mean_q: 6.751309
28 (array([58]),) False
 195720/500000: episode: 4893, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 20.825, mean reward: 0.521 [0.000, 1.000], mean action: 27.850 [15.000, 58.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.290372, mean_absolute_error: 5.980950, mean_q: 6.705553
140 (array([12]),) False
 195760/500000: episode: 4894, duration: 33.232s, episode steps: 40, steps per second: 1, episode reward: 31.257, mean reward: 0.781 [0.019, 0.947], mean action: 21.600 [7.000, 42.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.253564, mean_absolute_error: 5.984042, mean_q: 6.707069
503 (array([3]),) False
 195800/500000: episode: 4895, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 12.370, mean reward: 0.309 [0.159, 0.418], mean action: 17.650 [12.000, 54.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.279978, mean_absolute_error: 5.910236, mean_q: 6.627940
737 (array([15]),) False
 195840/500000: episode: 4896, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 27.074, mean reward: 0.677 [0.272, 0.971], mean action: 36.750 [12.000, 48.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.286339, mean_absolute_error: 6.016892, mean_q: 6.732858
767 (array([48]),) False
 195880/500000: episode: 4897, duration: 32.233s, episode steps: 40, steps per second: 1, episode reward: 28.566, mean reward: 0.714 [0.104, 1.000], mean action: 18.050 [12.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.254638, mean_absolute_error: 6.022654, mean_q: 6.734086
673 (array([3]),) False
 195920/500000: episode: 4898, duration: 33.199s, episode steps: 40, steps per second: 1, episode reward: 29.850, mean reward: 0.746 [0.158, 1.000], mean action: 15.750 [0.000, 56.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.265170, mean_absolute_error: 5.933668, mean_q: 6.649045
831 (array([3]),) False
 195960/500000: episode: 4899, duration: 32.229s, episode steps: 40, steps per second: 1, episode reward: 28.277, mean reward: 0.707 [0.000, 1.000], mean action: 10.225 [4.000, 51.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.238781, mean_absolute_error: 5.932411, mean_q: 6.653819
770 (array([22]),) False
 196000/500000: episode: 4900, duration: 33.245s, episode steps: 40, steps per second: 1, episode reward: 34.710, mean reward: 0.868 [0.002, 1.000], mean action: 15.625 [11.000, 59.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.269153, mean_absolute_error: 6.013513, mean_q: 6.735156
12 (array([22]),) False
 196040/500000: episode: 4901, duration: 32.306s, episode steps: 40, steps per second: 1, episode reward: 36.142, mean reward: 0.904 [0.038, 1.000], mean action: 26.725 [3.000, 52.000], mean observation: -0.037 [-1.000, 1.000], loss: 0.259049, mean_absolute_error: 6.019850, mean_q: 6.740154
854 (array([12]),) False
 196080/500000: episode: 4902, duration: 33.144s, episode steps: 40, steps per second: 1, episode reward: 32.737, mean reward: 0.818 [0.448, 1.000], mean action: 15.700 [12.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.246237, mean_absolute_error: 5.995584, mean_q: 6.720823
467 (array([48]),) False
 196120/500000: episode: 4903, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 34.908, mean reward: 0.873 [0.122, 1.000], mean action: 21.100 [0.000, 54.000], mean observation: -0.083 [-1.000, 1.000], loss: 0.295945, mean_absolute_error: 6.025311, mean_q: 6.742918
830 (array([22]),) False
 196160/500000: episode: 4904, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 37.626, mean reward: 0.941 [0.177, 1.000], mean action: 22.950 [12.000, 58.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.281790, mean_absolute_error: 5.959214, mean_q: 6.666953
495 (array([48]),) False
 196200/500000: episode: 4905, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 37.065, mean reward: 0.927 [0.354, 0.966], mean action: 21.850 [7.000, 41.000], mean observation: -0.093 [-1.000, 1.000], loss: 0.249135, mean_absolute_error: 5.916872, mean_q: 6.628100
482 (array([22]),) False
 196240/500000: episode: 4906, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 34.706, mean reward: 0.868 [0.178, 1.000], mean action: 33.100 [0.000, 49.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.256635, mean_absolute_error: 5.991027, mean_q: 6.716277
858 (array([12]),) False
 196280/500000: episode: 4907, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 31.835, mean reward: 0.796 [0.144, 1.000], mean action: 19.325 [10.000, 45.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.282301, mean_absolute_error: 5.894811, mean_q: 6.617170
233 (array([54]),) False
 196320/500000: episode: 4908, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 27.135, mean reward: 0.678 [0.316, 0.879], mean action: 23.925 [4.000, 46.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.259042, mean_absolute_error: 5.952663, mean_q: 6.678341
48 (array([12]),) False
 196360/500000: episode: 4909, duration: 32.295s, episode steps: 40, steps per second: 1, episode reward: 34.485, mean reward: 0.862 [0.414, 1.000], mean action: 15.375 [5.000, 59.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.254680, mean_absolute_error: 5.952830, mean_q: 6.678414
167 (array([22]),) False
 196400/500000: episode: 4910, duration: 33.080s, episode steps: 40, steps per second: 1, episode reward: 35.669, mean reward: 0.892 [0.203, 1.000], mean action: 14.275 [8.000, 44.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.246094, mean_absolute_error: 5.882957, mean_q: 6.602229
476 (array([48]),) False
 196440/500000: episode: 4911, duration: 32.221s, episode steps: 40, steps per second: 1, episode reward: 35.873, mean reward: 0.897 [0.422, 0.999], mean action: 16.375 [1.000, 49.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.271248, mean_absolute_error: 5.940327, mean_q: 6.663188
96 (array([22]),) False
 196480/500000: episode: 4912, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 37.033, mean reward: 0.926 [0.072, 1.000], mean action: 24.550 [10.000, 57.000], mean observation: -0.095 [-1.000, 1.000], loss: 0.238974, mean_absolute_error: 5.948281, mean_q: 6.671832
226 (array([22]),) False
 196520/500000: episode: 4913, duration: 32.262s, episode steps: 40, steps per second: 1, episode reward: 34.699, mean reward: 0.867 [0.099, 1.000], mean action: 24.600 [13.000, 55.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.272997, mean_absolute_error: 6.028458, mean_q: 6.754509
805 (array([22]),) False
 196560/500000: episode: 4914, duration: 33.193s, episode steps: 40, steps per second: 1, episode reward: 34.425, mean reward: 0.861 [0.017, 1.000], mean action: 25.350 [5.000, 48.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.295655, mean_absolute_error: 6.090283, mean_q: 6.815726
411 (array([22]),) False
 196600/500000: episode: 4915, duration: 33.028s, episode steps: 40, steps per second: 1, episode reward: 38.672, mean reward: 0.967 [0.418, 1.000], mean action: 20.925 [0.000, 22.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.299277, mean_absolute_error: 5.981052, mean_q: 6.693715
499 (array([8]),) False
 196640/500000: episode: 4916, duration: 33.160s, episode steps: 40, steps per second: 1, episode reward: 14.435, mean reward: 0.361 [0.225, 0.493], mean action: 29.800 [12.000, 54.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.254759, mean_absolute_error: 5.907603, mean_q: 6.617879
18 (array([22]),) False
 196680/500000: episode: 4917, duration: 33.153s, episode steps: 40, steps per second: 1, episode reward: 38.437, mean reward: 0.961 [0.333, 1.000], mean action: 23.700 [22.000, 60.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.274319, mean_absolute_error: 6.090536, mean_q: 6.815005
421 (array([22]),) False
 196720/500000: episode: 4918, duration: 33.151s, episode steps: 40, steps per second: 1, episode reward: 24.341, mean reward: 0.609 [0.000, 1.000], mean action: 29.400 [1.000, 54.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.256038, mean_absolute_error: 6.005210, mean_q: 6.724396
394 (array([22]),) False
 196760/500000: episode: 4919, duration: 33.155s, episode steps: 40, steps per second: 1, episode reward: 38.876, mean reward: 0.972 [0.083, 1.000], mean action: 22.325 [10.000, 47.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.275400, mean_absolute_error: 6.012938, mean_q: 6.734059
612 (array([22]),) False
 196800/500000: episode: 4920, duration: 33.110s, episode steps: 40, steps per second: 1, episode reward: 33.569, mean reward: 0.839 [0.000, 1.000], mean action: 17.550 [0.000, 48.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.246838, mean_absolute_error: 5.931917, mean_q: 6.653496
28 (array([58]),) False
 196840/500000: episode: 4921, duration: 32.227s, episode steps: 40, steps per second: 1, episode reward: 19.123, mean reward: 0.478 [0.000, 1.000], mean action: 21.550 [5.000, 60.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.264511, mean_absolute_error: 5.940153, mean_q: 6.651741
724 (array([58]),) False
 196880/500000: episode: 4922, duration: 33.135s, episode steps: 40, steps per second: 1, episode reward: 15.312, mean reward: 0.383 [0.005, 0.795], mean action: 24.900 [3.000, 53.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.256109, mean_absolute_error: 6.122177, mean_q: 6.837522
299 (array([12]),) False
 196920/500000: episode: 4923, duration: 32.251s, episode steps: 40, steps per second: 1, episode reward: 33.147, mean reward: 0.829 [0.119, 1.000], mean action: 21.000 [2.000, 27.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.297948, mean_absolute_error: 5.970014, mean_q: 6.680196
637 (array([12]),) False
 196960/500000: episode: 4924, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 36.427, mean reward: 0.911 [0.561, 1.000], mean action: 18.825 [12.000, 55.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.271003, mean_absolute_error: 6.002170, mean_q: 6.718611
34 (array([22]),) False
 197000/500000: episode: 4925, duration: 32.240s, episode steps: 40, steps per second: 1, episode reward: 38.145, mean reward: 0.954 [0.195, 1.000], mean action: 22.275 [7.000, 54.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.257507, mean_absolute_error: 5.946995, mean_q: 6.659451
49 (array([22]),) False
 197040/500000: episode: 4926, duration: 33.087s, episode steps: 40, steps per second: 1, episode reward: 37.225, mean reward: 0.931 [0.069, 1.000], mean action: 22.025 [10.000, 47.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.263011, mean_absolute_error: 6.049952, mean_q: 6.765939
456 (array([22]),) False
 197080/500000: episode: 4927, duration: 33.062s, episode steps: 40, steps per second: 1, episode reward: 37.996, mean reward: 0.950 [0.043, 1.000], mean action: 22.475 [19.000, 43.000], mean observation: -0.065 [-1.000, 1.000], loss: 0.250590, mean_absolute_error: 5.906710, mean_q: 6.614165
477 (array([22]),) False
 197120/500000: episode: 4928, duration: 33.184s, episode steps: 40, steps per second: 1, episode reward: 32.106, mean reward: 0.803 [0.055, 1.000], mean action: 31.100 [2.000, 52.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.319330, mean_absolute_error: 5.960683, mean_q: 6.668311
482 (array([22]),) False
 197160/500000: episode: 4929, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 33.304, mean reward: 0.833 [0.398, 1.000], mean action: 38.500 [12.000, 58.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.254347, mean_absolute_error: 5.984505, mean_q: 6.686937
70 (array([22]),) False
 197200/500000: episode: 4930, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 36.182, mean reward: 0.905 [0.037, 1.000], mean action: 16.725 [8.000, 38.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.323862, mean_absolute_error: 5.898160, mean_q: 6.607292
833 (array([22]),) False
 197240/500000: episode: 4931, duration: 33.177s, episode steps: 40, steps per second: 1, episode reward: 35.451, mean reward: 0.886 [0.289, 1.000], mean action: 17.075 [0.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.268691, mean_absolute_error: 5.956306, mean_q: 6.668664
327 (array([22]),) False
 197280/500000: episode: 4932, duration: 33.206s, episode steps: 40, steps per second: 1, episode reward: 33.961, mean reward: 0.849 [0.360, 1.000], mean action: 14.425 [0.000, 60.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.236641, mean_absolute_error: 5.929713, mean_q: 6.638339
766 (array([12]),) False
 197320/500000: episode: 4933, duration: 32.238s, episode steps: 40, steps per second: 1, episode reward: 34.542, mean reward: 0.864 [0.074, 1.000], mean action: 19.975 [5.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.259263, mean_absolute_error: 5.942658, mean_q: 6.657754
298 (array([22]),) False
 197360/500000: episode: 4934, duration: 33.125s, episode steps: 40, steps per second: 1, episode reward: 36.736, mean reward: 0.918 [0.226, 1.000], mean action: 23.625 [22.000, 55.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.278271, mean_absolute_error: 5.915130, mean_q: 6.630205
7 (array([22]),) False
 197400/500000: episode: 4935, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 37.753, mean reward: 0.944 [0.123, 1.000], mean action: 21.275 [0.000, 35.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.252880, mean_absolute_error: 5.855827, mean_q: 6.570160
84 (array([22]),) False
 197440/500000: episode: 4936, duration: 33.121s, episode steps: 40, steps per second: 1, episode reward: 34.705, mean reward: 0.868 [0.058, 1.000], mean action: 22.825 [8.000, 52.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.256791, mean_absolute_error: 5.909400, mean_q: 6.629105
544 (array([22]),) False
 197480/500000: episode: 4937, duration: 32.166s, episode steps: 40, steps per second: 1, episode reward: 38.899, mean reward: 0.972 [0.726, 1.000], mean action: 23.650 [12.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.254881, mean_absolute_error: 5.836467, mean_q: 6.549271
581 (array([22]),) False
 197520/500000: episode: 4938, duration: 33.214s, episode steps: 40, steps per second: 1, episode reward: 37.040, mean reward: 0.926 [0.252, 1.000], mean action: 22.100 [2.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.267193, mean_absolute_error: 5.930091, mean_q: 6.642166
684 (array([22]),) False
 197560/500000: episode: 4939, duration: 33.141s, episode steps: 40, steps per second: 1, episode reward: 34.838, mean reward: 0.871 [0.053, 1.000], mean action: 20.925 [8.000, 55.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.278927, mean_absolute_error: 5.921642, mean_q: 6.633130
516 (array([48]),) False
 197600/500000: episode: 4940, duration: 33.250s, episode steps: 40, steps per second: 1, episode reward: 35.397, mean reward: 0.885 [0.319, 1.000], mean action: 17.050 [12.000, 41.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.277018, mean_absolute_error: 5.833512, mean_q: 6.541714
303 (array([22]),) False
 197640/500000: episode: 4941, duration: 33.081s, episode steps: 40, steps per second: 1, episode reward: 37.124, mean reward: 0.928 [0.243, 1.000], mean action: 22.650 [16.000, 51.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.250764, mean_absolute_error: 5.863697, mean_q: 6.579158
121 (array([22]),) False
 197680/500000: episode: 4942, duration: 33.190s, episode steps: 40, steps per second: 1, episode reward: 35.168, mean reward: 0.879 [0.000, 1.000], mean action: 17.800 [9.000, 52.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.310939, mean_absolute_error: 5.853984, mean_q: 6.562699
179 (array([18]),) False
 197720/500000: episode: 4943, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 34.750, mean reward: 0.869 [0.181, 1.000], mean action: 19.225 [3.000, 47.000], mean observation: -0.175 [-1.000, 1.000], loss: 0.261178, mean_absolute_error: 5.904010, mean_q: 6.612043
22 (array([37]),) False
 197760/500000: episode: 4944, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 29.417, mean reward: 0.735 [0.134, 0.807], mean action: 30.150 [4.000, 49.000], mean observation: -0.041 [-1.000, 1.000], loss: 0.257368, mean_absolute_error: 5.868102, mean_q: 6.579956
91 (array([48]),) False
 197800/500000: episode: 4945, duration: 32.205s, episode steps: 40, steps per second: 1, episode reward: 34.338, mean reward: 0.858 [0.207, 1.000], mean action: 22.875 [8.000, 55.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.280089, mean_absolute_error: 5.832458, mean_q: 6.535586
140 (array([12]),) False
 197840/500000: episode: 4946, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 38.598, mean reward: 0.965 [0.264, 1.000], mean action: 13.750 [4.000, 50.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.279478, mean_absolute_error: 5.921888, mean_q: 6.622320
688 (array([22]),) False
 197880/500000: episode: 4947, duration: 32.250s, episode steps: 40, steps per second: 1, episode reward: 36.636, mean reward: 0.916 [0.000, 1.000], mean action: 22.275 [12.000, 58.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.263523, mean_absolute_error: 5.890601, mean_q: 6.592160
780 (array([22]),) False
 197920/500000: episode: 4948, duration: 33.225s, episode steps: 40, steps per second: 1, episode reward: 35.773, mean reward: 0.894 [0.024, 1.000], mean action: 20.550 [11.000, 50.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.253926, mean_absolute_error: 5.848215, mean_q: 6.540848
607 (array([12]),) False
 197960/500000: episode: 4949, duration: 32.278s, episode steps: 40, steps per second: 1, episode reward: 37.135, mean reward: 0.928 [0.174, 1.000], mean action: 18.300 [12.000, 51.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.264089, mean_absolute_error: 5.871184, mean_q: 6.561048
143 (array([12]),) False
 198000/500000: episode: 4950, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 36.196, mean reward: 0.905 [0.518, 1.000], mean action: 13.500 [12.000, 49.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.245408, mean_absolute_error: 5.973847, mean_q: 6.679205
595 (array([22]),) False
 198040/500000: episode: 4951, duration: 33.114s, episode steps: 40, steps per second: 1, episode reward: 34.258, mean reward: 0.856 [0.292, 1.000], mean action: 13.850 [12.000, 48.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.260991, mean_absolute_error: 5.874250, mean_q: 6.569218
312 (array([12]),) False
 198080/500000: episode: 4952, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 32.749, mean reward: 0.819 [0.082, 1.000], mean action: 16.050 [3.000, 43.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.249941, mean_absolute_error: 5.860756, mean_q: 6.558257
265 (array([22]),) False
 198120/500000: episode: 4953, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 34.952, mean reward: 0.874 [0.276, 1.000], mean action: 19.225 [6.000, 40.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.270135, mean_absolute_error: 5.953496, mean_q: 6.651227
211 (array([22]),) False
 198160/500000: episode: 4954, duration: 33.090s, episode steps: 40, steps per second: 1, episode reward: 33.219, mean reward: 0.830 [0.034, 1.000], mean action: 22.075 [1.000, 44.000], mean observation: -0.192 [-1.000, 1.000], loss: 0.296967, mean_absolute_error: 5.909137, mean_q: 6.600871
850 (array([12]),) False
 198200/500000: episode: 4955, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 32.159, mean reward: 0.804 [0.167, 1.000], mean action: 20.300 [1.000, 53.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.251712, mean_absolute_error: 5.895905, mean_q: 6.596517
540 (array([22]),) False
 198240/500000: episode: 4956, duration: 33.161s, episode steps: 40, steps per second: 1, episode reward: 37.610, mean reward: 0.940 [0.119, 1.000], mean action: 26.550 [0.000, 49.000], mean observation: -0.125 [-1.000, 1.000], loss: 0.257556, mean_absolute_error: 5.879210, mean_q: 6.579295
793 (array([12]),) False
 198280/500000: episode: 4957, duration: 32.206s, episode steps: 40, steps per second: 1, episode reward: 38.544, mean reward: 0.964 [0.265, 1.000], mean action: 14.050 [12.000, 57.000], mean observation: -0.149 [-1.000, 1.000], loss: 0.266113, mean_absolute_error: 5.832040, mean_q: 6.538275
435 (array([22]),) False
 198320/500000: episode: 4958, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 35.919, mean reward: 0.898 [0.044, 1.000], mean action: 22.025 [4.000, 40.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.304489, mean_absolute_error: 5.813378, mean_q: 6.515741
773 (array([22]),) False
 198360/500000: episode: 4959, duration: 32.175s, episode steps: 40, steps per second: 1, episode reward: 32.930, mean reward: 0.823 [0.000, 1.000], mean action: 18.200 [6.000, 52.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.264616, mean_absolute_error: 5.851354, mean_q: 6.556341
198 (array([22]),) False
 198400/500000: episode: 4960, duration: 33.168s, episode steps: 40, steps per second: 1, episode reward: 37.652, mean reward: 0.941 [0.430, 1.000], mean action: 13.950 [12.000, 41.000], mean observation: -0.177 [-1.000, 1.000], loss: 0.233057, mean_absolute_error: 5.844920, mean_q: 6.543118
171 (array([22]),) False
 198440/500000: episode: 4961, duration: 32.269s, episode steps: 40, steps per second: 1, episode reward: 34.352, mean reward: 0.859 [0.155, 1.000], mean action: 16.300 [8.000, 37.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.242382, mean_absolute_error: 5.913494, mean_q: 6.619426
133 (array([22]),) False
 198480/500000: episode: 4962, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 34.157, mean reward: 0.854 [0.094, 1.000], mean action: 21.300 [3.000, 45.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.259187, mean_absolute_error: 5.908082, mean_q: 6.606246
193 (array([36]),) False
 198520/500000: episode: 4963, duration: 33.138s, episode steps: 40, steps per second: 1, episode reward: 23.927, mean reward: 0.598 [0.009, 0.993], mean action: 19.725 [3.000, 46.000], mean observation: -0.172 [-1.000, 1.000], loss: 0.264710, mean_absolute_error: 5.881690, mean_q: 6.579214
401 (array([12]),) False
 198560/500000: episode: 4964, duration: 33.156s, episode steps: 40, steps per second: 1, episode reward: 30.989, mean reward: 0.775 [0.117, 1.000], mean action: 20.900 [9.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.240414, mean_absolute_error: 5.810770, mean_q: 6.509344
484 (array([22]),) False
 198600/500000: episode: 4965, duration: 33.173s, episode steps: 40, steps per second: 1, episode reward: 36.129, mean reward: 0.903 [0.227, 1.000], mean action: 38.550 [5.000, 56.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.264464, mean_absolute_error: 5.917065, mean_q: 6.621449
52 (array([22]),) False
 198640/500000: episode: 4966, duration: 33.150s, episode steps: 40, steps per second: 1, episode reward: 36.379, mean reward: 0.909 [0.105, 1.000], mean action: 22.675 [6.000, 48.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.292737, mean_absolute_error: 5.937441, mean_q: 6.635048
503 (array([3]),) False
 198680/500000: episode: 4967, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 11.759, mean reward: 0.294 [0.160, 0.465], mean action: 21.300 [12.000, 44.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.252270, mean_absolute_error: 5.953000, mean_q: 6.650810
573 (array([22]),) False
 198720/500000: episode: 4968, duration: 33.137s, episode steps: 40, steps per second: 1, episode reward: 34.183, mean reward: 0.855 [0.300, 1.000], mean action: 17.300 [0.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.280280, mean_absolute_error: 5.915895, mean_q: 6.611651
4 (array([22]),) False
 198760/500000: episode: 4969, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 30.619, mean reward: 0.765 [0.051, 1.000], mean action: 21.275 [4.000, 35.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.245450, mean_absolute_error: 5.977122, mean_q: 6.671492
322 (array([12]),) False
 198800/500000: episode: 4970, duration: 32.042s, episode steps: 40, steps per second: 1, episode reward: 34.623, mean reward: 0.866 [0.112, 1.000], mean action: 25.850 [22.000, 56.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.253064, mean_absolute_error: 5.875980, mean_q: 6.572378
268 (array([22]),) False
 198840/500000: episode: 4971, duration: 30.369s, episode steps: 40, steps per second: 1, episode reward: 38.657, mean reward: 0.966 [0.469, 1.000], mean action: 19.775 [12.000, 22.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.228449, mean_absolute_error: 5.893593, mean_q: 6.591990
751 (array([22]),) False
 198880/500000: episode: 4972, duration: 31.311s, episode steps: 40, steps per second: 1, episode reward: 30.551, mean reward: 0.764 [0.009, 1.000], mean action: 25.350 [4.000, 57.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.273623, mean_absolute_error: 5.929604, mean_q: 6.630067
360 (array([22]),) False
 198920/500000: episode: 4973, duration: 31.025s, episode steps: 40, steps per second: 1, episode reward: 31.103, mean reward: 0.778 [0.250, 1.000], mean action: 19.900 [3.000, 59.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.266743, mean_absolute_error: 5.891642, mean_q: 6.585434
831 (array([3]),) False
 198960/500000: episode: 4974, duration: 31.619s, episode steps: 40, steps per second: 1, episode reward: 31.113, mean reward: 0.778 [0.031, 1.000], mean action: 9.475 [0.000, 58.000], mean observation: -0.116 [-1.000, 1.000], loss: 0.225662, mean_absolute_error: 5.858420, mean_q: 6.561223
299 (array([12]),) False
 199000/500000: episode: 4975, duration: 31.438s, episode steps: 40, steps per second: 1, episode reward: 34.241, mean reward: 0.856 [0.284, 1.000], mean action: 21.475 [0.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.272186, mean_absolute_error: 5.858261, mean_q: 6.558973
735 (array([22]),) False
 199040/500000: episode: 4976, duration: 31.455s, episode steps: 40, steps per second: 1, episode reward: 34.079, mean reward: 0.852 [0.007, 1.000], mean action: 24.250 [7.000, 52.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.266773, mean_absolute_error: 5.913923, mean_q: 6.616334
51 (array([22]),) False
 199080/500000: episode: 4977, duration: 31.359s, episode steps: 40, steps per second: 1, episode reward: 38.715, mean reward: 0.968 [0.306, 1.000], mean action: 22.050 [0.000, 46.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.234603, mean_absolute_error: 5.904796, mean_q: 6.613348
500 (array([22]),) False
 199120/500000: episode: 4978, duration: 31.325s, episode steps: 40, steps per second: 1, episode reward: 33.811, mean reward: 0.845 [0.163, 1.000], mean action: 18.575 [2.000, 50.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.226522, mean_absolute_error: 5.896483, mean_q: 6.602572
121 (array([22]),) False
 199160/500000: episode: 4979, duration: 31.416s, episode steps: 40, steps per second: 1, episode reward: 34.905, mean reward: 0.873 [0.327, 1.000], mean action: 16.275 [5.000, 50.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.269100, mean_absolute_error: 5.884187, mean_q: 6.592059
173 (array([3]),) False
 199200/500000: episode: 4980, duration: 31.397s, episode steps: 40, steps per second: 1, episode reward: 32.401, mean reward: 0.810 [0.045, 1.000], mean action: 8.225 [0.000, 57.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.249169, mean_absolute_error: 5.951555, mean_q: 6.665526
106 (array([22]),) False
 199240/500000: episode: 4981, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 36.887, mean reward: 0.922 [0.254, 1.000], mean action: 20.600 [0.000, 56.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.285287, mean_absolute_error: 5.958524, mean_q: 6.662387
447 (array([44]),) False
 199280/500000: episode: 4982, duration: 31.382s, episode steps: 40, steps per second: 1, episode reward: 29.893, mean reward: 0.747 [0.000, 1.000], mean action: 21.950 [3.000, 54.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.290129, mean_absolute_error: 5.974855, mean_q: 6.677651
238 (array([22]),) False
 199320/500000: episode: 4983, duration: 30.923s, episode steps: 40, steps per second: 1, episode reward: 35.087, mean reward: 0.877 [0.062, 1.000], mean action: 22.925 [8.000, 60.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.234267, mean_absolute_error: 5.940565, mean_q: 6.645705
386 (array([12]),) False
 199360/500000: episode: 4984, duration: 31.522s, episode steps: 40, steps per second: 1, episode reward: 32.930, mean reward: 0.823 [0.306, 0.897], mean action: 28.075 [16.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.327001, mean_absolute_error: 5.974104, mean_q: 6.679659
577 (array([12]),) False
 199400/500000: episode: 4985, duration: 31.003s, episode steps: 40, steps per second: 1, episode reward: 35.136, mean reward: 0.878 [0.050, 1.000], mean action: 22.125 [2.000, 44.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.256511, mean_absolute_error: 5.953400, mean_q: 6.656302
569 (array([22]),) False
 199440/500000: episode: 4986, duration: 31.415s, episode steps: 40, steps per second: 1, episode reward: 30.805, mean reward: 0.770 [0.278, 1.000], mean action: 28.850 [12.000, 53.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.252067, mean_absolute_error: 5.923696, mean_q: 6.625797
792 (array([58]),) False
 199480/500000: episode: 4987, duration: 31.449s, episode steps: 40, steps per second: 1, episode reward: 12.127, mean reward: 0.303 [0.021, 0.708], mean action: 23.225 [12.000, 51.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.227929, mean_absolute_error: 5.894966, mean_q: 6.598620
547 (array([21]),) False
 199520/500000: episode: 4988, duration: 32.865s, episode steps: 40, steps per second: 1, episode reward: 29.178, mean reward: 0.729 [0.271, 1.000], mean action: 24.150 [12.000, 48.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.254135, mean_absolute_error: 5.909941, mean_q: 6.614998
185 (array([22]),) False
 199560/500000: episode: 4989, duration: 33.077s, episode steps: 40, steps per second: 1, episode reward: 33.859, mean reward: 0.846 [0.224, 1.000], mean action: 21.875 [12.000, 55.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.262759, mean_absolute_error: 5.882573, mean_q: 6.580724
788 (array([3]),) False
 199600/500000: episode: 4990, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 26.477, mean reward: 0.662 [0.057, 1.000], mean action: 26.600 [3.000, 58.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.267725, mean_absolute_error: 6.065853, mean_q: 6.776450
502 (array([22]),) False
 199640/500000: episode: 4991, duration: 33.226s, episode steps: 40, steps per second: 1, episode reward: 31.800, mean reward: 0.795 [0.160, 1.000], mean action: 17.700 [3.000, 45.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.234944, mean_absolute_error: 6.012632, mean_q: 6.716153
73 (array([22]),) False
 199680/500000: episode: 4992, duration: 33.130s, episode steps: 40, steps per second: 1, episode reward: 38.334, mean reward: 0.958 [0.340, 1.000], mean action: 19.650 [12.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.287437, mean_absolute_error: 6.008262, mean_q: 6.719136
73 (array([22]),) False
 199720/500000: episode: 4993, duration: 32.237s, episode steps: 40, steps per second: 1, episode reward: 37.014, mean reward: 0.925 [0.242, 1.000], mean action: 18.425 [12.000, 37.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.273856, mean_absolute_error: 5.994307, mean_q: 6.697910
821 (array([22]),) False
 199760/500000: episode: 4994, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 35.158, mean reward: 0.879 [0.142, 1.000], mean action: 19.400 [7.000, 56.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.271460, mean_absolute_error: 6.011897, mean_q: 6.716220
341 (array([22]),) False
 199800/500000: episode: 4995, duration: 32.245s, episode steps: 40, steps per second: 1, episode reward: 36.189, mean reward: 0.905 [0.104, 1.000], mean action: 27.950 [22.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.272571, mean_absolute_error: 6.008121, mean_q: 6.714880
35 (array([48]),) False
 199840/500000: episode: 4996, duration: 33.127s, episode steps: 40, steps per second: 1, episode reward: 31.922, mean reward: 0.798 [0.004, 0.959], mean action: 14.575 [5.000, 37.000], mean observation: -0.062 [-1.000, 1.000], loss: 0.243484, mean_absolute_error: 5.995145, mean_q: 6.706367
682 (array([22]),) False
 199880/500000: episode: 4997, duration: 32.282s, episode steps: 40, steps per second: 1, episode reward: 37.284, mean reward: 0.932 [0.174, 1.000], mean action: 13.450 [8.000, 47.000], mean observation: -0.111 [-1.000, 1.000], loss: 0.235986, mean_absolute_error: 6.025800, mean_q: 6.730482
842 (array([22]),) False
 199920/500000: episode: 4998, duration: 33.163s, episode steps: 40, steps per second: 1, episode reward: 29.401, mean reward: 0.735 [0.459, 1.000], mean action: 18.775 [12.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.257977, mean_absolute_error: 6.016507, mean_q: 6.723372
353 (array([22]),) False
 199960/500000: episode: 4999, duration: 33.266s, episode steps: 40, steps per second: 1, episode reward: 35.872, mean reward: 0.897 [0.194, 1.000], mean action: 23.225 [8.000, 47.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.261963, mean_absolute_error: 5.956845, mean_q: 6.668749
492 (array([22]),) False
 200000/500000: episode: 5000, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 35.656, mean reward: 0.891 [0.102, 1.000], mean action: 23.150 [7.000, 54.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.305922, mean_absolute_error: 6.011157, mean_q: 6.729374
95 (array([22]),) False
 200040/500000: episode: 5001, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 37.191, mean reward: 0.930 [0.195, 1.000], mean action: 22.525 [9.000, 53.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.268523, mean_absolute_error: 5.956382, mean_q: 6.667428
577 (array([12]),) False
 200080/500000: episode: 5002, duration: 33.107s, episode steps: 40, steps per second: 1, episode reward: 37.989, mean reward: 0.950 [0.072, 1.000], mean action: 23.825 [22.000, 59.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.245714, mean_absolute_error: 5.885826, mean_q: 6.591609
576 (array([58]),) False
 200120/500000: episode: 5003, duration: 33.175s, episode steps: 40, steps per second: 1, episode reward: 20.776, mean reward: 0.519 [0.239, 0.796], mean action: 24.400 [3.000, 57.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.263182, mean_absolute_error: 6.022442, mean_q: 6.730159
44 (array([22]),) False
 200160/500000: episode: 5004, duration: 33.109s, episode steps: 40, steps per second: 1, episode reward: 34.574, mean reward: 0.864 [0.001, 1.000], mean action: 22.275 [2.000, 60.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.292650, mean_absolute_error: 5.998547, mean_q: 6.696294
43 (array([12]),) False
 200200/500000: episode: 5005, duration: 32.188s, episode steps: 40, steps per second: 1, episode reward: 30.534, mean reward: 0.763 [0.730, 0.998], mean action: 7.975 [5.000, 22.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.262271, mean_absolute_error: 6.015765, mean_q: 6.718935
663 (array([22]),) False
 200240/500000: episode: 5006, duration: 33.113s, episode steps: 40, steps per second: 1, episode reward: 21.478, mean reward: 0.537 [0.089, 1.000], mean action: 17.800 [3.000, 51.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.243527, mean_absolute_error: 5.977065, mean_q: 6.677084
140 (array([12]),) False
 200280/500000: episode: 5007, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 36.090, mean reward: 0.902 [0.019, 1.000], mean action: 15.575 [8.000, 50.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.274096, mean_absolute_error: 5.982510, mean_q: 6.686143
364 (array([14]),) False
 200320/500000: episode: 5008, duration: 33.171s, episode steps: 40, steps per second: 1, episode reward: 33.805, mean reward: 0.845 [0.557, 1.000], mean action: 27.900 [12.000, 49.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.269140, mean_absolute_error: 6.027666, mean_q: 6.731745
610 (array([48]),) False
 200360/500000: episode: 5009, duration: 32.279s, episode steps: 40, steps per second: 1, episode reward: 34.341, mean reward: 0.859 [0.000, 1.000], mean action: 20.150 [2.000, 57.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.258298, mean_absolute_error: 5.960979, mean_q: 6.666247
254 (array([22]),) False
 200400/500000: episode: 5010, duration: 33.185s, episode steps: 40, steps per second: 1, episode reward: 35.902, mean reward: 0.898 [0.002, 1.000], mean action: 20.300 [9.000, 43.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.265942, mean_absolute_error: 5.936706, mean_q: 6.641662
436 (array([22]),) False
 200440/500000: episode: 5011, duration: 32.926s, episode steps: 40, steps per second: 1, episode reward: 36.549, mean reward: 0.914 [0.033, 1.000], mean action: 21.975 [11.000, 48.000], mean observation: -0.038 [-1.000, 1.000], loss: 0.264087, mean_absolute_error: 5.925217, mean_q: 6.638553
288 (array([33]),) False
 200480/500000: episode: 5012, duration: 32.972s, episode steps: 40, steps per second: 1, episode reward: 20.653, mean reward: 0.516 [0.000, 1.000], mean action: 19.650 [12.000, 46.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.303518, mean_absolute_error: 5.844121, mean_q: 6.542082
569 (array([22]),) False
 200520/500000: episode: 5013, duration: 32.102s, episode steps: 40, steps per second: 1, episode reward: 33.255, mean reward: 0.831 [0.160, 1.000], mean action: 24.725 [5.000, 48.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.268889, mean_absolute_error: 5.982362, mean_q: 6.688315
575 (array([44]),) False
 200560/500000: episode: 5014, duration: 32.085s, episode steps: 40, steps per second: 1, episode reward: 36.164, mean reward: 0.904 [0.653, 1.000], mean action: 22.650 [12.000, 40.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.261658, mean_absolute_error: 5.999812, mean_q: 6.708429
684 (array([22]),) False
 200600/500000: episode: 5015, duration: 32.171s, episode steps: 40, steps per second: 1, episode reward: 34.772, mean reward: 0.869 [0.082, 1.000], mean action: 23.375 [1.000, 54.000], mean observation: -0.103 [-1.000, 1.000], loss: 0.231514, mean_absolute_error: 5.931663, mean_q: 6.642467
679 (array([44]),) False
 200640/500000: episode: 5016, duration: 33.040s, episode steps: 40, steps per second: 1, episode reward: 30.171, mean reward: 0.754 [0.000, 1.000], mean action: 17.025 [12.000, 49.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.301736, mean_absolute_error: 5.902925, mean_q: 6.614743
282 (array([22]),) False
 200680/500000: episode: 5017, duration: 32.274s, episode steps: 40, steps per second: 1, episode reward: 37.055, mean reward: 0.926 [0.000, 1.000], mean action: 22.200 [3.000, 48.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.285313, mean_absolute_error: 5.998004, mean_q: 6.712979
342 (array([12]),) False
 200720/500000: episode: 5018, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 36.820, mean reward: 0.921 [0.389, 1.000], mean action: 22.025 [8.000, 43.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.270366, mean_absolute_error: 5.891264, mean_q: 6.600305
266 (array([12]),) False
 200760/500000: episode: 5019, duration: 32.357s, episode steps: 40, steps per second: 1, episode reward: 27.873, mean reward: 0.697 [0.455, 0.857], mean action: 23.925 [22.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.258905, mean_absolute_error: 5.913713, mean_q: 6.619710
294 (array([22]),) False
 200800/500000: episode: 5020, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 37.236, mean reward: 0.931 [0.254, 1.000], mean action: 22.075 [12.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.296928, mean_absolute_error: 5.931828, mean_q: 6.643008
686 (array([48]),) False
 200840/500000: episode: 5021, duration: 32.232s, episode steps: 40, steps per second: 1, episode reward: 32.885, mean reward: 0.822 [0.268, 0.930], mean action: 21.675 [4.000, 50.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.248560, mean_absolute_error: 5.928634, mean_q: 6.636168
17 (array([22]),) False
 200880/500000: episode: 5022, duration: 33.261s, episode steps: 40, steps per second: 1, episode reward: 39.222, mean reward: 0.981 [0.567, 1.000], mean action: 22.175 [12.000, 40.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.241772, mean_absolute_error: 5.938632, mean_q: 6.647340
71 (array([58]),) False
 200920/500000: episode: 5023, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 17.069, mean reward: 0.427 [0.000, 1.000], mean action: 30.750 [0.000, 58.000], mean observation: -0.090 [-1.000, 1.000], loss: 0.242912, mean_absolute_error: 5.988205, mean_q: 6.705066
76 (array([38]),) False
 200960/500000: episode: 5024, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 35.028, mean reward: 0.876 [0.667, 0.960], mean action: 21.125 [12.000, 58.000], mean observation: -0.086 [-1.000, 1.000], loss: 0.231501, mean_absolute_error: 5.963285, mean_q: 6.678533
496 (array([48]),) False
 201000/500000: episode: 5025, duration: 33.187s, episode steps: 40, steps per second: 1, episode reward: 37.166, mean reward: 0.929 [0.242, 1.000], mean action: 21.200 [5.000, 33.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.272197, mean_absolute_error: 5.878169, mean_q: 6.585882
158 (array([22]),) False
 201040/500000: episode: 5026, duration: 33.165s, episode steps: 40, steps per second: 1, episode reward: 36.053, mean reward: 0.901 [0.093, 1.000], mean action: 17.875 [3.000, 48.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.231254, mean_absolute_error: 5.949542, mean_q: 6.662888
17 (array([22]),) False
 201080/500000: episode: 5027, duration: 33.056s, episode steps: 40, steps per second: 1, episode reward: 38.685, mean reward: 0.967 [0.385, 1.000], mean action: 22.950 [22.000, 41.000], mean observation: -0.025 [-1.000, 1.000], loss: 0.279434, mean_absolute_error: 5.954955, mean_q: 6.663657
140 (array([12]),) False
 201120/500000: episode: 5028, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 32.151, mean reward: 0.804 [0.277, 1.000], mean action: 22.050 [6.000, 60.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.241729, mean_absolute_error: 5.885906, mean_q: 6.591456
61 (array([48]),) False
 201160/500000: episode: 5029, duration: 32.247s, episode steps: 40, steps per second: 1, episode reward: 36.778, mean reward: 0.919 [0.295, 1.000], mean action: 24.875 [15.000, 49.000], mean observation: -0.077 [-1.000, 1.000], loss: 0.281368, mean_absolute_error: 5.940974, mean_q: 6.645444
619 (array([3]),) False
 201200/500000: episode: 5030, duration: 33.194s, episode steps: 40, steps per second: 1, episode reward: 37.475, mean reward: 0.937 [0.201, 1.000], mean action: 5.150 [2.000, 41.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.296039, mean_absolute_error: 6.039921, mean_q: 6.748507
535 (array([22]),) False
 201240/500000: episode: 5031, duration: 32.207s, episode steps: 40, steps per second: 1, episode reward: 35.276, mean reward: 0.882 [0.139, 1.000], mean action: 22.225 [12.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.233045, mean_absolute_error: 5.998435, mean_q: 6.700971
230 (array([22]),) False
 201280/500000: episode: 5032, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 37.002, mean reward: 0.925 [0.028, 1.000], mean action: 25.550 [4.000, 59.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.271429, mean_absolute_error: 5.928523, mean_q: 6.636412
27 (array([22]),) False
 201320/500000: episode: 5033, duration: 32.257s, episode steps: 40, steps per second: 1, episode reward: 29.549, mean reward: 0.739 [0.116, 1.000], mean action: 25.650 [2.000, 49.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.317711, mean_absolute_error: 6.002716, mean_q: 6.706705
327 (array([22]),) False
 201360/500000: episode: 5034, duration: 33.139s, episode steps: 40, steps per second: 1, episode reward: 34.536, mean reward: 0.863 [0.138, 0.921], mean action: 13.775 [12.000, 43.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.269852, mean_absolute_error: 6.019065, mean_q: 6.712583
310 (array([12]),) False
 201400/500000: episode: 5035, duration: 33.169s, episode steps: 40, steps per second: 1, episode reward: 35.582, mean reward: 0.890 [0.252, 1.000], mean action: 31.750 [9.000, 43.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.275502, mean_absolute_error: 5.968616, mean_q: 6.665635
614 (array([22]),) False
 201440/500000: episode: 5036, duration: 33.242s, episode steps: 40, steps per second: 1, episode reward: 32.221, mean reward: 0.806 [0.487, 1.000], mean action: 25.075 [12.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.253337, mean_absolute_error: 5.813464, mean_q: 6.511556
220 (array([22]),) False
 201480/500000: episode: 5037, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 36.673, mean reward: 0.917 [0.103, 1.000], mean action: 22.500 [0.000, 54.000], mean observation: -0.194 [-1.000, 1.000], loss: 0.248754, mean_absolute_error: 5.847220, mean_q: 6.550926
792 (array([58]),) False
 201520/500000: episode: 5038, duration: 33.132s, episode steps: 40, steps per second: 1, episode reward: 17.081, mean reward: 0.427 [0.049, 0.965], mean action: 20.350 [4.000, 39.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.244389, mean_absolute_error: 5.977002, mean_q: 6.689351
755 (array([22]),) False
 201560/500000: episode: 5039, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 28.313, mean reward: 0.708 [0.000, 1.000], mean action: 39.200 [9.000, 47.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.273867, mean_absolute_error: 5.942722, mean_q: 6.654584
782 (array([22]),) False
 201600/500000: episode: 5040, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 27.055, mean reward: 0.676 [0.200, 1.000], mean action: 27.775 [12.000, 54.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.257268, mean_absolute_error: 5.926426, mean_q: 6.634524
459 (array([22]),) False
 201640/500000: episode: 5041, duration: 32.230s, episode steps: 40, steps per second: 1, episode reward: 37.631, mean reward: 0.941 [0.283, 1.000], mean action: 23.800 [2.000, 49.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.278166, mean_absolute_error: 5.920753, mean_q: 6.626201
756 (array([48]),) False
 201680/500000: episode: 5042, duration: 33.192s, episode steps: 40, steps per second: 1, episode reward: 35.784, mean reward: 0.895 [0.323, 0.991], mean action: 37.925 [22.000, 58.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.271289, mean_absolute_error: 5.950426, mean_q: 6.649671
601 (array([14]),) False
 201720/500000: episode: 5043, duration: 32.218s, episode steps: 40, steps per second: 1, episode reward: 33.879, mean reward: 0.847 [0.334, 1.000], mean action: 25.750 [12.000, 54.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.301616, mean_absolute_error: 6.016389, mean_q: 6.718927
230 (array([22]),) False
 201760/500000: episode: 5044, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 36.537, mean reward: 0.913 [0.015, 1.000], mean action: 23.225 [0.000, 59.000], mean observation: -0.159 [-1.000, 1.000], loss: 0.269173, mean_absolute_error: 5.875321, mean_q: 6.572421
707 (array([48]),) False
 201800/500000: episode: 5045, duration: 32.309s, episode steps: 40, steps per second: 1, episode reward: 32.118, mean reward: 0.803 [0.083, 0.943], mean action: 18.725 [3.000, 31.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.247669, mean_absolute_error: 5.882262, mean_q: 6.576964
39 (array([22]),) False
 201840/500000: episode: 5046, duration: 33.207s, episode steps: 40, steps per second: 1, episode reward: 38.429, mean reward: 0.961 [0.131, 1.000], mean action: 22.625 [15.000, 49.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.250122, mean_absolute_error: 5.920470, mean_q: 6.622598
697 (array([22]),) False
 201880/500000: episode: 5047, duration: 33.148s, episode steps: 40, steps per second: 1, episode reward: 37.369, mean reward: 0.934 [0.068, 1.000], mean action: 19.800 [11.000, 34.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.237709, mean_absolute_error: 5.871854, mean_q: 6.570262
68 (array([22]),) False
 201920/500000: episode: 5048, duration: 33.208s, episode steps: 40, steps per second: 1, episode reward: 31.022, mean reward: 0.776 [0.062, 1.000], mean action: 17.625 [0.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.259890, mean_absolute_error: 5.835518, mean_q: 6.541421
299 (array([12]),) False
 201960/500000: episode: 5049, duration: 33.147s, episode steps: 40, steps per second: 1, episode reward: 34.450, mean reward: 0.861 [0.332, 1.000], mean action: 24.225 [22.000, 56.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.254561, mean_absolute_error: 5.933653, mean_q: 6.646616
709 (array([41]),) False
 202000/500000: episode: 5050, duration: 33.180s, episode steps: 40, steps per second: 1, episode reward: 22.230, mean reward: 0.556 [0.000, 0.975], mean action: 18.950 [1.000, 40.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.292976, mean_absolute_error: 5.863387, mean_q: 6.577275
708 (array([40]),) False
 202040/500000: episode: 5051, duration: 33.203s, episode steps: 40, steps per second: 1, episode reward: 35.146, mean reward: 0.879 [0.262, 1.000], mean action: 20.550 [3.000, 47.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.232662, mean_absolute_error: 5.968349, mean_q: 6.683003
512 (array([48]),) False
 202080/500000: episode: 5052, duration: 33.111s, episode steps: 40, steps per second: 1, episode reward: 34.785, mean reward: 0.870 [0.014, 1.000], mean action: 21.475 [12.000, 59.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.257914, mean_absolute_error: 5.961278, mean_q: 6.683182
334 (array([48]),) False
 202120/500000: episode: 5053, duration: 32.344s, episode steps: 40, steps per second: 1, episode reward: 36.386, mean reward: 0.910 [0.115, 0.988], mean action: 24.000 [9.000, 52.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.261123, mean_absolute_error: 5.901673, mean_q: 6.615641
154 (array([44]),) False
 202160/500000: episode: 5054, duration: 33.136s, episode steps: 40, steps per second: 1, episode reward: 33.623, mean reward: 0.841 [0.186, 0.998], mean action: 19.675 [8.000, 60.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.252171, mean_absolute_error: 5.987142, mean_q: 6.704566
430 (array([22]),) False
 202200/500000: episode: 5055, duration: 32.332s, episode steps: 40, steps per second: 1, episode reward: 37.066, mean reward: 0.927 [0.360, 1.000], mean action: 23.150 [1.000, 53.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.251532, mean_absolute_error: 5.944685, mean_q: 6.659139
362 (array([22]),) False
 202240/500000: episode: 5056, duration: 33.265s, episode steps: 40, steps per second: 1, episode reward: 37.924, mean reward: 0.948 [0.197, 1.000], mean action: 22.025 [4.000, 56.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.254175, mean_absolute_error: 5.968717, mean_q: 6.684137
490 (array([12]),) False
 202280/500000: episode: 5057, duration: 32.300s, episode steps: 40, steps per second: 1, episode reward: 32.602, mean reward: 0.815 [0.471, 1.000], mean action: 22.750 [12.000, 60.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.266831, mean_absolute_error: 5.928893, mean_q: 6.639842
642 (array([22]),) False
 202320/500000: episode: 5058, duration: 33.311s, episode steps: 40, steps per second: 1, episode reward: 37.824, mean reward: 0.946 [0.228, 1.000], mean action: 21.200 [1.000, 31.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.256584, mean_absolute_error: 5.962109, mean_q: 6.681957
707 (array([48]),) False
 202360/500000: episode: 5059, duration: 33.211s, episode steps: 40, steps per second: 1, episode reward: 31.734, mean reward: 0.793 [0.000, 0.943], mean action: 19.975 [3.000, 57.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.236697, mean_absolute_error: 5.988258, mean_q: 6.702811
100 (array([22]),) False
 202400/500000: episode: 5060, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 35.781, mean reward: 0.895 [0.064, 1.000], mean action: 23.125 [6.000, 60.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.263933, mean_absolute_error: 5.955093, mean_q: 6.676048
667 (array([48]),) False
 202440/500000: episode: 5061, duration: 33.174s, episode steps: 40, steps per second: 1, episode reward: 38.037, mean reward: 0.951 [0.443, 1.000], mean action: 19.350 [0.000, 48.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.268255, mean_absolute_error: 5.988149, mean_q: 6.709437
300 (array([22]),) False
 202480/500000: episode: 5062, duration: 33.212s, episode steps: 40, steps per second: 1, episode reward: 30.388, mean reward: 0.760 [0.000, 1.000], mean action: 25.125 [6.000, 58.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.259416, mean_absolute_error: 5.814177, mean_q: 6.518980
843 (array([3]),) False
 202520/500000: episode: 5063, duration: 33.188s, episode steps: 40, steps per second: 1, episode reward: 22.782, mean reward: 0.570 [0.000, 1.000], mean action: 12.025 [1.000, 49.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.261126, mean_absolute_error: 5.922315, mean_q: 6.638233
850 (array([12]),) False
 202560/500000: episode: 5064, duration: 33.253s, episode steps: 40, steps per second: 1, episode reward: 30.559, mean reward: 0.764 [0.252, 1.000], mean action: 21.375 [12.000, 52.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.281504, mean_absolute_error: 6.004107, mean_q: 6.719584
620 (array([44]),) False
 202600/500000: episode: 5065, duration: 32.302s, episode steps: 40, steps per second: 1, episode reward: 23.899, mean reward: 0.597 [0.000, 1.000], mean action: 20.275 [3.000, 59.000], mean observation: -0.145 [-1.000, 1.000], loss: 0.246742, mean_absolute_error: 5.945663, mean_q: 6.652580
703 (array([3]),) False
 202640/500000: episode: 5066, duration: 33.131s, episode steps: 40, steps per second: 1, episode reward: 35.296, mean reward: 0.882 [0.161, 1.000], mean action: 8.875 [3.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.253783, mean_absolute_error: 5.925507, mean_q: 6.636818
844 (array([48]),) False
 202680/500000: episode: 5067, duration: 32.241s, episode steps: 40, steps per second: 1, episode reward: 36.720, mean reward: 0.918 [0.202, 1.000], mean action: 20.600 [12.000, 50.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.259432, mean_absolute_error: 5.889506, mean_q: 6.589326
601 (array([14]),) False
 202720/500000: episode: 5068, duration: 33.238s, episode steps: 40, steps per second: 1, episode reward: 34.134, mean reward: 0.853 [0.106, 1.000], mean action: 19.700 [0.000, 58.000], mean observation: -0.126 [-1.000, 1.000], loss: 0.255723, mean_absolute_error: 5.889650, mean_q: 6.591853
326 (array([48]),) False
 202760/500000: episode: 5069, duration: 32.321s, episode steps: 40, steps per second: 1, episode reward: 31.104, mean reward: 0.778 [0.128, 1.000], mean action: 17.325 [0.000, 59.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.275642, mean_absolute_error: 5.936048, mean_q: 6.633821
552 (array([22]),) False
 202800/500000: episode: 5070, duration: 33.271s, episode steps: 40, steps per second: 1, episode reward: 37.029, mean reward: 0.926 [0.391, 1.000], mean action: 24.225 [1.000, 49.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.273646, mean_absolute_error: 5.953808, mean_q: 6.659093
555 (array([22]),) False
 202840/500000: episode: 5071, duration: 33.181s, episode steps: 40, steps per second: 1, episode reward: 36.261, mean reward: 0.907 [0.311, 1.000], mean action: 15.375 [12.000, 47.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.305272, mean_absolute_error: 5.933124, mean_q: 6.631190
636 (array([12]),) False
 202880/500000: episode: 5072, duration: 33.228s, episode steps: 40, steps per second: 1, episode reward: 33.939, mean reward: 0.848 [0.041, 0.975], mean action: 20.425 [7.000, 46.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.259731, mean_absolute_error: 5.978319, mean_q: 6.686461
331 (array([22]),) False
 202920/500000: episode: 5073, duration: 33.267s, episode steps: 40, steps per second: 1, episode reward: 27.803, mean reward: 0.695 [0.000, 1.000], mean action: 18.675 [11.000, 58.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.238167, mean_absolute_error: 5.904348, mean_q: 6.607445
690 (array([22]),) False
 202960/500000: episode: 5074, duration: 33.155s, episode steps: 40, steps per second: 1, episode reward: 30.533, mean reward: 0.763 [0.141, 1.000], mean action: 36.750 [12.000, 48.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.241067, mean_absolute_error: 5.920579, mean_q: 6.622136
700 (array([44]),) False
 203000/500000: episode: 5075, duration: 33.216s, episode steps: 40, steps per second: 1, episode reward: 32.045, mean reward: 0.801 [0.142, 1.000], mean action: 28.050 [2.000, 44.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.242845, mean_absolute_error: 5.968899, mean_q: 6.674181
6 (array([58]),) False
 203040/500000: episode: 5076, duration: 33.140s, episode steps: 40, steps per second: 1, episode reward: 34.399, mean reward: 0.860 [0.087, 1.000], mean action: 23.450 [4.000, 50.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.263404, mean_absolute_error: 5.868574, mean_q: 6.564485
16 (array([22]),) False
 203080/500000: episode: 5077, duration: 32.239s, episode steps: 40, steps per second: 1, episode reward: 38.488, mean reward: 0.962 [0.377, 1.000], mean action: 24.250 [22.000, 59.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.246350, mean_absolute_error: 5.853425, mean_q: 6.553967
464 (array([22]),) False
 203120/500000: episode: 5078, duration: 33.155s, episode steps: 40, steps per second: 1, episode reward: 37.108, mean reward: 0.928 [0.171, 1.000], mean action: 24.850 [22.000, 58.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.285353, mean_absolute_error: 5.908113, mean_q: 6.613565
571 (array([48]),) False
 203160/500000: episode: 5079, duration: 32.253s, episode steps: 40, steps per second: 1, episode reward: 34.360, mean reward: 0.859 [0.549, 1.000], mean action: 27.675 [7.000, 50.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.290549, mean_absolute_error: 5.863550, mean_q: 6.576933
638 (array([22]),) False
 203200/500000: episode: 5080, duration: 33.167s, episode steps: 40, steps per second: 1, episode reward: 35.865, mean reward: 0.897 [0.000, 1.000], mean action: 22.650 [5.000, 49.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.227411, mean_absolute_error: 5.845076, mean_q: 6.560135
455 (array([22]),) False
 203240/500000: episode: 5081, duration: 32.308s, episode steps: 40, steps per second: 1, episode reward: 38.410, mean reward: 0.960 [0.579, 1.000], mean action: 22.975 [22.000, 44.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.280773, mean_absolute_error: 5.908736, mean_q: 6.623286
97 (array([22]),) False
 203280/500000: episode: 5082, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 38.340, mean reward: 0.958 [0.408, 1.000], mean action: 22.350 [19.000, 35.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.243488, mean_absolute_error: 5.799206, mean_q: 6.506499
581 (array([22]),) False
 203320/500000: episode: 5083, duration: 33.124s, episode steps: 40, steps per second: 1, episode reward: 32.957, mean reward: 0.824 [0.003, 1.000], mean action: 20.000 [12.000, 40.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.242193, mean_absolute_error: 5.942907, mean_q: 6.648713
630 (array([22]),) False
 203360/500000: episode: 5084, duration: 33.245s, episode steps: 40, steps per second: 1, episode reward: 38.760, mean reward: 0.969 [0.064, 1.000], mean action: 23.650 [22.000, 49.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.244620, mean_absolute_error: 5.861109, mean_q: 6.561217
353 (array([22]),) False
 203400/500000: episode: 5085, duration: 33.179s, episode steps: 40, steps per second: 1, episode reward: 39.179, mean reward: 0.979 [0.284, 1.000], mean action: 22.950 [22.000, 49.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.253684, mean_absolute_error: 5.856513, mean_q: 6.558085
118 (array([22]),) False
 203440/500000: episode: 5086, duration: 33.182s, episode steps: 40, steps per second: 1, episode reward: 37.684, mean reward: 0.942 [0.249, 1.000], mean action: 22.050 [5.000, 39.000], mean observation: -0.115 [-1.000, 1.000], loss: 0.269382, mean_absolute_error: 5.770873, mean_q: 6.469937
0 (array([48]),) False
 203480/500000: episode: 5087, duration: 33.239s, episode steps: 40, steps per second: 1, episode reward: 33.754, mean reward: 0.844 [0.010, 1.000], mean action: 23.150 [4.000, 60.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.254510, mean_absolute_error: 5.921015, mean_q: 6.627061
130 (array([22]),) False
 203520/500000: episode: 5088, duration: 33.213s, episode steps: 40, steps per second: 1, episode reward: 37.108, mean reward: 0.928 [0.117, 1.000], mean action: 22.175 [3.000, 38.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.235112, mean_absolute_error: 5.872123, mean_q: 6.580696
687 (array([44]),) False
 203560/500000: episode: 5089, duration: 32.247s, episode steps: 40, steps per second: 1, episode reward: 34.166, mean reward: 0.854 [0.242, 0.953], mean action: 23.950 [12.000, 48.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.250670, mean_absolute_error: 5.889632, mean_q: 6.611558
710 (array([12]),) False
 203600/500000: episode: 5090, duration: 33.142s, episode steps: 40, steps per second: 1, episode reward: 29.591, mean reward: 0.740 [0.207, 1.000], mean action: 22.225 [12.000, 60.000], mean observation: -0.142 [-1.000, 1.000], loss: 0.261185, mean_absolute_error: 5.858816, mean_q: 6.573951
847 (array([21]),) False
 203640/500000: episode: 5091, duration: 32.325s, episode steps: 40, steps per second: 1, episode reward: 33.003, mean reward: 0.825 [0.391, 1.000], mean action: 20.225 [1.000, 58.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.257916, mean_absolute_error: 5.907247, mean_q: 6.627401
564 (array([22]),) False
 203680/500000: episode: 5092, duration: 33.237s, episode steps: 40, steps per second: 1, episode reward: 34.709, mean reward: 0.868 [0.242, 1.000], mean action: 17.475 [12.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.235153, mean_absolute_error: 5.845521, mean_q: 6.558042
503 (array([3]),) False
 203720/500000: episode: 5093, duration: 32.282s, episode steps: 40, steps per second: 1, episode reward: 11.456, mean reward: 0.286 [0.000, 0.417], mean action: 21.925 [12.000, 48.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.325319, mean_absolute_error: 5.900229, mean_q: 6.612912
311 (array([22]),) False
 203760/500000: episode: 5094, duration: 33.270s, episode steps: 40, steps per second: 1, episode reward: 37.633, mean reward: 0.941 [0.119, 1.000], mean action: 23.800 [12.000, 57.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.264064, mean_absolute_error: 5.889990, mean_q: 6.594415
307 (array([22]),) False
 203800/500000: episode: 5095, duration: 33.178s, episode steps: 40, steps per second: 1, episode reward: 35.605, mean reward: 0.890 [0.046, 1.000], mean action: 25.225 [11.000, 58.000], mean observation: -0.059 [-1.000, 1.000], loss: 0.241569, mean_absolute_error: 5.929460, mean_q: 6.632355
390 (array([22]),) False
 203840/500000: episode: 5096, duration: 33.195s, episode steps: 40, steps per second: 1, episode reward: 31.118, mean reward: 0.778 [0.015, 1.000], mean action: 23.400 [8.000, 57.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.237515, mean_absolute_error: 5.833782, mean_q: 6.535542
834 (array([44]),) False
 203880/500000: episode: 5097, duration: 33.116s, episode steps: 40, steps per second: 1, episode reward: 24.783, mean reward: 0.620 [0.175, 0.986], mean action: 9.450 [2.000, 48.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.265299, mean_absolute_error: 5.873264, mean_q: 6.582194
781 (array([8]),) False
 203920/500000: episode: 5098, duration: 33.134s, episode steps: 40, steps per second: 1, episode reward: 31.801, mean reward: 0.795 [0.320, 1.000], mean action: 21.825 [11.000, 50.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.241221, mean_absolute_error: 5.864141, mean_q: 6.579783
140 (array([12]),) False
 203960/500000: episode: 5099, duration: 33.122s, episode steps: 40, steps per second: 1, episode reward: 39.119, mean reward: 0.978 [0.279, 1.000], mean action: 12.675 [12.000, 29.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.244312, mean_absolute_error: 5.889714, mean_q: 6.617307
413 (array([22]),) False
 204000/500000: episode: 5100, duration: 33.215s, episode steps: 40, steps per second: 1, episode reward: 37.883, mean reward: 0.947 [0.565, 1.000], mean action: 21.800 [12.000, 44.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.255719, mean_absolute_error: 5.914619, mean_q: 6.641219
769 (array([12]),) False
 204040/500000: episode: 5101, duration: 32.204s, episode steps: 40, steps per second: 1, episode reward: 35.918, mean reward: 0.898 [0.575, 1.000], mean action: 17.525 [12.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.260561, mean_absolute_error: 5.960084, mean_q: 6.686090
723 (array([48]),) False
 204080/500000: episode: 5102, duration: 33.220s, episode steps: 40, steps per second: 1, episode reward: 32.980, mean reward: 0.824 [0.047, 1.000], mean action: 18.350 [12.000, 60.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.255809, mean_absolute_error: 5.934293, mean_q: 6.664304
748 (array([22]),) False
 204120/500000: episode: 5103, duration: 32.202s, episode steps: 40, steps per second: 1, episode reward: 30.997, mean reward: 0.775 [0.020, 1.000], mean action: 26.700 [3.000, 55.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.263848, mean_absolute_error: 5.983885, mean_q: 6.719041
502 (array([22]),) False
 204160/500000: episode: 5104, duration: 33.205s, episode steps: 40, steps per second: 1, episode reward: 34.153, mean reward: 0.854 [0.122, 1.000], mean action: 18.900 [9.000, 57.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.267022, mean_absolute_error: 5.887395, mean_q: 6.616370
583 (array([22]),) False
 204200/500000: episode: 5105, duration: 32.318s, episode steps: 40, steps per second: 1, episode reward: 38.166, mean reward: 0.954 [0.244, 1.000], mean action: 14.900 [5.000, 60.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.260455, mean_absolute_error: 5.942208, mean_q: 6.666312
821 (array([22]),) False
 204240/500000: episode: 5106, duration: 33.198s, episode steps: 40, steps per second: 1, episode reward: 35.189, mean reward: 0.880 [0.084, 1.000], mean action: 16.600 [12.000, 55.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.288138, mean_absolute_error: 5.879148, mean_q: 6.588674
333 (array([12]),) False
 204280/500000: episode: 5107, duration: 31.605s, episode steps: 40, steps per second: 1, episode reward: 34.908, mean reward: 0.873 [0.169, 1.000], mean action: 13.575 [4.000, 52.000], mean observation: -0.084 [-1.000, 1.000], loss: 0.268868, mean_absolute_error: 5.987896, mean_q: 6.706608
846 (array([48]),) False
 204320/500000: episode: 5108, duration: 31.088s, episode steps: 40, steps per second: 1, episode reward: 37.443, mean reward: 0.936 [0.661, 1.000], mean action: 19.600 [14.000, 48.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.247065, mean_absolute_error: 5.921493, mean_q: 6.639435
585 (array([48]),) False
 204360/500000: episode: 5109, duration: 31.046s, episode steps: 40, steps per second: 1, episode reward: 35.870, mean reward: 0.897 [0.000, 0.960], mean action: 15.900 [3.000, 55.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.275682, mean_absolute_error: 5.868442, mean_q: 6.583805
55 (array([22]),) False
 204400/500000: episode: 5110, duration: 31.007s, episode steps: 40, steps per second: 1, episode reward: 34.650, mean reward: 0.866 [0.000, 1.000], mean action: 23.700 [11.000, 48.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.287023, mean_absolute_error: 5.947995, mean_q: 6.660136
99 (array([22]),) False
 204440/500000: episode: 5111, duration: 30.971s, episode steps: 40, steps per second: 1, episode reward: 36.076, mean reward: 0.902 [0.308, 1.000], mean action: 21.825 [6.000, 35.000], mean observation: -0.098 [-1.000, 1.000], loss: 0.236686, mean_absolute_error: 5.951945, mean_q: 6.663464
32 (array([48]),) False
 204480/500000: episode: 5112, duration: 30.977s, episode steps: 40, steps per second: 1, episode reward: 34.180, mean reward: 0.854 [0.017, 1.000], mean action: 29.025 [15.000, 58.000], mean observation: -0.036 [-1.000, 1.000], loss: 0.271026, mean_absolute_error: 5.886374, mean_q: 6.596974
370 (array([58]),) False
 204520/500000: episode: 5113, duration: 30.064s, episode steps: 40, steps per second: 1, episode reward: 18.583, mean reward: 0.465 [0.000, 1.000], mean action: 24.075 [12.000, 48.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.254100, mean_absolute_error: 5.960619, mean_q: 6.675265
552 (array([22]),) False
 204560/500000: episode: 5114, duration: 30.910s, episode steps: 40, steps per second: 1, episode reward: 36.390, mean reward: 0.910 [0.155, 1.000], mean action: 29.450 [5.000, 59.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.255498, mean_absolute_error: 5.862336, mean_q: 6.562868
432 (array([22]),) False
 204600/500000: episode: 5115, duration: 30.150s, episode steps: 40, steps per second: 1, episode reward: 25.045, mean reward: 0.626 [0.044, 0.676], mean action: 18.450 [1.000, 27.000], mean observation: -0.045 [-1.000, 1.000], loss: 0.277618, mean_absolute_error: 5.832656, mean_q: 6.528303
321 (array([22]),) False
 204640/500000: episode: 5116, duration: 30.987s, episode steps: 40, steps per second: 1, episode reward: 37.575, mean reward: 0.939 [0.256, 1.000], mean action: 23.575 [12.000, 57.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.287674, mean_absolute_error: 5.864591, mean_q: 6.564496
516 (array([48]),) False
 204680/500000: episode: 5117, duration: 30.101s, episode steps: 40, steps per second: 1, episode reward: 34.792, mean reward: 0.870 [0.157, 1.000], mean action: 19.200 [2.000, 44.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.288848, mean_absolute_error: 5.889838, mean_q: 6.585559
527 (array([58]),) False
 204720/500000: episode: 5118, duration: 30.929s, episode steps: 40, steps per second: 1, episode reward: 23.148, mean reward: 0.579 [0.192, 1.000], mean action: 23.200 [3.000, 60.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.244449, mean_absolute_error: 5.805099, mean_q: 6.501678
719 (array([22]),) False
 204760/500000: episode: 5119, duration: 30.875s, episode steps: 40, steps per second: 1, episode reward: 34.070, mean reward: 0.852 [0.269, 1.000], mean action: 21.750 [12.000, 50.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.235779, mean_absolute_error: 5.876699, mean_q: 6.570016
299 (array([12]),) False
 204800/500000: episode: 5120, duration: 30.990s, episode steps: 40, steps per second: 1, episode reward: 34.557, mean reward: 0.864 [0.254, 1.000], mean action: 22.350 [0.000, 51.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.260648, mean_absolute_error: 5.897970, mean_q: 6.592621
382 (array([22]),) False
 204840/500000: episode: 5121, duration: 30.916s, episode steps: 40, steps per second: 1, episode reward: 36.952, mean reward: 0.924 [0.257, 1.000], mean action: 25.125 [22.000, 59.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.293559, mean_absolute_error: 5.916162, mean_q: 6.614934
479 (array([22]),) False
 204880/500000: episode: 5122, duration: 30.877s, episode steps: 40, steps per second: 1, episode reward: 36.005, mean reward: 0.900 [0.548, 1.000], mean action: 38.075 [12.000, 54.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.263158, mean_absolute_error: 5.926646, mean_q: 6.630846
201 (array([22]),) False
 204920/500000: episode: 5123, duration: 30.940s, episode steps: 40, steps per second: 1, episode reward: 36.684, mean reward: 0.917 [0.047, 1.000], mean action: 23.350 [2.000, 56.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.264641, mean_absolute_error: 5.870580, mean_q: 6.578536
30 (array([22]),) False
 204960/500000: episode: 5124, duration: 30.835s, episode steps: 40, steps per second: 1, episode reward: 36.818, mean reward: 0.920 [0.346, 1.000], mean action: 24.525 [7.000, 49.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.235882, mean_absolute_error: 5.905485, mean_q: 6.613469
280 (array([48]),) False
 205000/500000: episode: 5125, duration: 30.042s, episode steps: 40, steps per second: 1, episode reward: 32.772, mean reward: 0.819 [0.003, 1.000], mean action: 23.850 [11.000, 60.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.264320, mean_absolute_error: 5.876612, mean_q: 6.595354
315 (array([12]),) False
 205040/500000: episode: 5126, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 33.331, mean reward: 0.833 [0.000, 1.000], mean action: 21.800 [6.000, 48.000], mean observation: -0.069 [-1.000, 1.000], loss: 0.271201, mean_absolute_error: 5.888559, mean_q: 6.599596
689 (array([12]),) False
 205080/500000: episode: 5127, duration: 30.065s, episode steps: 40, steps per second: 1, episode reward: 35.384, mean reward: 0.885 [0.028, 1.000], mean action: 18.400 [12.000, 53.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.244905, mean_absolute_error: 5.860875, mean_q: 6.564827
789 (array([22]),) False
 205120/500000: episode: 5128, duration: 30.937s, episode steps: 40, steps per second: 1, episode reward: 36.021, mean reward: 0.901 [0.155, 1.000], mean action: 42.675 [0.000, 55.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.282380, mean_absolute_error: 5.888998, mean_q: 6.600026
842 (array([22]),) False
 205160/500000: episode: 5129, duration: 30.085s, episode steps: 40, steps per second: 1, episode reward: 31.702, mean reward: 0.793 [0.406, 1.000], mean action: 16.375 [12.000, 55.000], mean observation: -0.120 [-1.000, 1.000], loss: 0.230959, mean_absolute_error: 5.817885, mean_q: 6.523815
715 (array([22]),) False
 205200/500000: episode: 5130, duration: 31.016s, episode steps: 40, steps per second: 1, episode reward: 37.487, mean reward: 0.937 [0.117, 1.000], mean action: 24.550 [2.000, 49.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.251493, mean_absolute_error: 5.802091, mean_q: 6.506231
177 (array([22]),) False
 205240/500000: episode: 5131, duration: 30.928s, episode steps: 40, steps per second: 1, episode reward: 34.448, mean reward: 0.861 [0.091, 1.000], mean action: 24.325 [12.000, 52.000], mean observation: -0.166 [-1.000, 1.000], loss: 0.238127, mean_absolute_error: 5.831533, mean_q: 6.537062
30 (array([22]),) False
 205280/500000: episode: 5132, duration: 30.969s, episode steps: 40, steps per second: 1, episode reward: 37.049, mean reward: 0.926 [0.126, 1.000], mean action: 23.000 [5.000, 56.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.294165, mean_absolute_error: 5.826920, mean_q: 6.520386
108 (array([48]),) False
 205320/500000: episode: 5133, duration: 30.921s, episode steps: 40, steps per second: 1, episode reward: 32.800, mean reward: 0.820 [0.297, 1.000], mean action: 23.650 [12.000, 59.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.265102, mean_absolute_error: 5.872464, mean_q: 6.570085
699 (array([22]),) False
 205360/500000: episode: 5134, duration: 30.930s, episode steps: 40, steps per second: 1, episode reward: 33.572, mean reward: 0.839 [0.102, 1.000], mean action: 23.350 [5.000, 58.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.264905, mean_absolute_error: 5.802403, mean_q: 6.506948
591 (array([22]),) False
 205400/500000: episode: 5135, duration: 30.999s, episode steps: 40, steps per second: 1, episode reward: 31.034, mean reward: 0.776 [0.270, 1.000], mean action: 16.325 [12.000, 53.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.245124, mean_absolute_error: 5.899785, mean_q: 6.604071
274 (array([12]),) False
 205440/500000: episode: 5136, duration: 30.882s, episode steps: 40, steps per second: 1, episode reward: 36.958, mean reward: 0.924 [0.090, 1.000], mean action: 19.950 [2.000, 30.000], mean observation: -0.152 [-1.000, 1.000], loss: 0.226906, mean_absolute_error: 5.903861, mean_q: 6.606659
90 (array([22]),) False
 205480/500000: episode: 5137, duration: 30.103s, episode steps: 40, steps per second: 1, episode reward: 36.581, mean reward: 0.915 [0.243, 1.000], mean action: 24.200 [12.000, 55.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.248127, mean_absolute_error: 5.920808, mean_q: 6.626449
58 (array([48]),) False
 205520/500000: episode: 5138, duration: 30.922s, episode steps: 40, steps per second: 1, episode reward: 34.289, mean reward: 0.857 [0.383, 0.876], mean action: 22.500 [22.000, 38.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.266332, mean_absolute_error: 5.874237, mean_q: 6.575062
203 (array([48]),) False
 205560/500000: episode: 5139, duration: 30.059s, episode steps: 40, steps per second: 1, episode reward: 37.977, mean reward: 0.949 [0.456, 0.977], mean action: 19.825 [12.000, 45.000], mean observation: -0.182 [-1.000, 1.000], loss: 0.280872, mean_absolute_error: 5.889781, mean_q: 6.584518
10 (array([3]),) False
 205600/500000: episode: 5140, duration: 30.962s, episode steps: 40, steps per second: 1, episode reward: 26.369, mean reward: 0.659 [0.007, 1.000], mean action: 29.700 [20.000, 51.000], mean observation: -0.050 [-1.000, 1.000], loss: 0.280660, mean_absolute_error: 5.847002, mean_q: 6.530324
462 (array([12]),) False
 205640/500000: episode: 5141, duration: 30.073s, episode steps: 40, steps per second: 1, episode reward: 31.848, mean reward: 0.796 [0.082, 1.000], mean action: 20.750 [0.000, 48.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.306790, mean_absolute_error: 5.859249, mean_q: 6.548903
59 (array([12]),) False
 205680/500000: episode: 5142, duration: 31.059s, episode steps: 40, steps per second: 1, episode reward: 35.500, mean reward: 0.887 [0.225, 1.000], mean action: 27.300 [2.000, 49.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.264243, mean_absolute_error: 5.784727, mean_q: 6.468709
489 (array([22]),) False
 205720/500000: episode: 5143, duration: 30.967s, episode steps: 40, steps per second: 1, episode reward: 36.649, mean reward: 0.916 [0.112, 1.000], mean action: 21.600 [4.000, 47.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.262615, mean_absolute_error: 5.891383, mean_q: 6.577462
29 (array([22]),) False
 205760/500000: episode: 5144, duration: 30.839s, episode steps: 40, steps per second: 1, episode reward: 27.813, mean reward: 0.695 [0.162, 1.000], mean action: 22.125 [15.000, 56.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.288859, mean_absolute_error: 5.935588, mean_q: 6.627244
18 (array([22]),) False
 205800/500000: episode: 5145, duration: 30.866s, episode steps: 40, steps per second: 1, episode reward: 35.869, mean reward: 0.897 [0.317, 1.000], mean action: 22.375 [1.000, 38.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.279004, mean_absolute_error: 5.924441, mean_q: 6.616868
415 (array([22]),) False
 205840/500000: episode: 5146, duration: 30.770s, episode steps: 40, steps per second: 1, episode reward: 35.413, mean reward: 0.885 [0.000, 1.000], mean action: 23.975 [4.000, 50.000], mean observation: -0.058 [-1.000, 1.000], loss: 0.272900, mean_absolute_error: 5.955866, mean_q: 6.659334
370 (array([58]),) False
 205880/500000: episode: 5147, duration: 30.758s, episode steps: 40, steps per second: 1, episode reward: 21.158, mean reward: 0.529 [0.000, 1.000], mean action: 24.575 [3.000, 58.000], mean observation: -0.057 [-1.000, 1.000], loss: 0.257889, mean_absolute_error: 5.912107, mean_q: 6.613757
791 (array([54]),) False
 205920/500000: episode: 5148, duration: 30.728s, episode steps: 40, steps per second: 1, episode reward: 17.042, mean reward: 0.426 [0.000, 0.936], mean action: 40.850 [3.000, 51.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.252367, mean_absolute_error: 5.878634, mean_q: 6.586750
790 (array([48]),) False
 205960/500000: episode: 5149, duration: 29.914s, episode steps: 40, steps per second: 1, episode reward: 37.362, mean reward: 0.934 [0.072, 1.000], mean action: 46.900 [3.000, 57.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.236576, mean_absolute_error: 5.948644, mean_q: 6.662343
15 (array([22]),) False
 206000/500000: episode: 5150, duration: 30.753s, episode steps: 40, steps per second: 1, episode reward: 37.799, mean reward: 0.945 [0.174, 1.000], mean action: 22.200 [8.000, 42.000], mean observation: -0.035 [-1.000, 1.000], loss: 0.279054, mean_absolute_error: 5.836467, mean_q: 6.538877
744 (array([22]),) False
 206040/500000: episode: 5151, duration: 29.939s, episode steps: 40, steps per second: 1, episode reward: 28.949, mean reward: 0.724 [0.163, 1.000], mean action: 26.925 [1.000, 49.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.281121, mean_absolute_error: 5.896267, mean_q: 6.596268
574 (array([8]),) False
 206080/500000: episode: 5152, duration: 30.864s, episode steps: 40, steps per second: 1, episode reward: 36.794, mean reward: 0.920 [0.286, 1.000], mean action: 23.800 [22.000, 48.000], mean observation: -0.138 [-1.000, 1.000], loss: 0.296672, mean_absolute_error: 5.884392, mean_q: 6.579611
481 (array([22]),) False
 206120/500000: episode: 5153, duration: 30.017s, episode steps: 40, steps per second: 1, episode reward: 33.434, mean reward: 0.836 [0.000, 1.000], mean action: 33.550 [2.000, 49.000], mean observation: -0.085 [-1.000, 1.000], loss: 0.240747, mean_absolute_error: 5.841548, mean_q: 6.533154
28 (array([58]),) False
 206160/500000: episode: 5154, duration: 30.869s, episode steps: 40, steps per second: 1, episode reward: 19.523, mean reward: 0.488 [0.012, 1.000], mean action: 18.750 [15.000, 56.000], mean observation: -0.040 [-1.000, 1.000], loss: 0.260083, mean_absolute_error: 5.824903, mean_q: 6.511645
249 (array([22]),) False
 206200/500000: episode: 5155, duration: 31.344s, episode steps: 40, steps per second: 1, episode reward: 37.467, mean reward: 0.937 [0.178, 1.000], mean action: 24.450 [22.000, 56.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.264038, mean_absolute_error: 5.841448, mean_q: 6.529909
443 (array([22]),) False
 206240/500000: episode: 5156, duration: 31.211s, episode steps: 40, steps per second: 1, episode reward: 38.450, mean reward: 0.961 [0.275, 1.000], mean action: 21.700 [5.000, 40.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.273615, mean_absolute_error: 5.835917, mean_q: 6.528639
359 (array([22]),) False
 206280/500000: episode: 5157, duration: 31.156s, episode steps: 40, steps per second: 1, episode reward: 32.666, mean reward: 0.817 [0.259, 1.000], mean action: 24.150 [12.000, 49.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.276575, mean_absolute_error: 5.924557, mean_q: 6.617449
391 (array([22]),) False
 206320/500000: episode: 5158, duration: 31.464s, episode steps: 40, steps per second: 1, episode reward: 34.528, mean reward: 0.863 [0.099, 1.000], mean action: 23.900 [2.000, 58.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.226709, mean_absolute_error: 5.919019, mean_q: 6.618619
52 (array([22]),) False
 206360/500000: episode: 5159, duration: 31.349s, episode steps: 40, steps per second: 1, episode reward: 37.650, mean reward: 0.941 [0.184, 1.000], mean action: 22.375 [0.000, 46.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.245534, mean_absolute_error: 5.882514, mean_q: 6.581838
522 (array([22]),) False
 206400/500000: episode: 5160, duration: 30.939s, episode steps: 40, steps per second: 1, episode reward: 32.920, mean reward: 0.823 [0.584, 1.000], mean action: 13.975 [12.000, 38.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.270392, mean_absolute_error: 5.855233, mean_q: 6.555581
758 (array([38]),) False
 206440/500000: episode: 5161, duration: 30.174s, episode steps: 40, steps per second: 1, episode reward: 37.161, mean reward: 0.929 [0.184, 0.967], mean action: 32.375 [11.000, 52.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.288056, mean_absolute_error: 5.853320, mean_q: 6.553950
247 (array([14]),) False
 206480/500000: episode: 5162, duration: 31.288s, episode steps: 40, steps per second: 1, episode reward: 31.630, mean reward: 0.791 [0.016, 1.000], mean action: 15.100 [5.000, 34.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.282876, mean_absolute_error: 5.898156, mean_q: 6.602472
264 (array([12]),) False
 206520/500000: episode: 5163, duration: 30.809s, episode steps: 40, steps per second: 1, episode reward: 37.751, mean reward: 0.944 [0.140, 1.000], mean action: 23.425 [20.000, 47.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.267894, mean_absolute_error: 5.905190, mean_q: 6.598641
234 (array([22]),) False
 206560/500000: episode: 5164, duration: 31.356s, episode steps: 40, steps per second: 1, episode reward: 34.921, mean reward: 0.873 [0.087, 1.000], mean action: 22.900 [0.000, 59.000], mean observation: -0.157 [-1.000, 1.000], loss: 0.283798, mean_absolute_error: 5.879123, mean_q: 6.578595
170 (array([44]),) False
 206600/500000: episode: 5165, duration: 30.848s, episode steps: 40, steps per second: 1, episode reward: 23.671, mean reward: 0.592 [0.113, 0.990], mean action: 22.650 [5.000, 56.000], mean observation: -0.171 [-1.000, 1.000], loss: 0.266277, mean_absolute_error: 5.989144, mean_q: 6.696517
796 (array([38]),) False
 206640/500000: episode: 5166, duration: 31.374s, episode steps: 40, steps per second: 1, episode reward: 37.213, mean reward: 0.930 [0.266, 0.995], mean action: 14.875 [0.000, 47.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.252375, mean_absolute_error: 5.956914, mean_q: 6.665666
832 (array([22]),) False
 206680/500000: episode: 5167, duration: 31.130s, episode steps: 40, steps per second: 1, episode reward: 37.007, mean reward: 0.925 [0.410, 1.000], mean action: 15.425 [12.000, 59.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.299823, mean_absolute_error: 5.874511, mean_q: 6.570592
153 (array([44]),) False
 206720/500000: episode: 5168, duration: 31.426s, episode steps: 40, steps per second: 1, episode reward: 31.545, mean reward: 0.789 [0.326, 0.963], mean action: 19.800 [12.000, 58.000], mean observation: -0.151 [-1.000, 1.000], loss: 0.272797, mean_absolute_error: 5.940792, mean_q: 6.647799
615 (array([36]),) False
 206760/500000: episode: 5169, duration: 31.368s, episode steps: 40, steps per second: 1, episode reward: 23.091, mean reward: 0.577 [0.137, 0.964], mean action: 25.125 [2.000, 53.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.281638, mean_absolute_error: 5.971648, mean_q: 6.676201
43 (array([12]),) False
 206800/500000: episode: 5170, duration: 31.503s, episode steps: 40, steps per second: 1, episode reward: 27.275, mean reward: 0.682 [0.259, 0.865], mean action: 9.275 [1.000, 44.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.247671, mean_absolute_error: 5.858775, mean_q: 6.561999
731 (array([21]),) False
 206840/500000: episode: 5171, duration: 31.324s, episode steps: 40, steps per second: 1, episode reward: 33.287, mean reward: 0.832 [0.251, 1.000], mean action: 27.975 [3.000, 59.000], mean observation: -0.144 [-1.000, 1.000], loss: 0.256205, mean_absolute_error: 5.841125, mean_q: 6.541331
269 (array([36]),) False
 206880/500000: episode: 5172, duration: 31.222s, episode steps: 40, steps per second: 1, episode reward: 25.703, mean reward: 0.643 [0.109, 0.881], mean action: 23.325 [12.000, 57.000], mean observation: -0.148 [-1.000, 1.000], loss: 0.315645, mean_absolute_error: 5.889238, mean_q: 6.584538
827 (array([14]),) False
 206920/500000: episode: 5173, duration: 31.089s, episode steps: 40, steps per second: 1, episode reward: 33.114, mean reward: 0.828 [0.183, 1.000], mean action: 18.325 [6.000, 50.000], mean observation: -0.129 [-1.000, 1.000], loss: 0.270482, mean_absolute_error: 5.928163, mean_q: 6.630755
155 (array([22]),) False
 206960/500000: episode: 5174, duration: 31.450s, episode steps: 40, steps per second: 1, episode reward: 36.270, mean reward: 0.907 [0.598, 1.000], mean action: 14.575 [12.000, 52.000], mean observation: -0.147 [-1.000, 1.000], loss: 0.240295, mean_absolute_error: 5.913043, mean_q: 6.614909
384 (array([22]),) False
 207000/500000: episode: 5175, duration: 31.144s, episode steps: 40, steps per second: 1, episode reward: 38.118, mean reward: 0.953 [0.324, 1.000], mean action: 23.125 [11.000, 45.000], mean observation: -0.048 [-1.000, 1.000], loss: 0.264561, mean_absolute_error: 5.886317, mean_q: 6.593478
34 (array([22]),) False
 207040/500000: episode: 5176, duration: 31.833s, episode steps: 40, steps per second: 1, episode reward: 36.723, mean reward: 0.918 [0.257, 1.000], mean action: 21.725 [10.000, 49.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.241678, mean_absolute_error: 5.824805, mean_q: 6.543235
361 (array([22]),) False
 207080/500000: episode: 5177, duration: 31.143s, episode steps: 40, steps per second: 1, episode reward: 36.761, mean reward: 0.919 [0.243, 1.000], mean action: 22.700 [12.000, 53.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.250501, mean_absolute_error: 5.844101, mean_q: 6.557799
776 (array([22]),) False
 207120/500000: episode: 5178, duration: 31.551s, episode steps: 40, steps per second: 1, episode reward: 38.199, mean reward: 0.955 [0.373, 1.000], mean action: 23.275 [14.000, 51.000], mean observation: -0.132 [-1.000, 1.000], loss: 0.251102, mean_absolute_error: 5.846007, mean_q: 6.565600
825 (array([22]),) False
 207160/500000: episode: 5179, duration: 31.350s, episode steps: 40, steps per second: 1, episode reward: 32.902, mean reward: 0.823 [0.247, 1.000], mean action: 16.450 [12.000, 39.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.277881, mean_absolute_error: 5.931165, mean_q: 6.646913
556 (array([48]),) False
 207200/500000: episode: 5180, duration: 32.655s, episode steps: 40, steps per second: 1, episode reward: 22.476, mean reward: 0.562 [0.054, 0.659], mean action: 23.675 [4.000, 59.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.276491, mean_absolute_error: 5.865454, mean_q: 6.577016
686 (array([48]),) False
 207240/500000: episode: 5181, duration: 32.933s, episode steps: 40, steps per second: 1, episode reward: 33.127, mean reward: 0.828 [0.045, 0.910], mean action: 22.400 [2.000, 46.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.306605, mean_absolute_error: 5.905750, mean_q: 6.607480
510 (array([22]),) False
 207280/500000: episode: 5182, duration: 32.922s, episode steps: 40, steps per second: 1, episode reward: 36.141, mean reward: 0.904 [0.097, 1.000], mean action: 18.550 [5.000, 33.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.259814, mean_absolute_error: 5.909955, mean_q: 6.612050
136 (array([12]),) False
 207320/500000: episode: 5183, duration: 32.888s, episode steps: 40, steps per second: 1, episode reward: 31.345, mean reward: 0.784 [0.280, 1.000], mean action: 22.175 [11.000, 48.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.294707, mean_absolute_error: 5.882627, mean_q: 6.583219
464 (array([22]),) False
 207360/500000: episode: 5184, duration: 32.963s, episode steps: 40, steps per second: 1, episode reward: 38.862, mean reward: 0.972 [0.052, 1.000], mean action: 23.250 [22.000, 57.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.272878, mean_absolute_error: 5.892604, mean_q: 6.592678
429 (array([22]),) False
 207400/500000: episode: 5185, duration: 32.027s, episode steps: 40, steps per second: 1, episode reward: 34.843, mean reward: 0.871 [0.156, 1.000], mean action: 23.350 [5.000, 60.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.257922, mean_absolute_error: 5.845347, mean_q: 6.539250
4 (array([22]),) False
 207440/500000: episode: 5186, duration: 32.852s, episode steps: 40, steps per second: 1, episode reward: 30.893, mean reward: 0.772 [0.180, 1.000], mean action: 22.100 [3.000, 45.000], mean observation: -0.054 [-1.000, 1.000], loss: 0.263059, mean_absolute_error: 5.760098, mean_q: 6.445181
349 (array([48]),) False
 207480/500000: episode: 5187, duration: 32.062s, episode steps: 40, steps per second: 1, episode reward: 38.992, mean reward: 0.975 [0.099, 1.000], mean action: 22.950 [22.000, 60.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.241715, mean_absolute_error: 5.883872, mean_q: 6.578815
115 (array([22]),) False
 207520/500000: episode: 5188, duration: 32.957s, episode steps: 40, steps per second: 1, episode reward: 37.757, mean reward: 0.944 [0.248, 1.000], mean action: 21.225 [8.000, 44.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.255020, mean_absolute_error: 5.819008, mean_q: 6.511606
424 (array([22]),) False
 207560/500000: episode: 5189, duration: 32.159s, episode steps: 40, steps per second: 1, episode reward: 36.710, mean reward: 0.918 [0.182, 1.000], mean action: 22.600 [19.000, 56.000], mean observation: -0.046 [-1.000, 1.000], loss: 0.314969, mean_absolute_error: 5.850066, mean_q: 6.549486
34 (array([22]),) False
 207600/500000: episode: 5190, duration: 32.983s, episode steps: 40, steps per second: 1, episode reward: 36.159, mean reward: 0.904 [0.175, 1.000], mean action: 24.125 [2.000, 55.000], mean observation: -0.032 [-1.000, 1.000], loss: 0.270344, mean_absolute_error: 5.870446, mean_q: 6.569354
503 (array([3]),) False
 207640/500000: episode: 5191, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 12.281, mean reward: 0.307 [0.164, 1.000], mean action: 22.225 [3.000, 56.000], mean observation: -0.101 [-1.000, 1.000], loss: 0.261118, mean_absolute_error: 5.915840, mean_q: 6.616744
679 (array([44]),) False
 207680/500000: episode: 5192, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 29.911, mean reward: 0.748 [0.000, 1.000], mean action: 15.200 [0.000, 22.000], mean observation: -0.106 [-1.000, 1.000], loss: 0.306823, mean_absolute_error: 5.803288, mean_q: 6.504302
477 (array([22]),) False
 207720/500000: episode: 5193, duration: 32.930s, episode steps: 40, steps per second: 1, episode reward: 36.551, mean reward: 0.914 [0.375, 1.000], mean action: 29.100 [14.000, 51.000], mean observation: -0.081 [-1.000, 1.000], loss: 0.243733, mean_absolute_error: 5.875148, mean_q: 6.577454
44 (array([22]),) False
 207760/500000: episode: 5194, duration: 32.927s, episode steps: 40, steps per second: 1, episode reward: 34.307, mean reward: 0.858 [0.000, 1.000], mean action: 24.925 [5.000, 56.000], mean observation: -0.061 [-1.000, 1.000], loss: 0.258078, mean_absolute_error: 5.918317, mean_q: 6.616355
54 (array([8]),) False
 207800/500000: episode: 5195, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 35.036, mean reward: 0.876 [0.394, 0.977], mean action: 13.800 [0.000, 45.000], mean observation: -0.055 [-1.000, 1.000], loss: 0.233558, mean_absolute_error: 5.961135, mean_q: 6.667462
570 (array([47]),) False
 207840/500000: episode: 5196, duration: 32.918s, episode steps: 40, steps per second: 1, episode reward: 32.784, mean reward: 0.820 [0.389, 1.000], mean action: 26.550 [12.000, 52.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.252595, mean_absolute_error: 6.025618, mean_q: 6.740539
174 (array([33]),) False
 207880/500000: episode: 5197, duration: 32.071s, episode steps: 40, steps per second: 1, episode reward: 21.477, mean reward: 0.537 [0.244, 0.996], mean action: 27.100 [12.000, 58.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.241680, mean_absolute_error: 5.935073, mean_q: 6.645561
381 (array([22]),) False
 207920/500000: episode: 5198, duration: 32.945s, episode steps: 40, steps per second: 1, episode reward: 38.344, mean reward: 0.959 [0.415, 1.000], mean action: 24.650 [22.000, 52.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.244753, mean_absolute_error: 5.895104, mean_q: 6.607465
487 (array([48]),) False
 207960/500000: episode: 5199, duration: 32.111s, episode steps: 40, steps per second: 1, episode reward: 37.710, mean reward: 0.943 [0.425, 1.000], mean action: 22.100 [13.000, 52.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.288361, mean_absolute_error: 5.999831, mean_q: 6.706715
27 (array([22]),) False
 208000/500000: episode: 5200, duration: 32.961s, episode steps: 40, steps per second: 1, episode reward: 33.584, mean reward: 0.840 [0.097, 1.000], mean action: 41.525 [8.000, 49.000], mean observation: -0.034 [-1.000, 1.000], loss: 0.266391, mean_absolute_error: 6.048116, mean_q: 6.755834
645 (array([48]),) False
 208040/500000: episode: 5201, duration: 32.082s, episode steps: 40, steps per second: 1, episode reward: 34.439, mean reward: 0.861 [0.135, 0.920], mean action: 22.475 [4.000, 59.000], mean observation: -0.080 [-1.000, 1.000], loss: 0.250708, mean_absolute_error: 5.932193, mean_q: 6.629838
381 (array([22]),) False
 208080/500000: episode: 5202, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 37.107, mean reward: 0.928 [0.307, 1.000], mean action: 22.950 [5.000, 60.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.235544, mean_absolute_error: 5.990338, mean_q: 6.693877
157 (array([48]),) False
 208120/500000: episode: 5203, duration: 32.896s, episode steps: 40, steps per second: 1, episode reward: 35.653, mean reward: 0.891 [0.262, 0.999], mean action: 19.275 [11.000, 59.000], mean observation: -0.161 [-1.000, 1.000], loss: 0.246811, mean_absolute_error: 5.974973, mean_q: 6.676263
517 (array([22]),) False
 208160/500000: episode: 5204, duration: 32.972s, episode steps: 40, steps per second: 1, episode reward: 37.111, mean reward: 0.928 [0.377, 1.000], mean action: 19.725 [12.000, 49.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.274703, mean_absolute_error: 6.028764, mean_q: 6.740028
80 (array([42]),) False
 208200/500000: episode: 5205, duration: 32.926s, episode steps: 40, steps per second: 1, episode reward: 36.747, mean reward: 0.919 [0.356, 1.000], mean action: 21.525 [11.000, 22.000], mean observation: -0.087 [-1.000, 1.000], loss: 0.289533, mean_absolute_error: 5.968527, mean_q: 6.683859
297 (array([15]),) False
 208240/500000: episode: 5206, duration: 33.007s, episode steps: 40, steps per second: 1, episode reward: 31.370, mean reward: 0.784 [0.000, 0.920], mean action: 22.125 [6.000, 55.000], mean observation: -0.066 [-1.000, 1.000], loss: 0.269767, mean_absolute_error: 5.995485, mean_q: 6.718076
751 (array([22]),) False
 208280/500000: episode: 5207, duration: 32.883s, episode steps: 40, steps per second: 1, episode reward: 33.953, mean reward: 0.849 [0.315, 1.000], mean action: 26.700 [12.000, 52.000], mean observation: -0.131 [-1.000, 1.000], loss: 0.266200, mean_absolute_error: 6.024595, mean_q: 6.748252
618 (array([12]),) False
 208320/500000: episode: 5208, duration: 33.011s, episode steps: 40, steps per second: 1, episode reward: 35.068, mean reward: 0.877 [0.199, 1.000], mean action: 21.750 [5.000, 48.000], mean observation: -0.139 [-1.000, 1.000], loss: 0.259414, mean_absolute_error: 5.932437, mean_q: 6.653491
835 (array([50]),) False
 208360/500000: episode: 5209, duration: 32.127s, episode steps: 40, steps per second: 1, episode reward: 35.412, mean reward: 0.885 [0.052, 0.941], mean action: 20.575 [5.000, 25.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.294982, mean_absolute_error: 6.053933, mean_q: 6.772105
199 (array([22]),) False
 208400/500000: episode: 5210, duration: 32.935s, episode steps: 40, steps per second: 1, episode reward: 37.598, mean reward: 0.940 [0.138, 1.000], mean action: 22.725 [12.000, 60.000], mean observation: -0.178 [-1.000, 1.000], loss: 0.279193, mean_absolute_error: 5.929929, mean_q: 6.642532
804 (array([3]),) False
 208440/500000: episode: 5211, duration: 32.023s, episode steps: 40, steps per second: 1, episode reward: 12.274, mean reward: 0.307 [0.051, 0.712], mean action: 26.525 [1.000, 48.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.238605, mean_absolute_error: 5.892303, mean_q: 6.609651
214 (array([22]),) False
 208480/500000: episode: 5212, duration: 33.024s, episode steps: 40, steps per second: 1, episode reward: 37.393, mean reward: 0.935 [0.274, 1.000], mean action: 21.825 [12.000, 45.000], mean observation: -0.191 [-1.000, 1.000], loss: 0.243654, mean_absolute_error: 5.892043, mean_q: 6.609525
345 (array([22]),) False
 208520/500000: episode: 5213, duration: 32.117s, episode steps: 40, steps per second: 1, episode reward: 38.035, mean reward: 0.951 [0.362, 1.000], mean action: 22.075 [12.000, 37.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.259787, mean_absolute_error: 5.911504, mean_q: 6.625043
685 (array([22]),) False
 208560/500000: episode: 5214, duration: 32.997s, episode steps: 40, steps per second: 1, episode reward: 37.001, mean reward: 0.925 [0.363, 1.000], mean action: 12.300 [11.000, 20.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.272988, mean_absolute_error: 5.927497, mean_q: 6.645402
498 (array([12]),) False
 208600/500000: episode: 5215, duration: 32.946s, episode steps: 40, steps per second: 1, episode reward: 23.744, mean reward: 0.594 [0.137, 0.979], mean action: 21.500 [5.000, 59.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.261080, mean_absolute_error: 5.956243, mean_q: 6.673531
249 (array([22]),) False
 208640/500000: episode: 5216, duration: 32.943s, episode steps: 40, steps per second: 1, episode reward: 37.289, mean reward: 0.932 [0.000, 1.000], mean action: 23.050 [11.000, 45.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.266508, mean_absolute_error: 5.987079, mean_q: 6.698666
121 (array([22]),) False
 208680/500000: episode: 5217, duration: 32.941s, episode steps: 40, steps per second: 1, episode reward: 34.581, mean reward: 0.865 [0.382, 1.000], mean action: 20.100 [12.000, 45.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.257421, mean_absolute_error: 5.985819, mean_q: 6.692703
671 (array([57]),) False
 208720/500000: episode: 5218, duration: 32.967s, episode steps: 40, steps per second: 1, episode reward: 25.207, mean reward: 0.630 [0.017, 1.000], mean action: 18.800 [3.000, 59.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.280158, mean_absolute_error: 5.964013, mean_q: 6.670068
572 (array([58]),) False
 208760/500000: episode: 5219, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 21.702, mean reward: 0.543 [0.144, 1.000], mean action: 22.400 [3.000, 58.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.254229, mean_absolute_error: 5.832661, mean_q: 6.532247
11 (array([22]),) False
 208800/500000: episode: 5220, duration: 32.987s, episode steps: 40, steps per second: 1, episode reward: 36.935, mean reward: 0.923 [0.016, 1.000], mean action: 25.150 [6.000, 49.000], mean observation: -0.033 [-1.000, 1.000], loss: 0.269450, mean_absolute_error: 5.970990, mean_q: 6.677733
313 (array([22]),) False
 208840/500000: episode: 5221, duration: 32.042s, episode steps: 40, steps per second: 1, episode reward: 32.541, mean reward: 0.814 [0.034, 1.000], mean action: 26.575 [11.000, 60.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.257511, mean_absolute_error: 5.955508, mean_q: 6.660432
516 (array([48]),) False
 208880/500000: episode: 5222, duration: 32.963s, episode steps: 40, steps per second: 1, episode reward: 36.075, mean reward: 0.902 [0.055, 1.000], mean action: 16.650 [3.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.257713, mean_absolute_error: 5.936176, mean_q: 6.634038
248 (array([12]),) False
 208920/500000: episode: 5223, duration: 32.074s, episode steps: 40, steps per second: 1, episode reward: 34.372, mean reward: 0.859 [0.385, 1.000], mean action: 21.650 [5.000, 32.000], mean observation: -0.113 [-1.000, 1.000], loss: 0.253047, mean_absolute_error: 6.008697, mean_q: 6.720398
570 (array([47]),) False
 208960/500000: episode: 5224, duration: 32.991s, episode steps: 40, steps per second: 1, episode reward: 33.806, mean reward: 0.845 [0.355, 1.000], mean action: 29.075 [12.000, 49.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.230301, mean_absolute_error: 6.010016, mean_q: 6.726048
858 (array([12]),) False
 209000/500000: episode: 5225, duration: 32.142s, episode steps: 40, steps per second: 1, episode reward: 31.454, mean reward: 0.786 [0.075, 1.000], mean action: 25.375 [6.000, 49.000], mean observation: -0.146 [-1.000, 1.000], loss: 0.267344, mean_absolute_error: 5.907890, mean_q: 6.619147
381 (array([22]),) False
 209040/500000: episode: 5226, duration: 32.955s, episode steps: 40, steps per second: 1, episode reward: 37.827, mean reward: 0.946 [0.251, 1.000], mean action: 22.725 [10.000, 47.000], mean observation: -0.047 [-1.000, 1.000], loss: 0.283863, mean_absolute_error: 5.852952, mean_q: 6.557123
494 (array([48]),) False
 209080/500000: episode: 5227, duration: 33.001s, episode steps: 40, steps per second: 1, episode reward: 32.030, mean reward: 0.801 [0.340, 1.000], mean action: 12.875 [11.000, 48.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.255979, mean_absolute_error: 5.855135, mean_q: 6.564685
429 (array([22]),) False
 209120/500000: episode: 5228, duration: 33.079s, episode steps: 40, steps per second: 1, episode reward: 37.038, mean reward: 0.926 [0.063, 1.000], mean action: 20.525 [2.000, 22.000], mean observation: -0.051 [-1.000, 1.000], loss: 0.253311, mean_absolute_error: 5.854323, mean_q: 6.561358
359 (array([22]),) False
 209160/500000: episode: 5229, duration: 32.956s, episode steps: 40, steps per second: 1, episode reward: 34.168, mean reward: 0.854 [0.168, 1.000], mean action: 23.900 [10.000, 49.000], mean observation: -0.072 [-1.000, 1.000], loss: 0.258424, mean_absolute_error: 5.873611, mean_q: 6.582207
465 (array([48]),) False
 209200/500000: episode: 5230, duration: 33.044s, episode steps: 40, steps per second: 1, episode reward: 39.215, mean reward: 0.980 [0.433, 0.999], mean action: 21.625 [5.000, 24.000], mean observation: -0.063 [-1.000, 1.000], loss: 0.259622, mean_absolute_error: 5.908640, mean_q: 6.622957
838 (array([21]),) False
 209240/500000: episode: 5231, duration: 32.985s, episode steps: 40, steps per second: 1, episode reward: 34.120, mean reward: 0.853 [0.491, 1.000], mean action: 16.775 [12.000, 51.000], mean observation: -0.121 [-1.000, 1.000], loss: 0.263561, mean_absolute_error: 5.908964, mean_q: 6.622647
559 (array([59]),) False
 209280/500000: episode: 5232, duration: 32.822s, episode steps: 40, steps per second: 1, episode reward: 27.690, mean reward: 0.692 [0.068, 1.000], mean action: 20.625 [4.000, 54.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.247244, mean_absolute_error: 5.814177, mean_q: 6.518809
529 (array([3]),) False
 209320/500000: episode: 5233, duration: 32.080s, episode steps: 40, steps per second: 1, episode reward: 35.846, mean reward: 0.896 [0.078, 1.000], mean action: 7.575 [3.000, 49.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.259822, mean_absolute_error: 5.896035, mean_q: 6.606843
133 (array([22]),) False
 209360/500000: episode: 5234, duration: 32.990s, episode steps: 40, steps per second: 1, episode reward: 36.793, mean reward: 0.920 [0.188, 1.000], mean action: 24.300 [4.000, 58.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.266512, mean_absolute_error: 5.863346, mean_q: 6.576926
713 (array([37]),) False
 209400/500000: episode: 5235, duration: 32.126s, episode steps: 40, steps per second: 1, episode reward: 35.351, mean reward: 0.884 [0.228, 1.000], mean action: 20.700 [1.000, 48.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.247123, mean_absolute_error: 5.902009, mean_q: 6.611539
55 (array([22]),) False
 209440/500000: episode: 5236, duration: 33.003s, episode steps: 40, steps per second: 1, episode reward: 10.494, mean reward: 0.262 [0.000, 0.836], mean action: 12.750 [2.000, 37.000], mean observation: -0.060 [-1.000, 1.000], loss: 0.293885, mean_absolute_error: 5.916555, mean_q: 6.624565
494 (array([48]),) False
 209480/500000: episode: 5237, duration: 32.104s, episode steps: 40, steps per second: 1, episode reward: 30.761, mean reward: 0.769 [0.155, 1.000], mean action: 14.500 [0.000, 48.000], mean observation: -0.097 [-1.000, 1.000], loss: 0.264152, mean_absolute_error: 5.927867, mean_q: 6.627912
308 (array([22]),) False
 209520/500000: episode: 5238, duration: 33.067s, episode steps: 40, steps per second: 1, episode reward: 33.977, mean reward: 0.849 [0.111, 1.000], mean action: 25.925 [15.000, 51.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.260693, mean_absolute_error: 6.007762, mean_q: 6.718274
700 (array([44]),) False
 209560/500000: episode: 5239, duration: 32.971s, episode steps: 40, steps per second: 1, episode reward: 30.364, mean reward: 0.759 [0.414, 1.000], mean action: 22.300 [1.000, 49.000], mean observation: -0.124 [-1.000, 1.000], loss: 0.260894, mean_absolute_error: 5.928474, mean_q: 6.646833
363 (array([36]),) False
 209600/500000: episode: 5240, duration: 33.002s, episode steps: 40, steps per second: 1, episode reward: 35.642, mean reward: 0.891 [0.089, 1.000], mean action: 23.350 [9.000, 48.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.278237, mean_absolute_error: 5.931088, mean_q: 6.644746
78 (array([55]),) False
 209640/500000: episode: 5241, duration: 33.015s, episode steps: 40, steps per second: 1, episode reward: 34.664, mean reward: 0.867 [0.464, 1.000], mean action: 22.575 [1.000, 52.000], mean observation: -0.092 [-1.000, 1.000], loss: 0.234646, mean_absolute_error: 5.916996, mean_q: 6.628192
112 (array([12]),) False
 209680/500000: episode: 5242, duration: 32.949s, episode steps: 40, steps per second: 1, episode reward: 37.203, mean reward: 0.930 [0.093, 1.000], mean action: 13.650 [7.000, 51.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.234247, mean_absolute_error: 5.866468, mean_q: 6.575890
84 (array([22]),) False
 209720/500000: episode: 5243, duration: 32.899s, episode steps: 40, steps per second: 1, episode reward: 37.504, mean reward: 0.938 [0.244, 1.000], mean action: 21.625 [2.000, 39.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.273665, mean_absolute_error: 5.956676, mean_q: 6.663565
229 (array([48]),) False
 209760/500000: episode: 5244, duration: 32.958s, episode steps: 40, steps per second: 1, episode reward: 31.041, mean reward: 0.776 [0.473, 0.874], mean action: 20.650 [12.000, 55.000], mean observation: -0.183 [-1.000, 1.000], loss: 0.270147, mean_absolute_error: 5.914718, mean_q: 6.623250
377 (array([22]),) False
 209800/500000: episode: 5245, duration: 32.041s, episode steps: 40, steps per second: 1, episode reward: 36.992, mean reward: 0.925 [0.110, 1.000], mean action: 22.775 [8.000, 47.000], mean observation: -0.043 [-1.000, 1.000], loss: 0.257303, mean_absolute_error: 5.860925, mean_q: 6.563976
340 (array([12]),) False
 209840/500000: episode: 5246, duration: 32.930s, episode steps: 40, steps per second: 1, episode reward: 33.311, mean reward: 0.833 [0.250, 1.000], mean action: 21.775 [11.000, 31.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.260975, mean_absolute_error: 5.890581, mean_q: 6.603065
301 (array([22]),) False
 209880/500000: episode: 5247, duration: 32.147s, episode steps: 40, steps per second: 1, episode reward: 34.749, mean reward: 0.869 [0.105, 1.000], mean action: 24.800 [11.000, 54.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.302767, mean_absolute_error: 5.949479, mean_q: 6.662585
813 (array([22]),) False
 209920/500000: episode: 5248, duration: 32.976s, episode steps: 40, steps per second: 1, episode reward: 37.627, mean reward: 0.941 [0.187, 1.000], mean action: 25.400 [12.000, 60.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.248054, mean_absolute_error: 5.982806, mean_q: 6.688584
327 (array([22]),) False
 209960/500000: episode: 5249, duration: 32.149s, episode steps: 40, steps per second: 1, episode reward: 33.907, mean reward: 0.848 [0.149, 1.000], mean action: 15.200 [1.000, 59.000], mean observation: -0.076 [-1.000, 1.000], loss: 0.270525, mean_absolute_error: 5.906051, mean_q: 6.618685
79 (array([22]),) False
 210000/500000: episode: 5250, duration: 32.981s, episode steps: 40, steps per second: 1, episode reward: 34.946, mean reward: 0.874 [0.014, 1.000], mean action: 22.750 [2.000, 55.000], mean observation: -0.091 [-1.000, 1.000], loss: 0.257126, mean_absolute_error: 5.902835, mean_q: 6.617022
257 (array([22]),) False
 210040/500000: episode: 5251, duration: 32.884s, episode steps: 40, steps per second: 1, episode reward: 38.116, mean reward: 0.953 [0.607, 1.000], mean action: 21.050 [5.000, 44.000], mean observation: -0.118 [-1.000, 1.000], loss: 0.244488, mean_absolute_error: 6.006265, mean_q: 6.724490
158 (array([22]),) False
 210080/500000: episode: 5252, duration: 32.974s, episode steps: 40, steps per second: 1, episode reward: 33.518, mean reward: 0.838 [0.098, 1.000], mean action: 15.625 [1.000, 44.000], mean observation: -0.168 [-1.000, 1.000], loss: 0.259936, mean_absolute_error: 5.929969, mean_q: 6.647623
343 (array([22]),) False
 210120/500000: episode: 5253, duration: 32.939s, episode steps: 40, steps per second: 1, episode reward: 38.260, mean reward: 0.957 [0.336, 1.000], mean action: 24.325 [22.000, 56.000], mean observation: -0.068 [-1.000, 1.000], loss: 0.280762, mean_absolute_error: 5.956155, mean_q: 6.676724
281 (array([48]),) False
 210160/500000: episode: 5254, duration: 33.020s, episode steps: 40, steps per second: 1, episode reward: 38.177, mean reward: 0.954 [0.286, 1.000], mean action: 22.400 [12.000, 40.000], mean observation: -0.134 [-1.000, 1.000], loss: 0.248667, mean_absolute_error: 5.957108, mean_q: 6.683245
712 (array([22]),) False
 210200/500000: episode: 5255, duration: 32.989s, episode steps: 40, steps per second: 1, episode reward: 37.630, mean reward: 0.941 [0.335, 1.000], mean action: 21.375 [12.000, 50.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.273756, mean_absolute_error: 5.991650, mean_q: 6.727273
304 (array([22]),) False
 210240/500000: episode: 5256, duration: 32.991s, episode steps: 40, steps per second: 1, episode reward: 34.573, mean reward: 0.864 [0.108, 1.000], mean action: 22.525 [9.000, 47.000], mean observation: -0.067 [-1.000, 1.000], loss: 0.259130, mean_absolute_error: 5.953842, mean_q: 6.690421
490 (array([12]),) False
 210280/500000: episode: 5257, duration: 32.117s, episode steps: 40, steps per second: 1, episode reward: 29.268, mean reward: 0.732 [0.310, 1.000], mean action: 21.250 [10.000, 49.000], mean observation: -0.094 [-1.000, 1.000], loss: 0.277274, mean_absolute_error: 5.990264, mean_q: 6.714111
184 (array([12]),) False
 210320/500000: episode: 5258, duration: 32.960s, episode steps: 40, steps per second: 1, episode reward: 33.093, mean reward: 0.827 [0.165, 1.000], mean action: 16.250 [11.000, 28.000], mean observation: -0.174 [-1.000, 1.000], loss: 0.284145, mean_absolute_error: 5.980338, mean_q: 6.699449
166 (array([22]),) False
 210360/500000: episode: 5259, duration: 32.079s, episode steps: 40, steps per second: 1, episode reward: 30.791, mean reward: 0.770 [0.198, 1.000], mean action: 15.175 [1.000, 43.000], mean observation: -0.180 [-1.000, 1.000], loss: 0.316718, mean_absolute_error: 5.949546, mean_q: 6.664104
259 (array([12]),) False
 210400/500000: episode: 5260, duration: 33.118s, episode steps: 40, steps per second: 1, episode reward: 31.144, mean reward: 0.779 [0.330, 1.000], mean action: 22.700 [12.000, 48.000], mean observation: -0.122 [-1.000, 1.000], loss: 0.254167, mean_absolute_error: 5.928490, mean_q: 6.645998
472 (array([22]),) False
 210440/500000: episode: 5261, duration: 32.103s, episode steps: 40, steps per second: 1, episode reward: 34.378, mean reward: 0.859 [0.000, 1.000], mean action: 24.300 [18.000, 52.000], mean observation: -0.075 [-1.000, 1.000], loss: 0.263940, mean_absolute_error: 5.998971, mean_q: 6.717359
318 (array([48]),) False
 210480/500000: episode: 5262, duration: 33.049s, episode steps: 40, steps per second: 1, episode reward: 38.255, mean reward: 0.956 [0.450, 1.000], mean action: 25.625 [12.000, 50.000], mean observation: -0.070 [-1.000, 1.000], loss: 0.252359, mean_absolute_error: 5.928254, mean_q: 6.646977
578 (array([22]),) False
 210520/500000: episode: 5263, duration: 32.911s, episode steps: 40, steps per second: 1, episode reward: 38.910, mean reward: 0.973 [0.886, 1.000], mean action: 27.600 [12.000, 48.000], mean observation: -0.133 [-1.000, 1.000], loss: 0.265055, mean_absolute_error: 5.964944, mean_q: 6.678780
668 (array([22]),) False
 210560/500000: episode: 5264, duration: 32.924s, episode steps: 40, steps per second: 1, episode reward: 32.515, mean reward: 0.813 [0.360, 1.000], mean action: 25.050 [22.000, 59.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.274824, mean_absolute_error: 5.898835, mean_q: 6.606983
516 (array([48]),) False
 210600/500000: episode: 5265, duration: 33.018s, episode steps: 40, steps per second: 1, episode reward: 36.558, mean reward: 0.914 [0.390, 1.000], mean action: 19.775 [8.000, 48.000], mean observation: -0.110 [-1.000, 1.000], loss: 0.255447, mean_absolute_error: 5.925576, mean_q: 6.640533
692 (array([22]),) False
 210640/500000: episode: 5266, duration: 32.901s, episode steps: 40, steps per second: 1, episode reward: 36.009, mean reward: 0.900 [0.168, 1.000], mean action: 23.225 [10.000, 54.000], mean observation: -0.119 [-1.000, 1.000], loss: 0.243247, mean_absolute_error: 5.954554, mean_q: 6.663098
808 (array([22]),) False
 210680/500000: episode: 5267, duration: 33.007s, episode steps: 40, steps per second: 1, episode reward: 32.984, mean reward: 0.825 [0.048, 1.000], mean action: 29.350 [5.000, 56.000], mean observation: -0.136 [-1.000, 1.000], loss: 0.278892, mean_absolute_error: 5.958247, mean_q: 6.669833
57 (array([37]),) False
 210720/500000: episode: 5268, duration: 32.872s, episode steps: 40, steps per second: 1, episode reward: 30.458, mean reward: 0.761 [0.135, 0.963], mean action: 22.550 [2.000, 49.000], mean observation: -0.078 [-1.000, 1.000], loss: 0.289753, mean_absolute_error: 5.964849, mean_q: 6.672917
667 (array([48]),) False
 210760/500000: episode: 5269, duration: 32.068s, episode steps: 40, steps per second: 1, episode reward: 35.824, mean reward: 0.896 [0.045, 1.000], mean action: 29.800 [0.000, 52.000], mean observation: -0.079 [-1.000, 1.000], loss: 0.314610, mean_absolute_error: 5.906146, mean_q: 6.609508
796 (array([38]),) False
 210800/500000: episode: 5270, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 37.582, mean reward: 0.940 [0.326, 1.000], mean action: 16.150 [12.000, 49.000], mean observation: -0.143 [-1.000, 1.000], loss: 0.241655, mean_absolute_error: 5.935814, mean_q: 6.651592
805 (array([22]),) False
 210840/500000: episode: 5271, duration: 32.077s, episode steps: 40, steps per second: 1, episode reward: 37.142, mean reward: 0.929 [0.252, 1.000], mean action: 24.550 [5.000, 56.000], mean observation: -0.137 [-1.000, 1.000], loss: 0.247816, mean_absolute_error: 5.839269, mean_q: 6.549873
833 (array([22]),) False
 210880/500000: episode: 5272, duration: 33.086s, episode steps: 40, steps per second: 1, episode reward: 36.277, mean reward: 0.907 [0.183, 1.000], mean action: 17.300 [4.000, 48.000], mean observation: -0.114 [-1.000, 1.000], loss: 0.263719, mean_absolute_error: 5.961137, mean_q: 6.670462
90 (array([22]),) False
 210920/500000: episode: 5273, duration: 32.122s, episode steps: 40, steps per second: 1, episode reward: 36.759, mean reward: 0.919 [0.406, 1.000], mean action: 21.700 [0.000, 56.000], mean observation: -0.096 [-1.000, 1.000], loss: 0.265772, mean_absolute_error: 6.005337, mean_q: 6.707037
239 (array([22]),) False
 210960/500000: episode: 5274, duration: 33.027s, episode steps: 40, steps per second: 1, episode reward: 35.875, mean reward: 0.897 [0.325, 1.000], mean action: 24.775 [12.000, 55.000], mean observation: -0.135 [-1.000, 1.000], loss: 0.263463, mean_absolute_error: 6.152074, mean_q: 6.856614
658 (array([48]),) False
 211000/500000: episode: 5275, duration: 32.936s, episode steps: 40, steps per second: 1, episode reward: 34.704, mean reward: 0.868 [0.300, 1.000], mean action: 25.325 [0.000, 49.000], mean observation: -0.071 [-1.000, 1.000], loss: 0.252044, mean_absolute_error: 6.024016, mean_q: 6.727267
172 (array([12]),) False
 211040/500000: episode: 5276, duration: 31.905s, episode steps: 40, steps per second: 1, episode reward: 34.166, mean reward: 0.854 [0.329, 1.000], mean action: 16.375 [9.000, 48.000], mean observation: -0.179 [-1.000, 1.000], loss: 0.236200, mean_absolute_error: 6.092295, mean_q: 6.808470
800 (array([22]),) False
 211080/500000: episode: 5277, duration: 31.258s, episode steps: 40, steps per second: 1, episode reward: 32.348, mean reward: 0.809 [0.461, 0.848], mean action: 13.425 [12.000, 36.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.261583, mean_absolute_error: 6.064548, mean_q: 6.781654
708 (array([40]),) False
 211120/500000: episode: 5278, duration: 31.453s, episode steps: 40, steps per second: 1, episode reward: 33.349, mean reward: 0.834 [0.273, 1.000], mean action: 19.525 [6.000, 49.000], mean observation: -0.141 [-1.000, 1.000], loss: 0.302784, mean_absolute_error: 6.066763, mean_q: 6.781270
354 (array([12]),) False
 211160/500000: episode: 5279, duration: 31.731s, episode steps: 40, steps per second: 1, episode reward: 26.827, mean reward: 0.671 [0.531, 1.000], mean action: 21.975 [0.000, 49.000], mean observation: -0.064 [-1.000, 1.000], loss: 0.263407, mean_absolute_error: 6.037655, mean_q: 6.752678
765 (array([48]),) False
 211200/500000: episode: 5280, duration: 31.575s, episode steps: 40, steps per second: 1, episode reward: 31.598, mean reward: 0.790 [0.086, 1.000], mean action: 29.675 [1.000, 50.000], mean observation: -0.128 [-1.000, 1.000], loss: 0.266628, mean_absolute_error: 5.996700, mean_q: 6.705708
680 (array([22]),) False
 211240/500000: episode: 5281, duration: 31.274s, episode steps: 40, steps per second: 1, episode reward: 34.954, mean reward: 0.874 [0.113, 1.000], mean action: 23.700 [1.000, 51.000], mean observation: -0.105 [-1.000, 1.000], loss: 0.304060, mean_absolute_error: 5.951041, mean_q: 6.657463
238 (array([22]),) False
 211280/500000: episode: 5282, duration: 31.449s, episode steps: 40, steps per second: 1, episode reward: 34.123, mean reward: 0.853 [0.216, 1.000], mean action: 29.275 [6.000, 55.000], mean observation: -0.140 [-1.000, 1.000], loss: 0.282142, mean_absolute_error: 6.063895, mean_q: 6.783084
